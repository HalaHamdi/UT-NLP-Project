{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd45822",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "&emsp;[<a id=\"#vocab\" /> <font color='yellow' size=5> Vocab </font>](#%3Ca-id%3D%22%23vocab%22-/%3E-%3Cfont-color%3D%27yellow%27%3E-Vocab-%3C/font%3E)<br>\n",
    "&emsp;&emsp;[1. Comparison](#1.-Comparison)<br>\n",
    "&emsp;&emsp;[2. Intensifier](#2.-Intensifier)<br><br>\n",
    "&emsp;[<a id=\"Taxonomy\" /> <font color='yellow' size=5> Taxonomy </font>](#%3Ca-id%3D%22Taxonomy%22-/%3E-%3Cfont-color%3D%27yellow%27%3E-Taxonomy-%3C/font%3E)<br>\n",
    "&emsp;&emsp;[1. Size, Shape, Color, Age, Material](#1.-Size%2C-Shape%2C-Color%2C-Age%2C-Material)<br>\n",
    "&emsp;&emsp;[2. Professions vs nationalities](#2.-Professions-vs-nationalities)<br>\n",
    "&emsp;&emsp;[3. Animal vs Vehicles - Example1](#3.-Animal-vs-Vehicles---Example1)<br>\n",
    "&emsp;&emsp;[4. Animal vs Vehicles - Example2](#4.-Animal-vs-Vehicles---Example2)<br>\n",
    "&emsp;&emsp;[5. Synonyms](#5.-Synonyms)<br>\n",
    "&emsp;&emsp;[6. Antonyms](#6.-Antonyms)<br>\n",
    "&emsp;&emsp;[7. Antonyms Comparison](#7.-Antonyms-Comparison)<br><br>\n",
    "&emsp;[<a id=\"Temporal\" /> <font color='yellow' size=5> Temporal </font>](#%3Ca-id%3D%22Temporal%22-/%3E-%3Cfont-color%3D%27yellow%27%3E-Temporal-%3C/font%3E)<br>\n",
    "&emsp;&emsp;[1. Change in profession](#1.-Change-in-profession)<br>\n",
    "&emsp;&emsp;[2. Understand time difference](#2.-Understand-time-difference)<br><br>\n",
    "&emsp;[<a id=\"Negation\" /> <font color='yellow' size=5> Negation </font>](#%3Ca-id%3D%22Negation%22-/%3E-%3Cfont-color%3D%27yellow%27%3E-Negation-%3C/font%3E)<br>\n",
    "&emsp;&emsp;[1. Negation in Context](#1.-Negation-in-Context)<br>\n",
    "&emsp;&emsp;[3. Negation in Question](#3.-Negation-in-Question)<br><br>\n",
    "&emsp;[<a id=\"Coref\" /> <font color='yellow' size=5> Coref </font>](#%3Ca-id%3D%22Coref%22-/%3E-%3Cfont-color%3D%27yellow%27%3E-Coref-%3C/font%3E)<br>\n",
    "&emsp;&emsp;[1. He/she coref](#1.-He/she-coref)<br>\n",
    "&emsp;&emsp;[2. His/Her coref](#2.-His/Her-coref)<br>\n",
    "&emsp;&emsp;[3. Former and Latter](#3.-Former-and-Latter)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9554af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import checklist.editor\n",
    "import munch\n",
    "import itertools\n",
    "from checklist.test_suite import TestSuite\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.expect import Expect\n",
    "from checklist.perturb import Perturb\n",
    "from helper import get_finetuned_electra_predictor, format_squad_with_context,show_example, crossproduct, export_suite_to_jsonl, get_summary,display_and_export_mdtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f46dfd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = TestSuite()\n",
    "editor = checklist.editor.Editor()\n",
    "model_predictor = get_finetuned_electra_predictor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3553fb3a",
   "metadata": {},
   "source": [
    "## <a id=\"#vocab\" /> <font color='yellow'> Vocab </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b2c19",
   "metadata": {},
   "source": [
    "### 1. Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "468d31f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = ['old', 'smart', 'tall', 'young', 'strong', 'short', 'tough', 'cool', 'fast', 'nice', 'small', 'dark', 'wise', 'rich', 'great', 'weak', 'high', 'slow', 'strange', 'clean']\n",
    "adj = [(x.rstrip('e'), x) for x in adj]\n",
    "\n",
    "\n",
    "t_comparison = editor.template(\n",
    "    [(\n",
    "    '{first_name} is {adj[0]}er than {first_name1}.',\n",
    "    'Who is less {adj[1]}?'\n",
    "    ),(\n",
    "    '{first_name} is {adj[0]}er than {first_name1}.',\n",
    "    'Who is {adj[0]}er?'\n",
    "    ),\n",
    "    ],\n",
    "    labels = ['{first_name1}','{first_name}'],\n",
    "    adj=adj,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52cd8aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Ed is greater than George.', 'Who is less great?') , pred: Ed , label: George\n",
      "  [2] ('Ed is greater than George.', 'Who is greater?') , pred: Ed , label: Ed\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_comparison, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae1c32b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1000 examples\n",
      "Test cases:      500\n",
      "Fails (rate):    500 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Daniel is cooler than Claire.\n",
      "Q: Who is less cool?\n",
      "A: Claire\n",
      "P: Daniel\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Comparisons'\n",
    "description = 'A is COMP than B. Who is more / less COMP?'\n",
    "test = MFT(**t_comparison, name=name, description=description, capability='Vocabulary')\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830cf1d4",
   "metadata": {},
   "source": [
    "### 2. Intensifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0a13a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp-proj/lib/python3.10/site-packages/checklist/text_generation.py:171: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:256.)\n",
      "  to_pred = torch.tensor(to_pred, device=self.device).to(torch.int64)\n"
     ]
    }
   ],
   "source": [
    "state = editor.suggest('John is very {mask} about the project.')[:20]\n",
    "very = ['very', 'extremely', 'really', 'quite', 'incredibly', 'particularly', 'highly', 'super']\n",
    "somewhat = ['a little', 'somewhat', 'slightly', 'mildly']\n",
    "\n",
    "t_intensifier = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {very} {s} about the project. {first_name1} is {s} about the project.',\n",
    "            '{first_name1} is {s} about the project. {first_name} is {very} {s} about the project.',\n",
    "            '{first_name} is {s} about the project. {first_name1} is {somewhat} {s} about the project.',\n",
    "            '{first_name1} is {somewhat} {s} about the project. {first_name} is {s} about the project.',\n",
    "            '{first_name} is {very} {s} about the project. {first_name1} is {somewhat} {s} about the project.',\n",
    "            '{first_name1} is {somewhat} {s} about the project. {first_name} is {very} {s} about the project.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is most {s} about the project?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is least {s} about the project?',\n",
    "                '{first_name1}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    s = state,\n",
    "    very=very,\n",
    "    somewhat=somewhat,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26fe5333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Kate is really confident about the project. Virginia is confident about the project.', 'Who is most confident about the project?') , pred: Virginia , label: Kate\n",
      "  [2] ('Kate is really confident about the project. Virginia is confident about the project.', 'Who is least confident about the project?') , pred: Virginia , label: Virginia\n",
      "  [3] ('Virginia is confident about the project. Kate is really confident about the project.', 'Who is most confident about the project?') , pred: Kate , label: Kate\n",
      "  [4] ('Virginia is confident about the project. Kate is really confident about the project.', 'Who is least confident about the project?') , pred: Kate , label: Virginia\n",
      "  [5] ('Kate is confident about the project. Virginia is slightly confident about the project.', 'Who is most confident about the project?') , pred: Kate , label: Kate\n",
      "  [6] ('Kate is confident about the project. Virginia is slightly confident about the project.', 'Who is least confident about the project?') , pred: Virginia , label: Virginia\n",
      "  [7] ('Virginia is slightly confident about the project. Kate is confident about the project.', 'Who is most confident about the project?') , pred: Kate , label: Kate\n",
      "  [8] ('Virginia is slightly confident about the project. Kate is confident about the project.', 'Who is least confident about the project?') , pred: Kate , label: Virginia\n",
      "  [9] ('Kate is really confident about the project. Virginia is slightly confident about the project.', 'Who is most confident about the project?') , pred: Virginia , label: Kate\n",
      "  [10] ('Kate is really confident about the project. Virginia is slightly confident about the project.', 'Who is least confident about the project?') , pred: Virginia , label: Virginia\n",
      "  [11] ('Virginia is slightly confident about the project. Kate is really confident about the project.', 'Who is most confident about the project?') , pred: Kate , label: Kate\n",
      "  [12] ('Virginia is slightly confident about the project. Kate is really confident about the project.', 'Who is least confident about the project?') , pred: Kate , label: Virginia\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_intensifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "923bf7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 5964 examples\n",
      "Test cases:      497\n",
      "Fails (rate):    497 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Ruth is incredibly pessimistic about the project. Donna is pessimistic about the project.\n",
      "Q: Who is most pessimistic about the project?\n",
      "A: Ruth\n",
      "P: empty\n",
      "\n",
      "C: Donna is pessimistic about the project. Ruth is incredibly pessimistic about the project.\n",
      "Q: Who is most pessimistic about the project?\n",
      "A: Ruth\n",
      "P: empty\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Intensifiers'\n",
    "desc = '(very, super, extremely) and reducers (somewhat, kinda, etc)?'\n",
    "test = MFT(**t_intensifier, name=name, description=desc, capability='Vocabulary')\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context, n_per_testcase=2)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c73d21",
   "metadata": {},
   "source": [
    "## <a id=\"Taxonomy\" /> <font color='yellow'> Taxonomy </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11420c60",
   "metadata": {},
   "source": [
    "### 1. Size, Shape, Color, Age, Material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74fb9081",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['size', 'shape', 'age', 'color']\n",
    "props = []\n",
    "properties = {\n",
    "    'color' : ['red', 'blue','yellow', 'green', 'pink', 'white', 'black', 'orange', 'grey', 'purple', 'brown'],\n",
    "    'size' : ['big', 'small', 'tiny', 'enormous'],\n",
    "    'age' : ['old', 'new'],\n",
    "    'shape' : ['round', 'oval', 'square', 'triangular'],\n",
    "    'material' : ['iron', 'wooden', 'ceramic', 'glass', 'stone']\n",
    "}\n",
    "objects = ['box', 'clock', 'table', 'object', 'toy', 'painting', 'sculpture', 'thing', 'figure']\n",
    "\n",
    "for i in range(len(order)):\n",
    "    for j in range(i + 1, len(order)):\n",
    "        p1, p2 = order[i], order[j]\n",
    "        for v1, v2 in itertools.product(properties[p1], properties[p2]):\n",
    "            props.append(munch.Munch({\n",
    "                'p1': p1,\n",
    "                'p2': p2,\n",
    "                'v1': v1,\n",
    "                'v2': v2,\n",
    "            }))\n",
    "            \n",
    "t_properties = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            'There is {a:p.v1} {p.v2} {obj} in the room.',\n",
    "            'There is {a:obj} in the room. The {obj} is {p.v1} and {p.v2}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What {p.p1} is the {obj}?',\n",
    "                '{p.v1}'\n",
    "            ), \n",
    "            (\n",
    "                'What {p.p2} is the {obj}?',\n",
    "                '{p.v2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "    },\n",
    "    obj=objects,\n",
    "    p=props,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcf6a4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('There is a round black thing in the room.', 'What shape is the thing?') , pred: round black , label: round\n",
      "  [2] ('There is a round black thing in the room.', 'What color is the thing?') , pred: round black , label: black\n",
      "  [3] ('There is a thing in the room. The thing is round and black.', 'What shape is the thing?') , pred: round and black , label: round\n",
      "  [4] ('There is a thing in the room. The thing is round and black.', 'What color is the thing?') , pred: black , label: black\n",
      "---\n",
      "  [1] ('There is a tiny black clock in the room.', 'What size is the clock?') , pred: tiny black , label: tiny\n",
      "  [2] ('There is a tiny black clock in the room.', 'What color is the clock?') , pred: black , label: black\n",
      "  [3] ('There is a clock in the room. The clock is tiny and black.', 'What size is the clock?') , pred: tiny and black , label: tiny\n",
      "  [4] ('There is a clock in the room. The clock is tiny and black.', 'What color is the clock?') , pred: black , label: black\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_properties, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6d2ef6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 2000 examples\n",
      "Test cases:      500\n",
      "Fails (rate):    500 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: There is a small oval box in the room.\n",
      "Q: What size is the box?\n",
      "A: small\n",
      "P: oval\n",
      "\n",
      "C: There is a box in the room. The box is small and oval.\n",
      "Q: What size is the box?\n",
      "A: small\n",
      "P: small and oval\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Properites'\n",
    "desc = 'size, shape, age, color'\n",
    "test = MFT(**t_properties, name=name, description=desc, capability='Taxonomy')\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884728ed",
   "metadata": {},
   "source": [
    "### 2. Professions vs nationalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d590180",
   "metadata": {},
   "outputs": [],
   "source": [
    "professions = editor.suggest('{first_name} works as {a:mask}.')[:30]\n",
    "professions += editor.suggest('{first_name} {last_name} works as {a:mask}.')[:30]\n",
    "professions = list(set(professions))\n",
    "if 'translator' in professions:\n",
    "    professions.remove('translator')\n",
    "\n",
    "\n",
    "def clean(string):\n",
    "    return string.lstrip('[a,the,an,in,at] ').rstrip('.')\n",
    "def expect_squad(x, pred, conf, label=None, meta=None):\n",
    "    return clean(pred) == clean(label)\n",
    "expect_squad = Expect.single(expect_squad)\n",
    "\n",
    "\n",
    "t_profession_nationtionality = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {a:nat} {prof}.',\n",
    "            '{first_name} is {a:prof}. {first_name} is {nat}.',\n",
    "            '{first_name} is {nat}. {first_name} is {a:prof}.',\n",
    "            '{first_name} is {nat} and {a:prof}.',\n",
    "            '{first_name} is {a:prof} and {nat}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What is {first_name}\\'s job?',\n",
    "                '{prof}'\n",
    "            ), \n",
    "            (\n",
    "                'What is {first_name}\\'s nationality?',\n",
    "                '{nat}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    nat = editor.lexicons['nationality'][:10],\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af7acebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Nick is a Russian assistant.', \"What is Nick's job?\") , pred: Russian assistant , label: assistant\n",
      "  [2] ('Nick is a Russian assistant.', \"What is Nick's nationality?\") , pred: Russian , label: Russian\n",
      "  [3] ('Nick is an assistant. Nick is Russian.', \"What is Nick's job?\") , pred: assistant , label: assistant\n",
      "  [4] ('Nick is an assistant. Nick is Russian.', \"What is Nick's nationality?\") , pred: Russian , label: Russian\n",
      "  [5] ('Nick is Russian. Nick is an assistant.', \"What is Nick's job?\") , pred: assistant , label: assistant\n",
      "  [6] ('Nick is Russian. Nick is an assistant.', \"What is Nick's nationality?\") , pred: Russian , label: Russian\n",
      "  [7] ('Nick is Russian and an assistant.', \"What is Nick's job?\") , pred: assistant , label: assistant\n",
      "  [8] ('Nick is Russian and an assistant.', \"What is Nick's nationality?\") , pred: Russian , label: Russian\n",
      "  [9] ('Nick is an assistant and Russian.', \"What is Nick's job?\") , pred: assistant and Russian , label: assistant\n",
      "  [10] ('Nick is an assistant and Russian.', \"What is Nick's nationality?\") , pred: Russian , label: Russian\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_profession_nationtionality, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aac9ad40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 5000 examples\n",
      "Test cases:      500\n",
      "Fails (rate):    274 (54.8%)\n",
      "\n",
      "Example fails:\n",
      "C: Sara is a Chinese investor.\n",
      "Q: What is Sara's job?\n",
      "A: investor\n",
      "P: Chinese investor\n",
      "\n",
      "C: Sara is an investor and Chinese.\n",
      "Q: What is Sara's job?\n",
      "A: investor\n",
      "P: investor and Chinese\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Profession vs nationality'\n",
    "test = MFT(**t_profession_nationtionality, name=name, expect=expect_squad, description='',  capability='Taxonomy')\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4c4b23",
   "metadata": {},
   "source": [
    "### 3. Animal vs Vehicles - Example1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ddfb790",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['dog', 'cat', 'bull', 'cow', 'fish', 'serpent', 'snake', 'lizard', 'hamster', 'rabbit', 'guinea pig', 'iguana', 'duck']\n",
    "vehicles = ['car', 'truck', 'train', 'motorcycle', 'bike', 'firetruck', 'tractor', 'van', 'SUV', 'minivan']\n",
    "t_animal_vehicles = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} has {a:animal} and {a:vehicle}.',\n",
    "            '{first_name} has {a:vehicle} and {a:animal}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What animal does {first_name} have?',\n",
    "                '{animal}'\n",
    "            ), \n",
    "            (\n",
    "                'What vehicle does {first_name} have?',\n",
    "                '{vehicle}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    animal=animals,\n",
    "    vehicle=vehicles,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "676021eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Ray has a lizard and a train.', 'What animal does Ray have?') , pred: lizard , label: lizard\n",
      "  [2] ('Ray has a lizard and a train.', 'What vehicle does Ray have?') , pred: a lizard and a train , label: train\n",
      "  [3] ('Ray has a train and a lizard.', 'What animal does Ray have?') , pred: lizard , label: lizard\n",
      "  [4] ('Ray has a train and a lizard.', 'What vehicle does Ray have?') , pred: a train , label: train\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_animal_vehicles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab9156a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 2000 examples\n",
      "Test cases:      500\n",
      "Fails (rate):    493 (98.6%)\n",
      "\n",
      "Example fails:\n",
      "C: Philip has an iguana and a bike.\n",
      "Q: What vehicle does Philip have?\n",
      "A: bike\n",
      "P: iguana and a bike\n",
      "\n",
      "C: Philip has a bike and an iguana.\n",
      "Q: What animal does Philip have?\n",
      "A: iguana\n",
      "P: a bike and an iguana\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Animal vs Vehicle'\n",
    "test = MFT(**t_animal_vehicles, name=name, description='', capability='Taxonomy', expect=expect_squad)\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a4d734",
   "metadata": {},
   "source": [
    "### 4. Animal vs Vehicles - Example2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3640824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['dog', 'cat', 'bull', 'cow', 'fish', 'serpent', 'snake', 'lizard', 'hamster', 'rabbit', 'guinea pig', 'iguana', 'duck']\n",
    "vehicles = ['car', 'truck', 'train', 'motorcycle', 'bike', 'firetruck', 'tractor', 'van', 'SUV', 'minivan']\n",
    "t_animals_vehicles_2 = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} bought {a:animal}. {first_name2} bought {a:vehicle}.',\n",
    "            '{first_name2} bought {a:vehicle}. {first_name} bought {a:animal}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who bought an animal?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who bought a vehicle?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    animal=animals,\n",
    "    vehicle=vehicles,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aecad4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('James bought a snake. Pamela bought a bike.', 'Who bought an animal?') , pred: James , label: James\n",
      "  [2] ('James bought a snake. Pamela bought a bike.', 'Who bought a vehicle?') , pred: Pamela , label: Pamela\n",
      "  [3] ('Pamela bought a bike. James bought a snake.', 'Who bought an animal?') , pred: James , label: James\n",
      "  [4] ('Pamela bought a bike. James bought a snake.', 'Who bought a vehicle?') , pred: Pamela , label: Pamela\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_animals_vehicles_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "88855a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1992 examples\n",
      "Test cases:      498\n",
      "Fails (rate):    242 (48.6%)\n",
      "\n",
      "Example fails:\n",
      "C: Florence bought a firetruck. Alex bought a bull.\n",
      "Q: Who bought a vehicle?\n",
      "A: Florence\n",
      "P: Alex\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "name = 'Animal vs Vehicle v2'\n",
    "test = MFT(**t_animals_vehicles_2, name=name, description='', capability='Taxonomy', expect=expect_squad)\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a62d52",
   "metadata": {},
   "source": [
    "### 5. Synonyms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "036b0cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms = [ ('spiritual', 'religious'), ('angry', 'furious'), ('organized', 'organised'),\n",
    "            ('vocal', 'outspoken'), ('grateful', 'thankful'), ('intelligent', 'smart'),\n",
    "            ('humble', 'modest'), ('courageous', 'brave'), ('happy', 'joyful'), ('scared', 'frightened'),\n",
    "           ]\n",
    "\n",
    "t_synonym = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is very {s1[0]}. {first_name2} is very {s2[0]}.',\n",
    "            '{first_name2} is very {s2[0]}. {first_name} is very {s1[0]}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {s1[1]}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {s2[1]}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    s=synonyms,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=250,\n",
    "    save=True\n",
    "   ))\n",
    "t_synonym += crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is very {s1[1]}. {first_name2} is very {s2[1]}.',\n",
    "            '{first_name2} is very {s2[1]}. {first_name} is very {s1[1]}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {s1[0]}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {s2[0]}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    s=synonyms,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=250,\n",
    "    save=True\n",
    "    )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3b8b03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Tony is very courageous. Philip is very scared.', 'Who is brave?') , pred: Tony , label: Tony\n",
      "  [2] ('Tony is very courageous. Philip is very scared.', 'Who is frightened?') , pred: Philip , label: Philip\n",
      "  [3] ('Philip is very scared. Tony is very courageous.', 'Who is brave?') , pred: Tony , label: Tony\n",
      "  [4] ('Philip is very scared. Tony is very courageous.', 'Who is frightened?') , pred: Philip , label: Philip\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_synonym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23609083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1796 examples\n",
      "Test cases:      449\n",
      "Fails (rate):    28 (6.2%)\n",
      "\n",
      "Example fails:\n",
      "C: Anna is very vocal. Frances is very courageous.\n",
      "Q: Who is outspoken?\n",
      "A: Anna\n",
      "P: Frances\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Synonyms'\n",
    "test = MFT(**t_synonym, name=name, description='', capability='Taxonomy', expect=expect_squad)\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeb30bc",
   "metadata": {},
   "source": [
    "### 6. Antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24f3c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_pairs = [('better', 'worse'), ('older', 'younger'), ('smarter', 'dumber'), ('taller', 'shorter'), ('bigger', 'smaller'), ('stronger', 'weaker'), ('faster', 'slower'), ('darker', 'lighter'), ('richer', 'poorer'), ('happier', 'sadder'), ('louder', 'quieter'), ('warmer', 'colder')]\n",
    "comp_pairs = list(set(comp_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ff915519",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_antonymns = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {comp[0]} than {first_name1}.',\n",
    "            '{first_name1} is {comp[1]} than {first_name}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {comp[1]}?',\n",
    "                '{first_name1}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is {comp[0]}?',\n",
    "                '{first_name}',\n",
    "            )\n",
    "            \n",
    "        ]\n",
    "        ,\n",
    "    },\n",
    "    comp=comp_pairs,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c8cb5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Rose is taller than Amanda.', 'Who is shorter?') , pred: empty , label: Amanda\n",
      "  [2] ('Rose is taller than Amanda.', 'Who is taller?') , pred: Rose , label: Rose\n",
      "  [3] ('Amanda is shorter than Rose.', 'Who is shorter?') , pred: Amanda , label: Amanda\n",
      "  [4] ('Amanda is shorter than Rose.', 'Who is taller?') , pred: Amanda , label: Rose\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_antonymns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2fa1fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1992 examples\n",
      "Test cases:      498\n",
      "Fails (rate):    498 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Pamela is older than Roy.\n",
      "Q: Who is younger?\n",
      "A: Roy\n",
      "P: Pamela\n",
      "\n",
      "C: Roy is younger than Pamela.\n",
      "Q: Who is older?\n",
      "A: Pamela\n",
      "P: Roy\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Antonyms'\n",
    "test = MFT(**t_antonymns, name=name, description='A is COMP than B. Who is antonym(COMP)? B', capability='Taxonomy')\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d7e79f",
   "metadata": {},
   "source": [
    "### 7. Antonyms Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3a0ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "antonym_adjs = [('progressive', 'conservative'),('religious', 'secular'),('positive', 'negative'),('defensive', 'offensive'),('rude',  'polite'),('optimistic', 'pessimistic'),('stupid', 'smart'),('negative', 'positive'),('unhappy', 'happy'),('active', 'passive'),('impatient', 'patient'),('powerless', 'powerful'),('visible', 'invisible'),('fat', 'thin'),('bad', 'good'),('cautious', 'brave'), ('hopeful', 'hopeless'),('insecure', 'secure'),('humble', 'proud'),('passive', 'active'),('dependent', 'independent'),('pessimistic', 'optimistic'),('irresponsible', 'responsible'),('courageous', 'fearful')]\n",
    "\n",
    "t_antonymns_compare = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is more {a[0]} than {first_name1}.',\n",
    "            '{first_name1} is more {a[1]} than {first_name}.',\n",
    "            '{first_name} is less {a[1]} than {first_name1}.',\n",
    "            '{first_name1} is less {a[0]} than {first_name}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is more {a[0]}?',\n",
    "                '{first_name}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is less {a[0]}?',\n",
    "                '{first_name1}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is more {a[1]}?',\n",
    "                '{first_name1}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is less {a[1]}?',\n",
    "                '{first_name}',\n",
    "            ),\n",
    "        ]\n",
    "        ,\n",
    "    },\n",
    "    a = antonym_adjs,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "464ff0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Mary is more insecure than Kate.', 'Who is more insecure?') , pred: Mary , label: Mary\n",
      "  [2] ('Mary is more insecure than Kate.', 'Who is less insecure?') , pred: Mary , label: Kate\n",
      "  [3] ('Mary is more insecure than Kate.', 'Who is more secure?') , pred: Mary , label: Kate\n",
      "  [4] ('Mary is more insecure than Kate.', 'Who is less secure?') , pred: Mary , label: Mary\n",
      "  [5] ('Kate is more secure than Mary.', 'Who is more insecure?') , pred: Kate , label: Mary\n",
      "  [6] ('Kate is more secure than Mary.', 'Who is less insecure?') , pred: Kate , label: Kate\n",
      "  [7] ('Kate is more secure than Mary.', 'Who is more secure?') , pred: Kate , label: Kate\n",
      "  [8] ('Kate is more secure than Mary.', 'Who is less secure?') , pred: Kate , label: Mary\n",
      "  [9] ('Mary is less secure than Kate.', 'Who is more insecure?') , pred: Mary , label: Mary\n",
      "  [10] ('Mary is less secure than Kate.', 'Who is less insecure?') , pred: Mary , label: Kate\n",
      "  [11] ('Mary is less secure than Kate.', 'Who is more secure?') , pred: Mary , label: Kate\n",
      "  [12] ('Mary is less secure than Kate.', 'Who is less secure?') , pred: Mary , label: Mary\n",
      "  [13] ('Kate is less insecure than Mary.', 'Who is more insecure?') , pred: Kate , label: Mary\n",
      "  [14] ('Kate is less insecure than Mary.', 'Who is less insecure?') , pred: Kate , label: Kate\n",
      "  [15] ('Kate is less insecure than Mary.', 'Who is more secure?') , pred: Kate , label: Kate\n",
      "  [16] ('Kate is less insecure than Mary.', 'Who is less secure?') , pred: Kate , label: Mary\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_antonymns_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "196f8249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 7952 examples\n",
      "Test cases:      497\n",
      "Fails (rate):    497 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Roy is more religious than Diana.\n",
      "Q: Who is less religious?\n",
      "A: Diana\n",
      "P: Roy\n",
      "\n",
      "C: Roy is more religious than Diana.\n",
      "Q: Who is more secular?\n",
      "A: Diana\n",
      "P: Roy\n",
      "\n",
      "C: Diana is more secular than Roy.\n",
      "Q: Who is more religious?\n",
      "A: Roy\n",
      "P: Diana\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "description = 'A is more X than B. Who is more antonym(X)? B. Who is less X? B. Who is more X? A. Who is less antonym(X)? A.'\n",
    "name= 'Antonyms Comparison'\n",
    "test = MFT(**t_antonymns_compare, name=name, description=description, capability='Taxonomy')\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d3a4e1",
   "metadata": {},
   "source": [
    "## <a id=\"Temporal\" /> <font color='yellow'> Temporal </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3286ed2b",
   "metadata": {},
   "source": [
    "### 1. Change in profession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3eb86698",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_profession = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            'Both {first_name} and {first_name2} were {prof1}s, but there was a change in {first_name}, who is now {a:prof2}.',\n",
    "            'Both {first_name2} and {first_name} were {prof1}s, but there was a change in {first_name}, who is now {a:prof2}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a134f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Both Nick and Betty were editors, but there was a change in Nick, who is now an accountant.', 'Who is an accountant?') , pred: Nick , label: Nick\n",
      "  [2] ('Both Betty and Nick were editors, but there was a change in Nick, who is now an accountant.', 'Who is an accountant?') , pred: Nick , label: Nick\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_profession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "de629049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 948 examples\n",
      "Test cases:      474\n",
      "Fails (rate):    8 (1.7%)\n",
      "\n",
      "Example fails:\n",
      "C: Both Carol and James were analysts, but there was a change in James, who is now an author.\n",
      "Q: Who is an author?\n",
      "A: James\n",
      "P: empty\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'There was a change in profession'\n",
    "test = MFT(**t_profession, expect=expect_squad, capability='Temporal', name=name, description='' )\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7300c871",
   "metadata": {},
   "source": [
    "### 2. Understand time difference\n",
    "e.g before, after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "515cfdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_time_difference = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} became a {prof} before {first_name2} did.',\n",
    "            '{first_name2} became a {prof} after {first_name} did.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who became a {prof} first?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who became a {prof} last?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "96eed107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Betty became a producer before Tim did.', 'Who became a producer first?') , pred: Betty , label: Betty\n",
      "  [2] ('Betty became a producer before Tim did.', 'Who became a producer last?') , pred: Betty , label: Tim\n",
      "  [3] ('Tim became a producer after Betty did.', 'Who became a producer first?') , pred: Tim , label: Betty\n",
      "  [4] ('Tim became a producer after Betty did.', 'Who became a producer last?') , pred: Tim , label: Tim\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_time_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ba2f2ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1992 examples\n",
      "Test cases:      498\n",
      "Fails (rate):    498 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Joseph became a assistant before Bruce did.\n",
      "Q: Who became a assistant last?\n",
      "A: Bruce\n",
      "P: Joseph\n",
      "\n",
      "C: Bruce became a assistant after Joseph did.\n",
      "Q: Who became a assistant first?\n",
      "A: Joseph\n",
      "P: Bruce\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "description = 'Understanding before / after -> first / last.'\n",
    "name=\"Time Difference\"\n",
    "test = MFT(**t_time_difference, expect=expect_squad, capability='Temporal', name=name, description=description )\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5f6cdf",
   "metadata": {},
   "source": [
    "## <a id=\"Negation\" /> <font color='yellow'> Negation </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec797b",
   "metadata": {},
   "source": [
    "### 1. Negation in Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e68825cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_context_negation = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is not {a:prof}. {first_name2} is.',\n",
    "            '{first_name2} is {a:prof}. {first_name} is not.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fba91de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Mark is not a DJ. Ralph is.', 'Who is a DJ?') , pred: empty , label: Ralph\n",
      "  [2] ('Mark is not a DJ. Ralph is.', 'Who is not a DJ?') , pred: Mark , label: Mark\n",
      "  [3] ('Ralph is a DJ. Mark is not.', 'Who is a DJ?') , pred: Ralph , label: Ralph\n",
      "  [4] ('Ralph is a DJ. Mark is not.', 'Who is not a DJ?') , pred: Mark , label: Mark\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_context_negation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f84d7436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 2000 examples\n",
      "Test cases:      500\n",
      "Fails (rate):    487 (97.4%)\n",
      "\n",
      "Example fails:\n",
      "C: Walter is not a waitress. Kathleen is.\n",
      "Q: Who is a waitress?\n",
      "A: Kathleen\n",
      "P: Walter\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "name = 'Negation in context, may or may not be in question'\n",
    "test = MFT(**t_context_negation, expect=expect_squad, capability='Negation', name=name, description='' )\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a3c75e",
   "metadata": {},
   "source": [
    "### 3. Negation in Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "be0bb69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_question_negation = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {a:prof}. {first_name2} is {a:prof2}.',\n",
    "            '{first_name2} is {a:prof2}. {first_name} is {a:prof}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof2}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "10697847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Judith is an editor. Ron is an assistant.', 'Who is an editor?') , pred: Judith , label: Judith\n",
      "  [2] ('Judith is an editor. Ron is an assistant.', 'Who is not an editor?') , pred: Judith , label: Ron\n",
      "  [3] ('Judith is an editor. Ron is an assistant.', 'Who is an assistant?') , pred: Ron , label: Ron\n",
      "  [4] ('Judith is an editor. Ron is an assistant.', 'Who is not an assistant?') , pred: Ron , label: Judith\n",
      "  [5] ('Ron is an assistant. Judith is an editor.', 'Who is an editor?') , pred: Judith , label: Judith\n",
      "  [6] ('Ron is an assistant. Judith is an editor.', 'Who is not an editor?') , pred: Judith , label: Ron\n",
      "  [7] ('Ron is an assistant. Judith is an editor.', 'Who is an assistant?') , pred: Ron , label: Ron\n",
      "  [8] ('Ron is an assistant. Judith is an editor.', 'Who is not an assistant?') , pred: Ron , label: Judith\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "show_example(t_question_negation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "333ce971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 3888 examples\n",
      "Test cases:      486\n",
      "Fails (rate):    486 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Greg is a reporter. Ellen is an analyst.\n",
      "Q: Who is not a reporter?\n",
      "A: Ellen\n",
      "P: Greg\n",
      "\n",
      "C: Greg is a reporter. Ellen is an analyst.\n",
      "Q: Who is not an analyst?\n",
      "A: Greg\n",
      "P: Ellen\n",
      "\n",
      "C: Ellen is an analyst. Greg is a reporter.\n",
      "Q: Who is not a reporter?\n",
      "A: Ellen\n",
      "P: Greg\n",
      "\n",
      "\n",
      "----\n",
      "C: Kathryn is an economist. Adam is an interpreter.\n",
      "Q: Who is not an economist?\n",
      "A: Adam\n",
      "P: Kathryn\n",
      "\n",
      "C: Kathryn is an economist. Adam is an interpreter.\n",
      "Q: Who is not an interpreter?\n",
      "A: Kathryn\n",
      "P: Adam\n",
      "\n",
      "C: Adam is an interpreter. Kathryn is an economist.\n",
      "Q: Who is not an economist?\n",
      "A: Adam\n",
      "P: Kathryn\n",
      "\n",
      "\n",
      "----\n",
      "C: Robin is an activist. Jonathan is an entrepreneur.\n",
      "Q: Who is not an activist?\n",
      "A: Jonathan\n",
      "P: Robin\n",
      "\n",
      "C: Robin is an activist. Jonathan is an entrepreneur.\n",
      "Q: Who is not an entrepreneur?\n",
      "A: Robin\n",
      "P: Jonathan\n",
      "\n",
      "C: Jonathan is an entrepreneur. Robin is an activist.\n",
      "Q: Who is not an activist?\n",
      "A: Jonathan\n",
      "P: Robin\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Negation in question only.'\n",
    "test = MFT(**t_question_negation, expect=expect_squad, capability='Negation', name=name, description='' )\n",
    "test.run(model_predictor)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1326ba4",
   "metadata": {},
   "source": [
    "## <a id=\"Coref\" /> <font color='yellow'> Coref </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b51294",
   "metadata": {},
   "source": [
    "### 1. He/she coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1b7df953",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'actress' in professions:\n",
    "    professions.remove('actress')\n",
    "\n",
    "t_he_she_coref = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{male} and {female} are friends. He is {a:prof1}, and she is {a:prof2}.',\n",
    "            '{female} and {male} are friends. He is {a:prof1}, and she is {a:prof2}.',\n",
    "            '{male} and {female} are friends. She is {a:prof2}, and he is {a:prof1}.',\n",
    "            '{female} and {male} are friends. She is {a:prof2}, and he is {a:prof1}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof1}?',\n",
    "                '{male}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{female}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "70595b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Adam and Sophie are friends. He is an agent, and she is an interpreter.', 'Who is an agent?') , pred: Adam and Sophie , label: Adam\n",
      "  [2] ('Adam and Sophie are friends. He is an agent, and she is an interpreter.', 'Who is an interpreter?') , pred: Adam and Sophie , label: Sophie\n",
      "  [3] ('Sophie and Adam are friends. He is an agent, and she is an interpreter.', 'Who is an agent?') , pred: Sophie and Adam , label: Adam\n",
      "  [4] ('Sophie and Adam are friends. He is an agent, and she is an interpreter.', 'Who is an interpreter?') , pred: Sophie and Adam , label: Sophie\n",
      "  [5] ('Adam and Sophie are friends. She is an interpreter, and he is an agent.', 'Who is an agent?') , pred: Adam and Sophie , label: Adam\n",
      "  [6] ('Adam and Sophie are friends. She is an interpreter, and he is an agent.', 'Who is an interpreter?') , pred: Adam and Sophie , label: Sophie\n",
      "  [7] ('Sophie and Adam are friends. She is an interpreter, and he is an agent.', 'Who is an agent?') , pred: Sophie and Adam , label: Adam\n",
      "  [8] ('Sophie and Adam are friends. She is an interpreter, and he is an agent.', 'Who is an interpreter?') , pred: Sophie and Adam , label: Sophie\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_he_she_coref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f65eaeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 3784 examples\n",
      "Test cases:      473\n",
      "Fails (rate):    473 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Jimmy and Lucy are friends. He is an entrepreneur, and she is a model.\n",
      "Q: Who is an entrepreneur?\n",
      "A: Jimmy\n",
      "P: Jimmy and Lucy\n",
      "\n",
      "C: Jimmy and Lucy are friends. He is an entrepreneur, and she is a model.\n",
      "Q: Who is a model?\n",
      "A: Lucy\n",
      "P: Jimmy and Lucy\n",
      "\n",
      "C: Lucy and Jimmy are friends. He is an entrepreneur, and she is a model.\n",
      "Q: Who is an entrepreneur?\n",
      "A: Jimmy\n",
      "P: Lucy and Jimmy\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Basic coref, he / she'\n",
    "test = MFT(**t_he_she_coref, expect=expect_squad, name=name, description='', capability='Coref')\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcd0745",
   "metadata": {},
   "source": [
    "### 2. His/Her coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "22ddda5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_his_her = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{male} and {female} are friends. His mom is {a:prof}.',\n",
    "            '{female} and {male} are friends. His mom is {a:prof}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Whose mom is {a:prof}?',\n",
    "                '{male}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=250,\n",
    "    ))\n",
    "t_his_her += crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{male} and {female} are friends. Her mom is {a:prof}.',\n",
    "            '{female} and {male} are friends. Her mom is {a:prof}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Whose mom is {a:prof}?',\n",
    "                '{female}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=250,\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9aaa5a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Ray and Frances are friends. His mom is an intern.', 'Whose mom is an intern?') , pred: Ray and Frances , label: Ray\n",
      "  [2] ('Frances and Ray are friends. His mom is an intern.', 'Whose mom is an intern?') , pred: Frances and Ray , label: Ray\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_his_her)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8f3adae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1000 examples\n",
      "Test cases:      500\n",
      "Fails (rate):    500 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Bruce and Edith are friends. His mom is an intern.\n",
      "Q: Whose mom is an intern?\n",
      "A: Bruce\n",
      "P: Bruce and Edith\n",
      "\n",
      "C: Edith and Bruce are friends. His mom is an intern.\n",
      "Q: Whose mom is an intern?\n",
      "A: Bruce\n",
      "P: Edith and Bruce\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Basic coref, his / her'\n",
    "test = MFT(**t_his_her, expect=expect_squad, name=name, description='', capability='Coref')\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175dbb79",
   "metadata": {},
   "source": [
    "### 3. Former and Latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c34dfc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_former_latter = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} and {first_name2} are friends. The former is {a:prof1}.',\n",
    "            '{first_name2} and {first_name} are friends. The latter is {a:prof1}.',\n",
    "            '{first_name} and {first_name2} are friends. The former is {a:prof1} and the latter is {a:prof2}.',\n",
    "            '{first_name2} and {first_name} are friends. The former is {a:prof2} and the latter is {a:prof1}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof1}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "02abdb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Heather and Eric are friends. The former is a nurse.', 'Who is a nurse?') , pred: Heather and Eric , label: Heather\n",
      "  [2] ('Eric and Heather are friends. The latter is a nurse.', 'Who is a nurse?') , pred: Eric and Heather , label: Heather\n",
      "  [3] ('Heather and Eric are friends. The former is a nurse and the latter is an artist.', 'Who is a nurse?') , pred: Heather and Eric are friends. The former is a nurse and the latter is an artist , label: Heather\n",
      "  [4] ('Eric and Heather are friends. The former is an artist and the latter is a nurse.', 'Who is a nurse?') , pred: Eric and Heather , label: Heather\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_former_latter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aa437c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1920 examples\n",
      "Test cases:      480\n",
      "Fails (rate):    480 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Henry and Sharon are friends. The former is an editor.\n",
      "Q: Who is an editor?\n",
      "A: Henry\n",
      "P: Henry and Sharon\n",
      "\n",
      "C: Sharon and Henry are friends. The latter is an editor.\n",
      "Q: Who is an editor?\n",
      "A: Henry\n",
      "P: Sharon and Henry\n",
      "\n",
      "C: Henry and Sharon are friends. The former is an editor and the latter is an accountant.\n",
      "Q: Who is an editor?\n",
      "A: Henry\n",
      "P: an accountant\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Former / Latter'\n",
    "test = MFT(**t_former_latter, expect=expect_squad, name=name, description='', capability='Coref')\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7d996ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suite.summary(n=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9f86d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_suite=get_summary(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fa080659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Test Name                                          |   Total Cases |   Example Per Case |   Failures | Failure Rate   |\n",
       "|----------------------------------------------------|---------------|--------------------|------------|----------------|\n",
       "| Comparisons                                        |           500 |                  2 |        500 | 100.00%        |\n",
       "| Intensifiers                                       |           497 |                 12 |        497 | 100.00%        |\n",
       "| Properites                                         |           500 |                  4 |        500 | 100.00%        |\n",
       "| Profession vs nationality                          |           500 |                 10 |        274 | 54.80%         |\n",
       "| Animal vs Vehicle                                  |           500 |                  4 |        493 | 98.60%         |\n",
       "| Animal vs Vehicle v2                               |           498 |                  4 |        242 | 48.59%         |\n",
       "| Synonyms                                           |           449 |                  4 |         28 | 6.24%          |\n",
       "| Antonyms                                           |           498 |                  4 |        498 | 100.00%        |\n",
       "| Antonyms Comparison                                |           497 |                 16 |        497 | 100.00%        |\n",
       "| There was a change in profession                   |           474 |                  2 |          8 | 1.69%          |\n",
       "| Time Difference                                    |           498 |                  4 |        498 | 100.00%        |\n",
       "| Negation in context, may or may not be in question |           500 |                  4 |        487 | 97.40%         |\n",
       "| Negation in question only.                         |           486 |                  8 |        486 | 100.00%        |\n",
       "| Basic coref, he / she                              |           473 |                  8 |        473 | 100.00%        |\n",
       "| Basic coref, his / her                             |           500 |                  2 |        500 | 100.00%        |\n",
       "| Former / Latter                                    |           480 |                  4 |        480 | 100.00%        |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_and_export_mdtable(df_suite, do_export=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d152a628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved, 45228 rows to checklist_testsuite.jsonl.\n"
     ]
    }
   ],
   "source": [
    "export_suite_to_jsonl(suite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

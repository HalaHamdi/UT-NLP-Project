{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd45822",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "&emsp;[<a id=\"#vocab\" /> <font color='yellow' size=5> Vocab </font>](#%3Ca-id%3D%22%23vocab%22-/%3E-%3Cfont-color%3D%27yellow%27%3E-Vocab-%3C/font%3E)<br>\n",
    "&emsp;&emsp;[1. Comparison](#1.-Comparison)<br>\n",
    "&emsp;&emsp;[2. Intensifier](#2.-Intensifier)<br><br>\n",
    "&emsp;[<a id=\"Taxonomy\" /> <font color='yellow' size=5> Taxonomy </font>](#%3Ca-id%3D%22Taxonomy%22-/%3E-%3Cfont-color%3D%27yellow%27%3E-Taxonomy-%3C/font%3E)<br>\n",
    "&emsp;&emsp;[1. Size, Shape, Color, Age, Material](#1.-Size%2C-Shape%2C-Color%2C-Age%2C-Material)<br>\n",
    "&emsp;&emsp;[2. Professions vs nationalities](#2.-Professions-vs-nationalities)<br>\n",
    "&emsp;&emsp;[3. Animal vs Vehicles - Example1](#3.-Animal-vs-Vehicles---Example1)<br>\n",
    "&emsp;&emsp;[4. Animal vs Vehicles - Example2](#4.-Animal-vs-Vehicles---Example2)<br>\n",
    "&emsp;&emsp;[5. Synonyms](#5.-Synonyms)<br>\n",
    "&emsp;&emsp;[6. Antonyms](#6.-Antonyms)<br>\n",
    "&emsp;&emsp;[7. Antonyms Comparison](#7.-Antonyms-Comparison)<br><br>\n",
    "&emsp;[<a id=\"Temporal\" /> <font color='yellow' size=5> Temporal </font>](#%3Ca-id%3D%22Temporal%22-/%3E-%3Cfont-color%3D%27yellow%27%3E-Temporal-%3C/font%3E)<br>\n",
    "&emsp;&emsp;[1. Change in profession](#1.-Change-in-profession)<br>\n",
    "&emsp;&emsp;[2. Understand time difference](#2.-Understand-time-difference)<br><br>\n",
    "&emsp;[<a id=\"Negation\" /> <font color='yellow' size=5> Negation </font>](#%3Ca-id%3D%22Negation%22-/%3E-%3Cfont-color%3D%27yellow%27%3E-Negation-%3C/font%3E)<br>\n",
    "&emsp;&emsp;[1. Negation in Context](#1.-Negation-in-Context)<br>\n",
    "&emsp;&emsp;[3. Negation in Question](#3.-Negation-in-Question)<br><br>\n",
    "&emsp;[<a id=\"Coref\" /> <font color='yellow' size=5> Coref </font>](#%3Ca-id%3D%22Coref%22-/%3E-%3Cfont-color%3D%27yellow%27%3E-Coref-%3C/font%3E)<br>\n",
    "&emsp;&emsp;[1. He/she coref](#1.-He/she-coref)<br>\n",
    "&emsp;&emsp;[2. His/Her coref](#2.-His/Her-coref)<br>\n",
    "&emsp;&emsp;[3. Former and Latter](#3.-Former-and-Latter)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d9554af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import checklist.editor\n",
    "import munch\n",
    "import itertools\n",
    "from checklist.test_suite import TestSuite\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.expect import Expect\n",
    "from checklist.perturb import Perturb\n",
    "from helper import get_finetuned_electra_predictor, format_squad_with_context,show_example, crossproduct, export_suite_to_jsonl, get_summary,display_and_export_mdtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f46dfd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp-proj/lib/python3.10/site-packages/iso639/iso639.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n"
     ]
    }
   ],
   "source": [
    "suite = TestSuite()\n",
    "editor = checklist.editor.Editor()\n",
    "model_predictor = get_finetuned_electra_predictor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3553fb3a",
   "metadata": {},
   "source": [
    "## <a id=\"#vocab\" /> <font color='yellow'> Vocab </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b2c19",
   "metadata": {},
   "source": [
    "### 1. Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "468d31f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### <a id=\"1-comparison\"></a> 1. Comparisonart', 'tall', 'young', 'strong', 'short', 'tough', 'cool', 'fast', 'nice', 'small', 'dark', 'wise', 'rich', 'great', 'weak', 'high', 'slow', 'strange', 'clean']\n",
    "adj = [(x.rstrip('e'), x) for x in adj]\n",
    "\n",
    "\n",
    "t_comparison = editor.template(\n",
    "    [(\n",
    "    '{first_name} is {adj[0]}er than {first_name1}.',\n",
    "    'Who is less {adj[1]}?'\n",
    "    ),(\n",
    "    '{first_name} is {adj[0]}er than {first_name1}.',\n",
    "    'Who is {adj[0]}er?'\n",
    "    ),\n",
    "    ],\n",
    "    labels = ['{first_name1}','{first_name}'],\n",
    "    adj=adj,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52cd8aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Jonathan is stranger than Carolyn.', 'Who is less strange?') , pred: Jonathan , label: Carolyn\n",
      "  [2] ('Jonathan is stranger than Carolyn.', 'Who is stranger?') , pred: Jonathan , label: Jonathan\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_comparison, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae1c32b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 996 examples\n",
      "Test cases:      498\n",
      "Fails (rate):    498 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Jack is tougher than Greg.\n",
      "Q: Who is less tough?\n",
      "A: Greg\n",
      "P: Jack\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Comparisons'\n",
    "description = 'A is COMP than B. Who is more / less COMP?'\n",
    "test = MFT(**t_comparison, name=name, description=description, capability='Vocabulary')\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830cf1d4",
   "metadata": {},
   "source": [
    "### 2. Intensifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0a13a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp-proj/lib/python3.10/site-packages/checklist/text_generation.py:171: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:256.)\n",
      "  to_pred = torch.tensor(to_pred, device=self.device).to(torch.int64)\n"
     ]
    }
   ],
   "source": [
    "state = editor.suggest('John is very {mask} about the project.')[:20]\n",
    "very = ['very', 'extremely', 'really', 'quite', 'incredibly', 'particularly', 'highly', 'super']\n",
    "somewhat = ['a little', 'somewhat', 'slightly', 'mildly']\n",
    "\n",
    "t_intensifier = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {very} {s} about the project. {first_name1} is {s} about the project.',\n",
    "            '{first_name1} is {s} about the project. {first_name} is {very} {s} about the project.',\n",
    "            '{first_name} is {s} about the project. {first_name1} is {somewhat} {s} about the project.',\n",
    "            '{first_name1} is {somewhat} {s} about the project. {first_name} is {s} about the project.',\n",
    "            '{first_name} is {very} {s} about the project. {first_name1} is {somewhat} {s} about the project.',\n",
    "            '{first_name1} is {somewhat} {s} about the project. {first_name} is {very} {s} about the project.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is most {s} about the project?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is least {s} about the project?',\n",
    "                '{first_name1}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    s = state,\n",
    "    very=very,\n",
    "    somewhat=somewhat,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26fe5333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Kathy is incredibly upbeat about the project. Jimmy is upbeat about the project.', 'Who is most upbeat about the project?') , pred: Jimmy , label: Kathy\n",
      "  [2] ('Kathy is incredibly upbeat about the project. Jimmy is upbeat about the project.', 'Who is least upbeat about the project?') , pred: Jimmy , label: Jimmy\n",
      "  [3] ('Jimmy is upbeat about the project. Kathy is incredibly upbeat about the project.', 'Who is most upbeat about the project?') , pred: Kathy , label: Kathy\n",
      "  [4] ('Jimmy is upbeat about the project. Kathy is incredibly upbeat about the project.', 'Who is least upbeat about the project?') , pred: Kathy , label: Jimmy\n",
      "  [5] ('Kathy is upbeat about the project. Jimmy is somewhat upbeat about the project.', 'Who is most upbeat about the project?') , pred: Jimmy , label: Kathy\n",
      "  [6] ('Kathy is upbeat about the project. Jimmy is somewhat upbeat about the project.', 'Who is least upbeat about the project?') , pred: Jimmy , label: Jimmy\n",
      "  [7] ('Jimmy is somewhat upbeat about the project. Kathy is upbeat about the project.', 'Who is most upbeat about the project?') , pred: Kathy , label: Kathy\n",
      "  [8] ('Jimmy is somewhat upbeat about the project. Kathy is upbeat about the project.', 'Who is least upbeat about the project?') , pred: Kathy , label: Jimmy\n",
      "  [9] ('Kathy is incredibly upbeat about the project. Jimmy is somewhat upbeat about the project.', 'Who is most upbeat about the project?') , pred: Jimmy , label: Kathy\n",
      "  [10] ('Kathy is incredibly upbeat about the project. Jimmy is somewhat upbeat about the project.', 'Who is least upbeat about the project?') , pred: Jimmy , label: Jimmy\n",
      "  [11] ('Jimmy is somewhat upbeat about the project. Kathy is incredibly upbeat about the project.', 'Who is most upbeat about the project?') , pred: Kathy , label: Kathy\n",
      "  [12] ('Jimmy is somewhat upbeat about the project. Kathy is incredibly upbeat about the project.', 'Who is least upbeat about the project?') , pred: Kathy , label: Jimmy\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_intensifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "923bf7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 5988 examples\n",
      "Test cases:      499\n",
      "Fails (rate):    499 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: George is incredibly particular about the project. Edward is particular about the project.\n",
      "Q: Who is most particular about the project?\n",
      "A: George\n",
      "P: Edward\n",
      "\n",
      "C: Edward is particular about the project. George is incredibly particular about the project.\n",
      "Q: Who is least particular about the project?\n",
      "A: Edward\n",
      "P: George\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Intensifiers'\n",
    "desc = '(very, super, extremely) and reducers (somewhat, kinda, etc)?'\n",
    "test = MFT(**t_intensifier, name=name, description=desc, capability='Vocabulary')\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context, n_per_testcase=2)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c73d21",
   "metadata": {},
   "source": [
    "## <a id=\"Taxonomy\" /> <font color='yellow'> Taxonomy </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11420c60",
   "metadata": {},
   "source": [
    "### 1. Size, Shape, Color, Age, Material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74fb9081",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['size', 'shape', 'age', 'color']\n",
    "props = []\n",
    "properties = {\n",
    "    'color' : ['red', 'blue','yellow', 'green', 'pink', 'white', 'black', 'orange', 'grey', 'purple', 'brown'],\n",
    "    'size' : ['big', 'small', 'tiny', 'enormous'],\n",
    "    'age' : ['old', 'new'],\n",
    "    'shape' : ['round', 'oval', 'square', 'triangular'],\n",
    "    'material' : ['iron', 'wooden', 'ceramic', 'glass', 'stone']\n",
    "}\n",
    "objects = ['box', 'clock', 'table', 'object', 'toy', 'painting', 'sculpture', 'thing', 'figure']\n",
    "\n",
    "for i in range(len(order)):\n",
    "    for j in range(i + 1, len(order)):\n",
    "        p1, p2 = order[i], order[j]\n",
    "        for v1, v2 in itertools.product(properties[p1], properties[p2]):\n",
    "            props.append(munch.Munch({\n",
    "                'p1': p1,\n",
    "                'p2': p2,\n",
    "                'v1': v1,\n",
    "                'v2': v2,\n",
    "            }))\n",
    "            \n",
    "t_properties = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            'There is {a:p.v1} {p.v2} {obj} in the room.',\n",
    "            'There is {a:obj} in the room. The {obj} is {p.v1} and {p.v2}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What {p.p1} is the {obj}?',\n",
    "                '{p.v1}'\n",
    "            ), \n",
    "            (\n",
    "                'What {p.p2} is the {obj}?',\n",
    "                '{p.v2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "    },\n",
    "    obj=objects,\n",
    "    p=props,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcf6a4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('There is a new purple box in the room.', 'What age is the box?') , pred: purple , label: new\n",
      "  [2] ('There is a new purple box in the room.', 'What color is the box?') , pred: purple , label: purple\n",
      "  [3] ('There is a box in the room. The box is new and purple.', 'What age is the box?') , pred: new and purple , label: new\n",
      "  [4] ('There is a box in the room. The box is new and purple.', 'What color is the box?') , pred: purple , label: purple\n",
      "---\n",
      "  [1] ('There is a triangular new table in the room.', 'What shape is the table?') , pred: triangular , label: triangular\n",
      "  [2] ('There is a triangular new table in the room.', 'What age is the table?') , pred: triangular new , label: new\n",
      "  [3] ('There is a table in the room. The table is triangular and new.', 'What shape is the table?') , pred: triangular , label: triangular\n",
      "  [4] ('There is a table in the room. The table is triangular and new.', 'What age is the table?') , pred: triangular and new , label: new\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_properties, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6d2ef6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 2000 examples\n",
      "Test cases:      500\n",
      "Fails (rate):    499 (99.8%)\n",
      "\n",
      "Example fails:\n",
      "C: There is an enormous triangular object in the room.\n",
      "Q: What size is the object?\n",
      "A: enormous\n",
      "P: triangular\n",
      "\n",
      "C: There is an object in the room. The object is enormous and triangular.\n",
      "Q: What size is the object?\n",
      "A: enormous\n",
      "P: enormous and triangular\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Properites'\n",
    "desc = 'size, shape, age, color'\n",
    "test = MFT(**t_properties, name=name, description=desc, capability='Taxonomy')\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884728ed",
   "metadata": {},
   "source": [
    "### 2. Professions vs nationalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d590180",
   "metadata": {},
   "outputs": [],
   "source": [
    "professions = editor.suggest('{first_name} works as {a:mask}.')[:30]\n",
    "professions += editor.suggest('{first_name} {last_name} works as {a:mask}.')[:30]\n",
    "professions = list(set(professions))\n",
    "if 'translator' in professions:\n",
    "    professions.remove('translator')\n",
    "\n",
    "\n",
    "def clean(string):\n",
    "    return string.lstrip('[a,the,an,in,at] ').rstrip('.')\n",
    "def expect_squad(x, pred, conf, label=None, meta=None):\n",
    "    return clean(pred) == clean(label)\n",
    "expect_squad = Expect.single(expect_squad)\n",
    "\n",
    "\n",
    "t_profession_nationtionality = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {a:nat} {prof}.',\n",
    "            '{first_name} is {a:prof}. {first_name} is {nat}.',\n",
    "            '{first_name} is {nat}. {first_name} is {a:prof}.',\n",
    "            '{first_name} is {nat} and {a:prof}.',\n",
    "            '{first_name} is {a:prof} and {nat}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What is {first_name}\\'s job?',\n",
    "                '{prof}'\n",
    "            ), \n",
    "            (\n",
    "                'What is {first_name}\\'s nationality?',\n",
    "                '{nat}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    nat = editor.lexicons['nationality'][:10],\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af7acebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Janet is an American investor.', \"What is Janet's job?\") , pred: American investor , label: investor\n",
      "  [2] ('Janet is an American investor.', \"What is Janet's nationality?\") , pred: American , label: American\n",
      "  [3] ('Janet is an investor. Janet is American.', \"What is Janet's job?\") , pred: investor , label: investor\n",
      "  [4] ('Janet is an investor. Janet is American.', \"What is Janet's nationality?\") , pred: American , label: American\n",
      "  [5] ('Janet is American. Janet is an investor.', \"What is Janet's job?\") , pred: investor , label: investor\n",
      "  [6] ('Janet is American. Janet is an investor.', \"What is Janet's nationality?\") , pred: American , label: American\n",
      "  [7] ('Janet is American and an investor.', \"What is Janet's job?\") , pred: American and an investor , label: investor\n",
      "  [8] ('Janet is American and an investor.', \"What is Janet's nationality?\") , pred: American , label: American\n",
      "  [9] ('Janet is an investor and American.', \"What is Janet's job?\") , pred: investor and American , label: investor\n",
      "  [10] ('Janet is an investor and American.', \"What is Janet's nationality?\") , pred: American , label: American\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_profession_nationtionality, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aac9ad40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 5000 examples\n",
      "Test cases:      500\n",
      "Fails (rate):    260 (52.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Donald is an educator and Nigerian.\n",
      "Q: What is Donald's job?\n",
      "A: educator\n",
      "P: educator and Nigerian\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Profession vs nationality'\n",
    "test = MFT(**t_profession_nationtionality, name=name, expect=expect_squad, description='',  capability='Taxonomy')\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4c4b23",
   "metadata": {},
   "source": [
    "### 3. Animal vs Vehicles - Example1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ddfb790",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['dog', 'cat', 'bull', 'cow', 'fish', 'serpent', 'snake', 'lizard', 'hamster', 'rabbit', 'guinea pig', 'iguana', 'duck']\n",
    "vehicles = ['car', 'truck', 'train', 'motorcycle', 'bike', 'firetruck', 'tractor', 'van', 'SUV', 'minivan']\n",
    "t_animal_vehicles = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} has {a:animal} and {a:vehicle}.',\n",
    "            '{first_name} has {a:vehicle} and {a:animal}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What animal does {first_name} have?',\n",
    "                '{animal}'\n",
    "            ), \n",
    "            (\n",
    "                'What vehicle does {first_name} have?',\n",
    "                '{vehicle}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    animal=animals,\n",
    "    vehicle=vehicles,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "676021eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Mike has a hamster and a tractor.', 'What animal does Mike have?') , pred: hamster , label: hamster\n",
      "  [2] ('Mike has a hamster and a tractor.', 'What vehicle does Mike have?') , pred: hamster and a tractor , label: tractor\n",
      "  [3] ('Mike has a tractor and a hamster.', 'What animal does Mike have?') , pred: a tractor and a hamster , label: hamster\n",
      "  [4] ('Mike has a tractor and a hamster.', 'What vehicle does Mike have?') , pred: a tractor , label: tractor\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_animal_vehicles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab9156a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 2000 examples\n",
      "Test cases:      500\n",
      "Fails (rate):    495 (99.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Alex has a serpent and a bike.\n",
      "Q: What vehicle does Alex have?\n",
      "A: bike\n",
      "P: a serpent and a bike\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Animal vs Vehicle'\n",
    "test = MFT(**t_animal_vehicles, name=name, description='', capability='Taxonomy', expect=expect_squad)\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a4d734",
   "metadata": {},
   "source": [
    "### 4. Animal vs Vehicles - Example2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3640824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['dog', 'cat', 'bull', 'cow', 'fish', 'serpent', 'snake', 'lizard', 'hamster', 'rabbit', 'guinea pig', 'iguana', 'duck']\n",
    "vehicles = ['car', 'truck', 'train', 'motorcycle', 'bike', 'firetruck', 'tractor', 'van', 'SUV', 'minivan']\n",
    "t_animals_vehicles_2 = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} bought {a:animal}. {first_name2} bought {a:vehicle}.',\n",
    "            '{first_name2} bought {a:vehicle}. {first_name} bought {a:animal}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who bought an animal?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who bought a vehicle?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    animal=animals,\n",
    "    vehicle=vehicles,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aecad4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Sandra bought a cat. Ellen bought a tractor.', 'Who bought an animal?') , pred: Sandra , label: Sandra\n",
      "  [2] ('Sandra bought a cat. Ellen bought a tractor.', 'Who bought a vehicle?') , pred: Ellen , label: Ellen\n",
      "  [3] ('Ellen bought a tractor. Sandra bought a cat.', 'Who bought an animal?') , pred: Sandra , label: Sandra\n",
      "  [4] ('Ellen bought a tractor. Sandra bought a cat.', 'Who bought a vehicle?') , pred: Ellen , label: Ellen\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_animals_vehicles_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88855a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1996 examples\n",
      "Test cases:      499\n",
      "Fails (rate):    266 (53.3%)\n",
      "\n",
      "Example fails:\n",
      "C: Anne bought a duck. Harriet bought a train.\n",
      "Q: Who bought an animal?\n",
      "A: Anne\n",
      "P: Harriet\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "name = 'Animal vs Vehicle v2'\n",
    "test = MFT(**t_animals_vehicles_2, name=name, description='', capability='Taxonomy', expect=expect_squad)\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a62d52",
   "metadata": {},
   "source": [
    "### 5. Synonyms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "036b0cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms = [ ('spiritual', 'religious'), ('angry', 'furious'), ('organized', 'organised'),\n",
    "            ('vocal', 'outspoken'), ('grateful', 'thankful'), ('intelligent', 'smart'),\n",
    "            ('humble', 'modest'), ('courageous', 'brave'), ('happy', 'joyful'), ('scared', 'frightened'),\n",
    "           ]\n",
    "\n",
    "t_synonym = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is very {s1[0]}. {first_name2} is very {s2[0]}.',\n",
    "            '{first_name2} is very {s2[0]}. {first_name} is very {s1[0]}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {s1[1]}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {s2[1]}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    s=synonyms,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=250,\n",
    "    save=True\n",
    "   ))\n",
    "t_synonym += crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is very {s1[1]}. {first_name2} is very {s2[1]}.',\n",
    "            '{first_name2} is very {s2[1]}. {first_name} is very {s1[1]}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {s1[0]}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {s2[0]}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    s=synonyms,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=250,\n",
    "    save=True\n",
    "    )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3b8b03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Kathleen is very vocal. Edwin is very angry.', 'Who is outspoken?') , pred: Edwin , label: Kathleen\n",
      "  [2] ('Kathleen is very vocal. Edwin is very angry.', 'Who is furious?') , pred: Edwin , label: Edwin\n",
      "  [3] ('Edwin is very angry. Kathleen is very vocal.', 'Who is outspoken?') , pred: Kathleen , label: Kathleen\n",
      "  [4] ('Edwin is very angry. Kathleen is very vocal.', 'Who is furious?') , pred: Edwin , label: Edwin\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_synonym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23609083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1832 examples\n",
      "Test cases:      458\n",
      "Fails (rate):    21 (4.6%)\n",
      "\n",
      "Example fails:\n",
      "C: Sam is very happy. Eric is very grateful.\n",
      "Q: Who is joyful?\n",
      "A: Sam\n",
      "P: Eric\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Synonyms'\n",
    "test = MFT(**t_synonym, name=name, description='', capability='Taxonomy', expect=expect_squad)\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeb30bc",
   "metadata": {},
   "source": [
    "### 6. Antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24f3c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_pairs = [('better', 'worse'), ('older', 'younger'), ('smarter', 'dumber'), ('taller', 'shorter'), ('bigger', 'smaller'), ('stronger', 'weaker'), ('faster', 'slower'), ('darker', 'lighter'), ('richer', 'poorer'), ('happier', 'sadder'), ('louder', 'quieter'), ('warmer', 'colder')]\n",
    "comp_pairs = list(set(comp_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff915519",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_antonymns = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {comp[0]} than {first_name1}.',\n",
    "            '{first_name1} is {comp[1]} than {first_name}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {comp[1]}?',\n",
    "                '{first_name1}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is {comp[0]}?',\n",
    "                '{first_name}',\n",
    "            )\n",
    "            \n",
    "        ]\n",
    "        ,\n",
    "    },\n",
    "    comp=comp_pairs,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c8cb5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Al is louder than Gary.', 'Who is quieter?') , pred: Al , label: Gary\n",
      "  [2] ('Al is louder than Gary.', 'Who is louder?') , pred: Al , label: Al\n",
      "  [3] ('Gary is quieter than Al.', 'Who is quieter?') , pred: Gary , label: Gary\n",
      "  [4] ('Gary is quieter than Al.', 'Who is louder?') , pred: Gary , label: Al\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_antonymns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2fa1fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1992 examples\n",
      "Test cases:      498\n",
      "Fails (rate):    498 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Francis is darker than Bruce.\n",
      "Q: Who is lighter?\n",
      "A: Bruce\n",
      "P: Francis\n",
      "\n",
      "C: Bruce is lighter than Francis.\n",
      "Q: Who is darker?\n",
      "A: Francis\n",
      "P: Bruce\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Antonyms'\n",
    "test = MFT(**t_antonymns, name=name, description='A is COMP than B. Who is antonym(COMP)? B', capability='Taxonomy')\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d7e79f",
   "metadata": {},
   "source": [
    "### 7. Antonyms Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3a0ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "antonym_adjs = [('progressive', 'conservative'),('religious', 'secular'),('positive', 'negative'),('defensive', 'offensive'),('rude',  'polite'),('optimistic', 'pessimistic'),('stupid', 'smart'),('negative', 'positive'),('unhappy', 'happy'),('active', 'passive'),('impatient', 'patient'),('powerless', 'powerful'),('visible', 'invisible'),('fat', 'thin'),('bad', 'good'),('cautious', 'brave'), ('hopeful', 'hopeless'),('insecure', 'secure'),('humble', 'proud'),('passive', 'active'),('dependent', 'independent'),('pessimistic', 'optimistic'),('irresponsible', 'responsible'),('courageous', 'fearful')]\n",
    "\n",
    "t_antonymns_compare = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is more {a[0]} than {first_name1}.',\n",
    "            '{first_name1} is more {a[1]} than {first_name}.',\n",
    "            '{first_name} is less {a[1]} than {first_name1}.',\n",
    "            '{first_name1} is less {a[0]} than {first_name}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is more {a[0]}?',\n",
    "                '{first_name}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is less {a[0]}?',\n",
    "                '{first_name1}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is more {a[1]}?',\n",
    "                '{first_name1}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is less {a[1]}?',\n",
    "                '{first_name}',\n",
    "            ),\n",
    "        ]\n",
    "        ,\n",
    "    },\n",
    "    a = antonym_adjs,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "464ff0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Lauren is more active than Arthur.', 'Who is more active?') , pred: Lauren , label: Lauren\n",
      "  [2] ('Lauren is more active than Arthur.', 'Who is less active?') , pred: Lauren , label: Arthur\n",
      "  [3] ('Lauren is more active than Arthur.', 'Who is more passive?') , pred: Lauren , label: Arthur\n",
      "  [4] ('Lauren is more active than Arthur.', 'Who is less passive?') , pred: Lauren , label: Lauren\n",
      "  [5] ('Arthur is more passive than Lauren.', 'Who is more active?') , pred: Arthur , label: Lauren\n",
      "  [6] ('Arthur is more passive than Lauren.', 'Who is less active?') , pred: Arthur , label: Arthur\n",
      "  [7] ('Arthur is more passive than Lauren.', 'Who is more passive?') , pred: Arthur , label: Arthur\n",
      "  [8] ('Arthur is more passive than Lauren.', 'Who is less passive?') , pred: Arthur , label: Lauren\n",
      "  [9] ('Lauren is less passive than Arthur.', 'Who is more active?') , pred: Lauren , label: Lauren\n",
      "  [10] ('Lauren is less passive than Arthur.', 'Who is less active?') , pred: Lauren , label: Arthur\n",
      "  [11] ('Lauren is less passive than Arthur.', 'Who is more passive?') , pred: Lauren , label: Arthur\n",
      "  [12] ('Lauren is less passive than Arthur.', 'Who is less passive?') , pred: Lauren , label: Lauren\n",
      "  [13] ('Arthur is less active than Lauren.', 'Who is more active?') , pred: Arthur , label: Lauren\n",
      "  [14] ('Arthur is less active than Lauren.', 'Who is less active?') , pred: Arthur , label: Arthur\n",
      "  [15] ('Arthur is less active than Lauren.', 'Who is more passive?') , pred: Arthur , label: Arthur\n",
      "  [16] ('Arthur is less active than Lauren.', 'Who is less passive?') , pred: Arthur , label: Lauren\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_antonymns_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "196f8249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 7984 examples\n",
      "Test cases:      499\n",
      "Fails (rate):    499 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Suzanne is more irresponsible than Tom.\n",
      "Q: Who is less irresponsible?\n",
      "A: Tom\n",
      "P: Suzanne\n",
      "\n",
      "C: Suzanne is more irresponsible than Tom.\n",
      "Q: Who is more responsible?\n",
      "A: Tom\n",
      "P: Suzanne\n",
      "\n",
      "C: Tom is more responsible than Suzanne.\n",
      "Q: Who is more irresponsible?\n",
      "A: Suzanne\n",
      "P: Tom\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "description = 'A is more X than B. Who is more antonym(X)? B. Who is less X? B. Who is more X? A. Who is less antonym(X)? A.'\n",
    "name= 'Antonyms Comparison'\n",
    "test = MFT(**t_antonymns_compare, name=name, description=description, capability='Taxonomy')\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d3a4e1",
   "metadata": {},
   "source": [
    "## <a id=\"Temporal\" /> <font color='yellow'> Temporal </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3286ed2b",
   "metadata": {},
   "source": [
    "### 1. Change in profession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3eb86698",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_profession = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            'Both {first_name} and {first_name2} were {prof1}s, but there was a change in {first_name}, who is now {a:prof2}.',\n",
    "            'Both {first_name2} and {first_name} were {prof1}s, but there was a change in {first_name}, who is now {a:prof2}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a134f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Both Evelyn and Charlie were nurses, but there was a change in Evelyn, who is now an assistant.', 'Who is an assistant?') , pred: Evelyn , label: Evelyn\n",
      "  [2] ('Both Charlie and Evelyn were nurses, but there was a change in Evelyn, who is now an assistant.', 'Who is an assistant?') , pred: Evelyn , label: Evelyn\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_profession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de629049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 970 examples\n",
      "Test cases:      485\n",
      "Fails (rate):    10 (2.1%)\n",
      "\n",
      "Example fails:\n",
      "C: Both Arthur and Don were historians, but there was a change in Don, who is now an artist.\n",
      "Q: Who is an artist?\n",
      "A: Don\n",
      "P: Arthur and Don\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'There was a change in profession'\n",
    "test = MFT(**t_profession, expect=expect_squad, capability='Temporal', name=name, description='' )\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7300c871",
   "metadata": {},
   "source": [
    "### 2. Understand time difference\n",
    "e.g before, after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "515cfdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_time_difference = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} became a {prof} before {first_name2} did.',\n",
    "            '{first_name2} became a {prof} after {first_name} did.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who became a {prof} first?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who became a {prof} last?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96eed107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Lucy became a artist before Kate did.', 'Who became a artist first?') , pred: Lucy , label: Lucy\n",
      "  [2] ('Lucy became a artist before Kate did.', 'Who became a artist last?') , pred: Lucy , label: Kate\n",
      "  [3] ('Kate became a artist after Lucy did.', 'Who became a artist first?') , pred: Kate , label: Lucy\n",
      "  [4] ('Kate became a artist after Lucy did.', 'Who became a artist last?') , pred: empty , label: Kate\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_time_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba2f2ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1988 examples\n",
      "Test cases:      497\n",
      "Fails (rate):    497 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Lisa became a actor before Mike did.\n",
      "Q: Who became a actor last?\n",
      "A: Mike\n",
      "P: Lisa\n",
      "\n",
      "C: Mike became a actor after Lisa did.\n",
      "Q: Who became a actor first?\n",
      "A: Lisa\n",
      "P: empty\n",
      "\n",
      "C: Mike became a actor after Lisa did.\n",
      "Q: Who became a actor last?\n",
      "A: Mike\n",
      "P: Lisa\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "description = 'Understanding before / after -> first / last.'\n",
    "name=\"Time Difference\"\n",
    "test = MFT(**t_time_difference, expect=expect_squad, capability='Temporal', name=name, description=description )\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5f6cdf",
   "metadata": {},
   "source": [
    "## <a id=\"Negation\" /> <font color='yellow'> Negation </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec797b",
   "metadata": {},
   "source": [
    "### 1. Negation in Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e68825cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_context_negation = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is not {a:prof}. {first_name2} is.',\n",
    "            '{first_name2} is {a:prof}. {first_name} is not.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fba91de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Bob is not an accountant. Helen is.', 'Who is an accountant?') , pred: Bob , label: Helen\n",
      "  [2] ('Bob is not an accountant. Helen is.', 'Who is not an accountant?') , pred: Bob , label: Bob\n",
      "  [3] ('Helen is an accountant. Bob is not.', 'Who is an accountant?') , pred: Helen , label: Helen\n",
      "  [4] ('Helen is an accountant. Bob is not.', 'Who is not an accountant?') , pred: Bob , label: Bob\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_context_negation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f84d7436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1980 examples\n",
      "Test cases:      495\n",
      "Fails (rate):    487 (98.4%)\n",
      "\n",
      "Example fails:\n",
      "C: Robin is not an investor. Tony is.\n",
      "Q: Who is an investor?\n",
      "A: Tony\n",
      "P: Robin\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "name = 'Negation in context, may or may not be in question'\n",
    "test = MFT(**t_context_negation, expect=expect_squad, capability='Negation', name=name, description='' )\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a3c75e",
   "metadata": {},
   "source": [
    "### 3. Negation in Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be0bb69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_question_negation = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {a:prof}. {first_name2} is {a:prof2}.',\n",
    "            '{first_name2} is {a:prof2}. {first_name} is {a:prof}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof2}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10697847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Amanda is an administrator. Jill is an organizer.', 'Who is an administrator?') , pred: Amanda , label: Amanda\n",
      "  [2] ('Amanda is an administrator. Jill is an organizer.', 'Who is not an administrator?') , pred: Amanda , label: Jill\n",
      "  [3] ('Amanda is an administrator. Jill is an organizer.', 'Who is an organizer?') , pred: Jill , label: Jill\n",
      "  [4] ('Amanda is an administrator. Jill is an organizer.', 'Who is not an organizer?') , pred: Jill , label: Amanda\n",
      "  [5] ('Jill is an organizer. Amanda is an administrator.', 'Who is an administrator?') , pred: Amanda , label: Amanda\n",
      "  [6] ('Jill is an organizer. Amanda is an administrator.', 'Who is not an administrator?') , pred: Amanda , label: Jill\n",
      "  [7] ('Jill is an organizer. Amanda is an administrator.', 'Who is an organizer?') , pred: Jill , label: Jill\n",
      "  [8] ('Jill is an organizer. Amanda is an administrator.', 'Who is not an organizer?') , pred: Jill , label: Amanda\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "show_example(t_question_negation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "333ce971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 3912 examples\n",
      "Test cases:      489\n",
      "Fails (rate):    489 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Walter is an entrepreneur. Frances is an architect.\n",
      "Q: Who is not an entrepreneur?\n",
      "A: Frances\n",
      "P: Walter\n",
      "\n",
      "C: Walter is an entrepreneur. Frances is an architect.\n",
      "Q: Who is not an architect?\n",
      "A: Walter\n",
      "P: Frances\n",
      "\n",
      "C: Frances is an architect. Walter is an entrepreneur.\n",
      "Q: Who is not an entrepreneur?\n",
      "A: Frances\n",
      "P: Walter\n",
      "\n",
      "\n",
      "----\n",
      "C: Jonathan is a model. Richard is a journalist.\n",
      "Q: Who is not a model?\n",
      "A: Richard\n",
      "P: Jonathan\n",
      "\n",
      "C: Jonathan is a model. Richard is a journalist.\n",
      "Q: Who is not a journalist?\n",
      "A: Jonathan\n",
      "P: Richard\n",
      "\n",
      "C: Richard is a journalist. Jonathan is a model.\n",
      "Q: Who is not a model?\n",
      "A: Richard\n",
      "P: Jonathan\n",
      "\n",
      "\n",
      "----\n",
      "C: Gary is an entrepreneur. Larry is a waitress.\n",
      "Q: Who is not an entrepreneur?\n",
      "A: Larry\n",
      "P: Gary\n",
      "\n",
      "C: Gary is an entrepreneur. Larry is a waitress.\n",
      "Q: Who is not a waitress?\n",
      "A: Gary\n",
      "P: Larry\n",
      "\n",
      "C: Larry is a waitress. Gary is an entrepreneur.\n",
      "Q: Who is not an entrepreneur?\n",
      "A: Larry\n",
      "P: Gary\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Negation in question only.'\n",
    "test = MFT(**t_question_negation, expect=expect_squad, capability='Negation', name=name, description='' )\n",
    "test.run(model_predictor)\n",
    "test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1326ba4",
   "metadata": {},
   "source": [
    "## <a id=\"Coref\" /> <font color='yellow'> Coref </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b51294",
   "metadata": {},
   "source": [
    "### 1. He/she coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b7df953",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'actress' in professions:\n",
    "    professions.remove('actress')\n",
    "\n",
    "t_he_she_coref = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{male} and {female} are friends. He is {a:prof1}, and she is {a:prof2}.',\n",
    "            '{female} and {male} are friends. He is {a:prof1}, and she is {a:prof2}.',\n",
    "            '{male} and {female} are friends. She is {a:prof2}, and he is {a:prof1}.',\n",
    "            '{female} and {male} are friends. She is {a:prof2}, and he is {a:prof1}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof1}?',\n",
    "                '{male}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{female}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "70595b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Donald and Emily are friends. He is an editor, and she is an executive.', 'Who is an editor?') , pred: Donald and Emily , label: Donald\n",
      "  [2] ('Donald and Emily are friends. He is an editor, and she is an executive.', 'Who is an executive?') , pred: Donald and Emily , label: Emily\n",
      "  [3] ('Emily and Donald are friends. He is an editor, and she is an executive.', 'Who is an editor?') , pred: Emily and Donald , label: Donald\n",
      "  [4] ('Emily and Donald are friends. He is an editor, and she is an executive.', 'Who is an executive?') , pred: Emily and Donald , label: Emily\n",
      "  [5] ('Donald and Emily are friends. She is an executive, and he is an editor.', 'Who is an editor?') , pred: Donald and Emily , label: Donald\n",
      "  [6] ('Donald and Emily are friends. She is an executive, and he is an editor.', 'Who is an executive?') , pred: Donald and Emily , label: Emily\n",
      "  [7] ('Emily and Donald are friends. She is an executive, and he is an editor.', 'Who is an editor?') , pred: Emily and Donald , label: Donald\n",
      "  [8] ('Emily and Donald are friends. She is an executive, and he is an editor.', 'Who is an executive?') , pred: Emily and Donald , label: Emily\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_he_she_coref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f65eaeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 3808 examples\n",
      "Test cases:      476\n",
      "Fails (rate):    476 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Ian and Stephanie are friends. He is a producer, and she is an editor.\n",
      "Q: Who is a producer?\n",
      "A: Ian\n",
      "P: Ian and Stephanie\n",
      "\n",
      "C: Ian and Stephanie are friends. He is a producer, and she is an editor.\n",
      "Q: Who is an editor?\n",
      "A: Stephanie\n",
      "P: Ian and Stephanie\n",
      "\n",
      "C: Stephanie and Ian are friends. He is a producer, and she is an editor.\n",
      "Q: Who is a producer?\n",
      "A: Ian\n",
      "P: Stephanie and Ian\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Basic coref, he / she'\n",
    "test = MFT(**t_he_she_coref, expect=expect_squad, name=name, description='', capability='Coref')\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcd0745",
   "metadata": {},
   "source": [
    "### 2. His/Her coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22ddda5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_his_her = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{male} and {female} are friends. His mom is {a:prof}.',\n",
    "            '{female} and {male} are friends. His mom is {a:prof}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Whose mom is {a:prof}?',\n",
    "                '{male}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=250,\n",
    "    ))\n",
    "t_his_her += crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{male} and {female} are friends. Her mom is {a:prof}.',\n",
    "            '{female} and {male} are friends. Her mom is {a:prof}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Whose mom is {a:prof}?',\n",
    "                '{female}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=250,\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9aaa5a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Steven and Kelly are friends. His mom is an actor.', 'Whose mom is an actor?') , pred: Steven and Kelly , label: Steven\n",
      "  [2] ('Kelly and Steven are friends. His mom is an actor.', 'Whose mom is an actor?') , pred: Kelly and Steven , label: Steven\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_his_her)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f3adae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1000 examples\n",
      "Test cases:      500\n",
      "Fails (rate):    500 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Samuel and Lucy are friends. His mom is an entrepreneur.\n",
      "Q: Whose mom is an entrepreneur?\n",
      "A: Samuel\n",
      "P: Samuel and Lucy\n",
      "\n",
      "C: Lucy and Samuel are friends. His mom is an entrepreneur.\n",
      "Q: Whose mom is an entrepreneur?\n",
      "A: Samuel\n",
      "P: Lucy and Samuel\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Basic coref, his / her'\n",
    "test = MFT(**t_his_her, expect=expect_squad, name=name, description='', capability='Coref')\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175dbb79",
   "metadata": {},
   "source": [
    "### 3. Former and Latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c34dfc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_former_latter = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} and {first_name2} are friends. The former is {a:prof1}.',\n",
    "            '{first_name2} and {first_name} are friends. The latter is {a:prof1}.',\n",
    "            '{first_name} and {first_name2} are friends. The former is {a:prof1} and the latter is {a:prof2}.',\n",
    "            '{first_name2} and {first_name} are friends. The former is {a:prof2} and the latter is {a:prof1}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof1}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02abdb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] ('Jean and Karen are friends. The former is an interpreter.', 'Who is an interpreter?') , pred: Jean and Karen , label: Jean\n",
      "  [2] ('Karen and Jean are friends. The latter is an interpreter.', 'Who is an interpreter?') , pred: Karen and Jean are friends , label: Jean\n",
      "  [3] ('Jean and Karen are friends. The former is an interpreter and the latter is an activist.', 'Who is an interpreter?') , pred: Jean and Karen , label: Jean\n",
      "  [4] ('Karen and Jean are friends. The former is an activist and the latter is an interpreter.', 'Who is an interpreter?') , pred: Karen and Jean , label: Jean\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "show_example(t_former_latter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa437c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1928 examples\n",
      "Test cases:      482\n",
      "Fails (rate):    482 (100.0%)\n",
      "\n",
      "Example fails:\n",
      "C: Alice and Edward are friends. The former is an organizer.\n",
      "Q: Who is an organizer?\n",
      "A: Alice\n",
      "P: Alice and Edward\n",
      "\n",
      "C: Edward and Alice are friends. The latter is an organizer.\n",
      "Q: Who is an organizer?\n",
      "A: Alice\n",
      "P: Edward and Alice\n",
      "\n",
      "C: Alice and Edward are friends. The former is an organizer and the latter is an architect.\n",
      "Q: Who is an organizer?\n",
      "A: Alice\n",
      "P: Alice and Edward are friends. The former is an organizer and the latter is an architect\n",
      "\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "name = 'Former / Latter'\n",
    "test = MFT(**t_former_latter, expect=expect_squad, name=name, description='', capability='Coref')\n",
    "test.run(model_predictor)\n",
    "test.summary(n=1, format_example_fn=format_squad_with_context)\n",
    "suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7d996ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suite.summary(n=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9f86d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_suite=get_summary(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fa080659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Test Name                                          |   Total Cases |   Example Per Case |   Failures | Failure Rate   |\n",
       "|----------------------------------------------------|---------------|--------------------|------------|----------------|\n",
       "| Comparisons                                        |           498 |                  2 |        498 | 100.00%        |\n",
       "| Intensifiers                                       |           499 |                 12 |        499 | 100.00%        |\n",
       "| Properites                                         |           500 |                  4 |        499 | 99.80%         |\n",
       "| Profession vs nationality                          |           500 |                 10 |        260 | 52.00%         |\n",
       "| Animal vs Vehicle                                  |           500 |                  4 |        495 | 99.00%         |\n",
       "| Animal vs Vehicle v2                               |           499 |                  4 |        266 | 53.31%         |\n",
       "| Synonyms                                           |           458 |                  4 |         21 | 4.59%          |\n",
       "| Antonyms                                           |           498 |                  4 |        498 | 100.00%        |\n",
       "| Antonyms Comparison                                |           499 |                 16 |        499 | 100.00%        |\n",
       "| There was a change in profession                   |           485 |                  2 |         10 | 2.06%          |\n",
       "| Time Difference                                    |           497 |                  4 |        497 | 100.00%        |\n",
       "| Negation in context, may or may not be in question |           495 |                  4 |        487 | 98.38%         |\n",
       "| Negation in question only.                         |           489 |                  8 |        489 | 100.00%        |\n",
       "| Basic coref, he / she                              |           476 |                  8 |        476 | 100.00%        |\n",
       "| Basic coref, his / her                             |           500 |                  2 |        500 | 100.00%        |\n",
       "| Former / Latter                                    |           482 |                  4 |        482 | 100.00%        |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_and_export_mdtable(df_suite, do_export=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d152a628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved 45374 rows to {output_file}.\n"
     ]
    }
   ],
   "source": [
    "export_suite_to_jsonl(suite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

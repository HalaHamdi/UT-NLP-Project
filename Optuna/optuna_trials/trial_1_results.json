{
  "trial_number": 1,
  "hyperparameters": {
    "learning_rate": 1.4700695830624907e-05,
    "per_device_train_batch_size": 8,
    "num_train_epochs": 2,
    "warmup_steps": 67,
    "per_device_eval_batch_size": 32
  },
  "best_f1": 83.33020674717997,
  "all_eval_f1_scores": [
    82.28023536176272,
    82.28023536176272,
    83.33020674717997,
    83.33020674717997
  ],
  "training_logs": [
    {
      "loss": 6.2168,
      "grad_norm": 6.110471725463867,
      "learning_rate": 1.0751255159710752e-05,
      "epoch": 0.002206531332744925,
      "step": 50
    },
    {
      "loss": 5.2135,
      "grad_norm": 7.989681243896484,
      "learning_rate": 1.4690300447631956e-05,
      "epoch": 0.00441306266548985,
      "step": 100
    },
    {
      "loss": 4.222,
      "grad_norm": 6.7762579917907715,
      "learning_rate": 1.467405766170547e-05,
      "epoch": 0.006619593998234775,
      "step": 150
    },
    {
      "loss": 3.6245,
      "grad_norm": 7.979050159454346,
      "learning_rate": 1.4657814875778986e-05,
      "epoch": 0.0088261253309797,
      "step": 200
    },
    {
      "loss": 3.4235,
      "grad_norm": 7.502691268920898,
      "learning_rate": 1.46415720898525e-05,
      "epoch": 0.011032656663724626,
      "step": 250
    },
    {
      "loss": 3.1256,
      "grad_norm": 8.454612731933594,
      "learning_rate": 1.4625329303926014e-05,
      "epoch": 0.01323918799646955,
      "step": 300
    },
    {
      "loss": 3.3149,
      "grad_norm": 16.44761848449707,
      "learning_rate": 1.460908651799953e-05,
      "epoch": 0.015445719329214475,
      "step": 350
    },
    {
      "loss": 3.1576,
      "grad_norm": 12.983197212219238,
      "learning_rate": 1.4592843732073044e-05,
      "epoch": 0.0176522506619594,
      "step": 400
    },
    {
      "loss": 2.9725,
      "grad_norm": 11.159276008605957,
      "learning_rate": 1.4576600946146558e-05,
      "epoch": 0.019858781994704325,
      "step": 450
    },
    {
      "loss": 2.8189,
      "grad_norm": 15.5265474319458,
      "learning_rate": 1.4560358160220074e-05,
      "epoch": 0.02206531332744925,
      "step": 500
    },
    {
      "loss": 2.7573,
      "grad_norm": 18.821121215820312,
      "learning_rate": 1.4544115374293588e-05,
      "epoch": 0.024271844660194174,
      "step": 550
    },
    {
      "loss": 2.7156,
      "grad_norm": 11.785593032836914,
      "learning_rate": 1.4527872588367102e-05,
      "epoch": 0.0264783759929391,
      "step": 600
    },
    {
      "loss": 2.5371,
      "grad_norm": 18.60039710998535,
      "learning_rate": 1.4511629802440618e-05,
      "epoch": 0.028684907325684024,
      "step": 650
    },
    {
      "loss": 2.6644,
      "grad_norm": 24.461706161499023,
      "learning_rate": 1.4495387016514132e-05,
      "epoch": 0.03089143865842895,
      "step": 700
    },
    {
      "loss": 2.5142,
      "grad_norm": 27.107938766479492,
      "learning_rate": 1.4479144230587646e-05,
      "epoch": 0.03309796999117388,
      "step": 750
    },
    {
      "loss": 2.6211,
      "grad_norm": 19.71525001525879,
      "learning_rate": 1.446290144466116e-05,
      "epoch": 0.0353045013239188,
      "step": 800
    },
    {
      "loss": 2.5154,
      "grad_norm": 17.726333618164062,
      "learning_rate": 1.4446658658734676e-05,
      "epoch": 0.03751103265666372,
      "step": 850
    },
    {
      "loss": 2.5267,
      "grad_norm": 15.647836685180664,
      "learning_rate": 1.443041587280819e-05,
      "epoch": 0.03971756398940865,
      "step": 900
    },
    {
      "loss": 2.458,
      "grad_norm": 13.470812797546387,
      "learning_rate": 1.4414173086881704e-05,
      "epoch": 0.041924095322153576,
      "step": 950
    },
    {
      "loss": 2.3979,
      "grad_norm": 23.796194076538086,
      "learning_rate": 1.4397930300955218e-05,
      "epoch": 0.0441306266548985,
      "step": 1000
    },
    {
      "loss": 2.291,
      "grad_norm": 22.326194763183594,
      "learning_rate": 1.4381687515028733e-05,
      "epoch": 0.04633715798764342,
      "step": 1050
    },
    {
      "loss": 2.3682,
      "grad_norm": 28.96335220336914,
      "learning_rate": 1.4365444729102248e-05,
      "epoch": 0.04854368932038835,
      "step": 1100
    },
    {
      "loss": 2.3587,
      "grad_norm": 16.5205135345459,
      "learning_rate": 1.4349201943175762e-05,
      "epoch": 0.050750220653133275,
      "step": 1150
    },
    {
      "loss": 2.56,
      "grad_norm": 21.02536392211914,
      "learning_rate": 1.4332959157249277e-05,
      "epoch": 0.0529567519858782,
      "step": 1200
    },
    {
      "loss": 2.2614,
      "grad_norm": 19.307167053222656,
      "learning_rate": 1.4316716371322791e-05,
      "epoch": 0.05516328331862312,
      "step": 1250
    },
    {
      "loss": 2.2768,
      "grad_norm": 34.571720123291016,
      "learning_rate": 1.4300473585396305e-05,
      "epoch": 0.05736981465136805,
      "step": 1300
    },
    {
      "loss": 2.2071,
      "grad_norm": 25.236753463745117,
      "learning_rate": 1.4284230799469821e-05,
      "epoch": 0.059576345984112974,
      "step": 1350
    },
    {
      "loss": 2.1752,
      "grad_norm": 19.172008514404297,
      "learning_rate": 1.4267988013543335e-05,
      "epoch": 0.0617828773168579,
      "step": 1400
    },
    {
      "loss": 2.2504,
      "grad_norm": 21.7506046295166,
      "learning_rate": 1.425174522761685e-05,
      "epoch": 0.06398940864960283,
      "step": 1450
    },
    {
      "loss": 2.3024,
      "grad_norm": 27.19388198852539,
      "learning_rate": 1.4235502441690363e-05,
      "epoch": 0.06619593998234775,
      "step": 1500
    },
    {
      "loss": 2.2096,
      "grad_norm": 23.69597625732422,
      "learning_rate": 1.4219259655763879e-05,
      "epoch": 0.06840247131509268,
      "step": 1550
    },
    {
      "loss": 2.0983,
      "grad_norm": 15.501617431640625,
      "learning_rate": 1.4203016869837393e-05,
      "epoch": 0.0706090026478376,
      "step": 1600
    },
    {
      "loss": 2.2235,
      "grad_norm": 10.842416763305664,
      "learning_rate": 1.4186774083910907e-05,
      "epoch": 0.07281553398058252,
      "step": 1650
    },
    {
      "loss": 2.2496,
      "grad_norm": 28.871164321899414,
      "learning_rate": 1.4170531297984423e-05,
      "epoch": 0.07502206531332745,
      "step": 1700
    },
    {
      "loss": 2.209,
      "grad_norm": 12.675921440124512,
      "learning_rate": 1.4154288512057937e-05,
      "epoch": 0.07722859664607237,
      "step": 1750
    },
    {
      "loss": 2.2163,
      "grad_norm": 15.520780563354492,
      "learning_rate": 1.4138045726131451e-05,
      "epoch": 0.0794351279788173,
      "step": 1800
    },
    {
      "loss": 2.1718,
      "grad_norm": 10.615499496459961,
      "learning_rate": 1.4121802940204967e-05,
      "epoch": 0.08164165931156223,
      "step": 1850
    },
    {
      "loss": 2.1905,
      "grad_norm": 23.606380462646484,
      "learning_rate": 1.4105560154278481e-05,
      "epoch": 0.08384819064430715,
      "step": 1900
    },
    {
      "loss": 2.2145,
      "grad_norm": 16.22981071472168,
      "learning_rate": 1.4089317368351995e-05,
      "epoch": 0.08605472197705208,
      "step": 1950
    },
    {
      "loss": 2.1383,
      "grad_norm": 25.57815933227539,
      "learning_rate": 1.407307458242551e-05,
      "epoch": 0.088261253309797,
      "step": 2000
    },
    {
      "loss": 2.2287,
      "grad_norm": 25.136337280273438,
      "learning_rate": 1.4056831796499025e-05,
      "epoch": 0.09046778464254192,
      "step": 2050
    },
    {
      "loss": 2.0029,
      "grad_norm": 19.581884384155273,
      "learning_rate": 1.4040589010572539e-05,
      "epoch": 0.09267431597528684,
      "step": 2100
    },
    {
      "loss": 2.1453,
      "grad_norm": 26.622861862182617,
      "learning_rate": 1.4024346224646055e-05,
      "epoch": 0.09488084730803177,
      "step": 2150
    },
    {
      "loss": 2.0689,
      "grad_norm": 12.749005317687988,
      "learning_rate": 1.4008103438719567e-05,
      "epoch": 0.0970873786407767,
      "step": 2200
    },
    {
      "loss": 2.1383,
      "grad_norm": 15.193975448608398,
      "learning_rate": 1.3991860652793083e-05,
      "epoch": 0.09929390997352162,
      "step": 2250
    },
    {
      "loss": 2.1017,
      "grad_norm": 17.30556869506836,
      "learning_rate": 1.3975617866866598e-05,
      "epoch": 0.10150044130626655,
      "step": 2300
    },
    {
      "loss": 2.0616,
      "grad_norm": 10.07156753540039,
      "learning_rate": 1.395937508094011e-05,
      "epoch": 0.10370697263901148,
      "step": 2350
    },
    {
      "loss": 2.0742,
      "grad_norm": 18.668651580810547,
      "learning_rate": 1.3943132295013627e-05,
      "epoch": 0.1059135039717564,
      "step": 2400
    },
    {
      "loss": 1.9863,
      "grad_norm": 14.34119987487793,
      "learning_rate": 1.3926889509087142e-05,
      "epoch": 0.10812003530450133,
      "step": 2450
    },
    {
      "loss": 2.1049,
      "grad_norm": 14.701542854309082,
      "learning_rate": 1.3910646723160655e-05,
      "epoch": 0.11032656663724624,
      "step": 2500
    },
    {
      "loss": 2.096,
      "grad_norm": 17.29583168029785,
      "learning_rate": 1.389440393723417e-05,
      "epoch": 0.11253309796999117,
      "step": 2550
    },
    {
      "loss": 2.1219,
      "grad_norm": 35.133853912353516,
      "learning_rate": 1.3878161151307686e-05,
      "epoch": 0.1147396293027361,
      "step": 2600
    },
    {
      "loss": 1.9824,
      "grad_norm": 26.337663650512695,
      "learning_rate": 1.3861918365381199e-05,
      "epoch": 0.11694616063548102,
      "step": 2650
    },
    {
      "loss": 1.9519,
      "grad_norm": 30.92133140563965,
      "learning_rate": 1.3845675579454714e-05,
      "epoch": 0.11915269196822595,
      "step": 2700
    },
    {
      "loss": 2.0374,
      "grad_norm": 28.897850036621094,
      "learning_rate": 1.3829432793528228e-05,
      "epoch": 0.12135922330097088,
      "step": 2750
    },
    {
      "loss": 1.9817,
      "grad_norm": 23.68856430053711,
      "learning_rate": 1.3813190007601742e-05,
      "epoch": 0.1235657546337158,
      "step": 2800
    },
    {
      "loss": 1.8954,
      "grad_norm": 11.137046813964844,
      "learning_rate": 1.3796947221675258e-05,
      "epoch": 0.12577228596646073,
      "step": 2850
    },
    {
      "loss": 2.0912,
      "grad_norm": 29.166454315185547,
      "learning_rate": 1.3780704435748772e-05,
      "epoch": 0.12797881729920565,
      "step": 2900
    },
    {
      "loss": 1.9112,
      "grad_norm": 21.689559936523438,
      "learning_rate": 1.3764461649822286e-05,
      "epoch": 0.13018534863195058,
      "step": 2950
    },
    {
      "loss": 1.9432,
      "grad_norm": 26.606348037719727,
      "learning_rate": 1.3748218863895802e-05,
      "epoch": 0.1323918799646955,
      "step": 3000
    },
    {
      "loss": 1.9808,
      "grad_norm": 21.368892669677734,
      "learning_rate": 1.3731976077969316e-05,
      "epoch": 0.13459841129744043,
      "step": 3050
    },
    {
      "loss": 1.9327,
      "grad_norm": 33.765560150146484,
      "learning_rate": 1.371573329204283e-05,
      "epoch": 0.13680494263018536,
      "step": 3100
    },
    {
      "loss": 2.0393,
      "grad_norm": 23.650634765625,
      "learning_rate": 1.3699490506116346e-05,
      "epoch": 0.13901147396293026,
      "step": 3150
    },
    {
      "loss": 1.9833,
      "grad_norm": 16.01788902282715,
      "learning_rate": 1.3683247720189858e-05,
      "epoch": 0.1412180052956752,
      "step": 3200
    },
    {
      "loss": 1.9118,
      "grad_norm": 18.97690773010254,
      "learning_rate": 1.3667004934263374e-05,
      "epoch": 0.1434245366284201,
      "step": 3250
    },
    {
      "loss": 1.9322,
      "grad_norm": 24.65421485900879,
      "learning_rate": 1.365076214833689e-05,
      "epoch": 0.14563106796116504,
      "step": 3300
    },
    {
      "loss": 2.005,
      "grad_norm": 20.61157989501953,
      "learning_rate": 1.3634519362410402e-05,
      "epoch": 0.14783759929390997,
      "step": 3350
    },
    {
      "loss": 1.9396,
      "grad_norm": 16.44845962524414,
      "learning_rate": 1.3618276576483918e-05,
      "epoch": 0.1500441306266549,
      "step": 3400
    },
    {
      "loss": 2.0161,
      "grad_norm": 18.80994987487793,
      "learning_rate": 1.3602033790557432e-05,
      "epoch": 0.15225066195939982,
      "step": 3450
    },
    {
      "loss": 1.8198,
      "grad_norm": 32.873538970947266,
      "learning_rate": 1.3585791004630946e-05,
      "epoch": 0.15445719329214475,
      "step": 3500
    },
    {
      "loss": 1.8457,
      "grad_norm": 21.96578025817871,
      "learning_rate": 1.3569548218704462e-05,
      "epoch": 0.15666372462488967,
      "step": 3550
    },
    {
      "loss": 1.966,
      "grad_norm": 24.534746170043945,
      "learning_rate": 1.3553305432777976e-05,
      "epoch": 0.1588702559576346,
      "step": 3600
    },
    {
      "loss": 1.8787,
      "grad_norm": 12.394939422607422,
      "learning_rate": 1.353706264685149e-05,
      "epoch": 0.16107678729037953,
      "step": 3650
    },
    {
      "loss": 1.9398,
      "grad_norm": 21.11183738708496,
      "learning_rate": 1.3520819860925006e-05,
      "epoch": 0.16328331862312445,
      "step": 3700
    },
    {
      "loss": 1.936,
      "grad_norm": 19.84583854675293,
      "learning_rate": 1.350457707499852e-05,
      "epoch": 0.16548984995586938,
      "step": 3750
    },
    {
      "loss": 1.8244,
      "grad_norm": 22.630592346191406,
      "learning_rate": 1.3488334289072034e-05,
      "epoch": 0.1676963812886143,
      "step": 3800
    },
    {
      "loss": 1.8464,
      "grad_norm": 27.601665496826172,
      "learning_rate": 1.347209150314555e-05,
      "epoch": 0.16990291262135923,
      "step": 3850
    },
    {
      "loss": 1.8446,
      "grad_norm": 17.462223052978516,
      "learning_rate": 1.3455848717219063e-05,
      "epoch": 0.17210944395410416,
      "step": 3900
    },
    {
      "loss": 1.8232,
      "grad_norm": 15.021284103393555,
      "learning_rate": 1.3439605931292578e-05,
      "epoch": 0.17431597528684908,
      "step": 3950
    },
    {
      "loss": 1.8567,
      "grad_norm": 24.226316452026367,
      "learning_rate": 1.3423363145366093e-05,
      "epoch": 0.176522506619594,
      "step": 4000
    },
    {
      "loss": 1.7888,
      "grad_norm": 17.45235824584961,
      "learning_rate": 1.3407120359439607e-05,
      "epoch": 0.1787290379523389,
      "step": 4050
    },
    {
      "loss": 1.8097,
      "grad_norm": 25.617708206176758,
      "learning_rate": 1.3390877573513121e-05,
      "epoch": 0.18093556928508384,
      "step": 4100
    },
    {
      "loss": 1.8051,
      "grad_norm": 26.22475814819336,
      "learning_rate": 1.3374634787586635e-05,
      "epoch": 0.18314210061782876,
      "step": 4150
    },
    {
      "loss": 1.8971,
      "grad_norm": 16.322250366210938,
      "learning_rate": 1.3358392001660151e-05,
      "epoch": 0.1853486319505737,
      "step": 4200
    },
    {
      "loss": 2.0439,
      "grad_norm": 25.85201072692871,
      "learning_rate": 1.3342149215733665e-05,
      "epoch": 0.18755516328331862,
      "step": 4250
    },
    {
      "loss": 1.68,
      "grad_norm": 29.832738876342773,
      "learning_rate": 1.332590642980718e-05,
      "epoch": 0.18976169461606354,
      "step": 4300
    },
    {
      "loss": 1.8879,
      "grad_norm": 20.08184814453125,
      "learning_rate": 1.3309663643880695e-05,
      "epoch": 0.19196822594880847,
      "step": 4350
    },
    {
      "loss": 1.6769,
      "grad_norm": 19.126388549804688,
      "learning_rate": 1.3293420857954209e-05,
      "epoch": 0.1941747572815534,
      "step": 4400
    },
    {
      "loss": 1.713,
      "grad_norm": 18.221960067749023,
      "learning_rate": 1.3277178072027723e-05,
      "epoch": 0.19638128861429832,
      "step": 4450
    },
    {
      "loss": 1.6524,
      "grad_norm": 20.374862670898438,
      "learning_rate": 1.3260935286101239e-05,
      "epoch": 0.19858781994704325,
      "step": 4500
    },
    {
      "loss": 1.7206,
      "grad_norm": 11.005546569824219,
      "learning_rate": 1.3244692500174753e-05,
      "epoch": 0.20079435127978817,
      "step": 4550
    },
    {
      "loss": 1.8111,
      "grad_norm": 16.05925178527832,
      "learning_rate": 1.3228449714248267e-05,
      "epoch": 0.2030008826125331,
      "step": 4600
    },
    {
      "loss": 1.8473,
      "grad_norm": 29.054641723632812,
      "learning_rate": 1.3212206928321783e-05,
      "epoch": 0.20520741394527803,
      "step": 4650
    },
    {
      "loss": 1.7708,
      "grad_norm": 18.211219787597656,
      "learning_rate": 1.3195964142395297e-05,
      "epoch": 0.20741394527802295,
      "step": 4700
    },
    {
      "loss": 1.8348,
      "grad_norm": 19.32350730895996,
      "learning_rate": 1.3179721356468811e-05,
      "epoch": 0.20962047661076788,
      "step": 4750
    },
    {
      "loss": 1.6026,
      "grad_norm": 25.23383903503418,
      "learning_rate": 1.3163478570542327e-05,
      "epoch": 0.2118270079435128,
      "step": 4800
    },
    {
      "loss": 1.7581,
      "grad_norm": 17.85724639892578,
      "learning_rate": 1.3147235784615839e-05,
      "epoch": 0.21403353927625773,
      "step": 4850
    },
    {
      "loss": 1.5092,
      "grad_norm": 6.975995063781738,
      "learning_rate": 1.3130992998689355e-05,
      "epoch": 0.21624007060900266,
      "step": 4900
    },
    {
      "loss": 1.7832,
      "grad_norm": 20.899349212646484,
      "learning_rate": 1.311475021276287e-05,
      "epoch": 0.21844660194174756,
      "step": 4950
    },
    {
      "loss": 1.7207,
      "grad_norm": 23.07401466369629,
      "learning_rate": 1.3098507426836383e-05,
      "epoch": 0.22065313327449249,
      "step": 5000
    },
    {
      "loss": 1.7171,
      "grad_norm": 18.914718627929688,
      "learning_rate": 1.3082264640909899e-05,
      "epoch": 0.2228596646072374,
      "step": 5050
    },
    {
      "loss": 1.8249,
      "grad_norm": 13.251886367797852,
      "learning_rate": 1.3066021854983413e-05,
      "epoch": 0.22506619593998234,
      "step": 5100
    },
    {
      "loss": 1.5751,
      "grad_norm": 24.885221481323242,
      "learning_rate": 1.3049779069056927e-05,
      "epoch": 0.22727272727272727,
      "step": 5150
    },
    {
      "loss": 1.6044,
      "grad_norm": 22.185104370117188,
      "learning_rate": 1.3033536283130442e-05,
      "epoch": 0.2294792586054722,
      "step": 5200
    },
    {
      "loss": 1.5959,
      "grad_norm": 37.92963409423828,
      "learning_rate": 1.3017293497203957e-05,
      "epoch": 0.23168578993821712,
      "step": 5250
    },
    {
      "loss": 1.7597,
      "grad_norm": 20.758445739746094,
      "learning_rate": 1.300105071127747e-05,
      "epoch": 0.23389232127096204,
      "step": 5300
    },
    {
      "loss": 1.843,
      "grad_norm": 7.49424409866333,
      "learning_rate": 1.2984807925350986e-05,
      "epoch": 0.23609885260370697,
      "step": 5350
    },
    {
      "loss": 1.6222,
      "grad_norm": 17.723691940307617,
      "learning_rate": 1.29685651394245e-05,
      "epoch": 0.2383053839364519,
      "step": 5400
    },
    {
      "loss": 1.6787,
      "grad_norm": 23.3533935546875,
      "learning_rate": 1.2952322353498014e-05,
      "epoch": 0.24051191526919682,
      "step": 5450
    },
    {
      "loss": 1.5795,
      "grad_norm": 15.778388023376465,
      "learning_rate": 1.293607956757153e-05,
      "epoch": 0.24271844660194175,
      "step": 5500
    },
    {
      "loss": 1.6828,
      "grad_norm": 18.886695861816406,
      "learning_rate": 1.2919836781645043e-05,
      "epoch": 0.24492497793468668,
      "step": 5550
    },
    {
      "loss": 1.7476,
      "grad_norm": 31.743961334228516,
      "learning_rate": 1.2903593995718558e-05,
      "epoch": 0.2471315092674316,
      "step": 5600
    },
    {
      "loss": 1.6697,
      "grad_norm": 21.876134872436523,
      "learning_rate": 1.2887351209792074e-05,
      "epoch": 0.24933804060017653,
      "step": 5650
    },
    {
      "loss": 1.7648,
      "grad_norm": 20.336101531982422,
      "learning_rate": 1.2871108423865586e-05,
      "epoch": 0.25154457193292146,
      "step": 5700
    },
    {
      "loss": 1.7836,
      "grad_norm": 15.338360786437988,
      "learning_rate": 1.2854865637939102e-05,
      "epoch": 0.25375110326566636,
      "step": 5750
    },
    {
      "loss": 1.662,
      "grad_norm": 18.535289764404297,
      "learning_rate": 1.2838622852012618e-05,
      "epoch": 0.2559576345984113,
      "step": 5800
    },
    {
      "loss": 1.5409,
      "grad_norm": 17.190628051757812,
      "learning_rate": 1.282238006608613e-05,
      "epoch": 0.2581641659311562,
      "step": 5850
    },
    {
      "loss": 1.6304,
      "grad_norm": 17.106708526611328,
      "learning_rate": 1.2806137280159646e-05,
      "epoch": 0.26037069726390116,
      "step": 5900
    },
    {
      "loss": 1.6637,
      "grad_norm": 19.784608840942383,
      "learning_rate": 1.2789894494233162e-05,
      "epoch": 0.26257722859664606,
      "step": 5950
    },
    {
      "loss": 1.7164,
      "grad_norm": 17.105329513549805,
      "learning_rate": 1.2773651708306674e-05,
      "epoch": 0.264783759929391,
      "step": 6000
    },
    {
      "loss": 1.646,
      "grad_norm": 28.094390869140625,
      "learning_rate": 1.275740892238019e-05,
      "epoch": 0.2669902912621359,
      "step": 6050
    },
    {
      "loss": 1.7692,
      "grad_norm": 21.51331901550293,
      "learning_rate": 1.2741166136453706e-05,
      "epoch": 0.26919682259488087,
      "step": 6100
    },
    {
      "loss": 1.4991,
      "grad_norm": 39.10862731933594,
      "learning_rate": 1.2724923350527218e-05,
      "epoch": 0.27140335392762577,
      "step": 6150
    },
    {
      "loss": 1.6624,
      "grad_norm": 16.49273109436035,
      "learning_rate": 1.2708680564600734e-05,
      "epoch": 0.2736098852603707,
      "step": 6200
    },
    {
      "loss": 1.6896,
      "grad_norm": 18.119794845581055,
      "learning_rate": 1.2692437778674248e-05,
      "epoch": 0.2758164165931156,
      "step": 6250
    },
    {
      "loss": 1.6528,
      "grad_norm": 18.64816665649414,
      "learning_rate": 1.2676194992747762e-05,
      "epoch": 0.2780229479258605,
      "step": 6300
    },
    {
      "loss": 1.7106,
      "grad_norm": 30.193593978881836,
      "learning_rate": 1.2659952206821278e-05,
      "epoch": 0.2802294792586055,
      "step": 6350
    },
    {
      "loss": 1.4923,
      "grad_norm": 26.412975311279297,
      "learning_rate": 1.2643709420894792e-05,
      "epoch": 0.2824360105913504,
      "step": 6400
    },
    {
      "loss": 1.4327,
      "grad_norm": 13.714276313781738,
      "learning_rate": 1.2627466634968306e-05,
      "epoch": 0.2846425419240953,
      "step": 6450
    },
    {
      "loss": 1.5271,
      "grad_norm": 25.503616333007812,
      "learning_rate": 1.2611223849041821e-05,
      "epoch": 0.2868490732568402,
      "step": 6500
    },
    {
      "loss": 1.5816,
      "grad_norm": 21.64668083190918,
      "learning_rate": 1.2594981063115336e-05,
      "epoch": 0.2890556045895852,
      "step": 6550
    },
    {
      "loss": 1.5691,
      "grad_norm": 29.861377716064453,
      "learning_rate": 1.257873827718885e-05,
      "epoch": 0.2912621359223301,
      "step": 6600
    },
    {
      "loss": 1.4969,
      "grad_norm": 20.556522369384766,
      "learning_rate": 1.2562495491262365e-05,
      "epoch": 0.29346866725507503,
      "step": 6650
    },
    {
      "loss": 1.5077,
      "grad_norm": 31.18105697631836,
      "learning_rate": 1.254625270533588e-05,
      "epoch": 0.29567519858781993,
      "step": 6700
    },
    {
      "loss": 1.6935,
      "grad_norm": 20.013181686401367,
      "learning_rate": 1.2530009919409393e-05,
      "epoch": 0.2978817299205649,
      "step": 6750
    },
    {
      "loss": 1.4731,
      "grad_norm": 30.129369735717773,
      "learning_rate": 1.251376713348291e-05,
      "epoch": 0.3000882612533098,
      "step": 6800
    },
    {
      "loss": 1.4724,
      "grad_norm": 21.19291114807129,
      "learning_rate": 1.2497524347556423e-05,
      "epoch": 0.30229479258605474,
      "step": 6850
    },
    {
      "loss": 1.5156,
      "grad_norm": 8.670161247253418,
      "learning_rate": 1.2481281561629937e-05,
      "epoch": 0.30450132391879964,
      "step": 6900
    },
    {
      "loss": 1.3802,
      "grad_norm": 15.022604942321777,
      "learning_rate": 1.2465038775703451e-05,
      "epoch": 0.3067078552515446,
      "step": 6950
    },
    {
      "loss": 1.5593,
      "grad_norm": 18.542783737182617,
      "learning_rate": 1.2448795989776967e-05,
      "epoch": 0.3089143865842895,
      "step": 7000
    },
    {
      "loss": 1.4995,
      "grad_norm": 21.890439987182617,
      "learning_rate": 1.2432553203850481e-05,
      "epoch": 0.31112091791703445,
      "step": 7050
    },
    {
      "loss": 1.4877,
      "grad_norm": 17.39307975769043,
      "learning_rate": 1.2416310417923995e-05,
      "epoch": 0.31332744924977934,
      "step": 7100
    },
    {
      "loss": 1.5384,
      "grad_norm": 24.739768981933594,
      "learning_rate": 1.2400067631997511e-05,
      "epoch": 0.3155339805825243,
      "step": 7150
    },
    {
      "loss": 1.4409,
      "grad_norm": 20.601327896118164,
      "learning_rate": 1.2383824846071025e-05,
      "epoch": 0.3177405119152692,
      "step": 7200
    },
    {
      "loss": 1.3723,
      "grad_norm": 17.854873657226562,
      "learning_rate": 1.2367582060144539e-05,
      "epoch": 0.3199470432480141,
      "step": 7250
    },
    {
      "loss": 1.6039,
      "grad_norm": 27.236806869506836,
      "learning_rate": 1.2351339274218053e-05,
      "epoch": 0.32215357458075905,
      "step": 7300
    },
    {
      "loss": 1.5009,
      "grad_norm": 18.286296844482422,
      "learning_rate": 1.2335096488291569e-05,
      "epoch": 0.32436010591350395,
      "step": 7350
    },
    {
      "loss": 1.6257,
      "grad_norm": 13.664302825927734,
      "learning_rate": 1.2318853702365083e-05,
      "epoch": 0.3265666372462489,
      "step": 7400
    },
    {
      "loss": 1.4496,
      "grad_norm": 20.070629119873047,
      "learning_rate": 1.2302610916438597e-05,
      "epoch": 0.3287731685789938,
      "step": 7450
    },
    {
      "loss": 1.5758,
      "grad_norm": 23.46717071533203,
      "learning_rate": 1.2286368130512113e-05,
      "epoch": 0.33097969991173876,
      "step": 7500
    },
    {
      "loss": 1.543,
      "grad_norm": 15.710832595825195,
      "learning_rate": 1.2270125344585627e-05,
      "epoch": 0.33318623124448365,
      "step": 7550
    },
    {
      "loss": 1.4883,
      "grad_norm": 39.55313491821289,
      "learning_rate": 1.2253882558659141e-05,
      "epoch": 0.3353927625772286,
      "step": 7600
    },
    {
      "loss": 1.4681,
      "grad_norm": 24.700666427612305,
      "learning_rate": 1.2237639772732655e-05,
      "epoch": 0.3375992939099735,
      "step": 7650
    },
    {
      "loss": 1.5211,
      "grad_norm": 19.239105224609375,
      "learning_rate": 1.222139698680617e-05,
      "epoch": 0.33980582524271846,
      "step": 7700
    },
    {
      "loss": 1.5677,
      "grad_norm": 32.587677001953125,
      "learning_rate": 1.2205154200879685e-05,
      "epoch": 0.34201235657546336,
      "step": 7750
    },
    {
      "loss": 1.5,
      "grad_norm": 12.523279190063477,
      "learning_rate": 1.2188911414953199e-05,
      "epoch": 0.3442188879082083,
      "step": 7800
    },
    {
      "loss": 1.2965,
      "grad_norm": 20.545347213745117,
      "learning_rate": 1.2172668629026715e-05,
      "epoch": 0.3464254192409532,
      "step": 7850
    },
    {
      "loss": 1.4296,
      "grad_norm": 20.503414154052734,
      "learning_rate": 1.2156425843100229e-05,
      "epoch": 0.34863195057369817,
      "step": 7900
    },
    {
      "loss": 1.4675,
      "grad_norm": 29.49596405029297,
      "learning_rate": 1.2140183057173743e-05,
      "epoch": 0.35083848190644307,
      "step": 7950
    },
    {
      "loss": 1.5419,
      "grad_norm": 16.269250869750977,
      "learning_rate": 1.2123940271247258e-05,
      "epoch": 0.353045013239188,
      "step": 8000
    },
    {
      "loss": 1.3956,
      "grad_norm": 20.184419631958008,
      "learning_rate": 1.2107697485320772e-05,
      "epoch": 0.3552515445719329,
      "step": 8050
    },
    {
      "loss": 1.4571,
      "grad_norm": 16.670137405395508,
      "learning_rate": 1.2091454699394287e-05,
      "epoch": 0.3574580759046778,
      "step": 8100
    },
    {
      "loss": 1.5836,
      "grad_norm": 18.87906837463379,
      "learning_rate": 1.2075211913467802e-05,
      "epoch": 0.3596646072374228,
      "step": 8150
    },
    {
      "loss": 1.6308,
      "grad_norm": 29.11574363708496,
      "learning_rate": 1.2058969127541316e-05,
      "epoch": 0.36187113857016767,
      "step": 8200
    },
    {
      "loss": 1.464,
      "grad_norm": 14.771878242492676,
      "learning_rate": 1.204272634161483e-05,
      "epoch": 0.3640776699029126,
      "step": 8250
    },
    {
      "loss": 1.4021,
      "grad_norm": 14.61635684967041,
      "learning_rate": 1.2026483555688346e-05,
      "epoch": 0.3662842012356575,
      "step": 8300
    },
    {
      "loss": 1.5734,
      "grad_norm": 13.063151359558105,
      "learning_rate": 1.2010240769761858e-05,
      "epoch": 0.3684907325684025,
      "step": 8350
    },
    {
      "loss": 1.4495,
      "grad_norm": 31.25999641418457,
      "learning_rate": 1.1993997983835374e-05,
      "epoch": 0.3706972639011474,
      "step": 8400
    },
    {
      "loss": 1.5995,
      "grad_norm": 18.421724319458008,
      "learning_rate": 1.197775519790889e-05,
      "epoch": 0.37290379523389233,
      "step": 8450
    },
    {
      "loss": 1.4481,
      "grad_norm": 12.04399585723877,
      "learning_rate": 1.1961512411982402e-05,
      "epoch": 0.37511032656663723,
      "step": 8500
    },
    {
      "loss": 1.359,
      "grad_norm": 22.651918411254883,
      "learning_rate": 1.1945269626055918e-05,
      "epoch": 0.3773168578993822,
      "step": 8550
    },
    {
      "loss": 1.5448,
      "grad_norm": 14.461289405822754,
      "learning_rate": 1.1929026840129434e-05,
      "epoch": 0.3795233892321271,
      "step": 8600
    },
    {
      "loss": 1.4739,
      "grad_norm": 22.59820556640625,
      "learning_rate": 1.1912784054202946e-05,
      "epoch": 0.38172992056487204,
      "step": 8650
    },
    {
      "loss": 1.3865,
      "grad_norm": 17.22809410095215,
      "learning_rate": 1.1896541268276462e-05,
      "epoch": 0.38393645189761694,
      "step": 8700
    },
    {
      "loss": 1.6123,
      "grad_norm": 22.909591674804688,
      "learning_rate": 1.1880298482349978e-05,
      "epoch": 0.3861429832303619,
      "step": 8750
    },
    {
      "loss": 1.4247,
      "grad_norm": 23.187955856323242,
      "learning_rate": 1.186405569642349e-05,
      "epoch": 0.3883495145631068,
      "step": 8800
    },
    {
      "loss": 1.357,
      "grad_norm": 26.300613403320312,
      "learning_rate": 1.1847812910497006e-05,
      "epoch": 0.39055604589585174,
      "step": 8850
    },
    {
      "loss": 1.4817,
      "grad_norm": 17.827774047851562,
      "learning_rate": 1.183157012457052e-05,
      "epoch": 0.39276257722859664,
      "step": 8900
    },
    {
      "loss": 1.4381,
      "grad_norm": 16.741275787353516,
      "learning_rate": 1.1815327338644034e-05,
      "epoch": 0.3949691085613416,
      "step": 8950
    },
    {
      "loss": 1.4019,
      "grad_norm": 18.72136878967285,
      "learning_rate": 1.179908455271755e-05,
      "epoch": 0.3971756398940865,
      "step": 9000
    },
    {
      "loss": 1.5272,
      "grad_norm": 27.072847366333008,
      "learning_rate": 1.1782841766791064e-05,
      "epoch": 0.3993821712268314,
      "step": 9050
    },
    {
      "loss": 1.4182,
      "grad_norm": 19.266712188720703,
      "learning_rate": 1.1766598980864578e-05,
      "epoch": 0.40158870255957635,
      "step": 9100
    },
    {
      "loss": 1.2966,
      "grad_norm": 24.091699600219727,
      "learning_rate": 1.1750356194938094e-05,
      "epoch": 0.40379523389232125,
      "step": 9150
    },
    {
      "loss": 1.4746,
      "grad_norm": 13.63086223602295,
      "learning_rate": 1.1734113409011608e-05,
      "epoch": 0.4060017652250662,
      "step": 9200
    },
    {
      "loss": 1.3221,
      "grad_norm": 28.187612533569336,
      "learning_rate": 1.1717870623085122e-05,
      "epoch": 0.4082082965578111,
      "step": 9250
    },
    {
      "loss": 1.459,
      "grad_norm": 15.362814903259277,
      "learning_rate": 1.1701627837158637e-05,
      "epoch": 0.41041482789055606,
      "step": 9300
    },
    {
      "loss": 1.557,
      "grad_norm": 29.70057487487793,
      "learning_rate": 1.168538505123215e-05,
      "epoch": 0.41262135922330095,
      "step": 9350
    },
    {
      "loss": 1.5486,
      "grad_norm": 16.79754066467285,
      "learning_rate": 1.1669142265305666e-05,
      "epoch": 0.4148278905560459,
      "step": 9400
    },
    {
      "loss": 1.3875,
      "grad_norm": 38.56063461303711,
      "learning_rate": 1.1652899479379181e-05,
      "epoch": 0.4170344218887908,
      "step": 9450
    },
    {
      "loss": 1.5412,
      "grad_norm": 25.364816665649414,
      "learning_rate": 1.1636656693452694e-05,
      "epoch": 0.41924095322153576,
      "step": 9500
    },
    {
      "loss": 1.5628,
      "grad_norm": 26.261770248413086,
      "learning_rate": 1.162041390752621e-05,
      "epoch": 0.42144748455428066,
      "step": 9550
    },
    {
      "loss": 1.5394,
      "grad_norm": 22.50493049621582,
      "learning_rate": 1.1604171121599723e-05,
      "epoch": 0.4236540158870256,
      "step": 9600
    },
    {
      "loss": 1.3677,
      "grad_norm": 21.82549285888672,
      "learning_rate": 1.1587928335673237e-05,
      "epoch": 0.4258605472197705,
      "step": 9650
    },
    {
      "loss": 1.5088,
      "grad_norm": 28.48146629333496,
      "learning_rate": 1.1571685549746753e-05,
      "epoch": 0.42806707855251547,
      "step": 9700
    },
    {
      "loss": 1.3474,
      "grad_norm": 14.278905868530273,
      "learning_rate": 1.1555442763820267e-05,
      "epoch": 0.43027360988526037,
      "step": 9750
    },
    {
      "loss": 1.4424,
      "grad_norm": 20.61680793762207,
      "learning_rate": 1.1539199977893781e-05,
      "epoch": 0.4324801412180053,
      "step": 9800
    },
    {
      "loss": 1.489,
      "grad_norm": 26.686681747436523,
      "learning_rate": 1.1522957191967297e-05,
      "epoch": 0.4346866725507502,
      "step": 9850
    },
    {
      "loss": 1.4392,
      "grad_norm": 23.264822006225586,
      "learning_rate": 1.1506714406040811e-05,
      "epoch": 0.4368932038834951,
      "step": 9900
    },
    {
      "loss": 1.3152,
      "grad_norm": 24.151336669921875,
      "learning_rate": 1.1490471620114325e-05,
      "epoch": 0.4390997352162401,
      "step": 9950
    },
    {
      "loss": 1.4873,
      "grad_norm": 22.6091251373291,
      "learning_rate": 1.1474228834187841e-05,
      "epoch": 0.44130626654898497,
      "step": 10000
    },
    {
      "loss": 1.5753,
      "grad_norm": 14.334115028381348,
      "learning_rate": 1.1457986048261355e-05,
      "epoch": 0.4435127978817299,
      "step": 10050
    },
    {
      "loss": 1.4323,
      "grad_norm": 20.863590240478516,
      "learning_rate": 1.1441743262334869e-05,
      "epoch": 0.4457193292144748,
      "step": 10100
    },
    {
      "loss": 1.3323,
      "grad_norm": 29.44125747680664,
      "learning_rate": 1.1425500476408385e-05,
      "epoch": 0.4479258605472198,
      "step": 10150
    },
    {
      "loss": 1.385,
      "grad_norm": 20.653268814086914,
      "learning_rate": 1.1409257690481899e-05,
      "epoch": 0.4501323918799647,
      "step": 10200
    },
    {
      "loss": 1.4443,
      "grad_norm": 28.610746383666992,
      "learning_rate": 1.1393014904555413e-05,
      "epoch": 0.45233892321270963,
      "step": 10250
    },
    {
      "loss": 1.3202,
      "grad_norm": 37.220882415771484,
      "learning_rate": 1.1376772118628927e-05,
      "epoch": 0.45454545454545453,
      "step": 10300
    },
    {
      "loss": 1.4315,
      "grad_norm": 14.7789945602417,
      "learning_rate": 1.1360529332702443e-05,
      "epoch": 0.4567519858781995,
      "step": 10350
    },
    {
      "loss": 1.4307,
      "grad_norm": 11.484140396118164,
      "learning_rate": 1.1344286546775957e-05,
      "epoch": 0.4589585172109444,
      "step": 10400
    },
    {
      "loss": 1.4111,
      "grad_norm": 29.261058807373047,
      "learning_rate": 1.132804376084947e-05,
      "epoch": 0.46116504854368934,
      "step": 10450
    },
    {
      "loss": 1.3129,
      "grad_norm": 19.861555099487305,
      "learning_rate": 1.1311800974922987e-05,
      "epoch": 0.46337157987643424,
      "step": 10500
    },
    {
      "loss": 1.2981,
      "grad_norm": 18.985803604125977,
      "learning_rate": 1.12955581889965e-05,
      "epoch": 0.4655781112091792,
      "step": 10550
    },
    {
      "loss": 1.4334,
      "grad_norm": 19.21772003173828,
      "learning_rate": 1.1279315403070015e-05,
      "epoch": 0.4677846425419241,
      "step": 10600
    },
    {
      "loss": 1.4886,
      "grad_norm": 22.401586532592773,
      "learning_rate": 1.126307261714353e-05,
      "epoch": 0.46999117387466904,
      "step": 10650
    },
    {
      "loss": 1.3138,
      "grad_norm": 19.246095657348633,
      "learning_rate": 1.1246829831217045e-05,
      "epoch": 0.47219770520741394,
      "step": 10700
    },
    {
      "loss": 1.2832,
      "grad_norm": 11.11854076385498,
      "learning_rate": 1.1230587045290559e-05,
      "epoch": 0.4744042365401589,
      "step": 10750
    },
    {
      "loss": 1.3062,
      "grad_norm": 13.747954368591309,
      "learning_rate": 1.1214344259364074e-05,
      "epoch": 0.4766107678729038,
      "step": 10800
    },
    {
      "loss": 1.3316,
      "grad_norm": 9.969978332519531,
      "learning_rate": 1.1198101473437588e-05,
      "epoch": 0.4788172992056487,
      "step": 10850
    },
    {
      "loss": 1.4187,
      "grad_norm": 11.047731399536133,
      "learning_rate": 1.1181858687511102e-05,
      "epoch": 0.48102383053839365,
      "step": 10900
    },
    {
      "loss": 1.3378,
      "grad_norm": 21.514205932617188,
      "learning_rate": 1.1165615901584618e-05,
      "epoch": 0.48323036187113855,
      "step": 10950
    },
    {
      "loss": 1.4542,
      "grad_norm": 20.49308967590332,
      "learning_rate": 1.114937311565813e-05,
      "epoch": 0.4854368932038835,
      "step": 11000
    },
    {
      "loss": 1.3763,
      "grad_norm": 10.372209548950195,
      "learning_rate": 1.1133130329731646e-05,
      "epoch": 0.4876434245366284,
      "step": 11050
    },
    {
      "loss": 1.4246,
      "grad_norm": 18.76401138305664,
      "learning_rate": 1.1116887543805162e-05,
      "epoch": 0.48984995586937335,
      "step": 11100
    },
    {
      "loss": 1.3054,
      "grad_norm": 23.54195785522461,
      "learning_rate": 1.1100644757878674e-05,
      "epoch": 0.49205648720211825,
      "step": 11150
    },
    {
      "loss": 1.3592,
      "grad_norm": 18.134519577026367,
      "learning_rate": 1.108440197195219e-05,
      "epoch": 0.4942630185348632,
      "step": 11200
    },
    {
      "loss": 1.4479,
      "grad_norm": 25.795509338378906,
      "learning_rate": 1.1068159186025706e-05,
      "epoch": 0.4964695498676081,
      "step": 11250
    },
    {
      "loss": 1.3031,
      "grad_norm": 20.978012084960938,
      "learning_rate": 1.1051916400099218e-05,
      "epoch": 0.49867608120035306,
      "step": 11300
    },
    {
      "loss": 1.4927,
      "grad_norm": 15.957992553710938,
      "learning_rate": 1.1035673614172734e-05,
      "epoch": 0.500882612533098,
      "step": 11350
    },
    {
      "loss": 1.3213,
      "grad_norm": 12.566631317138672,
      "learning_rate": 1.1019430828246248e-05,
      "epoch": 0.5030891438658429,
      "step": 11400
    },
    {
      "loss": 1.411,
      "grad_norm": 17.434362411499023,
      "learning_rate": 1.1003188042319762e-05,
      "epoch": 0.5052956751985879,
      "step": 11450
    },
    {
      "loss": 1.324,
      "grad_norm": 18.8949031829834,
      "learning_rate": 1.0986945256393278e-05,
      "epoch": 0.5075022065313327,
      "step": 11500
    },
    {
      "loss": 1.369,
      "grad_norm": 14.739141464233398,
      "learning_rate": 1.0970702470466792e-05,
      "epoch": 0.5097087378640777,
      "step": 11550
    },
    {
      "loss": 1.3531,
      "grad_norm": 19.86971664428711,
      "learning_rate": 1.0954459684540306e-05,
      "epoch": 0.5119152691968226,
      "step": 11600
    },
    {
      "loss": 1.2963,
      "grad_norm": 39.9728889465332,
      "learning_rate": 1.0938216898613822e-05,
      "epoch": 0.5141218005295676,
      "step": 11650
    },
    {
      "loss": 1.356,
      "grad_norm": 17.877065658569336,
      "learning_rate": 1.0921974112687334e-05,
      "epoch": 0.5163283318623124,
      "step": 11700
    },
    {
      "loss": 1.2524,
      "grad_norm": 4.575936317443848,
      "learning_rate": 1.090573132676085e-05,
      "epoch": 0.5185348631950574,
      "step": 11750
    },
    {
      "loss": 1.38,
      "grad_norm": 25.7137451171875,
      "learning_rate": 1.0889488540834366e-05,
      "epoch": 0.5207413945278023,
      "step": 11800
    },
    {
      "loss": 1.3779,
      "grad_norm": 24.254459381103516,
      "learning_rate": 1.0873245754907878e-05,
      "epoch": 0.5229479258605472,
      "step": 11850
    },
    {
      "loss": 1.5328,
      "grad_norm": 24.709383010864258,
      "learning_rate": 1.0857002968981394e-05,
      "epoch": 0.5251544571932921,
      "step": 11900
    },
    {
      "loss": 1.4935,
      "grad_norm": 21.67832374572754,
      "learning_rate": 1.084076018305491e-05,
      "epoch": 0.5273609885260371,
      "step": 11950
    },
    {
      "loss": 1.2743,
      "grad_norm": 10.37155532836914,
      "learning_rate": 1.0824517397128422e-05,
      "epoch": 0.529567519858782,
      "step": 12000
    },
    {
      "loss": 1.5077,
      "grad_norm": 24.56914520263672,
      "learning_rate": 1.0808274611201938e-05,
      "epoch": 0.5317740511915269,
      "step": 12050
    },
    {
      "loss": 1.2911,
      "grad_norm": 25.640579223632812,
      "learning_rate": 1.0792031825275453e-05,
      "epoch": 0.5339805825242718,
      "step": 12100
    },
    {
      "loss": 1.4757,
      "grad_norm": 22.670856475830078,
      "learning_rate": 1.0775789039348966e-05,
      "epoch": 0.5361871138570168,
      "step": 12150
    },
    {
      "loss": 1.3909,
      "grad_norm": 16.30510711669922,
      "learning_rate": 1.0759546253422481e-05,
      "epoch": 0.5383936451897617,
      "step": 12200
    },
    {
      "loss": 1.2646,
      "grad_norm": 23.554458618164062,
      "learning_rate": 1.0743303467495997e-05,
      "epoch": 0.5406001765225066,
      "step": 12250
    },
    {
      "loss": 1.3312,
      "grad_norm": 30.440732955932617,
      "learning_rate": 1.072706068156951e-05,
      "epoch": 0.5428067078552515,
      "step": 12300
    },
    {
      "loss": 1.2676,
      "grad_norm": 10.441330909729004,
      "learning_rate": 1.0710817895643025e-05,
      "epoch": 0.5450132391879965,
      "step": 12350
    },
    {
      "loss": 1.2466,
      "grad_norm": 14.08594799041748,
      "learning_rate": 1.069457510971654e-05,
      "epoch": 0.5472197705207414,
      "step": 12400
    },
    {
      "loss": 1.3016,
      "grad_norm": 22.941139221191406,
      "learning_rate": 1.0678332323790053e-05,
      "epoch": 0.5494263018534863,
      "step": 12450
    },
    {
      "loss": 1.2879,
      "grad_norm": 11.20793342590332,
      "learning_rate": 1.066208953786357e-05,
      "epoch": 0.5516328331862312,
      "step": 12500
    },
    {
      "loss": 1.3157,
      "grad_norm": 17.013408660888672,
      "learning_rate": 1.0645846751937083e-05,
      "epoch": 0.5538393645189762,
      "step": 12550
    },
    {
      "loss": 1.4976,
      "grad_norm": 38.177162170410156,
      "learning_rate": 1.0629603966010597e-05,
      "epoch": 0.556045895851721,
      "step": 12600
    },
    {
      "loss": 1.279,
      "grad_norm": 51.3570671081543,
      "learning_rate": 1.0613361180084113e-05,
      "epoch": 0.558252427184466,
      "step": 12650
    },
    {
      "loss": 1.2899,
      "grad_norm": 14.710204124450684,
      "learning_rate": 1.0597118394157627e-05,
      "epoch": 0.560458958517211,
      "step": 12700
    },
    {
      "loss": 1.3714,
      "grad_norm": 10.843667984008789,
      "learning_rate": 1.0580875608231141e-05,
      "epoch": 0.5626654898499559,
      "step": 12750
    },
    {
      "loss": 1.3466,
      "grad_norm": 21.706689834594727,
      "learning_rate": 1.0564632822304657e-05,
      "epoch": 0.5648720211827007,
      "step": 12800
    },
    {
      "loss": 1.2819,
      "grad_norm": 14.455397605895996,
      "learning_rate": 1.0548390036378171e-05,
      "epoch": 0.5670785525154457,
      "step": 12850
    },
    {
      "loss": 1.2435,
      "grad_norm": 28.434053421020508,
      "learning_rate": 1.0532147250451685e-05,
      "epoch": 0.5692850838481907,
      "step": 12900
    },
    {
      "loss": 1.3584,
      "grad_norm": 23.01266860961914,
      "learning_rate": 1.05159044645252e-05,
      "epoch": 0.5714916151809356,
      "step": 12950
    },
    {
      "loss": 1.2594,
      "grad_norm": 19.250995635986328,
      "learning_rate": 1.0499661678598715e-05,
      "epoch": 0.5736981465136805,
      "step": 13000
    },
    {
      "loss": 1.1577,
      "grad_norm": 17.52190399169922,
      "learning_rate": 1.0483418892672229e-05,
      "epoch": 0.5759046778464254,
      "step": 13050
    },
    {
      "loss": 1.3463,
      "grad_norm": 17.658119201660156,
      "learning_rate": 1.0467176106745743e-05,
      "epoch": 0.5781112091791704,
      "step": 13100
    },
    {
      "loss": 1.4717,
      "grad_norm": 27.50117301940918,
      "learning_rate": 1.0450933320819259e-05,
      "epoch": 0.5803177405119153,
      "step": 13150
    },
    {
      "loss": 1.3705,
      "grad_norm": 18.066953659057617,
      "learning_rate": 1.0434690534892773e-05,
      "epoch": 0.5825242718446602,
      "step": 13200
    },
    {
      "loss": 1.3604,
      "grad_norm": 23.504276275634766,
      "learning_rate": 1.0418447748966287e-05,
      "epoch": 0.5847308031774051,
      "step": 13250
    },
    {
      "loss": 1.2508,
      "grad_norm": 31.58177947998047,
      "learning_rate": 1.0402204963039803e-05,
      "epoch": 0.5869373345101501,
      "step": 13300
    },
    {
      "loss": 1.3331,
      "grad_norm": 21.35402488708496,
      "learning_rate": 1.0385962177113317e-05,
      "epoch": 0.589143865842895,
      "step": 13350
    },
    {
      "loss": 1.3107,
      "grad_norm": 9.22954273223877,
      "learning_rate": 1.036971939118683e-05,
      "epoch": 0.5913503971756399,
      "step": 13400
    },
    {
      "loss": 1.2675,
      "grad_norm": 17.5911865234375,
      "learning_rate": 1.0353476605260346e-05,
      "epoch": 0.5935569285083848,
      "step": 13450
    },
    {
      "loss": 1.267,
      "grad_norm": 13.654784202575684,
      "learning_rate": 1.033723381933386e-05,
      "epoch": 0.5957634598411298,
      "step": 13500
    },
    {
      "loss": 1.1548,
      "grad_norm": 21.921401977539062,
      "learning_rate": 1.0320991033407374e-05,
      "epoch": 0.5979699911738746,
      "step": 13550
    },
    {
      "loss": 1.2611,
      "grad_norm": 13.853053092956543,
      "learning_rate": 1.0304748247480889e-05,
      "epoch": 0.6001765225066196,
      "step": 13600
    },
    {
      "loss": 1.209,
      "grad_norm": 14.75668716430664,
      "learning_rate": 1.0288505461554404e-05,
      "epoch": 0.6023830538393645,
      "step": 13650
    },
    {
      "loss": 1.4005,
      "grad_norm": 21.439781188964844,
      "learning_rate": 1.0272262675627918e-05,
      "epoch": 0.6045895851721095,
      "step": 13700
    },
    {
      "loss": 1.2561,
      "grad_norm": 11.527057647705078,
      "learning_rate": 1.0256019889701432e-05,
      "epoch": 0.6067961165048543,
      "step": 13750
    },
    {
      "loss": 1.2803,
      "grad_norm": 25.200223922729492,
      "learning_rate": 1.0239777103774946e-05,
      "epoch": 0.6090026478375993,
      "step": 13800
    },
    {
      "loss": 1.2874,
      "grad_norm": 16.09778594970703,
      "learning_rate": 1.0223534317848462e-05,
      "epoch": 0.6112091791703442,
      "step": 13850
    },
    {
      "loss": 1.2614,
      "grad_norm": 31.491485595703125,
      "learning_rate": 1.0207291531921976e-05,
      "epoch": 0.6134157105030892,
      "step": 13900
    },
    {
      "loss": 1.3603,
      "grad_norm": 18.389461517333984,
      "learning_rate": 1.019104874599549e-05,
      "epoch": 0.615622241835834,
      "step": 13950
    },
    {
      "loss": 1.3042,
      "grad_norm": 25.21179962158203,
      "learning_rate": 1.0174805960069006e-05,
      "epoch": 0.617828773168579,
      "step": 14000
    },
    {
      "loss": 1.2237,
      "grad_norm": 23.442859649658203,
      "learning_rate": 1.015856317414252e-05,
      "epoch": 0.6200353045013239,
      "step": 14050
    },
    {
      "loss": 1.3314,
      "grad_norm": 16.908109664916992,
      "learning_rate": 1.0142320388216034e-05,
      "epoch": 0.6222418358340689,
      "step": 14100
    },
    {
      "loss": 1.0568,
      "grad_norm": 24.659744262695312,
      "learning_rate": 1.012607760228955e-05,
      "epoch": 0.6244483671668137,
      "step": 14150
    },
    {
      "loss": 1.2489,
      "grad_norm": 13.247180938720703,
      "learning_rate": 1.0109834816363064e-05,
      "epoch": 0.6266548984995587,
      "step": 14200
    },
    {
      "loss": 1.2749,
      "grad_norm": 35.8871955871582,
      "learning_rate": 1.0093592030436578e-05,
      "epoch": 0.6288614298323036,
      "step": 14250
    },
    {
      "loss": 1.3461,
      "grad_norm": 22.076326370239258,
      "learning_rate": 1.0077349244510094e-05,
      "epoch": 0.6310679611650486,
      "step": 14300
    },
    {
      "loss": 1.2307,
      "grad_norm": 26.57254409790039,
      "learning_rate": 1.0061106458583608e-05,
      "epoch": 0.6332744924977934,
      "step": 14350
    },
    {
      "loss": 1.3505,
      "grad_norm": 21.03481674194336,
      "learning_rate": 1.0044863672657122e-05,
      "epoch": 0.6354810238305384,
      "step": 14400
    },
    {
      "loss": 1.197,
      "grad_norm": 22.167448043823242,
      "learning_rate": 1.0028620886730638e-05,
      "epoch": 0.6376875551632833,
      "step": 14450
    },
    {
      "loss": 1.13,
      "grad_norm": 23.49064826965332,
      "learning_rate": 1.001237810080415e-05,
      "epoch": 0.6398940864960282,
      "step": 14500
    },
    {
      "loss": 1.1995,
      "grad_norm": 16.746305465698242,
      "learning_rate": 9.996135314877666e-06,
      "epoch": 0.6421006178287731,
      "step": 14550
    },
    {
      "loss": 1.3246,
      "grad_norm": 21.704639434814453,
      "learning_rate": 9.979892528951182e-06,
      "epoch": 0.6443071491615181,
      "step": 14600
    },
    {
      "loss": 1.2944,
      "grad_norm": 20.804954528808594,
      "learning_rate": 9.963649743024694e-06,
      "epoch": 0.646513680494263,
      "step": 14650
    },
    {
      "loss": 1.3689,
      "grad_norm": 21.04338264465332,
      "learning_rate": 9.94740695709821e-06,
      "epoch": 0.6487202118270079,
      "step": 14700
    },
    {
      "loss": 1.299,
      "grad_norm": 14.57713508605957,
      "learning_rate": 9.931164171171725e-06,
      "epoch": 0.6509267431597529,
      "step": 14750
    },
    {
      "loss": 1.179,
      "grad_norm": 10.76343822479248,
      "learning_rate": 9.914921385245238e-06,
      "epoch": 0.6531332744924978,
      "step": 14800
    },
    {
      "loss": 1.2325,
      "grad_norm": 27.332752227783203,
      "learning_rate": 9.898678599318753e-06,
      "epoch": 0.6553398058252428,
      "step": 14850
    },
    {
      "loss": 1.1878,
      "grad_norm": 27.95671844482422,
      "learning_rate": 9.88243581339227e-06,
      "epoch": 0.6575463371579876,
      "step": 14900
    },
    {
      "loss": 1.1848,
      "grad_norm": 28.61886215209961,
      "learning_rate": 9.866193027465782e-06,
      "epoch": 0.6597528684907326,
      "step": 14950
    },
    {
      "loss": 1.1419,
      "grad_norm": 15.996411323547363,
      "learning_rate": 9.849950241539297e-06,
      "epoch": 0.6619593998234775,
      "step": 15000
    },
    {
      "loss": 1.2498,
      "grad_norm": 24.02991485595703,
      "learning_rate": 9.833707455612813e-06,
      "epoch": 0.6641659311562225,
      "step": 15050
    },
    {
      "loss": 1.1644,
      "grad_norm": 30.385971069335938,
      "learning_rate": 9.817464669686325e-06,
      "epoch": 0.6663724624889673,
      "step": 15100
    },
    {
      "loss": 1.2051,
      "grad_norm": 20.037940979003906,
      "learning_rate": 9.801221883759841e-06,
      "epoch": 0.6685789938217123,
      "step": 15150
    },
    {
      "loss": 1.3047,
      "grad_norm": 12.65534496307373,
      "learning_rate": 9.784979097833355e-06,
      "epoch": 0.6707855251544572,
      "step": 15200
    },
    {
      "loss": 1.2285,
      "grad_norm": 31.67881202697754,
      "learning_rate": 9.76873631190687e-06,
      "epoch": 0.6729920564872022,
      "step": 15250
    },
    {
      "loss": 1.0716,
      "grad_norm": 21.42732810974121,
      "learning_rate": 9.752493525980385e-06,
      "epoch": 0.675198587819947,
      "step": 15300
    },
    {
      "loss": 1.2365,
      "grad_norm": 29.123729705810547,
      "learning_rate": 9.736250740053899e-06,
      "epoch": 0.677405119152692,
      "step": 15350
    },
    {
      "loss": 1.1854,
      "grad_norm": 9.611696243286133,
      "learning_rate": 9.720007954127413e-06,
      "epoch": 0.6796116504854369,
      "step": 15400
    },
    {
      "loss": 1.2978,
      "grad_norm": 15.741338729858398,
      "learning_rate": 9.703765168200929e-06,
      "epoch": 0.6818181818181818,
      "step": 15450
    },
    {
      "loss": 1.1893,
      "grad_norm": 35.92026901245117,
      "learning_rate": 9.687522382274443e-06,
      "epoch": 0.6840247131509267,
      "step": 15500
    },
    {
      "loss": 1.2426,
      "grad_norm": 12.895734786987305,
      "learning_rate": 9.671279596347957e-06,
      "epoch": 0.6862312444836717,
      "step": 15550
    },
    {
      "loss": 1.2875,
      "grad_norm": 17.365419387817383,
      "learning_rate": 9.655036810421473e-06,
      "epoch": 0.6884377758164166,
      "step": 15600
    },
    {
      "loss": 1.3314,
      "grad_norm": 12.137877464294434,
      "learning_rate": 9.638794024494985e-06,
      "epoch": 0.6906443071491615,
      "step": 15650
    },
    {
      "loss": 1.2956,
      "grad_norm": 20.09888458251953,
      "learning_rate": 9.622551238568501e-06,
      "epoch": 0.6928508384819064,
      "step": 15700
    },
    {
      "loss": 1.1417,
      "grad_norm": 14.295622825622559,
      "learning_rate": 9.606308452642015e-06,
      "epoch": 0.6950573698146514,
      "step": 15750
    },
    {
      "loss": 1.1682,
      "grad_norm": 25.06616973876953,
      "learning_rate": 9.590065666715529e-06,
      "epoch": 0.6972639011473963,
      "step": 15800
    },
    {
      "loss": 1.3343,
      "grad_norm": 16.126056671142578,
      "learning_rate": 9.573822880789045e-06,
      "epoch": 0.6994704324801412,
      "step": 15850
    },
    {
      "loss": 1.2633,
      "grad_norm": 18.31256675720215,
      "learning_rate": 9.557580094862559e-06,
      "epoch": 0.7016769638128861,
      "step": 15900
    },
    {
      "loss": 1.368,
      "grad_norm": 16.399106979370117,
      "learning_rate": 9.541337308936073e-06,
      "epoch": 0.7038834951456311,
      "step": 15950
    },
    {
      "loss": 1.1788,
      "grad_norm": 16.062652587890625,
      "learning_rate": 9.525094523009589e-06,
      "epoch": 0.706090026478376,
      "step": 16000
    },
    {
      "loss": 1.0411,
      "grad_norm": 28.592716217041016,
      "learning_rate": 9.508851737083103e-06,
      "epoch": 0.7082965578111209,
      "step": 16050
    },
    {
      "loss": 1.2741,
      "grad_norm": 10.045074462890625,
      "learning_rate": 9.492608951156617e-06,
      "epoch": 0.7105030891438658,
      "step": 16100
    },
    {
      "loss": 1.127,
      "grad_norm": 17.21312141418457,
      "learning_rate": 9.476366165230132e-06,
      "epoch": 0.7127096204766108,
      "step": 16150
    },
    {
      "loss": 1.1265,
      "grad_norm": 21.271684646606445,
      "learning_rate": 9.460123379303647e-06,
      "epoch": 0.7149161518093556,
      "step": 16200
    },
    {
      "loss": 1.2752,
      "grad_norm": 26.890209197998047,
      "learning_rate": 9.44388059337716e-06,
      "epoch": 0.7171226831421006,
      "step": 16250
    },
    {
      "loss": 1.3004,
      "grad_norm": 15.05501651763916,
      "learning_rate": 9.427637807450676e-06,
      "epoch": 0.7193292144748455,
      "step": 16300
    },
    {
      "loss": 1.237,
      "grad_norm": 15.141227722167969,
      "learning_rate": 9.41139502152419e-06,
      "epoch": 0.7215357458075905,
      "step": 16350
    },
    {
      "loss": 1.3536,
      "grad_norm": 15.61817455291748,
      "learning_rate": 9.395152235597704e-06,
      "epoch": 0.7237422771403353,
      "step": 16400
    },
    {
      "loss": 1.1771,
      "grad_norm": 23.508743286132812,
      "learning_rate": 9.378909449671219e-06,
      "epoch": 0.7259488084730803,
      "step": 16450
    },
    {
      "loss": 1.1415,
      "grad_norm": 37.87376403808594,
      "learning_rate": 9.362666663744734e-06,
      "epoch": 0.7281553398058253,
      "step": 16500
    },
    {
      "loss": 1.2726,
      "grad_norm": 36.534820556640625,
      "learning_rate": 9.346423877818248e-06,
      "epoch": 0.7303618711385702,
      "step": 16550
    },
    {
      "loss": 1.183,
      "grad_norm": 23.060504913330078,
      "learning_rate": 9.330181091891762e-06,
      "epoch": 0.732568402471315,
      "step": 16600
    },
    {
      "loss": 1.2062,
      "grad_norm": 22.68377685546875,
      "learning_rate": 9.313938305965278e-06,
      "epoch": 0.73477493380406,
      "step": 16650
    },
    {
      "loss": 1.1775,
      "grad_norm": 12.981327056884766,
      "learning_rate": 9.297695520038792e-06,
      "epoch": 0.736981465136805,
      "step": 16700
    },
    {
      "loss": 1.1196,
      "grad_norm": 23.797948837280273,
      "learning_rate": 9.281452734112306e-06,
      "epoch": 0.7391879964695499,
      "step": 16750
    },
    {
      "loss": 1.1105,
      "grad_norm": 9.669742584228516,
      "learning_rate": 9.265209948185822e-06,
      "epoch": 0.7413945278022948,
      "step": 16800
    },
    {
      "loss": 1.3114,
      "grad_norm": 24.781652450561523,
      "learning_rate": 9.248967162259336e-06,
      "epoch": 0.7436010591350397,
      "step": 16850
    },
    {
      "loss": 1.0105,
      "grad_norm": 17.03835678100586,
      "learning_rate": 9.23272437633285e-06,
      "epoch": 0.7458075904677847,
      "step": 16900
    },
    {
      "loss": 1.2063,
      "grad_norm": 28.811128616333008,
      "learning_rate": 9.216481590406366e-06,
      "epoch": 0.7480141218005296,
      "step": 16950
    },
    {
      "loss": 1.1774,
      "grad_norm": 22.074983596801758,
      "learning_rate": 9.20023880447988e-06,
      "epoch": 0.7502206531332745,
      "step": 17000
    },
    {
      "loss": 1.1493,
      "grad_norm": 27.24452018737793,
      "learning_rate": 9.183996018553394e-06,
      "epoch": 0.7524271844660194,
      "step": 17050
    },
    {
      "loss": 1.108,
      "grad_norm": 13.727462768554688,
      "learning_rate": 9.16775323262691e-06,
      "epoch": 0.7546337157987644,
      "step": 17100
    },
    {
      "loss": 1.3164,
      "grad_norm": 16.8636417388916,
      "learning_rate": 9.151510446700422e-06,
      "epoch": 0.7568402471315092,
      "step": 17150
    },
    {
      "loss": 1.1404,
      "grad_norm": 14.081506729125977,
      "learning_rate": 9.135267660773938e-06,
      "epoch": 0.7590467784642542,
      "step": 17200
    },
    {
      "loss": 1.215,
      "grad_norm": 14.478031158447266,
      "learning_rate": 9.119024874847454e-06,
      "epoch": 0.7612533097969991,
      "step": 17250
    },
    {
      "loss": 1.173,
      "grad_norm": 24.85870361328125,
      "learning_rate": 9.102782088920966e-06,
      "epoch": 0.7634598411297441,
      "step": 17300
    },
    {
      "loss": 1.2158,
      "grad_norm": 12.28085708618164,
      "learning_rate": 9.086539302994482e-06,
      "epoch": 0.7656663724624889,
      "step": 17350
    },
    {
      "loss": 1.2841,
      "grad_norm": 27.53449249267578,
      "learning_rate": 9.070296517067997e-06,
      "epoch": 0.7678729037952339,
      "step": 17400
    },
    {
      "loss": 1.1634,
      "grad_norm": 22.746109008789062,
      "learning_rate": 9.05405373114151e-06,
      "epoch": 0.7700794351279788,
      "step": 17450
    },
    {
      "loss": 1.082,
      "grad_norm": 14.374300956726074,
      "learning_rate": 9.037810945215026e-06,
      "epoch": 0.7722859664607238,
      "step": 17500
    },
    {
      "loss": 1.1901,
      "grad_norm": 31.678077697753906,
      "learning_rate": 9.021568159288541e-06,
      "epoch": 0.7744924977934686,
      "step": 17550
    },
    {
      "loss": 1.3665,
      "grad_norm": 17.786148071289062,
      "learning_rate": 9.005325373362054e-06,
      "epoch": 0.7766990291262136,
      "step": 17600
    },
    {
      "loss": 1.2233,
      "grad_norm": 14.194457054138184,
      "learning_rate": 8.98908258743557e-06,
      "epoch": 0.7789055604589585,
      "step": 17650
    },
    {
      "loss": 1.199,
      "grad_norm": 17.988679885864258,
      "learning_rate": 8.972839801509083e-06,
      "epoch": 0.7811120917917035,
      "step": 17700
    },
    {
      "loss": 1.1982,
      "grad_norm": 27.32423973083496,
      "learning_rate": 8.956597015582598e-06,
      "epoch": 0.7833186231244483,
      "step": 17750
    },
    {
      "loss": 1.1444,
      "grad_norm": 16.11638832092285,
      "learning_rate": 8.940354229656113e-06,
      "epoch": 0.7855251544571933,
      "step": 17800
    },
    {
      "loss": 1.0873,
      "grad_norm": 21.21269416809082,
      "learning_rate": 8.924111443729626e-06,
      "epoch": 0.7877316857899382,
      "step": 17850
    },
    {
      "loss": 1.1722,
      "grad_norm": 19.514591217041016,
      "learning_rate": 8.907868657803141e-06,
      "epoch": 0.7899382171226832,
      "step": 17900
    },
    {
      "loss": 1.1204,
      "grad_norm": 23.918235778808594,
      "learning_rate": 8.891625871876657e-06,
      "epoch": 0.792144748455428,
      "step": 17950
    },
    {
      "loss": 1.2573,
      "grad_norm": 28.50021743774414,
      "learning_rate": 8.87538308595017e-06,
      "epoch": 0.794351279788173,
      "step": 18000
    },
    {
      "loss": 1.2322,
      "grad_norm": 21.132835388183594,
      "learning_rate": 8.859140300023685e-06,
      "epoch": 0.796557811120918,
      "step": 18050
    },
    {
      "loss": 1.1896,
      "grad_norm": 13.269730567932129,
      "learning_rate": 8.842897514097201e-06,
      "epoch": 0.7987643424536628,
      "step": 18100
    },
    {
      "loss": 1.2431,
      "grad_norm": 9.906908988952637,
      "learning_rate": 8.826654728170713e-06,
      "epoch": 0.8009708737864077,
      "step": 18150
    },
    {
      "loss": 1.208,
      "grad_norm": 20.18669891357422,
      "learning_rate": 8.810411942244229e-06,
      "epoch": 0.8031774051191527,
      "step": 18200
    },
    {
      "loss": 1.2709,
      "grad_norm": 20.831201553344727,
      "learning_rate": 8.794169156317745e-06,
      "epoch": 0.8053839364518977,
      "step": 18250
    },
    {
      "loss": 1.1152,
      "grad_norm": 16.81288719177246,
      "learning_rate": 8.777926370391257e-06,
      "epoch": 0.8075904677846425,
      "step": 18300
    },
    {
      "loss": 1.2766,
      "grad_norm": 19.2952823638916,
      "learning_rate": 8.761683584464773e-06,
      "epoch": 0.8097969991173875,
      "step": 18350
    },
    {
      "loss": 1.2619,
      "grad_norm": 21.815006256103516,
      "learning_rate": 8.745440798538289e-06,
      "epoch": 0.8120035304501324,
      "step": 18400
    },
    {
      "loss": 1.0541,
      "grad_norm": 23.014558792114258,
      "learning_rate": 8.729198012611801e-06,
      "epoch": 0.8142100617828774,
      "step": 18450
    },
    {
      "loss": 1.1787,
      "grad_norm": 13.89507007598877,
      "learning_rate": 8.712955226685317e-06,
      "epoch": 0.8164165931156222,
      "step": 18500
    },
    {
      "loss": 1.2602,
      "grad_norm": 26.432199478149414,
      "learning_rate": 8.696712440758831e-06,
      "epoch": 0.8186231244483672,
      "step": 18550
    },
    {
      "loss": 0.9847,
      "grad_norm": 15.551855087280273,
      "learning_rate": 8.680469654832345e-06,
      "epoch": 0.8208296557811121,
      "step": 18600
    },
    {
      "loss": 1.1917,
      "grad_norm": 23.392810821533203,
      "learning_rate": 8.66422686890586e-06,
      "epoch": 0.8230361871138571,
      "step": 18650
    },
    {
      "loss": 1.1712,
      "grad_norm": 25.005910873413086,
      "learning_rate": 8.647984082979375e-06,
      "epoch": 0.8252427184466019,
      "step": 18700
    },
    {
      "loss": 1.2311,
      "grad_norm": 19.80619239807129,
      "learning_rate": 8.631741297052889e-06,
      "epoch": 0.8274492497793469,
      "step": 18750
    },
    {
      "loss": 1.2553,
      "grad_norm": 27.85420036315918,
      "learning_rate": 8.615498511126405e-06,
      "epoch": 0.8296557811120918,
      "step": 18800
    },
    {
      "loss": 1.2198,
      "grad_norm": 18.306640625,
      "learning_rate": 8.599255725199919e-06,
      "epoch": 0.8318623124448368,
      "step": 18850
    },
    {
      "loss": 1.2353,
      "grad_norm": 19.006046295166016,
      "learning_rate": 8.583012939273433e-06,
      "epoch": 0.8340688437775816,
      "step": 18900
    },
    {
      "loss": 1.2616,
      "grad_norm": 141.8189239501953,
      "learning_rate": 8.566770153346948e-06,
      "epoch": 0.8362753751103266,
      "step": 18950
    },
    {
      "loss": 1.3344,
      "grad_norm": 16.451810836791992,
      "learning_rate": 8.550527367420462e-06,
      "epoch": 0.8384819064430715,
      "step": 19000
    },
    {
      "loss": 1.2304,
      "grad_norm": 20.028392791748047,
      "learning_rate": 8.534284581493977e-06,
      "epoch": 0.8406884377758164,
      "step": 19050
    },
    {
      "loss": 1.1095,
      "grad_norm": 21.582027435302734,
      "learning_rate": 8.518041795567492e-06,
      "epoch": 0.8428949691085613,
      "step": 19100
    },
    {
      "loss": 1.1595,
      "grad_norm": 17.906633377075195,
      "learning_rate": 8.501799009641006e-06,
      "epoch": 0.8451015004413063,
      "step": 19150
    },
    {
      "loss": 1.0921,
      "grad_norm": 33.3035774230957,
      "learning_rate": 8.48555622371452e-06,
      "epoch": 0.8473080317740512,
      "step": 19200
    },
    {
      "loss": 1.283,
      "grad_norm": 10.921796798706055,
      "learning_rate": 8.469313437788034e-06,
      "epoch": 0.8495145631067961,
      "step": 19250
    },
    {
      "loss": 1.3119,
      "grad_norm": 21.597673416137695,
      "learning_rate": 8.45307065186155e-06,
      "epoch": 0.851721094439541,
      "step": 19300
    },
    {
      "loss": 1.2082,
      "grad_norm": 20.426576614379883,
      "learning_rate": 8.436827865935064e-06,
      "epoch": 0.853927625772286,
      "step": 19350
    },
    {
      "loss": 1.117,
      "grad_norm": 17.749691009521484,
      "learning_rate": 8.420585080008578e-06,
      "epoch": 0.8561341571050309,
      "step": 19400
    },
    {
      "loss": 1.2006,
      "grad_norm": 36.2922477722168,
      "learning_rate": 8.404342294082094e-06,
      "epoch": 0.8583406884377758,
      "step": 19450
    },
    {
      "loss": 1.0479,
      "grad_norm": 24.411317825317383,
      "learning_rate": 8.388099508155608e-06,
      "epoch": 0.8605472197705207,
      "step": 19500
    },
    {
      "loss": 1.2447,
      "grad_norm": 17.858407974243164,
      "learning_rate": 8.371856722229122e-06,
      "epoch": 0.8627537511032657,
      "step": 19550
    },
    {
      "loss": 1.213,
      "grad_norm": 32.485355377197266,
      "learning_rate": 8.355613936302638e-06,
      "epoch": 0.8649602824360106,
      "step": 19600
    },
    {
      "loss": 1.0665,
      "grad_norm": 23.26077651977539,
      "learning_rate": 8.339371150376152e-06,
      "epoch": 0.8671668137687555,
      "step": 19650
    },
    {
      "loss": 1.3085,
      "grad_norm": 19.65972137451172,
      "learning_rate": 8.323128364449666e-06,
      "epoch": 0.8693733451015004,
      "step": 19700
    },
    {
      "loss": 1.1548,
      "grad_norm": 18.2393798828125,
      "learning_rate": 8.306885578523182e-06,
      "epoch": 0.8715798764342454,
      "step": 19750
    },
    {
      "loss": 1.2049,
      "grad_norm": 10.523338317871094,
      "learning_rate": 8.290642792596696e-06,
      "epoch": 0.8737864077669902,
      "step": 19800
    },
    {
      "loss": 1.1828,
      "grad_norm": 28.131309509277344,
      "learning_rate": 8.27440000667021e-06,
      "epoch": 0.8759929390997352,
      "step": 19850
    },
    {
      "loss": 1.0974,
      "grad_norm": 12.75698184967041,
      "learning_rate": 8.258157220743724e-06,
      "epoch": 0.8781994704324801,
      "step": 19900
    },
    {
      "loss": 1.1597,
      "grad_norm": 26.059690475463867,
      "learning_rate": 8.241914434817238e-06,
      "epoch": 0.8804060017652251,
      "step": 19950
    },
    {
      "loss": 1.1658,
      "grad_norm": 21.3603458404541,
      "learning_rate": 8.225671648890754e-06,
      "epoch": 0.8826125330979699,
      "step": 20000
    },
    {
      "loss": 1.066,
      "grad_norm": 19.122352600097656,
      "learning_rate": 8.209428862964268e-06,
      "epoch": 0.8848190644307149,
      "step": 20050
    },
    {
      "loss": 1.1843,
      "grad_norm": 14.566482543945312,
      "learning_rate": 8.193186077037782e-06,
      "epoch": 0.8870255957634599,
      "step": 20100
    },
    {
      "loss": 1.0903,
      "grad_norm": 15.436376571655273,
      "learning_rate": 8.176943291111298e-06,
      "epoch": 0.8892321270962048,
      "step": 20150
    },
    {
      "loss": 1.1113,
      "grad_norm": 18.76708221435547,
      "learning_rate": 8.160700505184812e-06,
      "epoch": 0.8914386584289496,
      "step": 20200
    },
    {
      "loss": 1.1464,
      "grad_norm": 26.845592498779297,
      "learning_rate": 8.144457719258326e-06,
      "epoch": 0.8936451897616946,
      "step": 20250
    },
    {
      "loss": 1.2598,
      "grad_norm": 30.274316787719727,
      "learning_rate": 8.128214933331841e-06,
      "epoch": 0.8958517210944396,
      "step": 20300
    },
    {
      "loss": 1.2494,
      "grad_norm": 13.22695541381836,
      "learning_rate": 8.111972147405356e-06,
      "epoch": 0.8980582524271845,
      "step": 20350
    },
    {
      "loss": 1.1941,
      "grad_norm": 21.876291275024414,
      "learning_rate": 8.09572936147887e-06,
      "epoch": 0.9002647837599294,
      "step": 20400
    },
    {
      "loss": 1.2775,
      "grad_norm": 17.20716094970703,
      "learning_rate": 8.079486575552385e-06,
      "epoch": 0.9024713150926743,
      "step": 20450
    },
    {
      "loss": 1.1617,
      "grad_norm": 22.024394989013672,
      "learning_rate": 8.0632437896259e-06,
      "epoch": 0.9046778464254193,
      "step": 20500
    },
    {
      "loss": 1.0335,
      "grad_norm": 38.101470947265625,
      "learning_rate": 8.047001003699413e-06,
      "epoch": 0.9068843777581642,
      "step": 20550
    },
    {
      "loss": 1.2598,
      "grad_norm": 16.334537506103516,
      "learning_rate": 8.03075821777293e-06,
      "epoch": 0.9090909090909091,
      "step": 20600
    },
    {
      "loss": 1.1221,
      "grad_norm": 16.241628646850586,
      "learning_rate": 8.014515431846442e-06,
      "epoch": 0.911297440423654,
      "step": 20650
    },
    {
      "loss": 1.0025,
      "grad_norm": 15.969074249267578,
      "learning_rate": 7.998272645919957e-06,
      "epoch": 0.913503971756399,
      "step": 20700
    },
    {
      "loss": 1.2119,
      "grad_norm": 14.986063003540039,
      "learning_rate": 7.982029859993473e-06,
      "epoch": 0.9157105030891438,
      "step": 20750
    },
    {
      "loss": 1.1383,
      "grad_norm": 13.288439750671387,
      "learning_rate": 7.965787074066985e-06,
      "epoch": 0.9179170344218888,
      "step": 20800
    },
    {
      "loss": 1.1592,
      "grad_norm": 35.44583511352539,
      "learning_rate": 7.949544288140501e-06,
      "epoch": 0.9201235657546337,
      "step": 20850
    },
    {
      "loss": 1.1783,
      "grad_norm": 13.372000694274902,
      "learning_rate": 7.933301502214017e-06,
      "epoch": 0.9223300970873787,
      "step": 20900
    },
    {
      "loss": 1.0892,
      "grad_norm": 20.330163955688477,
      "learning_rate": 7.91705871628753e-06,
      "epoch": 0.9245366284201235,
      "step": 20950
    },
    {
      "loss": 1.2159,
      "grad_norm": 8.508296012878418,
      "learning_rate": 7.900815930361045e-06,
      "epoch": 0.9267431597528685,
      "step": 21000
    },
    {
      "loss": 1.2201,
      "grad_norm": 17.683366775512695,
      "learning_rate": 7.88457314443456e-06,
      "epoch": 0.9289496910856134,
      "step": 21050
    },
    {
      "loss": 1.0752,
      "grad_norm": 21.71880340576172,
      "learning_rate": 7.868330358508073e-06,
      "epoch": 0.9311562224183584,
      "step": 21100
    },
    {
      "loss": 1.1158,
      "grad_norm": 17.27005958557129,
      "learning_rate": 7.852087572581589e-06,
      "epoch": 0.9333627537511032,
      "step": 21150
    },
    {
      "loss": 1.0413,
      "grad_norm": 40.16570281982422,
      "learning_rate": 7.835844786655105e-06,
      "epoch": 0.9355692850838482,
      "step": 21200
    },
    {
      "loss": 1.0699,
      "grad_norm": 20.702585220336914,
      "learning_rate": 7.819602000728617e-06,
      "epoch": 0.9377758164165931,
      "step": 21250
    },
    {
      "loss": 1.0633,
      "grad_norm": 26.713659286499023,
      "learning_rate": 7.803359214802133e-06,
      "epoch": 0.9399823477493381,
      "step": 21300
    },
    {
      "loss": 1.2274,
      "grad_norm": 17.561864852905273,
      "learning_rate": 7.787116428875647e-06,
      "epoch": 0.9421888790820829,
      "step": 21350
    },
    {
      "loss": 1.0964,
      "grad_norm": 20.264575958251953,
      "learning_rate": 7.770873642949161e-06,
      "epoch": 0.9443954104148279,
      "step": 21400
    },
    {
      "loss": 1.1586,
      "grad_norm": 16.099435806274414,
      "learning_rate": 7.754630857022677e-06,
      "epoch": 0.9466019417475728,
      "step": 21450
    },
    {
      "loss": 1.1504,
      "grad_norm": 21.202308654785156,
      "learning_rate": 7.73838807109619e-06,
      "epoch": 0.9488084730803178,
      "step": 21500
    },
    {
      "loss": 1.0315,
      "grad_norm": 16.82834815979004,
      "learning_rate": 7.722145285169705e-06,
      "epoch": 0.9510150044130626,
      "step": 21550
    },
    {
      "loss": 1.0719,
      "grad_norm": 12.522126197814941,
      "learning_rate": 7.70590249924322e-06,
      "epoch": 0.9532215357458076,
      "step": 21600
    },
    {
      "loss": 1.1494,
      "grad_norm": 15.55062198638916,
      "learning_rate": 7.689659713316735e-06,
      "epoch": 0.9554280670785525,
      "step": 21650
    },
    {
      "loss": 1.102,
      "grad_norm": 18.310073852539062,
      "learning_rate": 7.673416927390249e-06,
      "epoch": 0.9576345984112974,
      "step": 21700
    },
    {
      "loss": 1.1756,
      "grad_norm": 17.619274139404297,
      "learning_rate": 7.657174141463764e-06,
      "epoch": 0.9598411297440423,
      "step": 21750
    },
    {
      "loss": 1.2112,
      "grad_norm": 19.145551681518555,
      "learning_rate": 7.640931355537278e-06,
      "epoch": 0.9620476610767873,
      "step": 21800
    },
    {
      "loss": 1.1604,
      "grad_norm": 26.96156883239746,
      "learning_rate": 7.6246885696107925e-06,
      "epoch": 0.9642541924095323,
      "step": 21850
    },
    {
      "loss": 0.9546,
      "grad_norm": 24.933116912841797,
      "learning_rate": 7.608445783684308e-06,
      "epoch": 0.9664607237422771,
      "step": 21900
    },
    {
      "loss": 1.1691,
      "grad_norm": 17.886213302612305,
      "learning_rate": 7.592202997757821e-06,
      "epoch": 0.968667255075022,
      "step": 21950
    },
    {
      "loss": 1.1524,
      "grad_norm": 18.237689971923828,
      "learning_rate": 7.575960211831336e-06,
      "epoch": 0.970873786407767,
      "step": 22000
    },
    {
      "loss": 1.2138,
      "grad_norm": 18.369096755981445,
      "learning_rate": 7.55971742590485e-06,
      "epoch": 0.973080317740512,
      "step": 22050
    },
    {
      "loss": 1.1029,
      "grad_norm": 23.972732543945312,
      "learning_rate": 7.543474639978365e-06,
      "epoch": 0.9752868490732568,
      "step": 22100
    },
    {
      "loss": 1.2404,
      "grad_norm": 31.175077438354492,
      "learning_rate": 7.52723185405188e-06,
      "epoch": 0.9774933804060018,
      "step": 22150
    },
    {
      "loss": 1.1165,
      "grad_norm": 51.103538513183594,
      "learning_rate": 7.510989068125394e-06,
      "epoch": 0.9796999117387467,
      "step": 22200
    },
    {
      "loss": 1.1592,
      "grad_norm": 12.613497734069824,
      "learning_rate": 7.494746282198909e-06,
      "epoch": 0.9819064430714917,
      "step": 22250
    },
    {
      "loss": 1.1789,
      "grad_norm": 23.91727638244629,
      "learning_rate": 7.478503496272424e-06,
      "epoch": 0.9841129744042365,
      "step": 22300
    },
    {
      "loss": 1.1375,
      "grad_norm": 20.072208404541016,
      "learning_rate": 7.462260710345938e-06,
      "epoch": 0.9863195057369815,
      "step": 22350
    },
    {
      "loss": 1.1694,
      "grad_norm": 27.409637451171875,
      "learning_rate": 7.446017924419453e-06,
      "epoch": 0.9885260370697264,
      "step": 22400
    },
    {
      "loss": 0.9429,
      "grad_norm": 22.317699432373047,
      "learning_rate": 7.429775138492968e-06,
      "epoch": 0.9907325684024714,
      "step": 22450
    },
    {
      "loss": 1.0338,
      "grad_norm": 16.292774200439453,
      "learning_rate": 7.413532352566481e-06,
      "epoch": 0.9929390997352162,
      "step": 22500
    },
    {
      "loss": 1.1656,
      "grad_norm": 12.680140495300293,
      "learning_rate": 7.397289566639997e-06,
      "epoch": 0.9951456310679612,
      "step": 22550
    },
    {
      "loss": 1.0516,
      "grad_norm": 15.338128089904785,
      "learning_rate": 7.38104678071351e-06,
      "epoch": 0.9973521624007061,
      "step": 22600
    },
    {
      "loss": 1.1443,
      "grad_norm": 8.398151397705078,
      "learning_rate": 7.364803994787025e-06,
      "epoch": 0.999558693733451,
      "step": 22650
    },
    {
      "eval_loss": 0.9231742770497976,
      "eval_exact_match": 76.73843981644899,
      "eval_f1": 82.28023536176272,
      "eval_samples": 22720,
      "step": 22660
    },
    {
      "eval_loss": 0.9231742770497976,
      "eval_exact_match": 76.73843981644899,
      "eval_f1": 82.28023536176272,
      "eval_samples": 22720,
      "epoch": 1.0,
      "step": 22660
    },
    {
      "loss": 1.0609,
      "grad_norm": 10.642525672912598,
      "learning_rate": 7.348561208860541e-06,
      "epoch": 1.001765225066196,
      "step": 22700
    },
    {
      "loss": 0.9792,
      "grad_norm": 17.408302307128906,
      "learning_rate": 7.332318422934055e-06,
      "epoch": 1.0039717563989408,
      "step": 22750
    },
    {
      "loss": 1.0856,
      "grad_norm": 47.262451171875,
      "learning_rate": 7.316075637007569e-06,
      "epoch": 1.0061782877316858,
      "step": 22800
    },
    {
      "loss": 1.1205,
      "grad_norm": 18.40640640258789,
      "learning_rate": 7.299832851081084e-06,
      "epoch": 1.0083848190644307,
      "step": 22850
    },
    {
      "loss": 1.1232,
      "grad_norm": 23.699819564819336,
      "learning_rate": 7.283590065154599e-06,
      "epoch": 1.0105913503971757,
      "step": 22900
    },
    {
      "loss": 1.1549,
      "grad_norm": 16.509504318237305,
      "learning_rate": 7.267347279228113e-06,
      "epoch": 1.0127978817299206,
      "step": 22950
    },
    {
      "loss": 1.2159,
      "grad_norm": 53.709537506103516,
      "learning_rate": 7.251104493301628e-06,
      "epoch": 1.0150044130626654,
      "step": 23000
    },
    {
      "loss": 0.9216,
      "grad_norm": 4.641679763793945,
      "learning_rate": 7.2348617073751425e-06,
      "epoch": 1.0172109443954105,
      "step": 23050
    },
    {
      "loss": 1.0353,
      "grad_norm": 29.130287170410156,
      "learning_rate": 7.2186189214486566e-06,
      "epoch": 1.0194174757281553,
      "step": 23100
    },
    {
      "loss": 1.0814,
      "grad_norm": 17.22952651977539,
      "learning_rate": 7.2023761355221715e-06,
      "epoch": 1.0216240070609002,
      "step": 23150
    },
    {
      "loss": 1.0797,
      "grad_norm": 26.52242088317871,
      "learning_rate": 7.1861333495956855e-06,
      "epoch": 1.0238305383936452,
      "step": 23200
    },
    {
      "loss": 1.0757,
      "grad_norm": 16.232336044311523,
      "learning_rate": 7.1698905636692e-06,
      "epoch": 1.02603706972639,
      "step": 23250
    },
    {
      "loss": 1.174,
      "grad_norm": 11.734601020812988,
      "learning_rate": 7.153647777742715e-06,
      "epoch": 1.0282436010591351,
      "step": 23300
    },
    {
      "loss": 0.9392,
      "grad_norm": 21.838054656982422,
      "learning_rate": 7.137404991816229e-06,
      "epoch": 1.03045013239188,
      "step": 23350
    },
    {
      "loss": 1.0996,
      "grad_norm": 23.346689224243164,
      "learning_rate": 7.121162205889744e-06,
      "epoch": 1.0326566637246248,
      "step": 23400
    },
    {
      "loss": 1.1393,
      "grad_norm": 14.29551887512207,
      "learning_rate": 7.104919419963259e-06,
      "epoch": 1.03486319505737,
      "step": 23450
    },
    {
      "loss": 0.9505,
      "grad_norm": 3.860825777053833,
      "learning_rate": 7.088676634036773e-06,
      "epoch": 1.0370697263901147,
      "step": 23500
    },
    {
      "loss": 1.1813,
      "grad_norm": 17.895668029785156,
      "learning_rate": 7.072433848110287e-06,
      "epoch": 1.0392762577228596,
      "step": 23550
    },
    {
      "loss": 0.9612,
      "grad_norm": 18.526718139648438,
      "learning_rate": 7.056191062183802e-06,
      "epoch": 1.0414827890556047,
      "step": 23600
    },
    {
      "loss": 1.0015,
      "grad_norm": 17.180038452148438,
      "learning_rate": 7.039948276257317e-06,
      "epoch": 1.0436893203883495,
      "step": 23650
    },
    {
      "loss": 0.9803,
      "grad_norm": 13.470370292663574,
      "learning_rate": 7.023705490330831e-06,
      "epoch": 1.0458958517210943,
      "step": 23700
    },
    {
      "loss": 1.0327,
      "grad_norm": 22.856101989746094,
      "learning_rate": 7.007462704404346e-06,
      "epoch": 1.0481023830538394,
      "step": 23750
    },
    {
      "loss": 1.1072,
      "grad_norm": 31.798547744750977,
      "learning_rate": 6.991219918477861e-06,
      "epoch": 1.0503089143865842,
      "step": 23800
    },
    {
      "loss": 1.0509,
      "grad_norm": 23.053340911865234,
      "learning_rate": 6.974977132551375e-06,
      "epoch": 1.0525154457193293,
      "step": 23850
    },
    {
      "loss": 0.9343,
      "grad_norm": 19.686941146850586,
      "learning_rate": 6.958734346624889e-06,
      "epoch": 1.0547219770520742,
      "step": 23900
    },
    {
      "loss": 0.9757,
      "grad_norm": 41.29219436645508,
      "learning_rate": 6.942491560698405e-06,
      "epoch": 1.056928508384819,
      "step": 23950
    },
    {
      "loss": 1.0597,
      "grad_norm": 25.131317138671875,
      "learning_rate": 6.926248774771919e-06,
      "epoch": 1.059135039717564,
      "step": 24000
    },
    {
      "loss": 1.0237,
      "grad_norm": 24.852563858032227,
      "learning_rate": 6.910005988845433e-06,
      "epoch": 1.061341571050309,
      "step": 24050
    },
    {
      "loss": 0.998,
      "grad_norm": 6.084137439727783,
      "learning_rate": 6.893763202918949e-06,
      "epoch": 1.0635481023830538,
      "step": 24100
    },
    {
      "loss": 0.9707,
      "grad_norm": 27.96683120727539,
      "learning_rate": 6.877520416992463e-06,
      "epoch": 1.0657546337157988,
      "step": 24150
    },
    {
      "loss": 1.0487,
      "grad_norm": 200.1900634765625,
      "learning_rate": 6.861277631065977e-06,
      "epoch": 1.0679611650485437,
      "step": 24200
    },
    {
      "loss": 1.0572,
      "grad_norm": 37.78874969482422,
      "learning_rate": 6.845034845139492e-06,
      "epoch": 1.0701676963812887,
      "step": 24250
    },
    {
      "loss": 0.967,
      "grad_norm": 28.862838745117188,
      "learning_rate": 6.828792059213007e-06,
      "epoch": 1.0723742277140336,
      "step": 24300
    },
    {
      "loss": 1.1082,
      "grad_norm": 12.930730819702148,
      "learning_rate": 6.812549273286521e-06,
      "epoch": 1.0745807590467784,
      "step": 24350
    },
    {
      "loss": 1.0324,
      "grad_norm": 12.744283676147461,
      "learning_rate": 6.7963064873600356e-06,
      "epoch": 1.0767872903795235,
      "step": 24400
    },
    {
      "loss": 1.1012,
      "grad_norm": 12.60591983795166,
      "learning_rate": 6.7800637014335505e-06,
      "epoch": 1.0789938217122683,
      "step": 24450
    },
    {
      "loss": 0.9986,
      "grad_norm": 11.84534740447998,
      "learning_rate": 6.7638209155070645e-06,
      "epoch": 1.0812003530450132,
      "step": 24500
    },
    {
      "loss": 1.2077,
      "grad_norm": 18.91702651977539,
      "learning_rate": 6.7475781295805786e-06,
      "epoch": 1.0834068843777582,
      "step": 24550
    },
    {
      "loss": 0.9356,
      "grad_norm": 0.35198983550071716,
      "learning_rate": 6.7313353436540935e-06,
      "epoch": 1.085613415710503,
      "step": 24600
    },
    {
      "loss": 1.1699,
      "grad_norm": 24.289886474609375,
      "learning_rate": 6.715092557727608e-06,
      "epoch": 1.087819947043248,
      "step": 24650
    },
    {
      "loss": 1.0296,
      "grad_norm": 22.377607345581055,
      "learning_rate": 6.6988497718011224e-06,
      "epoch": 1.090026478375993,
      "step": 24700
    },
    {
      "loss": 0.9719,
      "grad_norm": 9.048869132995605,
      "learning_rate": 6.682606985874637e-06,
      "epoch": 1.0922330097087378,
      "step": 24750
    },
    {
      "loss": 1.0322,
      "grad_norm": 12.776793479919434,
      "learning_rate": 6.666364199948152e-06,
      "epoch": 1.0944395410414829,
      "step": 24800
    },
    {
      "loss": 1.1147,
      "grad_norm": 18.019678115844727,
      "learning_rate": 6.650121414021666e-06,
      "epoch": 1.0966460723742277,
      "step": 24850
    },
    {
      "loss": 1.1617,
      "grad_norm": 10.25285530090332,
      "learning_rate": 6.633878628095181e-06,
      "epoch": 1.0988526037069726,
      "step": 24900
    },
    {
      "loss": 1.1012,
      "grad_norm": 17.19300079345703,
      "learning_rate": 6.617635842168695e-06,
      "epoch": 1.1010591350397176,
      "step": 24950
    },
    {
      "loss": 1.0828,
      "grad_norm": 27.08743667602539,
      "learning_rate": 6.60139305624221e-06,
      "epoch": 1.1032656663724625,
      "step": 25000
    },
    {
      "loss": 1.0022,
      "grad_norm": 22.507678985595703,
      "learning_rate": 6.585150270315725e-06,
      "epoch": 1.1054721977052073,
      "step": 25050
    },
    {
      "loss": 0.9987,
      "grad_norm": 17.644561767578125,
      "learning_rate": 6.568907484389239e-06,
      "epoch": 1.1076787290379524,
      "step": 25100
    },
    {
      "loss": 1.0416,
      "grad_norm": 29.056102752685547,
      "learning_rate": 6.552664698462754e-06,
      "epoch": 1.1098852603706972,
      "step": 25150
    },
    {
      "loss": 1.1126,
      "grad_norm": 10.420980453491211,
      "learning_rate": 6.536421912536269e-06,
      "epoch": 1.1120917917034423,
      "step": 25200
    },
    {
      "loss": 1.142,
      "grad_norm": 26.487276077270508,
      "learning_rate": 6.520179126609783e-06,
      "epoch": 1.1142983230361871,
      "step": 25250
    },
    {
      "loss": 1.0033,
      "grad_norm": 18.256519317626953,
      "learning_rate": 6.503936340683297e-06,
      "epoch": 1.116504854368932,
      "step": 25300
    },
    {
      "loss": 1.0863,
      "grad_norm": 13.344533920288086,
      "learning_rate": 6.487693554756813e-06,
      "epoch": 1.118711385701677,
      "step": 25350
    },
    {
      "loss": 1.0321,
      "grad_norm": 19.940141677856445,
      "learning_rate": 6.471450768830327e-06,
      "epoch": 1.120917917034422,
      "step": 25400
    },
    {
      "loss": 1.0574,
      "grad_norm": 17.464698791503906,
      "learning_rate": 6.455207982903841e-06,
      "epoch": 1.1231244483671667,
      "step": 25450
    },
    {
      "loss": 1.1665,
      "grad_norm": 18.084346771240234,
      "learning_rate": 6.438965196977357e-06,
      "epoch": 1.1253309796999118,
      "step": 25500
    },
    {
      "loss": 1.1683,
      "grad_norm": 29.490957260131836,
      "learning_rate": 6.422722411050871e-06,
      "epoch": 1.1275375110326566,
      "step": 25550
    },
    {
      "loss": 1.0712,
      "grad_norm": 29.00558853149414,
      "learning_rate": 6.406479625124385e-06,
      "epoch": 1.1297440423654015,
      "step": 25600
    },
    {
      "loss": 1.0995,
      "grad_norm": 28.275747299194336,
      "learning_rate": 6.390236839197899e-06,
      "epoch": 1.1319505736981466,
      "step": 25650
    },
    {
      "loss": 1.0612,
      "grad_norm": 12.609646797180176,
      "learning_rate": 6.3739940532714146e-06,
      "epoch": 1.1341571050308914,
      "step": 25700
    },
    {
      "loss": 0.8999,
      "grad_norm": 17.66314697265625,
      "learning_rate": 6.357751267344929e-06,
      "epoch": 1.1363636363636362,
      "step": 25750
    },
    {
      "loss": 1.1076,
      "grad_norm": 37.82536697387695,
      "learning_rate": 6.341508481418443e-06,
      "epoch": 1.1385701676963813,
      "step": 25800
    },
    {
      "loss": 1.1075,
      "grad_norm": 6.971540927886963,
      "learning_rate": 6.325265695491958e-06,
      "epoch": 1.1407766990291262,
      "step": 25850
    },
    {
      "loss": 0.9987,
      "grad_norm": 19.87690544128418,
      "learning_rate": 6.3090229095654725e-06,
      "epoch": 1.1429832303618712,
      "step": 25900
    },
    {
      "loss": 1.1316,
      "grad_norm": 34.28675079345703,
      "learning_rate": 6.2927801236389865e-06,
      "epoch": 1.145189761694616,
      "step": 25950
    },
    {
      "loss": 0.9541,
      "grad_norm": 11.567648887634277,
      "learning_rate": 6.2765373377125014e-06,
      "epoch": 1.147396293027361,
      "step": 26000
    },
    {
      "loss": 0.9712,
      "grad_norm": 5.502350807189941,
      "learning_rate": 6.260294551786016e-06,
      "epoch": 1.149602824360106,
      "step": 26050
    },
    {
      "loss": 1.2094,
      "grad_norm": 24.105924606323242,
      "learning_rate": 6.24405176585953e-06,
      "epoch": 1.1518093556928508,
      "step": 26100
    },
    {
      "loss": 1.0202,
      "grad_norm": 24.289337158203125,
      "learning_rate": 6.227808979933045e-06,
      "epoch": 1.1540158870255959,
      "step": 26150
    },
    {
      "loss": 1.1332,
      "grad_norm": 15.532342910766602,
      "learning_rate": 6.211566194006559e-06,
      "epoch": 1.1562224183583407,
      "step": 26200
    },
    {
      "loss": 1.0726,
      "grad_norm": 12.014793395996094,
      "learning_rate": 6.195323408080074e-06,
      "epoch": 1.1584289496910856,
      "step": 26250
    },
    {
      "loss": 1.1529,
      "grad_norm": 20.75602912902832,
      "learning_rate": 6.179080622153589e-06,
      "epoch": 1.1606354810238306,
      "step": 26300
    },
    {
      "loss": 1.0574,
      "grad_norm": 19.623510360717773,
      "learning_rate": 6.162837836227103e-06,
      "epoch": 1.1628420123565755,
      "step": 26350
    },
    {
      "loss": 1.0739,
      "grad_norm": 11.155649185180664,
      "learning_rate": 6.146595050300618e-06,
      "epoch": 1.1650485436893203,
      "step": 26400
    },
    {
      "loss": 1.0678,
      "grad_norm": 12.783308029174805,
      "learning_rate": 6.130352264374133e-06,
      "epoch": 1.1672550750220654,
      "step": 26450
    },
    {
      "loss": 1.0897,
      "grad_norm": 15.401531219482422,
      "learning_rate": 6.114109478447647e-06,
      "epoch": 1.1694616063548102,
      "step": 26500
    },
    {
      "loss": 1.0001,
      "grad_norm": 33.25346755981445,
      "learning_rate": 6.097866692521161e-06,
      "epoch": 1.171668137687555,
      "step": 26550
    },
    {
      "loss": 1.0625,
      "grad_norm": 20.475515365600586,
      "learning_rate": 6.081623906594676e-06,
      "epoch": 1.1738746690203001,
      "step": 26600
    },
    {
      "loss": 1.1158,
      "grad_norm": 27.41462516784668,
      "learning_rate": 6.065381120668191e-06,
      "epoch": 1.176081200353045,
      "step": 26650
    },
    {
      "loss": 0.9776,
      "grad_norm": 24.181251525878906,
      "learning_rate": 6.049138334741705e-06,
      "epoch": 1.1782877316857898,
      "step": 26700
    },
    {
      "loss": 1.0831,
      "grad_norm": 9.846405029296875,
      "learning_rate": 6.03289554881522e-06,
      "epoch": 1.1804942630185349,
      "step": 26750
    },
    {
      "loss": 1.0282,
      "grad_norm": 19.3492374420166,
      "learning_rate": 6.016652762888735e-06,
      "epoch": 1.1827007943512797,
      "step": 26800
    },
    {
      "loss": 0.9428,
      "grad_norm": 22.650569915771484,
      "learning_rate": 6.000409976962249e-06,
      "epoch": 1.1849073256840248,
      "step": 26850
    },
    {
      "loss": 1.0416,
      "grad_norm": 23.5760440826416,
      "learning_rate": 5.984167191035763e-06,
      "epoch": 1.1871138570167696,
      "step": 26900
    },
    {
      "loss": 0.9859,
      "grad_norm": 15.979968070983887,
      "learning_rate": 5.967924405109279e-06,
      "epoch": 1.1893203883495145,
      "step": 26950
    },
    {
      "loss": 1.2217,
      "grad_norm": 12.82094669342041,
      "learning_rate": 5.951681619182793e-06,
      "epoch": 1.1915269196822595,
      "step": 27000
    },
    {
      "loss": 1.0105,
      "grad_norm": 30.027673721313477,
      "learning_rate": 5.935438833256307e-06,
      "epoch": 1.1937334510150044,
      "step": 27050
    },
    {
      "loss": 1.0604,
      "grad_norm": 22.621618270874023,
      "learning_rate": 5.9191960473298225e-06,
      "epoch": 1.1959399823477495,
      "step": 27100
    },
    {
      "loss": 0.9616,
      "grad_norm": 23.84056282043457,
      "learning_rate": 5.902953261403337e-06,
      "epoch": 1.1981465136804943,
      "step": 27150
    },
    {
      "loss": 0.9119,
      "grad_norm": 22.70197868347168,
      "learning_rate": 5.886710475476851e-06,
      "epoch": 1.2003530450132391,
      "step": 27200
    },
    {
      "loss": 1.1851,
      "grad_norm": 17.77842903137207,
      "learning_rate": 5.8704676895503655e-06,
      "epoch": 1.2025595763459842,
      "step": 27250
    },
    {
      "loss": 1.1158,
      "grad_norm": 18.09619140625,
      "learning_rate": 5.8542249036238804e-06,
      "epoch": 1.204766107678729,
      "step": 27300
    },
    {
      "loss": 0.9551,
      "grad_norm": 21.409208297729492,
      "learning_rate": 5.8379821176973945e-06,
      "epoch": 1.206972639011474,
      "step": 27350
    },
    {
      "loss": 1.051,
      "grad_norm": 36.36893844604492,
      "learning_rate": 5.821739331770909e-06,
      "epoch": 1.209179170344219,
      "step": 27400
    },
    {
      "loss": 1.0849,
      "grad_norm": 16.706546783447266,
      "learning_rate": 5.805496545844424e-06,
      "epoch": 1.2113857016769638,
      "step": 27450
    },
    {
      "loss": 1.2029,
      "grad_norm": 88.21241760253906,
      "learning_rate": 5.789253759917938e-06,
      "epoch": 1.2135922330097086,
      "step": 27500
    },
    {
      "loss": 1.0382,
      "grad_norm": 16.99203872680664,
      "learning_rate": 5.773010973991453e-06,
      "epoch": 1.2157987643424537,
      "step": 27550
    },
    {
      "loss": 1.0384,
      "grad_norm": 17.5843448638916,
      "learning_rate": 5.756768188064967e-06,
      "epoch": 1.2180052956751986,
      "step": 27600
    },
    {
      "loss": 0.945,
      "grad_norm": 19.029743194580078,
      "learning_rate": 5.740525402138482e-06,
      "epoch": 1.2202118270079434,
      "step": 27650
    },
    {
      "loss": 1.1038,
      "grad_norm": 22.80605697631836,
      "learning_rate": 5.724282616211996e-06,
      "epoch": 1.2224183583406885,
      "step": 27700
    },
    {
      "loss": 0.9521,
      "grad_norm": 8.968960762023926,
      "learning_rate": 5.708039830285511e-06,
      "epoch": 1.2246248896734333,
      "step": 27750
    },
    {
      "loss": 1.1097,
      "grad_norm": 37.6826286315918,
      "learning_rate": 5.691797044359026e-06,
      "epoch": 1.2268314210061784,
      "step": 27800
    },
    {
      "loss": 0.9416,
      "grad_norm": 10.908103942871094,
      "learning_rate": 5.67555425843254e-06,
      "epoch": 1.2290379523389232,
      "step": 27850
    },
    {
      "loss": 1.061,
      "grad_norm": 17.315092086791992,
      "learning_rate": 5.659311472506055e-06,
      "epoch": 1.231244483671668,
      "step": 27900
    },
    {
      "loss": 1.0422,
      "grad_norm": 13.054293632507324,
      "learning_rate": 5.643068686579569e-06,
      "epoch": 1.2334510150044131,
      "step": 27950
    },
    {
      "loss": 1.0612,
      "grad_norm": 14.90390396118164,
      "learning_rate": 5.626825900653084e-06,
      "epoch": 1.235657546337158,
      "step": 28000
    },
    {
      "loss": 1.0612,
      "grad_norm": 27.38912010192871,
      "learning_rate": 5.610583114726599e-06,
      "epoch": 1.237864077669903,
      "step": 28050
    },
    {
      "loss": 1.1689,
      "grad_norm": 14.249561309814453,
      "learning_rate": 5.594340328800113e-06,
      "epoch": 1.2400706090026479,
      "step": 28100
    },
    {
      "loss": 0.8729,
      "grad_norm": 18.24465560913086,
      "learning_rate": 5.578097542873628e-06,
      "epoch": 1.2422771403353927,
      "step": 28150
    },
    {
      "loss": 0.9982,
      "grad_norm": 8.499348640441895,
      "learning_rate": 5.561854756947143e-06,
      "epoch": 1.2444836716681378,
      "step": 28200
    },
    {
      "loss": 1.1185,
      "grad_norm": 33.58701705932617,
      "learning_rate": 5.545611971020657e-06,
      "epoch": 1.2466902030008826,
      "step": 28250
    },
    {
      "loss": 1.0891,
      "grad_norm": 24.50873565673828,
      "learning_rate": 5.529369185094171e-06,
      "epoch": 1.2488967343336275,
      "step": 28300
    },
    {
      "loss": 1.0978,
      "grad_norm": 31.056549072265625,
      "learning_rate": 5.513126399167687e-06,
      "epoch": 1.2511032656663725,
      "step": 28350
    },
    {
      "loss": 1.0204,
      "grad_norm": 17.551067352294922,
      "learning_rate": 5.496883613241201e-06,
      "epoch": 1.2533097969991174,
      "step": 28400
    },
    {
      "loss": 0.9977,
      "grad_norm": 23.438840866088867,
      "learning_rate": 5.480640827314715e-06,
      "epoch": 1.2555163283318622,
      "step": 28450
    },
    {
      "loss": 1.1668,
      "grad_norm": 16.466156005859375,
      "learning_rate": 5.4643980413882305e-06,
      "epoch": 1.2577228596646073,
      "step": 28500
    },
    {
      "loss": 1.0763,
      "grad_norm": 16.158000946044922,
      "learning_rate": 5.4481552554617445e-06,
      "epoch": 1.2599293909973521,
      "step": 28550
    },
    {
      "loss": 1.0311,
      "grad_norm": 18.05098533630371,
      "learning_rate": 5.431912469535259e-06,
      "epoch": 1.262135922330097,
      "step": 28600
    },
    {
      "loss": 0.9786,
      "grad_norm": 15.490102767944336,
      "learning_rate": 5.4156696836087735e-06,
      "epoch": 1.264342453662842,
      "step": 28650
    },
    {
      "loss": 1.0691,
      "grad_norm": 38.85519027709961,
      "learning_rate": 5.399426897682288e-06,
      "epoch": 1.2665489849955869,
      "step": 28700
    },
    {
      "loss": 0.9962,
      "grad_norm": 27.66451644897461,
      "learning_rate": 5.3831841117558025e-06,
      "epoch": 1.268755516328332,
      "step": 28750
    },
    {
      "loss": 0.8938,
      "grad_norm": 10.688887596130371,
      "learning_rate": 5.3669413258293165e-06,
      "epoch": 1.2709620476610768,
      "step": 28800
    },
    {
      "loss": 1.0442,
      "grad_norm": 19.578039169311523,
      "learning_rate": 5.350698539902832e-06,
      "epoch": 1.2731685789938216,
      "step": 28850
    },
    {
      "loss": 1.0639,
      "grad_norm": 18.239694595336914,
      "learning_rate": 5.334455753976346e-06,
      "epoch": 1.2753751103265667,
      "step": 28900
    },
    {
      "loss": 1.031,
      "grad_norm": 20.563276290893555,
      "learning_rate": 5.31821296804986e-06,
      "epoch": 1.2775816416593115,
      "step": 28950
    },
    {
      "loss": 1.099,
      "grad_norm": 25.841907501220703,
      "learning_rate": 5.301970182123375e-06,
      "epoch": 1.2797881729920566,
      "step": 29000
    },
    {
      "loss": 1.1661,
      "grad_norm": 16.685962677001953,
      "learning_rate": 5.28572739619689e-06,
      "epoch": 1.2819947043248014,
      "step": 29050
    },
    {
      "loss": 1.1346,
      "grad_norm": 18.53701400756836,
      "learning_rate": 5.269484610270404e-06,
      "epoch": 1.2842012356575463,
      "step": 29100
    },
    {
      "loss": 1.0858,
      "grad_norm": 16.2436580657959,
      "learning_rate": 5.253241824343919e-06,
      "epoch": 1.2864077669902914,
      "step": 29150
    },
    {
      "loss": 1.1729,
      "grad_norm": 18.1815185546875,
      "learning_rate": 5.236999038417434e-06,
      "epoch": 1.2886142983230362,
      "step": 29200
    },
    {
      "loss": 0.9706,
      "grad_norm": 20.1231746673584,
      "learning_rate": 5.220756252490948e-06,
      "epoch": 1.290820829655781,
      "step": 29250
    },
    {
      "loss": 0.9393,
      "grad_norm": 16.817956924438477,
      "learning_rate": 5.204513466564463e-06,
      "epoch": 1.293027360988526,
      "step": 29300
    },
    {
      "loss": 1.0739,
      "grad_norm": 30.774566650390625,
      "learning_rate": 5.188270680637977e-06,
      "epoch": 1.295233892321271,
      "step": 29350
    },
    {
      "loss": 1.0768,
      "grad_norm": 19.834354400634766,
      "learning_rate": 5.172027894711492e-06,
      "epoch": 1.2974404236540158,
      "step": 29400
    },
    {
      "loss": 1.1141,
      "grad_norm": 20.699321746826172,
      "learning_rate": 5.155785108785007e-06,
      "epoch": 1.2996469549867609,
      "step": 29450
    },
    {
      "loss": 1.1095,
      "grad_norm": 12.805824279785156,
      "learning_rate": 5.139542322858521e-06,
      "epoch": 1.3018534863195057,
      "step": 29500
    },
    {
      "loss": 1.0753,
      "grad_norm": 10.893596649169922,
      "learning_rate": 5.123299536932036e-06,
      "epoch": 1.3040600176522505,
      "step": 29550
    },
    {
      "loss": 1.0049,
      "grad_norm": 18.443435668945312,
      "learning_rate": 5.107056751005551e-06,
      "epoch": 1.3062665489849956,
      "step": 29600
    },
    {
      "loss": 0.9892,
      "grad_norm": 37.5889892578125,
      "learning_rate": 5.090813965079065e-06,
      "epoch": 1.3084730803177405,
      "step": 29650
    },
    {
      "loss": 1.1543,
      "grad_norm": 14.606090545654297,
      "learning_rate": 5.074571179152579e-06,
      "epoch": 1.3106796116504853,
      "step": 29700
    },
    {
      "loss": 1.0184,
      "grad_norm": 11.191173553466797,
      "learning_rate": 5.058328393226094e-06,
      "epoch": 1.3128861429832304,
      "step": 29750
    },
    {
      "loss": 1.0278,
      "grad_norm": 8.065652847290039,
      "learning_rate": 5.042085607299609e-06,
      "epoch": 1.3150926743159752,
      "step": 29800
    },
    {
      "loss": 1.0149,
      "grad_norm": 21.026260375976562,
      "learning_rate": 5.025842821373123e-06,
      "epoch": 1.3172992056487203,
      "step": 29850
    },
    {
      "loss": 1.022,
      "grad_norm": 15.635645866394043,
      "learning_rate": 5.009600035446638e-06,
      "epoch": 1.3195057369814651,
      "step": 29900
    },
    {
      "loss": 1.1925,
      "grad_norm": 22.060997009277344,
      "learning_rate": 4.9933572495201525e-06,
      "epoch": 1.3217122683142102,
      "step": 29950
    },
    {
      "loss": 1.0012,
      "grad_norm": 17.5067195892334,
      "learning_rate": 4.9771144635936666e-06,
      "epoch": 1.323918799646955,
      "step": 30000
    },
    {
      "loss": 0.921,
      "grad_norm": 14.309187889099121,
      "learning_rate": 4.960871677667181e-06,
      "epoch": 1.3261253309796999,
      "step": 30050
    },
    {
      "loss": 1.0559,
      "grad_norm": 10.988444328308105,
      "learning_rate": 4.944628891740696e-06,
      "epoch": 1.328331862312445,
      "step": 30100
    },
    {
      "loss": 1.0136,
      "grad_norm": 32.558963775634766,
      "learning_rate": 4.92838610581421e-06,
      "epoch": 1.3305383936451898,
      "step": 30150
    },
    {
      "loss": 0.9902,
      "grad_norm": 14.890475273132324,
      "learning_rate": 4.9121433198877245e-06,
      "epoch": 1.3327449249779346,
      "step": 30200
    },
    {
      "loss": 0.9785,
      "grad_norm": 7.648209095001221,
      "learning_rate": 4.89590053396124e-06,
      "epoch": 1.3349514563106797,
      "step": 30250
    },
    {
      "loss": 1.0153,
      "grad_norm": 19.34231948852539,
      "learning_rate": 4.879657748034754e-06,
      "epoch": 1.3371579876434245,
      "step": 30300
    },
    {
      "loss": 0.9444,
      "grad_norm": 25.200191497802734,
      "learning_rate": 4.863414962108268e-06,
      "epoch": 1.3393645189761694,
      "step": 30350
    },
    {
      "loss": 1.0965,
      "grad_norm": 28.2724609375,
      "learning_rate": 4.847172176181783e-06,
      "epoch": 1.3415710503089144,
      "step": 30400
    },
    {
      "loss": 1.0285,
      "grad_norm": 12.7472562789917,
      "learning_rate": 4.830929390255298e-06,
      "epoch": 1.3437775816416593,
      "step": 30450
    },
    {
      "loss": 1.0082,
      "grad_norm": 24.381149291992188,
      "learning_rate": 4.814686604328812e-06,
      "epoch": 1.3459841129744041,
      "step": 30500
    },
    {
      "loss": 1.0515,
      "grad_norm": 13.87809944152832,
      "learning_rate": 4.798443818402327e-06,
      "epoch": 1.3481906443071492,
      "step": 30550
    },
    {
      "loss": 1.0583,
      "grad_norm": 26.261981964111328,
      "learning_rate": 4.782201032475842e-06,
      "epoch": 1.350397175639894,
      "step": 30600
    },
    {
      "loss": 1.0493,
      "grad_norm": 22.385265350341797,
      "learning_rate": 4.765958246549356e-06,
      "epoch": 1.3526037069726389,
      "step": 30650
    },
    {
      "loss": 1.006,
      "grad_norm": 14.815241813659668,
      "learning_rate": 4.749715460622871e-06,
      "epoch": 1.354810238305384,
      "step": 30700
    },
    {
      "loss": 0.8915,
      "grad_norm": 20.94198989868164,
      "learning_rate": 4.733472674696385e-06,
      "epoch": 1.3570167696381288,
      "step": 30750
    },
    {
      "loss": 1.0979,
      "grad_norm": 21.95098114013672,
      "learning_rate": 4.7172298887699e-06,
      "epoch": 1.3592233009708738,
      "step": 30800
    },
    {
      "loss": 1.0616,
      "grad_norm": 11.044532775878906,
      "learning_rate": 4.700987102843414e-06,
      "epoch": 1.3614298323036187,
      "step": 30850
    },
    {
      "loss": 0.9627,
      "grad_norm": 10.852505683898926,
      "learning_rate": 4.684744316916929e-06,
      "epoch": 1.3636363636363638,
      "step": 30900
    },
    {
      "loss": 0.9837,
      "grad_norm": 19.07978630065918,
      "learning_rate": 4.668501530990444e-06,
      "epoch": 1.3658428949691086,
      "step": 30950
    },
    {
      "loss": 0.9852,
      "grad_norm": 27.437419891357422,
      "learning_rate": 4.652258745063958e-06,
      "epoch": 1.3680494263018534,
      "step": 31000
    },
    {
      "loss": 0.9242,
      "grad_norm": 17.891958236694336,
      "learning_rate": 4.636015959137473e-06,
      "epoch": 1.3702559576345985,
      "step": 31050
    },
    {
      "loss": 0.9805,
      "grad_norm": 18.742605209350586,
      "learning_rate": 4.619773173210987e-06,
      "epoch": 1.3724624889673434,
      "step": 31100
    },
    {
      "loss": 1.0152,
      "grad_norm": 13.929910659790039,
      "learning_rate": 4.603530387284502e-06,
      "epoch": 1.3746690203000882,
      "step": 31150
    },
    {
      "loss": 0.9676,
      "grad_norm": 20.282711029052734,
      "learning_rate": 4.587287601358017e-06,
      "epoch": 1.3768755516328333,
      "step": 31200
    },
    {
      "loss": 1.0228,
      "grad_norm": 12.032758712768555,
      "learning_rate": 4.571044815431531e-06,
      "epoch": 1.379082082965578,
      "step": 31250
    },
    {
      "loss": 1.1721,
      "grad_norm": 22.64283561706543,
      "learning_rate": 4.5548020295050456e-06,
      "epoch": 1.381288614298323,
      "step": 31300
    },
    {
      "loss": 0.9998,
      "grad_norm": 13.659968376159668,
      "learning_rate": 4.5385592435785605e-06,
      "epoch": 1.383495145631068,
      "step": 31350
    },
    {
      "loss": 1.0335,
      "grad_norm": 22.424983978271484,
      "learning_rate": 4.5223164576520745e-06,
      "epoch": 1.3857016769638129,
      "step": 31400
    },
    {
      "loss": 1.0075,
      "grad_norm": 21.38799476623535,
      "learning_rate": 4.506073671725589e-06,
      "epoch": 1.3879082082965577,
      "step": 31450
    },
    {
      "loss": 1.1094,
      "grad_norm": 18.31536865234375,
      "learning_rate": 4.489830885799104e-06,
      "epoch": 1.3901147396293028,
      "step": 31500
    },
    {
      "loss": 1.0666,
      "grad_norm": 23.649038314819336,
      "learning_rate": 4.473588099872618e-06,
      "epoch": 1.3923212709620476,
      "step": 31550
    },
    {
      "loss": 0.9203,
      "grad_norm": 10.46388053894043,
      "learning_rate": 4.4573453139461324e-06,
      "epoch": 1.3945278022947925,
      "step": 31600
    },
    {
      "loss": 1.0406,
      "grad_norm": 24.21202850341797,
      "learning_rate": 4.441102528019648e-06,
      "epoch": 1.3967343336275375,
      "step": 31650
    },
    {
      "loss": 1.0574,
      "grad_norm": 19.45438575744629,
      "learning_rate": 4.424859742093162e-06,
      "epoch": 1.3989408649602824,
      "step": 31700
    },
    {
      "loss": 1.0841,
      "grad_norm": 25.134952545166016,
      "learning_rate": 4.408616956166676e-06,
      "epoch": 1.4011473962930274,
      "step": 31750
    },
    {
      "loss": 1.1069,
      "grad_norm": 14.604813575744629,
      "learning_rate": 4.392374170240191e-06,
      "epoch": 1.4033539276257723,
      "step": 31800
    },
    {
      "loss": 1.0713,
      "grad_norm": 24.462190628051758,
      "learning_rate": 4.376131384313706e-06,
      "epoch": 1.4055604589585173,
      "step": 31850
    },
    {
      "loss": 1.0567,
      "grad_norm": 18.58539581298828,
      "learning_rate": 4.35988859838722e-06,
      "epoch": 1.4077669902912622,
      "step": 31900
    },
    {
      "loss": 1.085,
      "grad_norm": 29.57516860961914,
      "learning_rate": 4.343645812460734e-06,
      "epoch": 1.409973521624007,
      "step": 31950
    },
    {
      "loss": 1.0258,
      "grad_norm": 14.371058464050293,
      "learning_rate": 4.32740302653425e-06,
      "epoch": 1.412180052956752,
      "step": 32000
    },
    {
      "loss": 1.0334,
      "grad_norm": 5.456805229187012,
      "learning_rate": 4.311160240607764e-06,
      "epoch": 1.414386584289497,
      "step": 32050
    },
    {
      "loss": 1.0638,
      "grad_norm": 9.541779518127441,
      "learning_rate": 4.294917454681278e-06,
      "epoch": 1.4165931156222418,
      "step": 32100
    },
    {
      "loss": 0.9728,
      "grad_norm": 28.74201011657715,
      "learning_rate": 4.278674668754793e-06,
      "epoch": 1.4187996469549868,
      "step": 32150
    },
    {
      "loss": 1.0835,
      "grad_norm": 11.516477584838867,
      "learning_rate": 4.262431882828308e-06,
      "epoch": 1.4210061782877317,
      "step": 32200
    },
    {
      "loss": 1.0478,
      "grad_norm": 32.683082580566406,
      "learning_rate": 4.246189096901822e-06,
      "epoch": 1.4232127096204765,
      "step": 32250
    },
    {
      "loss": 1.1397,
      "grad_norm": 23.076173782348633,
      "learning_rate": 4.229946310975337e-06,
      "epoch": 1.4254192409532216,
      "step": 32300
    },
    {
      "loss": 1.0735,
      "grad_norm": 16.154857635498047,
      "learning_rate": 4.213703525048851e-06,
      "epoch": 1.4276257722859664,
      "step": 32350
    },
    {
      "loss": 1.0489,
      "grad_norm": 24.4536075592041,
      "learning_rate": 4.197460739122366e-06,
      "epoch": 1.4298323036187113,
      "step": 32400
    },
    {
      "loss": 1.1915,
      "grad_norm": 11.490377426147461,
      "learning_rate": 4.181217953195881e-06,
      "epoch": 1.4320388349514563,
      "step": 32450
    },
    {
      "loss": 1.009,
      "grad_norm": 16.621627807617188,
      "learning_rate": 4.164975167269395e-06,
      "epoch": 1.4342453662842012,
      "step": 32500
    },
    {
      "loss": 0.9151,
      "grad_norm": 15.552935600280762,
      "learning_rate": 4.14873238134291e-06,
      "epoch": 1.436451897616946,
      "step": 32550
    },
    {
      "loss": 1.039,
      "grad_norm": 19.96803855895996,
      "learning_rate": 4.1324895954164246e-06,
      "epoch": 1.438658428949691,
      "step": 32600
    },
    {
      "loss": 1.041,
      "grad_norm": 25.46615982055664,
      "learning_rate": 4.116246809489939e-06,
      "epoch": 1.440864960282436,
      "step": 32650
    },
    {
      "loss": 1.0562,
      "grad_norm": 29.158803939819336,
      "learning_rate": 4.100004023563453e-06,
      "epoch": 1.443071491615181,
      "step": 32700
    },
    {
      "loss": 1.0455,
      "grad_norm": 17.029064178466797,
      "learning_rate": 4.0837612376369684e-06,
      "epoch": 1.4452780229479258,
      "step": 32750
    },
    {
      "loss": 1.0556,
      "grad_norm": 35.4015998840332,
      "learning_rate": 4.0675184517104825e-06,
      "epoch": 1.447484554280671,
      "step": 32800
    },
    {
      "loss": 1.0653,
      "grad_norm": 32.5125846862793,
      "learning_rate": 4.0512756657839965e-06,
      "epoch": 1.4496910856134158,
      "step": 32850
    },
    {
      "loss": 0.9745,
      "grad_norm": 18.72734832763672,
      "learning_rate": 4.0350328798575114e-06,
      "epoch": 1.4518976169461606,
      "step": 32900
    },
    {
      "loss": 1.1904,
      "grad_norm": 17.59340476989746,
      "learning_rate": 4.018790093931026e-06,
      "epoch": 1.4541041482789057,
      "step": 32950
    },
    {
      "loss": 1.1089,
      "grad_norm": 27.07973289489746,
      "learning_rate": 4.00254730800454e-06,
      "epoch": 1.4563106796116505,
      "step": 33000
    },
    {
      "loss": 1.0543,
      "grad_norm": 26.827058792114258,
      "learning_rate": 3.9863045220780545e-06,
      "epoch": 1.4585172109443953,
      "step": 33050
    },
    {
      "loss": 1.0692,
      "grad_norm": 24.78455352783203,
      "learning_rate": 3.97006173615157e-06,
      "epoch": 1.4607237422771404,
      "step": 33100
    },
    {
      "loss": 1.0141,
      "grad_norm": 26.600791931152344,
      "learning_rate": 3.953818950225084e-06,
      "epoch": 1.4629302736098853,
      "step": 33150
    },
    {
      "loss": 1.0436,
      "grad_norm": 10.283196449279785,
      "learning_rate": 3.937576164298598e-06,
      "epoch": 1.46513680494263,
      "step": 33200
    },
    {
      "loss": 0.9845,
      "grad_norm": 21.98051643371582,
      "learning_rate": 3.921333378372114e-06,
      "epoch": 1.4673433362753752,
      "step": 33250
    },
    {
      "loss": 1.0617,
      "grad_norm": 15.512102127075195,
      "learning_rate": 3.905090592445628e-06,
      "epoch": 1.46954986760812,
      "step": 33300
    },
    {
      "loss": 1.0325,
      "grad_norm": 28.933591842651367,
      "learning_rate": 3.888847806519142e-06,
      "epoch": 1.4717563989408649,
      "step": 33350
    },
    {
      "loss": 1.0401,
      "grad_norm": 25.960893630981445,
      "learning_rate": 3.872605020592657e-06,
      "epoch": 1.47396293027361,
      "step": 33400
    },
    {
      "loss": 1.0265,
      "grad_norm": 17.878034591674805,
      "learning_rate": 3.856362234666172e-06,
      "epoch": 1.4761694616063548,
      "step": 33450
    },
    {
      "loss": 0.9703,
      "grad_norm": 25.16287612915039,
      "learning_rate": 3.840119448739686e-06,
      "epoch": 1.4783759929390996,
      "step": 33500
    },
    {
      "loss": 1.138,
      "grad_norm": 27.12427520751953,
      "learning_rate": 3.823876662813201e-06,
      "epoch": 1.4805825242718447,
      "step": 33550
    },
    {
      "loss": 1.107,
      "grad_norm": 15.597825050354004,
      "learning_rate": 3.807633876886716e-06,
      "epoch": 1.4827890556045895,
      "step": 33600
    },
    {
      "loss": 1.056,
      "grad_norm": 16.159347534179688,
      "learning_rate": 3.7913910909602303e-06,
      "epoch": 1.4849955869373346,
      "step": 33650
    },
    {
      "loss": 0.9498,
      "grad_norm": 20.648900985717773,
      "learning_rate": 3.7751483050337444e-06,
      "epoch": 1.4872021182700794,
      "step": 33700
    },
    {
      "loss": 1.044,
      "grad_norm": 20.343435287475586,
      "learning_rate": 3.758905519107259e-06,
      "epoch": 1.4894086496028245,
      "step": 33750
    },
    {
      "loss": 1.0509,
      "grad_norm": 21.01259994506836,
      "learning_rate": 3.7426627331807738e-06,
      "epoch": 1.4916151809355693,
      "step": 33800
    },
    {
      "loss": 1.031,
      "grad_norm": 9.402669906616211,
      "learning_rate": 3.7264199472542882e-06,
      "epoch": 1.4938217122683142,
      "step": 33850
    },
    {
      "loss": 1.0821,
      "grad_norm": 5.49282169342041,
      "learning_rate": 3.7101771613278027e-06,
      "epoch": 1.4960282436010592,
      "step": 33900
    },
    {
      "loss": 1.0664,
      "grad_norm": 12.581415176391602,
      "learning_rate": 3.6939343754013176e-06,
      "epoch": 1.498234774933804,
      "step": 33950
    },
    {
      "loss": 1.1156,
      "grad_norm": 19.746313095092773,
      "learning_rate": 3.677691589474832e-06,
      "epoch": 1.500441306266549,
      "step": 34000
    },
    {
      "loss": 1.0648,
      "grad_norm": 12.660548210144043,
      "learning_rate": 3.6614488035483466e-06,
      "epoch": 1.502647837599294,
      "step": 34050
    },
    {
      "loss": 0.9397,
      "grad_norm": 32.30632781982422,
      "learning_rate": 3.645206017621861e-06,
      "epoch": 1.5048543689320388,
      "step": 34100
    },
    {
      "loss": 1.0793,
      "grad_norm": 15.881083488464355,
      "learning_rate": 3.6289632316953755e-06,
      "epoch": 1.5070609002647837,
      "step": 34150
    },
    {
      "loss": 1.0354,
      "grad_norm": 32.91627502441406,
      "learning_rate": 3.6127204457688904e-06,
      "epoch": 1.5092674315975287,
      "step": 34200
    },
    {
      "loss": 1.0884,
      "grad_norm": 24.944293975830078,
      "learning_rate": 3.596477659842405e-06,
      "epoch": 1.5114739629302736,
      "step": 34250
    },
    {
      "loss": 1.0913,
      "grad_norm": 18.56882095336914,
      "learning_rate": 3.5802348739159194e-06,
      "epoch": 1.5136804942630184,
      "step": 34300
    },
    {
      "loss": 1.0233,
      "grad_norm": 18.493955612182617,
      "learning_rate": 3.563992087989434e-06,
      "epoch": 1.5158870255957635,
      "step": 34350
    },
    {
      "loss": 1.0813,
      "grad_norm": 12.179512977600098,
      "learning_rate": 3.5477493020629484e-06,
      "epoch": 1.5180935569285083,
      "step": 34400
    },
    {
      "loss": 1.1099,
      "grad_norm": 18.001537322998047,
      "learning_rate": 3.5315065161364633e-06,
      "epoch": 1.5203000882612532,
      "step": 34450
    },
    {
      "loss": 0.9596,
      "grad_norm": 25.980321884155273,
      "learning_rate": 3.5152637302099773e-06,
      "epoch": 1.5225066195939982,
      "step": 34500
    },
    {
      "loss": 1.136,
      "grad_norm": 31.813825607299805,
      "learning_rate": 3.4990209442834922e-06,
      "epoch": 1.5247131509267433,
      "step": 34550
    },
    {
      "loss": 1.0326,
      "grad_norm": 9.960723876953125,
      "learning_rate": 3.482778158357007e-06,
      "epoch": 1.526919682259488,
      "step": 34600
    },
    {
      "loss": 1.0021,
      "grad_norm": 17.677968978881836,
      "learning_rate": 3.466535372430521e-06,
      "epoch": 1.529126213592233,
      "step": 34650
    },
    {
      "loss": 1.0749,
      "grad_norm": 35.33396530151367,
      "learning_rate": 3.450292586504036e-06,
      "epoch": 1.531332744924978,
      "step": 34700
    },
    {
      "loss": 1.0781,
      "grad_norm": 22.473180770874023,
      "learning_rate": 3.4340498005775506e-06,
      "epoch": 1.533539276257723,
      "step": 34750
    },
    {
      "loss": 1.1106,
      "grad_norm": 26.244382858276367,
      "learning_rate": 3.417807014651065e-06,
      "epoch": 1.5357458075904677,
      "step": 34800
    },
    {
      "loss": 1.0948,
      "grad_norm": 21.587430953979492,
      "learning_rate": 3.4015642287245795e-06,
      "epoch": 1.5379523389232128,
      "step": 34850
    },
    {
      "loss": 1.2111,
      "grad_norm": 12.475177764892578,
      "learning_rate": 3.385321442798094e-06,
      "epoch": 1.5401588702559577,
      "step": 34900
    },
    {
      "loss": 1.0669,
      "grad_norm": 19.803485870361328,
      "learning_rate": 3.369078656871609e-06,
      "epoch": 1.5423654015887025,
      "step": 34950
    },
    {
      "loss": 0.9773,
      "grad_norm": 23.72738265991211,
      "learning_rate": 3.3528358709451234e-06,
      "epoch": 1.5445719329214476,
      "step": 35000
    },
    {
      "loss": 1.0984,
      "grad_norm": 19.30367660522461,
      "learning_rate": 3.336593085018638e-06,
      "epoch": 1.5467784642541924,
      "step": 35050
    },
    {
      "loss": 1.0878,
      "grad_norm": 16.619712829589844,
      "learning_rate": 3.3203502990921523e-06,
      "epoch": 1.5489849955869373,
      "step": 35100
    },
    {
      "loss": 0.9495,
      "grad_norm": 18.70716667175293,
      "learning_rate": 3.3041075131656672e-06,
      "epoch": 1.5511915269196823,
      "step": 35150
    },
    {
      "loss": 1.0817,
      "grad_norm": 15.941239356994629,
      "learning_rate": 3.2878647272391813e-06,
      "epoch": 1.5533980582524272,
      "step": 35200
    },
    {
      "loss": 1.1417,
      "grad_norm": 14.267118453979492,
      "learning_rate": 3.271621941312696e-06,
      "epoch": 1.555604589585172,
      "step": 35250
    },
    {
      "loss": 0.9443,
      "grad_norm": 63.95326614379883,
      "learning_rate": 3.2553791553862107e-06,
      "epoch": 1.557811120917917,
      "step": 35300
    },
    {
      "loss": 1.0348,
      "grad_norm": 28.520666122436523,
      "learning_rate": 3.239136369459725e-06,
      "epoch": 1.560017652250662,
      "step": 35350
    },
    {
      "loss": 0.9816,
      "grad_norm": 25.538375854492188,
      "learning_rate": 3.22289358353324e-06,
      "epoch": 1.5622241835834068,
      "step": 35400
    },
    {
      "loss": 0.9845,
      "grad_norm": 26.593961715698242,
      "learning_rate": 3.206650797606754e-06,
      "epoch": 1.5644307149161518,
      "step": 35450
    },
    {
      "loss": 1.1007,
      "grad_norm": 28.959909439086914,
      "learning_rate": 3.190408011680269e-06,
      "epoch": 1.5666372462488969,
      "step": 35500
    },
    {
      "loss": 1.0008,
      "grad_norm": 22.091276168823242,
      "learning_rate": 3.1741652257537835e-06,
      "epoch": 1.5688437775816415,
      "step": 35550
    },
    {
      "loss": 0.9633,
      "grad_norm": 18.812040328979492,
      "learning_rate": 3.157922439827298e-06,
      "epoch": 1.5710503089143866,
      "step": 35600
    },
    {
      "loss": 0.9786,
      "grad_norm": 13.722427368164062,
      "learning_rate": 3.141679653900813e-06,
      "epoch": 1.5732568402471316,
      "step": 35650
    },
    {
      "loss": 1.1346,
      "grad_norm": 14.736591339111328,
      "learning_rate": 3.1254368679743274e-06,
      "epoch": 1.5754633715798765,
      "step": 35700
    },
    {
      "loss": 0.9466,
      "grad_norm": 16.113845825195312,
      "learning_rate": 3.109194082047842e-06,
      "epoch": 1.5776699029126213,
      "step": 35750
    },
    {
      "loss": 1.077,
      "grad_norm": 19.540691375732422,
      "learning_rate": 3.0929512961213563e-06,
      "epoch": 1.5798764342453664,
      "step": 35800
    },
    {
      "loss": 0.9806,
      "grad_norm": 22.701074600219727,
      "learning_rate": 3.076708510194871e-06,
      "epoch": 1.5820829655781112,
      "step": 35850
    },
    {
      "loss": 1.073,
      "grad_norm": 21.580781936645508,
      "learning_rate": 3.0604657242683853e-06,
      "epoch": 1.584289496910856,
      "step": 35900
    },
    {
      "loss": 0.9098,
      "grad_norm": 10.926237106323242,
      "learning_rate": 3.0442229383419e-06,
      "epoch": 1.5864960282436011,
      "step": 35950
    },
    {
      "loss": 1.064,
      "grad_norm": 28.09720230102539,
      "learning_rate": 3.0279801524154147e-06,
      "epoch": 1.588702559576346,
      "step": 36000
    },
    {
      "loss": 1.004,
      "grad_norm": 13.486719131469727,
      "learning_rate": 3.011737366488929e-06,
      "epoch": 1.5909090909090908,
      "step": 36050
    },
    {
      "loss": 0.9855,
      "grad_norm": 23.874210357666016,
      "learning_rate": 2.995494580562444e-06,
      "epoch": 1.593115622241836,
      "step": 36100
    },
    {
      "loss": 0.9034,
      "grad_norm": 26.87251853942871,
      "learning_rate": 2.979251794635958e-06,
      "epoch": 1.5953221535745807,
      "step": 36150
    },
    {
      "loss": 0.8933,
      "grad_norm": 17.995115280151367,
      "learning_rate": 2.963009008709473e-06,
      "epoch": 1.5975286849073256,
      "step": 36200
    },
    {
      "loss": 0.9825,
      "grad_norm": 17.035640716552734,
      "learning_rate": 2.9467662227829875e-06,
      "epoch": 1.5997352162400706,
      "step": 36250
    },
    {
      "loss": 1.0164,
      "grad_norm": 18.0012149810791,
      "learning_rate": 2.930523436856502e-06,
      "epoch": 1.6019417475728155,
      "step": 36300
    },
    {
      "loss": 1.0529,
      "grad_norm": 24.268789291381836,
      "learning_rate": 2.914280650930017e-06,
      "epoch": 1.6041482789055603,
      "step": 36350
    },
    {
      "loss": 0.9934,
      "grad_norm": 21.360002517700195,
      "learning_rate": 2.898037865003531e-06,
      "epoch": 1.6063548102383054,
      "step": 36400
    },
    {
      "loss": 0.9247,
      "grad_norm": 14.21136474609375,
      "learning_rate": 2.881795079077046e-06,
      "epoch": 1.6085613415710505,
      "step": 36450
    },
    {
      "loss": 1.0582,
      "grad_norm": 12.259356498718262,
      "learning_rate": 2.8655522931505603e-06,
      "epoch": 1.610767872903795,
      "step": 36500
    },
    {
      "loss": 0.9641,
      "grad_norm": 22.03168296813965,
      "learning_rate": 2.8493095072240748e-06,
      "epoch": 1.6129744042365401,
      "step": 36550
    },
    {
      "loss": 1.0764,
      "grad_norm": 15.153886795043945,
      "learning_rate": 2.8330667212975893e-06,
      "epoch": 1.6151809355692852,
      "step": 36600
    },
    {
      "loss": 1.0497,
      "grad_norm": 20.053447723388672,
      "learning_rate": 2.816823935371104e-06,
      "epoch": 1.61738746690203,
      "step": 36650
    },
    {
      "loss": 1.039,
      "grad_norm": 25.915925979614258,
      "learning_rate": 2.8005811494446186e-06,
      "epoch": 1.619593998234775,
      "step": 36700
    },
    {
      "loss": 1.0519,
      "grad_norm": 20.951642990112305,
      "learning_rate": 2.784338363518133e-06,
      "epoch": 1.62180052956752,
      "step": 36750
    },
    {
      "loss": 0.9401,
      "grad_norm": 20.933002471923828,
      "learning_rate": 2.768095577591648e-06,
      "epoch": 1.6240070609002648,
      "step": 36800
    },
    {
      "loss": 0.9903,
      "grad_norm": 23.634525299072266,
      "learning_rate": 2.751852791665162e-06,
      "epoch": 1.6262135922330097,
      "step": 36850
    },
    {
      "loss": 0.9966,
      "grad_norm": 33.85166549682617,
      "learning_rate": 2.735610005738677e-06,
      "epoch": 1.6284201235657547,
      "step": 36900
    },
    {
      "loss": 1.105,
      "grad_norm": 11.058332443237305,
      "learning_rate": 2.719367219812191e-06,
      "epoch": 1.6306266548984996,
      "step": 36950
    },
    {
      "loss": 1.1875,
      "grad_norm": 26.846492767333984,
      "learning_rate": 2.703124433885706e-06,
      "epoch": 1.6328331862312444,
      "step": 37000
    },
    {
      "loss": 0.9228,
      "grad_norm": 17.14443588256836,
      "learning_rate": 2.686881647959221e-06,
      "epoch": 1.6350397175639895,
      "step": 37050
    },
    {
      "loss": 0.9192,
      "grad_norm": 14.021873474121094,
      "learning_rate": 2.670638862032735e-06,
      "epoch": 1.6372462488967343,
      "step": 37100
    },
    {
      "loss": 1.0046,
      "grad_norm": 11.976360321044922,
      "learning_rate": 2.65439607610625e-06,
      "epoch": 1.6394527802294792,
      "step": 37150
    },
    {
      "loss": 0.9834,
      "grad_norm": 118.96969604492188,
      "learning_rate": 2.6381532901797643e-06,
      "epoch": 1.6416593115622242,
      "step": 37200
    },
    {
      "loss": 1.0242,
      "grad_norm": 19.963804244995117,
      "learning_rate": 2.6219105042532788e-06,
      "epoch": 1.643865842894969,
      "step": 37250
    },
    {
      "loss": 1.0369,
      "grad_norm": 14.919379234313965,
      "learning_rate": 2.6056677183267932e-06,
      "epoch": 1.646072374227714,
      "step": 37300
    },
    {
      "loss": 1.0532,
      "grad_norm": 11.11609935760498,
      "learning_rate": 2.589424932400308e-06,
      "epoch": 1.648278905560459,
      "step": 37350
    },
    {
      "loss": 1.1473,
      "grad_norm": 16.371055603027344,
      "learning_rate": 2.573182146473822e-06,
      "epoch": 1.650485436893204,
      "step": 37400
    },
    {
      "loss": 0.954,
      "grad_norm": 18.284324645996094,
      "learning_rate": 2.556939360547337e-06,
      "epoch": 1.6526919682259487,
      "step": 37450
    },
    {
      "loss": 1.1355,
      "grad_norm": 30.78138542175293,
      "learning_rate": 2.5406965746208516e-06,
      "epoch": 1.6548984995586937,
      "step": 37500
    },
    {
      "loss": 0.917,
      "grad_norm": 25.193723678588867,
      "learning_rate": 2.524453788694366e-06,
      "epoch": 1.6571050308914388,
      "step": 37550
    },
    {
      "loss": 1.0327,
      "grad_norm": 12.392350196838379,
      "learning_rate": 2.508211002767881e-06,
      "epoch": 1.6593115622241836,
      "step": 37600
    },
    {
      "loss": 1.0891,
      "grad_norm": 27.3555908203125,
      "learning_rate": 2.491968216841395e-06,
      "epoch": 1.6615180935569285,
      "step": 37650
    },
    {
      "loss": 1.0343,
      "grad_norm": 16.32837677001953,
      "learning_rate": 2.47572543091491e-06,
      "epoch": 1.6637246248896735,
      "step": 37700
    },
    {
      "loss": 1.2055,
      "grad_norm": 13.523508071899414,
      "learning_rate": 2.4594826449884244e-06,
      "epoch": 1.6659311562224184,
      "step": 37750
    },
    {
      "loss": 1.008,
      "grad_norm": 17.269685745239258,
      "learning_rate": 2.443239859061939e-06,
      "epoch": 1.6681376875551632,
      "step": 37800
    },
    {
      "loss": 0.9216,
      "grad_norm": 27.106809616088867,
      "learning_rate": 2.4269970731354538e-06,
      "epoch": 1.6703442188879083,
      "step": 37850
    },
    {
      "loss": 1.1409,
      "grad_norm": 18.931787490844727,
      "learning_rate": 2.4107542872089683e-06,
      "epoch": 1.6725507502206531,
      "step": 37900
    },
    {
      "loss": 0.9573,
      "grad_norm": 28.52354621887207,
      "learning_rate": 2.3945115012824827e-06,
      "epoch": 1.674757281553398,
      "step": 37950
    },
    {
      "loss": 0.9674,
      "grad_norm": 23.00478744506836,
      "learning_rate": 2.3782687153559972e-06,
      "epoch": 1.676963812886143,
      "step": 38000
    },
    {
      "loss": 1.2039,
      "grad_norm": 16.249662399291992,
      "learning_rate": 2.3620259294295117e-06,
      "epoch": 1.679170344218888,
      "step": 38050
    },
    {
      "loss": 1.1097,
      "grad_norm": 23.855613708496094,
      "learning_rate": 2.345783143503026e-06,
      "epoch": 1.6813768755516327,
      "step": 38100
    },
    {
      "loss": 0.9764,
      "grad_norm": 12.254993438720703,
      "learning_rate": 2.329540357576541e-06,
      "epoch": 1.6835834068843778,
      "step": 38150
    },
    {
      "loss": 0.9374,
      "grad_norm": 20.68777084350586,
      "learning_rate": 2.3132975716500556e-06,
      "epoch": 1.6857899382171226,
      "step": 38200
    },
    {
      "loss": 1.0046,
      "grad_norm": 19.988828659057617,
      "learning_rate": 2.29705478572357e-06,
      "epoch": 1.6879964695498675,
      "step": 38250
    },
    {
      "loss": 1.001,
      "grad_norm": 23.280914306640625,
      "learning_rate": 2.280811999797085e-06,
      "epoch": 1.6902030008826125,
      "step": 38300
    },
    {
      "loss": 0.942,
      "grad_norm": 24.738428115844727,
      "learning_rate": 2.264569213870599e-06,
      "epoch": 1.6924095322153576,
      "step": 38350
    },
    {
      "loss": 1.0097,
      "grad_norm": 24.171483993530273,
      "learning_rate": 2.248326427944114e-06,
      "epoch": 1.6946160635481022,
      "step": 38400
    },
    {
      "loss": 1.0723,
      "grad_norm": 21.54291343688965,
      "learning_rate": 2.2320836420176284e-06,
      "epoch": 1.6968225948808473,
      "step": 38450
    },
    {
      "loss": 1.0529,
      "grad_norm": 14.592679023742676,
      "learning_rate": 2.215840856091143e-06,
      "epoch": 1.6990291262135924,
      "step": 38500
    },
    {
      "loss": 1.0549,
      "grad_norm": 23.747095108032227,
      "learning_rate": 2.1995980701646578e-06,
      "epoch": 1.7012356575463372,
      "step": 38550
    },
    {
      "loss": 0.9935,
      "grad_norm": 20.473285675048828,
      "learning_rate": 2.183355284238172e-06,
      "epoch": 1.703442188879082,
      "step": 38600
    },
    {
      "loss": 0.9754,
      "grad_norm": 16.776615142822266,
      "learning_rate": 2.1671124983116867e-06,
      "epoch": 1.7056487202118271,
      "step": 38650
    },
    {
      "loss": 1.0172,
      "grad_norm": 24.365215301513672,
      "learning_rate": 2.150869712385201e-06,
      "epoch": 1.707855251544572,
      "step": 38700
    },
    {
      "loss": 0.9704,
      "grad_norm": 15.688156127929688,
      "learning_rate": 2.1346269264587157e-06,
      "epoch": 1.7100617828773168,
      "step": 38750
    },
    {
      "loss": 1.0249,
      "grad_norm": 21.245941162109375,
      "learning_rate": 2.11838414053223e-06,
      "epoch": 1.7122683142100619,
      "step": 38800
    },
    {
      "loss": 1.1309,
      "grad_norm": 19.282838821411133,
      "learning_rate": 2.102141354605745e-06,
      "epoch": 1.7144748455428067,
      "step": 38850
    },
    {
      "loss": 0.9872,
      "grad_norm": 7.48466157913208,
      "learning_rate": 2.0858985686792595e-06,
      "epoch": 1.7166813768755516,
      "step": 38900
    },
    {
      "loss": 1.1157,
      "grad_norm": 13.848905563354492,
      "learning_rate": 2.069655782752774e-06,
      "epoch": 1.7188879082082966,
      "step": 38950
    },
    {
      "loss": 1.0042,
      "grad_norm": 18.078962326049805,
      "learning_rate": 2.0534129968262885e-06,
      "epoch": 1.7210944395410415,
      "step": 39000
    },
    {
      "loss": 1.1776,
      "grad_norm": 28.413057327270508,
      "learning_rate": 2.037170210899803e-06,
      "epoch": 1.7233009708737863,
      "step": 39050
    },
    {
      "loss": 1.0903,
      "grad_norm": 19.393138885498047,
      "learning_rate": 2.020927424973318e-06,
      "epoch": 1.7255075022065314,
      "step": 39100
    },
    {
      "loss": 1.1557,
      "grad_norm": 23.028322219848633,
      "learning_rate": 2.004684639046832e-06,
      "epoch": 1.7277140335392762,
      "step": 39150
    },
    {
      "loss": 1.1013,
      "grad_norm": 20.25888442993164,
      "learning_rate": 1.988441853120347e-06,
      "epoch": 1.729920564872021,
      "step": 39200
    },
    {
      "loss": 0.9628,
      "grad_norm": 10.472604751586914,
      "learning_rate": 1.9721990671938617e-06,
      "epoch": 1.7321270962047661,
      "step": 39250
    },
    {
      "loss": 1.071,
      "grad_norm": 15.621648788452148,
      "learning_rate": 1.955956281267376e-06,
      "epoch": 1.7343336275375112,
      "step": 39300
    },
    {
      "loss": 1.1814,
      "grad_norm": 22.61158561706543,
      "learning_rate": 1.9397134953408907e-06,
      "epoch": 1.7365401588702558,
      "step": 39350
    },
    {
      "loss": 1.033,
      "grad_norm": 24.644933700561523,
      "learning_rate": 1.923470709414405e-06,
      "epoch": 1.7387466902030009,
      "step": 39400
    },
    {
      "loss": 1.1365,
      "grad_norm": 21.218727111816406,
      "learning_rate": 1.9072279234879197e-06,
      "epoch": 1.740953221535746,
      "step": 39450
    },
    {
      "loss": 1.0691,
      "grad_norm": 15.844372749328613,
      "learning_rate": 1.8909851375614341e-06,
      "epoch": 1.7431597528684908,
      "step": 39500
    },
    {
      "loss": 1.0051,
      "grad_norm": 15.120786666870117,
      "learning_rate": 1.8747423516349488e-06,
      "epoch": 1.7453662842012356,
      "step": 39550
    },
    {
      "loss": 0.9995,
      "grad_norm": 24.53193473815918,
      "learning_rate": 1.8584995657084635e-06,
      "epoch": 1.7475728155339807,
      "step": 39600
    },
    {
      "loss": 0.9445,
      "grad_norm": 15.935931205749512,
      "learning_rate": 1.8422567797819778e-06,
      "epoch": 1.7497793468667255,
      "step": 39650
    },
    {
      "loss": 1.0533,
      "grad_norm": 25.153091430664062,
      "learning_rate": 1.8260139938554925e-06,
      "epoch": 1.7519858781994704,
      "step": 39700
    },
    {
      "loss": 0.8785,
      "grad_norm": 9.712374687194824,
      "learning_rate": 1.809771207929007e-06,
      "epoch": 1.7541924095322154,
      "step": 39750
    },
    {
      "loss": 1.0439,
      "grad_norm": 23.589332580566406,
      "learning_rate": 1.7935284220025217e-06,
      "epoch": 1.7563989408649603,
      "step": 39800
    },
    {
      "loss": 1.0459,
      "grad_norm": 14.958285331726074,
      "learning_rate": 1.7772856360760363e-06,
      "epoch": 1.7586054721977051,
      "step": 39850
    },
    {
      "loss": 0.9981,
      "grad_norm": 27.467931747436523,
      "learning_rate": 1.7610428501495508e-06,
      "epoch": 1.7608120035304502,
      "step": 39900
    },
    {
      "loss": 1.0185,
      "grad_norm": 30.08759307861328,
      "learning_rate": 1.7448000642230653e-06,
      "epoch": 1.763018534863195,
      "step": 39950
    },
    {
      "loss": 0.9996,
      "grad_norm": 14.944659233093262,
      "learning_rate": 1.7285572782965798e-06,
      "epoch": 1.7652250661959399,
      "step": 40000
    },
    {
      "loss": 0.936,
      "grad_norm": 29.46001434326172,
      "learning_rate": 1.7123144923700945e-06,
      "epoch": 1.767431597528685,
      "step": 40050
    },
    {
      "loss": 0.9522,
      "grad_norm": 11.108941078186035,
      "learning_rate": 1.696071706443609e-06,
      "epoch": 1.7696381288614298,
      "step": 40100
    },
    {
      "loss": 1.1378,
      "grad_norm": 21.337369918823242,
      "learning_rate": 1.6798289205171236e-06,
      "epoch": 1.7718446601941746,
      "step": 40150
    },
    {
      "loss": 1.1295,
      "grad_norm": 16.038150787353516,
      "learning_rate": 1.6635861345906381e-06,
      "epoch": 1.7740511915269197,
      "step": 40200
    },
    {
      "loss": 0.9641,
      "grad_norm": 16.437562942504883,
      "learning_rate": 1.6473433486641528e-06,
      "epoch": 1.7762577228596648,
      "step": 40250
    },
    {
      "loss": 1.0696,
      "grad_norm": 12.305831909179688,
      "learning_rate": 1.6311005627376673e-06,
      "epoch": 1.7784642541924094,
      "step": 40300
    },
    {
      "loss": 0.85,
      "grad_norm": 17.600757598876953,
      "learning_rate": 1.6148577768111818e-06,
      "epoch": 1.7806707855251545,
      "step": 40350
    },
    {
      "loss": 0.9177,
      "grad_norm": 26.163808822631836,
      "learning_rate": 1.5986149908846965e-06,
      "epoch": 1.7828773168578995,
      "step": 40400
    },
    {
      "loss": 1.0581,
      "grad_norm": 26.66404914855957,
      "learning_rate": 1.582372204958211e-06,
      "epoch": 1.7850838481906444,
      "step": 40450
    },
    {
      "loss": 1.1702,
      "grad_norm": 35.79182434082031,
      "learning_rate": 1.5661294190317256e-06,
      "epoch": 1.7872903795233892,
      "step": 40500
    },
    {
      "loss": 1.1199,
      "grad_norm": 37.284969329833984,
      "learning_rate": 1.5498866331052401e-06,
      "epoch": 1.7894969108561343,
      "step": 40550
    },
    {
      "loss": 0.9199,
      "grad_norm": 18.38076400756836,
      "learning_rate": 1.5336438471787548e-06,
      "epoch": 1.7917034421888791,
      "step": 40600
    },
    {
      "loss": 0.9896,
      "grad_norm": 14.996118545532227,
      "learning_rate": 1.5174010612522693e-06,
      "epoch": 1.793909973521624,
      "step": 40650
    },
    {
      "loss": 1.041,
      "grad_norm": 22.12112808227539,
      "learning_rate": 1.5011582753257838e-06,
      "epoch": 1.796116504854369,
      "step": 40700
    },
    {
      "loss": 0.9925,
      "grad_norm": 10.239492416381836,
      "learning_rate": 1.4849154893992982e-06,
      "epoch": 1.7983230361871139,
      "step": 40750
    },
    {
      "loss": 1.0406,
      "grad_norm": 16.43597412109375,
      "learning_rate": 1.468672703472813e-06,
      "epoch": 1.8005295675198587,
      "step": 40800
    },
    {
      "loss": 0.9659,
      "grad_norm": 15.464530944824219,
      "learning_rate": 1.4524299175463276e-06,
      "epoch": 1.8027360988526038,
      "step": 40850
    },
    {
      "loss": 1.1905,
      "grad_norm": 18.893415451049805,
      "learning_rate": 1.4361871316198421e-06,
      "epoch": 1.8049426301853486,
      "step": 40900
    },
    {
      "loss": 1.048,
      "grad_norm": 22.63914680480957,
      "learning_rate": 1.4199443456933566e-06,
      "epoch": 1.8071491615180935,
      "step": 40950
    },
    {
      "loss": 0.9221,
      "grad_norm": 19.184837341308594,
      "learning_rate": 1.4037015597668713e-06,
      "epoch": 1.8093556928508385,
      "step": 41000
    },
    {
      "loss": 1.0162,
      "grad_norm": 20.92584800720215,
      "learning_rate": 1.3874587738403858e-06,
      "epoch": 1.8115622241835834,
      "step": 41050
    },
    {
      "loss": 1.052,
      "grad_norm": 30.908828735351562,
      "learning_rate": 1.3712159879139002e-06,
      "epoch": 1.8137687555163282,
      "step": 41100
    },
    {
      "loss": 1.1891,
      "grad_norm": 13.45591926574707,
      "learning_rate": 1.354973201987415e-06,
      "epoch": 1.8159752868490733,
      "step": 41150
    },
    {
      "loss": 1.048,
      "grad_norm": 10.085728645324707,
      "learning_rate": 1.3387304160609296e-06,
      "epoch": 1.8181818181818183,
      "step": 41200
    },
    {
      "loss": 0.9654,
      "grad_norm": 13.351456642150879,
      "learning_rate": 1.322487630134444e-06,
      "epoch": 1.820388349514563,
      "step": 41250
    },
    {
      "loss": 1.0508,
      "grad_norm": 13.44177532196045,
      "learning_rate": 1.3062448442079586e-06,
      "epoch": 1.822594880847308,
      "step": 41300
    },
    {
      "loss": 0.98,
      "grad_norm": 17.20277976989746,
      "learning_rate": 1.2900020582814733e-06,
      "epoch": 1.824801412180053,
      "step": 41350
    },
    {
      "loss": 1.0524,
      "grad_norm": 21.688297271728516,
      "learning_rate": 1.2737592723549877e-06,
      "epoch": 1.8270079435127977,
      "step": 41400
    },
    {
      "loss": 0.9418,
      "grad_norm": 28.803285598754883,
      "learning_rate": 1.2575164864285022e-06,
      "epoch": 1.8292144748455428,
      "step": 41450
    },
    {
      "loss": 0.9985,
      "grad_norm": 16.953044891357422,
      "learning_rate": 1.2412737005020167e-06,
      "epoch": 1.8314210061782878,
      "step": 41500
    },
    {
      "loss": 0.9903,
      "grad_norm": 29.857128143310547,
      "learning_rate": 1.2250309145755314e-06,
      "epoch": 1.8336275375110327,
      "step": 41550
    },
    {
      "loss": 0.9753,
      "grad_norm": 21.308958053588867,
      "learning_rate": 1.208788128649046e-06,
      "epoch": 1.8358340688437775,
      "step": 41600
    },
    {
      "loss": 1.0455,
      "grad_norm": 22.204607009887695,
      "learning_rate": 1.1925453427225606e-06,
      "epoch": 1.8380406001765226,
      "step": 41650
    },
    {
      "loss": 1.0825,
      "grad_norm": 16.454923629760742,
      "learning_rate": 1.1763025567960753e-06,
      "epoch": 1.8402471315092674,
      "step": 41700
    },
    {
      "loss": 1.0479,
      "grad_norm": 17.115520477294922,
      "learning_rate": 1.1600597708695897e-06,
      "epoch": 1.8424536628420123,
      "step": 41750
    },
    {
      "loss": 1.0849,
      "grad_norm": 15.75295639038086,
      "learning_rate": 1.1438169849431042e-06,
      "epoch": 1.8446601941747574,
      "step": 41800
    },
    {
      "loss": 1.0058,
      "grad_norm": 16.08697509765625,
      "learning_rate": 1.1275741990166187e-06,
      "epoch": 1.8468667255075022,
      "step": 41850
    },
    {
      "loss": 0.9637,
      "grad_norm": 14.079119682312012,
      "learning_rate": 1.1113314130901334e-06,
      "epoch": 1.849073256840247,
      "step": 41900
    },
    {
      "loss": 1.0826,
      "grad_norm": 29.522932052612305,
      "learning_rate": 1.095088627163648e-06,
      "epoch": 1.851279788172992,
      "step": 41950
    },
    {
      "loss": 1.1166,
      "grad_norm": 17.16066551208496,
      "learning_rate": 1.0788458412371626e-06,
      "epoch": 1.853486319505737,
      "step": 42000
    },
    {
      "loss": 1.0027,
      "grad_norm": 26.263843536376953,
      "learning_rate": 1.062603055310677e-06,
      "epoch": 1.8556928508384818,
      "step": 42050
    },
    {
      "loss": 0.9885,
      "grad_norm": 13.684356689453125,
      "learning_rate": 1.0463602693841917e-06,
      "epoch": 1.8578993821712269,
      "step": 42100
    },
    {
      "loss": 1.0447,
      "grad_norm": 21.624643325805664,
      "learning_rate": 1.0301174834577062e-06,
      "epoch": 1.860105913503972,
      "step": 42150
    },
    {
      "loss": 1.0014,
      "grad_norm": 28.018373489379883,
      "learning_rate": 1.0138746975312207e-06,
      "epoch": 1.8623124448367165,
      "step": 42200
    },
    {
      "loss": 0.9389,
      "grad_norm": 13.96805477142334,
      "learning_rate": 9.976319116047354e-07,
      "epoch": 1.8645189761694616,
      "step": 42250
    },
    {
      "loss": 1.0117,
      "grad_norm": 10.82310676574707,
      "learning_rate": 9.8138912567825e-07,
      "epoch": 1.8667255075022067,
      "step": 42300
    },
    {
      "loss": 1.0147,
      "grad_norm": 19.422725677490234,
      "learning_rate": 9.651463397517645e-07,
      "epoch": 1.8689320388349513,
      "step": 42350
    },
    {
      "loss": 0.887,
      "grad_norm": 17.080474853515625,
      "learning_rate": 9.489035538252791e-07,
      "epoch": 1.8711385701676964,
      "step": 42400
    },
    {
      "loss": 0.9557,
      "grad_norm": 24.315250396728516,
      "learning_rate": 9.326607678987936e-07,
      "epoch": 1.8733451015004414,
      "step": 42450
    },
    {
      "loss": 1.0177,
      "grad_norm": 26.464502334594727,
      "learning_rate": 9.164179819723082e-07,
      "epoch": 1.8755516328331863,
      "step": 42500
    },
    {
      "loss": 1.0211,
      "grad_norm": 19.78314971923828,
      "learning_rate": 9.001751960458228e-07,
      "epoch": 1.877758164165931,
      "step": 42550
    },
    {
      "loss": 1.0523,
      "grad_norm": 13.802725791931152,
      "learning_rate": 8.839324101193374e-07,
      "epoch": 1.8799646954986762,
      "step": 42600
    },
    {
      "loss": 1.0201,
      "grad_norm": 14.47410774230957,
      "learning_rate": 8.676896241928518e-07,
      "epoch": 1.882171226831421,
      "step": 42650
    },
    {
      "loss": 0.937,
      "grad_norm": 110.44477844238281,
      "learning_rate": 8.514468382663664e-07,
      "epoch": 1.8843777581641659,
      "step": 42700
    },
    {
      "loss": 1.0405,
      "grad_norm": 18.778135299682617,
      "learning_rate": 8.35204052339881e-07,
      "epoch": 1.886584289496911,
      "step": 42750
    },
    {
      "loss": 1.0173,
      "grad_norm": 18.388961791992188,
      "learning_rate": 8.189612664133956e-07,
      "epoch": 1.8887908208296558,
      "step": 42800
    },
    {
      "loss": 1.0074,
      "grad_norm": 22.280296325683594,
      "learning_rate": 8.027184804869102e-07,
      "epoch": 1.8909973521624006,
      "step": 42850
    },
    {
      "loss": 0.935,
      "grad_norm": 21.46468162536621,
      "learning_rate": 7.864756945604247e-07,
      "epoch": 1.8932038834951457,
      "step": 42900
    },
    {
      "loss": 1.0648,
      "grad_norm": 22.931474685668945,
      "learning_rate": 7.702329086339394e-07,
      "epoch": 1.8954104148278905,
      "step": 42950
    },
    {
      "loss": 0.9736,
      "grad_norm": 6.956689834594727,
      "learning_rate": 7.539901227074538e-07,
      "epoch": 1.8976169461606354,
      "step": 43000
    },
    {
      "loss": 1.0274,
      "grad_norm": 27.92091178894043,
      "learning_rate": 7.377473367809684e-07,
      "epoch": 1.8998234774933804,
      "step": 43050
    },
    {
      "loss": 1.0033,
      "grad_norm": 14.755989074707031,
      "learning_rate": 7.21504550854483e-07,
      "epoch": 1.9020300088261255,
      "step": 43100
    },
    {
      "loss": 1.0578,
      "grad_norm": 17.161334991455078,
      "learning_rate": 7.052617649279976e-07,
      "epoch": 1.9042365401588701,
      "step": 43150
    },
    {
      "loss": 1.184,
      "grad_norm": 19.182506561279297,
      "learning_rate": 6.890189790015121e-07,
      "epoch": 1.9064430714916152,
      "step": 43200
    },
    {
      "loss": 0.9845,
      "grad_norm": 19.335033416748047,
      "learning_rate": 6.727761930750267e-07,
      "epoch": 1.9086496028243602,
      "step": 43250
    },
    {
      "loss": 1.0009,
      "grad_norm": 33.65434646606445,
      "learning_rate": 6.565334071485412e-07,
      "epoch": 1.9108561341571049,
      "step": 43300
    },
    {
      "loss": 1.0394,
      "grad_norm": 18.344070434570312,
      "learning_rate": 6.402906212220558e-07,
      "epoch": 1.91306266548985,
      "step": 43350
    },
    {
      "loss": 1.168,
      "grad_norm": 14.519210815429688,
      "learning_rate": 6.240478352955703e-07,
      "epoch": 1.915269196822595,
      "step": 43400
    },
    {
      "loss": 1.0038,
      "grad_norm": 23.555927276611328,
      "learning_rate": 6.07805049369085e-07,
      "epoch": 1.9174757281553398,
      "step": 43450
    },
    {
      "loss": 1.1367,
      "grad_norm": 18.636192321777344,
      "learning_rate": 5.915622634425996e-07,
      "epoch": 1.9196822594880847,
      "step": 43500
    },
    {
      "loss": 1.0489,
      "grad_norm": 15.70365047454834,
      "learning_rate": 5.753194775161141e-07,
      "epoch": 1.9218887908208298,
      "step": 43550
    },
    {
      "loss": 0.9863,
      "grad_norm": 13.744427680969238,
      "learning_rate": 5.590766915896286e-07,
      "epoch": 1.9240953221535746,
      "step": 43600
    },
    {
      "loss": 1.0761,
      "grad_norm": 11.901655197143555,
      "learning_rate": 5.428339056631432e-07,
      "epoch": 1.9263018534863194,
      "step": 43650
    },
    {
      "loss": 1.0618,
      "grad_norm": 16.314546585083008,
      "learning_rate": 5.265911197366578e-07,
      "epoch": 1.9285083848190645,
      "step": 43700
    },
    {
      "loss": 1.0143,
      "grad_norm": 12.947165489196777,
      "learning_rate": 5.103483338101723e-07,
      "epoch": 1.9307149161518093,
      "step": 43750
    },
    {
      "loss": 0.9311,
      "grad_norm": 20.708412170410156,
      "learning_rate": 4.941055478836869e-07,
      "epoch": 1.9329214474845542,
      "step": 43800
    },
    {
      "loss": 1.0581,
      "grad_norm": 25.1508731842041,
      "learning_rate": 4.778627619572015e-07,
      "epoch": 1.9351279788172993,
      "step": 43850
    },
    {
      "loss": 1.2242,
      "grad_norm": 15.570557594299316,
      "learning_rate": 4.6161997603071605e-07,
      "epoch": 1.937334510150044,
      "step": 43900
    },
    {
      "loss": 0.9718,
      "grad_norm": 22.80719566345215,
      "learning_rate": 4.4537719010423064e-07,
      "epoch": 1.939541041482789,
      "step": 43950
    },
    {
      "loss": 0.9816,
      "grad_norm": 12.147244453430176,
      "learning_rate": 4.2913440417774517e-07,
      "epoch": 1.941747572815534,
      "step": 44000
    },
    {
      "loss": 0.9939,
      "grad_norm": 9.961523056030273,
      "learning_rate": 4.1289161825125976e-07,
      "epoch": 1.943954104148279,
      "step": 44050
    },
    {
      "loss": 1.0785,
      "grad_norm": 19.961711883544922,
      "learning_rate": 3.966488323247743e-07,
      "epoch": 1.9461606354810237,
      "step": 44100
    },
    {
      "loss": 0.975,
      "grad_norm": 16.875627517700195,
      "learning_rate": 3.804060463982889e-07,
      "epoch": 1.9483671668137688,
      "step": 44150
    },
    {
      "loss": 0.9576,
      "grad_norm": 30.503398895263672,
      "learning_rate": 3.641632604718034e-07,
      "epoch": 1.9505736981465138,
      "step": 44200
    },
    {
      "loss": 1.0658,
      "grad_norm": 24.887231826782227,
      "learning_rate": 3.47920474545318e-07,
      "epoch": 1.9527802294792584,
      "step": 44250
    },
    {
      "loss": 1.052,
      "grad_norm": 23.200132369995117,
      "learning_rate": 3.316776886188325e-07,
      "epoch": 1.9549867608120035,
      "step": 44300
    },
    {
      "loss": 1.0207,
      "grad_norm": 16.238609313964844,
      "learning_rate": 3.154349026923471e-07,
      "epoch": 1.9571932921447486,
      "step": 44350
    },
    {
      "loss": 1.0738,
      "grad_norm": 13.439373970031738,
      "learning_rate": 2.991921167658617e-07,
      "epoch": 1.9593998234774934,
      "step": 44400
    },
    {
      "loss": 0.9772,
      "grad_norm": 22.790449142456055,
      "learning_rate": 2.829493308393763e-07,
      "epoch": 1.9616063548102383,
      "step": 44450
    },
    {
      "loss": 0.9738,
      "grad_norm": 23.50490951538086,
      "learning_rate": 2.6670654491289086e-07,
      "epoch": 1.9638128861429833,
      "step": 44500
    },
    {
      "loss": 1.0587,
      "grad_norm": 16.61569595336914,
      "learning_rate": 2.504637589864054e-07,
      "epoch": 1.9660194174757282,
      "step": 44550
    },
    {
      "loss": 0.9935,
      "grad_norm": 22.65912437438965,
      "learning_rate": 2.3422097305991998e-07,
      "epoch": 1.968225948808473,
      "step": 44600
    },
    {
      "loss": 1.1743,
      "grad_norm": 25.070465087890625,
      "learning_rate": 2.1797818713343454e-07,
      "epoch": 1.970432480141218,
      "step": 44650
    },
    {
      "loss": 0.9269,
      "grad_norm": 10.151993751525879,
      "learning_rate": 2.017354012069491e-07,
      "epoch": 1.972639011473963,
      "step": 44700
    },
    {
      "loss": 0.9892,
      "grad_norm": 25.36774253845215,
      "learning_rate": 1.8549261528046366e-07,
      "epoch": 1.9748455428067078,
      "step": 44750
    },
    {
      "loss": 1.0569,
      "grad_norm": 9.78173828125,
      "learning_rate": 1.6924982935397822e-07,
      "epoch": 1.9770520741394528,
      "step": 44800
    },
    {
      "loss": 1.0271,
      "grad_norm": 8.338653564453125,
      "learning_rate": 1.5300704342749278e-07,
      "epoch": 1.9792586054721977,
      "step": 44850
    },
    {
      "loss": 1.1899,
      "grad_norm": 21.524986267089844,
      "learning_rate": 1.3676425750100736e-07,
      "epoch": 1.9814651368049425,
      "step": 44900
    },
    {
      "loss": 1.0716,
      "grad_norm": 12.011677742004395,
      "learning_rate": 1.2052147157452192e-07,
      "epoch": 1.9836716681376876,
      "step": 44950
    },
    {
      "loss": 0.9528,
      "grad_norm": 23.120624542236328,
      "learning_rate": 1.0427868564803649e-07,
      "epoch": 1.9858781994704324,
      "step": 45000
    },
    {
      "loss": 1.0403,
      "grad_norm": 9.257720947265625,
      "learning_rate": 8.803589972155105e-08,
      "epoch": 1.9880847308031773,
      "step": 45050
    },
    {
      "loss": 1.1361,
      "grad_norm": 27.094144821166992,
      "learning_rate": 7.179311379506562e-08,
      "epoch": 1.9902912621359223,
      "step": 45100
    },
    {
      "loss": 1.059,
      "grad_norm": 23.651309967041016,
      "learning_rate": 5.555032786858019e-08,
      "epoch": 1.9924977934686674,
      "step": 45150
    },
    {
      "loss": 0.9715,
      "grad_norm": 22.119911193847656,
      "learning_rate": 3.9307541942094746e-08,
      "epoch": 1.994704324801412,
      "step": 45200
    },
    {
      "loss": 1.051,
      "grad_norm": 19.353071212768555,
      "learning_rate": 2.306475601560932e-08,
      "epoch": 1.996910856134157,
      "step": 45250
    },
    {
      "loss": 1.1009,
      "grad_norm": 21.35259246826172,
      "learning_rate": 6.821970089123883e-09,
      "epoch": 1.9991173874669022,
      "step": 45300
    },
    {
      "eval_loss": 0.8763561211724741,
      "eval_exact_match": 77.86357218496293,
      "eval_f1": 83.33020674717997,
      "eval_samples": 22720,
      "step": 45320
    },
    {
      "eval_loss": 0.8763561211724741,
      "eval_exact_match": 77.86357218496293,
      "eval_f1": 83.33020674717997,
      "eval_samples": 22720,
      "epoch": 2.0,
      "step": 45320
    },
    {
      "train_runtime": 14492.2556,
      "train_samples_per_second": 25.017,
      "train_steps_per_second": 3.127,
      "total_flos": 1.0592990011957248e+16,
      "train_loss": 1.2811821387914673,
      "epoch": 2.0,
      "step": 45320
    }
  ]
}
{
  "trial_number": 0,
  "hyperparameters": {
    "learning_rate": 5.897342432728743e-06,
    "per_device_train_batch_size": 8,
    "num_train_epochs": 4,
    "warmup_steps": 525,
    "per_device_eval_batch_size": 16
  },
  "best_f1": 81.96464829364392,
  "all_eval_f1_scores": [
    63.88806165294192,
    63.88806165294192,
    75.4162686848286,
    75.4162686848286,
    81.58162861988517,
    81.58162861988517,
    81.96464829364392,
    81.96464829364392
  ],
  "training_logs": [
    {
      "loss": 6.3806,
      "grad_norm": 9.081987380981445,
      "learning_rate": 5.504186270546827e-07,
      "epoch": 0.002206531332744925,
      "step": 50
    },
    {
      "loss": 6.3257,
      "grad_norm": 10.014447212219238,
      "learning_rate": 1.112070287314563e-06,
      "epoch": 0.00441306266548985,
      "step": 100
    },
    {
      "loss": 6.2122,
      "grad_norm": 8.802824020385742,
      "learning_rate": 1.6737219475744432e-06,
      "epoch": 0.006619593998234775,
      "step": 150
    },
    {
      "loss": 6.0369,
      "grad_norm": 9.386504173278809,
      "learning_rate": 2.2353736078343235e-06,
      "epoch": 0.0088261253309797,
      "step": 200
    },
    {
      "loss": 5.7586,
      "grad_norm": 8.203513145446777,
      "learning_rate": 2.797025268094204e-06,
      "epoch": 0.011032656663724626,
      "step": 250
    },
    {
      "loss": 5.2426,
      "grad_norm": 8.386374473571777,
      "learning_rate": 3.358676928354084e-06,
      "epoch": 0.01323918799646955,
      "step": 300
    },
    {
      "loss": 4.9082,
      "grad_norm": 5.47393798828125,
      "learning_rate": 3.9203285886139645e-06,
      "epoch": 0.015445719329214475,
      "step": 350
    },
    {
      "loss": 4.5458,
      "grad_norm": 5.695077419281006,
      "learning_rate": 4.481980248873845e-06,
      "epoch": 0.0176522506619594,
      "step": 400
    },
    {
      "loss": 4.2388,
      "grad_norm": 6.574926376342773,
      "learning_rate": 5.043631909133725e-06,
      "epoch": 0.019858781994704325,
      "step": 450
    },
    {
      "loss": 4.0032,
      "grad_norm": 7.968915939331055,
      "learning_rate": 5.6052835693936056e-06,
      "epoch": 0.02206531332744925,
      "step": 500
    },
    {
      "loss": 3.8215,
      "grad_norm": 7.2246994972229,
      "learning_rate": 5.895771814980471e-06,
      "epoch": 0.024271844660194174,
      "step": 550
    },
    {
      "loss": 3.7029,
      "grad_norm": 10.805438041687012,
      "learning_rate": 5.8924996946715725e-06,
      "epoch": 0.0264783759929391,
      "step": 600
    },
    {
      "loss": 3.5289,
      "grad_norm": 7.890562057495117,
      "learning_rate": 5.889227574362674e-06,
      "epoch": 0.028684907325684024,
      "step": 650
    },
    {
      "loss": 3.5216,
      "grad_norm": 9.406785011291504,
      "learning_rate": 5.885955454053774e-06,
      "epoch": 0.03089143865842895,
      "step": 700
    },
    {
      "loss": 3.3792,
      "grad_norm": 19.623775482177734,
      "learning_rate": 5.882683333744876e-06,
      "epoch": 0.03309796999117388,
      "step": 750
    },
    {
      "loss": 3.3462,
      "grad_norm": 15.753865242004395,
      "learning_rate": 5.879411213435976e-06,
      "epoch": 0.0353045013239188,
      "step": 800
    },
    {
      "loss": 3.3052,
      "grad_norm": 13.248371124267578,
      "learning_rate": 5.876139093127078e-06,
      "epoch": 0.03751103265666372,
      "step": 850
    },
    {
      "loss": 3.2667,
      "grad_norm": 30.524507522583008,
      "learning_rate": 5.872866972818178e-06,
      "epoch": 0.03971756398940865,
      "step": 900
    },
    {
      "loss": 3.1883,
      "grad_norm": 11.279166221618652,
      "learning_rate": 5.8695948525092795e-06,
      "epoch": 0.041924095322153576,
      "step": 950
    },
    {
      "loss": 3.0852,
      "grad_norm": 14.50906753540039,
      "learning_rate": 5.866322732200381e-06,
      "epoch": 0.0441306266548985,
      "step": 1000
    },
    {
      "loss": 3.0029,
      "grad_norm": 13.347217559814453,
      "learning_rate": 5.863050611891481e-06,
      "epoch": 0.04633715798764342,
      "step": 1050
    },
    {
      "loss": 3.0262,
      "grad_norm": 13.860284805297852,
      "learning_rate": 5.859778491582583e-06,
      "epoch": 0.04854368932038835,
      "step": 1100
    },
    {
      "loss": 2.9776,
      "grad_norm": 19.225170135498047,
      "learning_rate": 5.856506371273683e-06,
      "epoch": 0.050750220653133275,
      "step": 1150
    },
    {
      "loss": 3.1505,
      "grad_norm": 20.784011840820312,
      "learning_rate": 5.853234250964785e-06,
      "epoch": 0.0529567519858782,
      "step": 1200
    },
    {
      "loss": 2.8858,
      "grad_norm": 15.283320426940918,
      "learning_rate": 5.849962130655885e-06,
      "epoch": 0.05516328331862312,
      "step": 1250
    },
    {
      "loss": 2.8978,
      "grad_norm": 18.656970977783203,
      "learning_rate": 5.846690010346986e-06,
      "epoch": 0.05736981465136805,
      "step": 1300
    },
    {
      "loss": 2.7916,
      "grad_norm": 18.230575561523438,
      "learning_rate": 5.843417890038087e-06,
      "epoch": 0.059576345984112974,
      "step": 1350
    },
    {
      "loss": 2.776,
      "grad_norm": 29.36939811706543,
      "learning_rate": 5.8401457697291875e-06,
      "epoch": 0.0617828773168579,
      "step": 1400
    },
    {
      "loss": 2.7984,
      "grad_norm": 29.288978576660156,
      "learning_rate": 5.836873649420289e-06,
      "epoch": 0.06398940864960283,
      "step": 1450
    },
    {
      "loss": 2.8297,
      "grad_norm": 19.040124893188477,
      "learning_rate": 5.833601529111389e-06,
      "epoch": 0.06619593998234775,
      "step": 1500
    },
    {
      "loss": 2.705,
      "grad_norm": 27.626951217651367,
      "learning_rate": 5.830329408802491e-06,
      "epoch": 0.06840247131509268,
      "step": 1550
    },
    {
      "loss": 2.519,
      "grad_norm": 22.254344940185547,
      "learning_rate": 5.827057288493591e-06,
      "epoch": 0.0706090026478376,
      "step": 1600
    },
    {
      "loss": 2.7198,
      "grad_norm": 17.03527069091797,
      "learning_rate": 5.823785168184693e-06,
      "epoch": 0.07281553398058252,
      "step": 1650
    },
    {
      "loss": 2.7458,
      "grad_norm": 21.89919090270996,
      "learning_rate": 5.820513047875793e-06,
      "epoch": 0.07502206531332745,
      "step": 1700
    },
    {
      "loss": 2.6477,
      "grad_norm": 13.230510711669922,
      "learning_rate": 5.8172409275668945e-06,
      "epoch": 0.07722859664607237,
      "step": 1750
    },
    {
      "loss": 2.7221,
      "grad_norm": 22.385652542114258,
      "learning_rate": 5.813968807257996e-06,
      "epoch": 0.0794351279788173,
      "step": 1800
    },
    {
      "loss": 2.5667,
      "grad_norm": 15.478255271911621,
      "learning_rate": 5.810696686949096e-06,
      "epoch": 0.08164165931156223,
      "step": 1850
    },
    {
      "loss": 2.6329,
      "grad_norm": 27.238643646240234,
      "learning_rate": 5.807424566640198e-06,
      "epoch": 0.08384819064430715,
      "step": 1900
    },
    {
      "loss": 2.6376,
      "grad_norm": 14.317340850830078,
      "learning_rate": 5.804152446331298e-06,
      "epoch": 0.08605472197705208,
      "step": 1950
    },
    {
      "loss": 2.5362,
      "grad_norm": 20.453054428100586,
      "learning_rate": 5.8008803260224e-06,
      "epoch": 0.088261253309797,
      "step": 2000
    },
    {
      "loss": 2.6352,
      "grad_norm": 33.23975372314453,
      "learning_rate": 5.7976082057135e-06,
      "epoch": 0.09046778464254192,
      "step": 2050
    },
    {
      "loss": 2.468,
      "grad_norm": 30.380422592163086,
      "learning_rate": 5.7943360854046015e-06,
      "epoch": 0.09267431597528684,
      "step": 2100
    },
    {
      "loss": 2.5631,
      "grad_norm": 23.149133682250977,
      "learning_rate": 5.791063965095703e-06,
      "epoch": 0.09488084730803177,
      "step": 2150
    },
    {
      "loss": 2.4788,
      "grad_norm": 18.604007720947266,
      "learning_rate": 5.787791844786803e-06,
      "epoch": 0.0970873786407767,
      "step": 2200
    },
    {
      "loss": 2.489,
      "grad_norm": 16.597362518310547,
      "learning_rate": 5.784519724477905e-06,
      "epoch": 0.09929390997352162,
      "step": 2250
    },
    {
      "loss": 2.5305,
      "grad_norm": 16.53997802734375,
      "learning_rate": 5.781247604169005e-06,
      "epoch": 0.10150044130626655,
      "step": 2300
    },
    {
      "loss": 2.4118,
      "grad_norm": 14.436187744140625,
      "learning_rate": 5.777975483860107e-06,
      "epoch": 0.10370697263901148,
      "step": 2350
    },
    {
      "loss": 2.4753,
      "grad_norm": 25.912092208862305,
      "learning_rate": 5.774703363551207e-06,
      "epoch": 0.1059135039717564,
      "step": 2400
    },
    {
      "loss": 2.3778,
      "grad_norm": 18.90761947631836,
      "learning_rate": 5.771431243242308e-06,
      "epoch": 0.10812003530450133,
      "step": 2450
    },
    {
      "loss": 2.4625,
      "grad_norm": 17.515804290771484,
      "learning_rate": 5.768159122933409e-06,
      "epoch": 0.11032656663724624,
      "step": 2500
    },
    {
      "loss": 2.4111,
      "grad_norm": 17.932275772094727,
      "learning_rate": 5.7648870026245095e-06,
      "epoch": 0.11253309796999117,
      "step": 2550
    },
    {
      "loss": 2.4801,
      "grad_norm": 15.373345375061035,
      "learning_rate": 5.761614882315611e-06,
      "epoch": 0.1147396293027361,
      "step": 2600
    },
    {
      "loss": 2.3091,
      "grad_norm": 35.90308380126953,
      "learning_rate": 5.758342762006711e-06,
      "epoch": 0.11694616063548102,
      "step": 2650
    },
    {
      "loss": 2.2883,
      "grad_norm": 28.565168380737305,
      "learning_rate": 5.755070641697813e-06,
      "epoch": 0.11915269196822595,
      "step": 2700
    },
    {
      "loss": 2.3811,
      "grad_norm": 25.763111114501953,
      "learning_rate": 5.751798521388913e-06,
      "epoch": 0.12135922330097088,
      "step": 2750
    },
    {
      "loss": 2.3093,
      "grad_norm": 17.891868591308594,
      "learning_rate": 5.748526401080015e-06,
      "epoch": 0.1235657546337158,
      "step": 2800
    },
    {
      "loss": 2.2431,
      "grad_norm": 14.819615364074707,
      "learning_rate": 5.745254280771116e-06,
      "epoch": 0.12577228596646073,
      "step": 2850
    },
    {
      "loss": 2.3731,
      "grad_norm": 27.52648162841797,
      "learning_rate": 5.7419821604622165e-06,
      "epoch": 0.12797881729920565,
      "step": 2900
    },
    {
      "loss": 2.2893,
      "grad_norm": 16.309236526489258,
      "learning_rate": 5.738710040153318e-06,
      "epoch": 0.13018534863195058,
      "step": 2950
    },
    {
      "loss": 2.31,
      "grad_norm": 23.910335540771484,
      "learning_rate": 5.735437919844418e-06,
      "epoch": 0.1323918799646955,
      "step": 3000
    },
    {
      "loss": 2.3085,
      "grad_norm": 26.632326126098633,
      "learning_rate": 5.73216579953552e-06,
      "epoch": 0.13459841129744043,
      "step": 3050
    },
    {
      "loss": 2.2069,
      "grad_norm": 36.7996826171875,
      "learning_rate": 5.72889367922662e-06,
      "epoch": 0.13680494263018536,
      "step": 3100
    },
    {
      "loss": 2.3823,
      "grad_norm": 18.172359466552734,
      "learning_rate": 5.725621558917722e-06,
      "epoch": 0.13901147396293026,
      "step": 3150
    },
    {
      "loss": 2.2491,
      "grad_norm": 25.679933547973633,
      "learning_rate": 5.722349438608823e-06,
      "epoch": 0.1412180052956752,
      "step": 3200
    },
    {
      "loss": 2.2371,
      "grad_norm": 25.73862648010254,
      "learning_rate": 5.7190773182999235e-06,
      "epoch": 0.1434245366284201,
      "step": 3250
    },
    {
      "loss": 2.2717,
      "grad_norm": 26.605167388916016,
      "learning_rate": 5.715805197991025e-06,
      "epoch": 0.14563106796116504,
      "step": 3300
    },
    {
      "loss": 2.3275,
      "grad_norm": 21.33416748046875,
      "learning_rate": 5.712533077682125e-06,
      "epoch": 0.14783759929390997,
      "step": 3350
    },
    {
      "loss": 2.297,
      "grad_norm": 19.103530883789062,
      "learning_rate": 5.709260957373227e-06,
      "epoch": 0.1500441306266549,
      "step": 3400
    },
    {
      "loss": 2.3254,
      "grad_norm": 26.819812774658203,
      "learning_rate": 5.705988837064327e-06,
      "epoch": 0.15225066195939982,
      "step": 3450
    },
    {
      "loss": 2.1515,
      "grad_norm": 25.897844314575195,
      "learning_rate": 5.702716716755429e-06,
      "epoch": 0.15445719329214475,
      "step": 3500
    },
    {
      "loss": 2.1726,
      "grad_norm": 32.092533111572266,
      "learning_rate": 5.699444596446529e-06,
      "epoch": 0.15666372462488967,
      "step": 3550
    },
    {
      "loss": 2.2698,
      "grad_norm": 27.3327693939209,
      "learning_rate": 5.69617247613763e-06,
      "epoch": 0.1588702559576346,
      "step": 3600
    },
    {
      "loss": 2.176,
      "grad_norm": 13.25102710723877,
      "learning_rate": 5.692900355828731e-06,
      "epoch": 0.16107678729037953,
      "step": 3650
    },
    {
      "loss": 2.2581,
      "grad_norm": 21.62671661376953,
      "learning_rate": 5.6896282355198315e-06,
      "epoch": 0.16328331862312445,
      "step": 3700
    },
    {
      "loss": 2.2132,
      "grad_norm": 30.45330047607422,
      "learning_rate": 5.686356115210933e-06,
      "epoch": 0.16548984995586938,
      "step": 3750
    },
    {
      "loss": 2.1376,
      "grad_norm": 17.024839401245117,
      "learning_rate": 5.683083994902033e-06,
      "epoch": 0.1676963812886143,
      "step": 3800
    },
    {
      "loss": 2.1872,
      "grad_norm": 22.27506446838379,
      "learning_rate": 5.679811874593135e-06,
      "epoch": 0.16990291262135923,
      "step": 3850
    },
    {
      "loss": 2.1564,
      "grad_norm": 25.527666091918945,
      "learning_rate": 5.676539754284235e-06,
      "epoch": 0.17210944395410416,
      "step": 3900
    },
    {
      "loss": 2.1768,
      "grad_norm": 22.816322326660156,
      "learning_rate": 5.673267633975337e-06,
      "epoch": 0.17431597528684908,
      "step": 3950
    },
    {
      "loss": 2.2214,
      "grad_norm": 28.683032989501953,
      "learning_rate": 5.669995513666438e-06,
      "epoch": 0.176522506619594,
      "step": 4000
    },
    {
      "loss": 2.1086,
      "grad_norm": 11.212214469909668,
      "learning_rate": 5.6667233933575385e-06,
      "epoch": 0.1787290379523389,
      "step": 4050
    },
    {
      "loss": 2.1737,
      "grad_norm": 13.969868659973145,
      "learning_rate": 5.66345127304864e-06,
      "epoch": 0.18093556928508384,
      "step": 4100
    },
    {
      "loss": 2.1777,
      "grad_norm": 26.604530334472656,
      "learning_rate": 5.66017915273974e-06,
      "epoch": 0.18314210061782876,
      "step": 4150
    },
    {
      "loss": 2.2092,
      "grad_norm": 13.037361145019531,
      "learning_rate": 5.656907032430842e-06,
      "epoch": 0.1853486319505737,
      "step": 4200
    },
    {
      "loss": 2.3277,
      "grad_norm": 21.189552307128906,
      "learning_rate": 5.653634912121942e-06,
      "epoch": 0.18755516328331862,
      "step": 4250
    },
    {
      "loss": 2.0746,
      "grad_norm": 31.729717254638672,
      "learning_rate": 5.650362791813044e-06,
      "epoch": 0.18976169461606354,
      "step": 4300
    },
    {
      "loss": 2.2001,
      "grad_norm": 21.703868865966797,
      "learning_rate": 5.647090671504145e-06,
      "epoch": 0.19196822594880847,
      "step": 4350
    },
    {
      "loss": 2.0381,
      "grad_norm": 16.360271453857422,
      "learning_rate": 5.6438185511952455e-06,
      "epoch": 0.1941747572815534,
      "step": 4400
    },
    {
      "loss": 2.1365,
      "grad_norm": 18.818532943725586,
      "learning_rate": 5.640546430886347e-06,
      "epoch": 0.19638128861429832,
      "step": 4450
    },
    {
      "loss": 2.0162,
      "grad_norm": 23.927772521972656,
      "learning_rate": 5.637274310577447e-06,
      "epoch": 0.19858781994704325,
      "step": 4500
    },
    {
      "loss": 2.0451,
      "grad_norm": 15.974325180053711,
      "learning_rate": 5.634002190268549e-06,
      "epoch": 0.20079435127978817,
      "step": 4550
    },
    {
      "loss": 2.2208,
      "grad_norm": 16.775230407714844,
      "learning_rate": 5.630730069959649e-06,
      "epoch": 0.2030008826125331,
      "step": 4600
    },
    {
      "loss": 2.24,
      "grad_norm": 21.045494079589844,
      "learning_rate": 5.627457949650751e-06,
      "epoch": 0.20520741394527803,
      "step": 4650
    },
    {
      "loss": 2.1876,
      "grad_norm": 20.043460845947266,
      "learning_rate": 5.624185829341851e-06,
      "epoch": 0.20741394527802295,
      "step": 4700
    },
    {
      "loss": 2.1664,
      "grad_norm": 21.510623931884766,
      "learning_rate": 5.620913709032952e-06,
      "epoch": 0.20962047661076788,
      "step": 4750
    },
    {
      "loss": 1.9729,
      "grad_norm": 20.366968154907227,
      "learning_rate": 5.617641588724053e-06,
      "epoch": 0.2118270079435128,
      "step": 4800
    },
    {
      "loss": 2.1414,
      "grad_norm": 17.387916564941406,
      "learning_rate": 5.6143694684151535e-06,
      "epoch": 0.21403353927625773,
      "step": 4850
    },
    {
      "loss": 1.9162,
      "grad_norm": 17.342697143554688,
      "learning_rate": 5.611097348106255e-06,
      "epoch": 0.21624007060900266,
      "step": 4900
    },
    {
      "loss": 2.1665,
      "grad_norm": 24.186311721801758,
      "learning_rate": 5.607825227797355e-06,
      "epoch": 0.21844660194174756,
      "step": 4950
    },
    {
      "loss": 2.1798,
      "grad_norm": 25.393417358398438,
      "learning_rate": 5.604553107488457e-06,
      "epoch": 0.22065313327449249,
      "step": 5000
    },
    {
      "loss": 2.1058,
      "grad_norm": 15.831456184387207,
      "learning_rate": 5.601280987179558e-06,
      "epoch": 0.2228596646072374,
      "step": 5050
    },
    {
      "loss": 2.2191,
      "grad_norm": 18.337993621826172,
      "learning_rate": 5.598008866870659e-06,
      "epoch": 0.22506619593998234,
      "step": 5100
    },
    {
      "loss": 1.9702,
      "grad_norm": 26.377666473388672,
      "learning_rate": 5.59473674656176e-06,
      "epoch": 0.22727272727272727,
      "step": 5150
    },
    {
      "loss": 2.0051,
      "grad_norm": 22.528512954711914,
      "learning_rate": 5.5914646262528605e-06,
      "epoch": 0.2294792586054722,
      "step": 5200
    },
    {
      "loss": 2.0503,
      "grad_norm": 27.857669830322266,
      "learning_rate": 5.588192505943962e-06,
      "epoch": 0.23168578993821712,
      "step": 5250
    },
    {
      "loss": 2.0885,
      "grad_norm": 28.412273406982422,
      "learning_rate": 5.584920385635062e-06,
      "epoch": 0.23389232127096204,
      "step": 5300
    },
    {
      "loss": 2.2846,
      "grad_norm": 11.616328239440918,
      "learning_rate": 5.581648265326164e-06,
      "epoch": 0.23609885260370697,
      "step": 5350
    },
    {
      "loss": 2.0407,
      "grad_norm": 18.50116729736328,
      "learning_rate": 5.578376145017265e-06,
      "epoch": 0.2383053839364519,
      "step": 5400
    },
    {
      "loss": 2.0708,
      "grad_norm": 25.81828498840332,
      "learning_rate": 5.575104024708366e-06,
      "epoch": 0.24051191526919682,
      "step": 5450
    },
    {
      "loss": 2.029,
      "grad_norm": 29.982694625854492,
      "learning_rate": 5.571831904399467e-06,
      "epoch": 0.24271844660194175,
      "step": 5500
    },
    {
      "loss": 2.1601,
      "grad_norm": 11.526246070861816,
      "learning_rate": 5.5685597840905675e-06,
      "epoch": 0.24492497793468668,
      "step": 5550
    },
    {
      "loss": 2.2003,
      "grad_norm": 27.37411880493164,
      "learning_rate": 5.565287663781669e-06,
      "epoch": 0.2471315092674316,
      "step": 5600
    },
    {
      "loss": 2.0876,
      "grad_norm": 18.141216278076172,
      "learning_rate": 5.562015543472769e-06,
      "epoch": 0.24933804060017653,
      "step": 5650
    },
    {
      "loss": 2.2064,
      "grad_norm": 26.656274795532227,
      "learning_rate": 5.558743423163871e-06,
      "epoch": 0.25154457193292146,
      "step": 5700
    },
    {
      "loss": 2.1809,
      "grad_norm": 12.862053871154785,
      "learning_rate": 5.555471302854971e-06,
      "epoch": 0.25375110326566636,
      "step": 5750
    },
    {
      "loss": 2.0731,
      "grad_norm": 28.2862606048584,
      "learning_rate": 5.5521991825460726e-06,
      "epoch": 0.2559576345984113,
      "step": 5800
    },
    {
      "loss": 1.9141,
      "grad_norm": 13.586140632629395,
      "learning_rate": 5.548927062237173e-06,
      "epoch": 0.2581641659311562,
      "step": 5850
    },
    {
      "loss": 2.0643,
      "grad_norm": 18.2835693359375,
      "learning_rate": 5.545654941928274e-06,
      "epoch": 0.26037069726390116,
      "step": 5900
    },
    {
      "loss": 2.0705,
      "grad_norm": 25.487287521362305,
      "learning_rate": 5.542382821619375e-06,
      "epoch": 0.26257722859664606,
      "step": 5950
    },
    {
      "loss": 2.1325,
      "grad_norm": 15.193260192871094,
      "learning_rate": 5.5391107013104755e-06,
      "epoch": 0.264783759929391,
      "step": 6000
    },
    {
      "loss": 2.1487,
      "grad_norm": 18.04986572265625,
      "learning_rate": 5.535838581001577e-06,
      "epoch": 0.2669902912621359,
      "step": 6050
    },
    {
      "loss": 2.2285,
      "grad_norm": 22.67900848388672,
      "learning_rate": 5.532566460692677e-06,
      "epoch": 0.26919682259488087,
      "step": 6100
    },
    {
      "loss": 1.9791,
      "grad_norm": 35.28630828857422,
      "learning_rate": 5.529294340383779e-06,
      "epoch": 0.27140335392762577,
      "step": 6150
    },
    {
      "loss": 2.1384,
      "grad_norm": 17.405654907226562,
      "learning_rate": 5.52602222007488e-06,
      "epoch": 0.2736098852603707,
      "step": 6200
    },
    {
      "loss": 2.1481,
      "grad_norm": 26.189289093017578,
      "learning_rate": 5.522750099765981e-06,
      "epoch": 0.2758164165931156,
      "step": 6250
    },
    {
      "loss": 2.0906,
      "grad_norm": 21.773591995239258,
      "learning_rate": 5.519477979457082e-06,
      "epoch": 0.2780229479258605,
      "step": 6300
    },
    {
      "loss": 2.1196,
      "grad_norm": 25.792734146118164,
      "learning_rate": 5.5162058591481825e-06,
      "epoch": 0.2802294792586055,
      "step": 6350
    },
    {
      "loss": 1.9961,
      "grad_norm": 22.69436264038086,
      "learning_rate": 5.512933738839284e-06,
      "epoch": 0.2824360105913504,
      "step": 6400
    },
    {
      "loss": 1.9103,
      "grad_norm": 15.2427396774292,
      "learning_rate": 5.509661618530384e-06,
      "epoch": 0.2846425419240953,
      "step": 6450
    },
    {
      "loss": 1.9617,
      "grad_norm": 47.31018829345703,
      "learning_rate": 5.506389498221486e-06,
      "epoch": 0.2868490732568402,
      "step": 6500
    },
    {
      "loss": 2.0657,
      "grad_norm": 16.21329116821289,
      "learning_rate": 5.503117377912587e-06,
      "epoch": 0.2890556045895852,
      "step": 6550
    },
    {
      "loss": 2.0454,
      "grad_norm": 26.0213565826416,
      "learning_rate": 5.499845257603688e-06,
      "epoch": 0.2912621359223301,
      "step": 6600
    },
    {
      "loss": 1.9606,
      "grad_norm": 30.386266708374023,
      "learning_rate": 5.496573137294789e-06,
      "epoch": 0.29346866725507503,
      "step": 6650
    },
    {
      "loss": 2.053,
      "grad_norm": 25.238183975219727,
      "learning_rate": 5.4933010169858895e-06,
      "epoch": 0.29567519858781993,
      "step": 6700
    },
    {
      "loss": 2.1513,
      "grad_norm": 19.14824676513672,
      "learning_rate": 5.490028896676991e-06,
      "epoch": 0.2978817299205649,
      "step": 6750
    },
    {
      "loss": 1.9781,
      "grad_norm": 30.390628814697266,
      "learning_rate": 5.486756776368091e-06,
      "epoch": 0.3000882612533098,
      "step": 6800
    },
    {
      "loss": 1.9902,
      "grad_norm": 20.81952667236328,
      "learning_rate": 5.483484656059193e-06,
      "epoch": 0.30229479258605474,
      "step": 6850
    },
    {
      "loss": 1.996,
      "grad_norm": 35.32917022705078,
      "learning_rate": 5.480212535750293e-06,
      "epoch": 0.30450132391879964,
      "step": 6900
    },
    {
      "loss": 1.8384,
      "grad_norm": 23.055931091308594,
      "learning_rate": 5.476940415441394e-06,
      "epoch": 0.3067078552515446,
      "step": 6950
    },
    {
      "loss": 1.992,
      "grad_norm": 18.219982147216797,
      "learning_rate": 5.473668295132495e-06,
      "epoch": 0.3089143865842895,
      "step": 7000
    },
    {
      "loss": 1.9811,
      "grad_norm": 20.347970962524414,
      "learning_rate": 5.470396174823596e-06,
      "epoch": 0.31112091791703445,
      "step": 7050
    },
    {
      "loss": 1.9511,
      "grad_norm": 11.360797882080078,
      "learning_rate": 5.467124054514697e-06,
      "epoch": 0.31332744924977934,
      "step": 7100
    },
    {
      "loss": 1.9474,
      "grad_norm": 63.35609436035156,
      "learning_rate": 5.4638519342057975e-06,
      "epoch": 0.3155339805825243,
      "step": 7150
    },
    {
      "loss": 1.8864,
      "grad_norm": 21.83254051208496,
      "learning_rate": 5.460579813896899e-06,
      "epoch": 0.3177405119152692,
      "step": 7200
    },
    {
      "loss": 1.8473,
      "grad_norm": 18.188243865966797,
      "learning_rate": 5.457307693588e-06,
      "epoch": 0.3199470432480141,
      "step": 7250
    },
    {
      "loss": 1.9869,
      "grad_norm": 38.922672271728516,
      "learning_rate": 5.454035573279101e-06,
      "epoch": 0.32215357458075905,
      "step": 7300
    },
    {
      "loss": 1.9843,
      "grad_norm": 17.995370864868164,
      "learning_rate": 5.450763452970202e-06,
      "epoch": 0.32436010591350395,
      "step": 7350
    },
    {
      "loss": 2.076,
      "grad_norm": 27.828760147094727,
      "learning_rate": 5.447491332661303e-06,
      "epoch": 0.3265666372462489,
      "step": 7400
    },
    {
      "loss": 1.866,
      "grad_norm": 14.8985595703125,
      "learning_rate": 5.444219212352404e-06,
      "epoch": 0.3287731685789938,
      "step": 7450
    },
    {
      "loss": 1.9686,
      "grad_norm": 18.822484970092773,
      "learning_rate": 5.4409470920435045e-06,
      "epoch": 0.33097969991173876,
      "step": 7500
    },
    {
      "loss": 1.975,
      "grad_norm": 17.223241806030273,
      "learning_rate": 5.437674971734606e-06,
      "epoch": 0.33318623124448365,
      "step": 7550
    },
    {
      "loss": 1.9495,
      "grad_norm": 23.952198028564453,
      "learning_rate": 5.434402851425707e-06,
      "epoch": 0.3353927625772286,
      "step": 7600
    },
    {
      "loss": 1.9773,
      "grad_norm": 18.03742218017578,
      "learning_rate": 5.431130731116808e-06,
      "epoch": 0.3375992939099735,
      "step": 7650
    },
    {
      "loss": 1.9985,
      "grad_norm": 23.99421501159668,
      "learning_rate": 5.427858610807909e-06,
      "epoch": 0.33980582524271846,
      "step": 7700
    },
    {
      "loss": 2.0187,
      "grad_norm": 31.623992919921875,
      "learning_rate": 5.42458649049901e-06,
      "epoch": 0.34201235657546336,
      "step": 7750
    },
    {
      "loss": 1.9261,
      "grad_norm": 12.821722030639648,
      "learning_rate": 5.421314370190111e-06,
      "epoch": 0.3442188879082083,
      "step": 7800
    },
    {
      "loss": 1.8076,
      "grad_norm": 22.25322914123535,
      "learning_rate": 5.4180422498812115e-06,
      "epoch": 0.3464254192409532,
      "step": 7850
    },
    {
      "loss": 1.8261,
      "grad_norm": 15.779034614562988,
      "learning_rate": 5.414770129572313e-06,
      "epoch": 0.34863195057369817,
      "step": 7900
    },
    {
      "loss": 1.8928,
      "grad_norm": 34.619712829589844,
      "learning_rate": 5.411498009263413e-06,
      "epoch": 0.35083848190644307,
      "step": 7950
    },
    {
      "loss": 2.0157,
      "grad_norm": 21.78766632080078,
      "learning_rate": 5.408225888954515e-06,
      "epoch": 0.353045013239188,
      "step": 8000
    },
    {
      "loss": 1.8878,
      "grad_norm": 28.805225372314453,
      "learning_rate": 5.404953768645615e-06,
      "epoch": 0.3552515445719329,
      "step": 8050
    },
    {
      "loss": 1.9444,
      "grad_norm": 11.284912109375,
      "learning_rate": 5.401681648336716e-06,
      "epoch": 0.3574580759046778,
      "step": 8100
    },
    {
      "loss": 2.0872,
      "grad_norm": 19.57188606262207,
      "learning_rate": 5.398409528027817e-06,
      "epoch": 0.3596646072374228,
      "step": 8150
    },
    {
      "loss": 2.1164,
      "grad_norm": 19.765708923339844,
      "learning_rate": 5.395137407718918e-06,
      "epoch": 0.36187113857016767,
      "step": 8200
    },
    {
      "loss": 1.8989,
      "grad_norm": 19.93486976623535,
      "learning_rate": 5.391865287410019e-06,
      "epoch": 0.3640776699029126,
      "step": 8250
    },
    {
      "loss": 1.9057,
      "grad_norm": 24.40935707092285,
      "learning_rate": 5.3885931671011195e-06,
      "epoch": 0.3662842012356575,
      "step": 8300
    },
    {
      "loss": 2.0552,
      "grad_norm": 16.588918685913086,
      "learning_rate": 5.385321046792221e-06,
      "epoch": 0.3684907325684025,
      "step": 8350
    },
    {
      "loss": 1.9254,
      "grad_norm": 23.77133560180664,
      "learning_rate": 5.382048926483322e-06,
      "epoch": 0.3706972639011474,
      "step": 8400
    },
    {
      "loss": 1.9933,
      "grad_norm": 19.377132415771484,
      "learning_rate": 5.378776806174423e-06,
      "epoch": 0.37290379523389233,
      "step": 8450
    },
    {
      "loss": 1.8902,
      "grad_norm": 18.17485809326172,
      "learning_rate": 5.375504685865524e-06,
      "epoch": 0.37511032656663723,
      "step": 8500
    },
    {
      "loss": 1.85,
      "grad_norm": 20.165565490722656,
      "learning_rate": 5.372232565556625e-06,
      "epoch": 0.3773168578993822,
      "step": 8550
    },
    {
      "loss": 1.9679,
      "grad_norm": 16.439382553100586,
      "learning_rate": 5.368960445247726e-06,
      "epoch": 0.3795233892321271,
      "step": 8600
    },
    {
      "loss": 1.8756,
      "grad_norm": 27.573633193969727,
      "learning_rate": 5.3656883249388265e-06,
      "epoch": 0.38172992056487204,
      "step": 8650
    },
    {
      "loss": 1.8139,
      "grad_norm": 20.303007125854492,
      "learning_rate": 5.362416204629928e-06,
      "epoch": 0.38393645189761694,
      "step": 8700
    },
    {
      "loss": 2.1101,
      "grad_norm": 30.889677047729492,
      "learning_rate": 5.359144084321029e-06,
      "epoch": 0.3861429832303619,
      "step": 8750
    },
    {
      "loss": 1.8857,
      "grad_norm": 23.328027725219727,
      "learning_rate": 5.35587196401213e-06,
      "epoch": 0.3883495145631068,
      "step": 8800
    },
    {
      "loss": 1.9284,
      "grad_norm": 16.451370239257812,
      "learning_rate": 5.352599843703231e-06,
      "epoch": 0.39055604589585174,
      "step": 8850
    },
    {
      "loss": 1.9773,
      "grad_norm": 20.398815155029297,
      "learning_rate": 5.349327723394332e-06,
      "epoch": 0.39276257722859664,
      "step": 8900
    },
    {
      "loss": 1.8808,
      "grad_norm": 25.980928421020508,
      "learning_rate": 5.346055603085433e-06,
      "epoch": 0.3949691085613416,
      "step": 8950
    },
    {
      "loss": 1.7881,
      "grad_norm": 20.862812042236328,
      "learning_rate": 5.3427834827765335e-06,
      "epoch": 0.3971756398940865,
      "step": 9000
    },
    {
      "loss": 1.9978,
      "grad_norm": 19.445289611816406,
      "learning_rate": 5.339511362467635e-06,
      "epoch": 0.3993821712268314,
      "step": 9050
    },
    {
      "loss": 1.8151,
      "grad_norm": 19.802536010742188,
      "learning_rate": 5.336239242158735e-06,
      "epoch": 0.40158870255957635,
      "step": 9100
    },
    {
      "loss": 1.7896,
      "grad_norm": 22.360692977905273,
      "learning_rate": 5.332967121849837e-06,
      "epoch": 0.40379523389232125,
      "step": 9150
    },
    {
      "loss": 1.9237,
      "grad_norm": 19.748462677001953,
      "learning_rate": 5.329695001540937e-06,
      "epoch": 0.4060017652250662,
      "step": 9200
    },
    {
      "loss": 1.8049,
      "grad_norm": 26.11183738708496,
      "learning_rate": 5.326422881232038e-06,
      "epoch": 0.4082082965578111,
      "step": 9250
    },
    {
      "loss": 1.8892,
      "grad_norm": 19.950227737426758,
      "learning_rate": 5.323150760923139e-06,
      "epoch": 0.41041482789055606,
      "step": 9300
    },
    {
      "loss": 2.047,
      "grad_norm": 36.87620544433594,
      "learning_rate": 5.31987864061424e-06,
      "epoch": 0.41262135922330095,
      "step": 9350
    },
    {
      "loss": 1.9584,
      "grad_norm": 23.41022300720215,
      "learning_rate": 5.316606520305341e-06,
      "epoch": 0.4148278905560459,
      "step": 9400
    },
    {
      "loss": 1.9156,
      "grad_norm": 25.852344512939453,
      "learning_rate": 5.313334399996442e-06,
      "epoch": 0.4170344218887908,
      "step": 9450
    },
    {
      "loss": 1.9801,
      "grad_norm": 20.501510620117188,
      "learning_rate": 5.310062279687543e-06,
      "epoch": 0.41924095322153576,
      "step": 9500
    },
    {
      "loss": 1.9398,
      "grad_norm": 30.157297134399414,
      "learning_rate": 5.306790159378644e-06,
      "epoch": 0.42144748455428066,
      "step": 9550
    },
    {
      "loss": 1.9253,
      "grad_norm": 22.544397354125977,
      "learning_rate": 5.303518039069745e-06,
      "epoch": 0.4236540158870256,
      "step": 9600
    },
    {
      "loss": 1.8799,
      "grad_norm": 20.58742904663086,
      "learning_rate": 5.300245918760846e-06,
      "epoch": 0.4258605472197705,
      "step": 9650
    },
    {
      "loss": 1.9685,
      "grad_norm": 18.04590606689453,
      "learning_rate": 5.296973798451947e-06,
      "epoch": 0.42806707855251547,
      "step": 9700
    },
    {
      "loss": 1.8278,
      "grad_norm": 15.409039497375488,
      "learning_rate": 5.293701678143048e-06,
      "epoch": 0.43027360988526037,
      "step": 9750
    },
    {
      "loss": 1.9193,
      "grad_norm": 23.88775634765625,
      "learning_rate": 5.290429557834149e-06,
      "epoch": 0.4324801412180053,
      "step": 9800
    },
    {
      "loss": 1.9447,
      "grad_norm": 17.689151763916016,
      "learning_rate": 5.28715743752525e-06,
      "epoch": 0.4346866725507502,
      "step": 9850
    },
    {
      "loss": 1.9113,
      "grad_norm": 28.483623504638672,
      "learning_rate": 5.283885317216351e-06,
      "epoch": 0.4368932038834951,
      "step": 9900
    },
    {
      "loss": 1.7481,
      "grad_norm": 21.47017478942871,
      "learning_rate": 5.280613196907452e-06,
      "epoch": 0.4390997352162401,
      "step": 9950
    },
    {
      "loss": 1.9321,
      "grad_norm": 20.80790901184082,
      "learning_rate": 5.277341076598553e-06,
      "epoch": 0.44130626654898497,
      "step": 10000
    },
    {
      "loss": 2.0003,
      "grad_norm": 16.407909393310547,
      "learning_rate": 5.274068956289654e-06,
      "epoch": 0.4435127978817299,
      "step": 10050
    },
    {
      "loss": 1.8517,
      "grad_norm": 27.909013748168945,
      "learning_rate": 5.270796835980755e-06,
      "epoch": 0.4457193292144748,
      "step": 10100
    },
    {
      "loss": 1.786,
      "grad_norm": 19.562633514404297,
      "learning_rate": 5.2675247156718555e-06,
      "epoch": 0.4479258605472198,
      "step": 10150
    },
    {
      "loss": 1.8494,
      "grad_norm": 26.557384490966797,
      "learning_rate": 5.264252595362957e-06,
      "epoch": 0.4501323918799647,
      "step": 10200
    },
    {
      "loss": 1.892,
      "grad_norm": 23.749879837036133,
      "learning_rate": 5.260980475054057e-06,
      "epoch": 0.45233892321270963,
      "step": 10250
    },
    {
      "loss": 1.7986,
      "grad_norm": 33.269287109375,
      "learning_rate": 5.257708354745159e-06,
      "epoch": 0.45454545454545453,
      "step": 10300
    },
    {
      "loss": 1.8948,
      "grad_norm": 15.59102725982666,
      "learning_rate": 5.254436234436259e-06,
      "epoch": 0.4567519858781995,
      "step": 10350
    },
    {
      "loss": 1.8769,
      "grad_norm": 11.126838684082031,
      "learning_rate": 5.25116411412736e-06,
      "epoch": 0.4589585172109444,
      "step": 10400
    },
    {
      "loss": 1.8776,
      "grad_norm": 31.758682250976562,
      "learning_rate": 5.247891993818461e-06,
      "epoch": 0.46116504854368934,
      "step": 10450
    },
    {
      "loss": 1.7508,
      "grad_norm": 17.950639724731445,
      "learning_rate": 5.244619873509562e-06,
      "epoch": 0.46337157987643424,
      "step": 10500
    },
    {
      "loss": 1.8134,
      "grad_norm": 14.426555633544922,
      "learning_rate": 5.241347753200663e-06,
      "epoch": 0.4655781112091792,
      "step": 10550
    },
    {
      "loss": 1.9205,
      "grad_norm": 19.78264617919922,
      "learning_rate": 5.238075632891764e-06,
      "epoch": 0.4677846425419241,
      "step": 10600
    },
    {
      "loss": 1.9005,
      "grad_norm": 29.151155471801758,
      "learning_rate": 5.234803512582865e-06,
      "epoch": 0.46999117387466904,
      "step": 10650
    },
    {
      "loss": 1.7573,
      "grad_norm": 18.831584930419922,
      "learning_rate": 5.231531392273966e-06,
      "epoch": 0.47219770520741394,
      "step": 10700
    },
    {
      "loss": 1.7239,
      "grad_norm": 14.993924140930176,
      "learning_rate": 5.228259271965067e-06,
      "epoch": 0.4744042365401589,
      "step": 10750
    },
    {
      "loss": 1.7406,
      "grad_norm": 17.848419189453125,
      "learning_rate": 5.224987151656168e-06,
      "epoch": 0.4766107678729038,
      "step": 10800
    },
    {
      "loss": 1.7722,
      "grad_norm": 10.088554382324219,
      "learning_rate": 5.221715031347269e-06,
      "epoch": 0.4788172992056487,
      "step": 10850
    },
    {
      "loss": 1.8678,
      "grad_norm": 13.099748611450195,
      "learning_rate": 5.21844291103837e-06,
      "epoch": 0.48102383053839365,
      "step": 10900
    },
    {
      "loss": 1.8806,
      "grad_norm": 22.443391799926758,
      "learning_rate": 5.215170790729471e-06,
      "epoch": 0.48323036187113855,
      "step": 10950
    },
    {
      "loss": 1.8532,
      "grad_norm": 16.431638717651367,
      "learning_rate": 5.211898670420572e-06,
      "epoch": 0.4854368932038835,
      "step": 11000
    },
    {
      "loss": 1.7943,
      "grad_norm": 13.984495162963867,
      "learning_rate": 5.208626550111673e-06,
      "epoch": 0.4876434245366284,
      "step": 11050
    },
    {
      "loss": 1.8159,
      "grad_norm": 24.330286026000977,
      "learning_rate": 5.205354429802774e-06,
      "epoch": 0.48984995586937335,
      "step": 11100
    },
    {
      "loss": 1.7056,
      "grad_norm": 28.7215518951416,
      "learning_rate": 5.202082309493875e-06,
      "epoch": 0.49205648720211825,
      "step": 11150
    },
    {
      "loss": 1.8409,
      "grad_norm": 20.45547866821289,
      "learning_rate": 5.198810189184976e-06,
      "epoch": 0.4942630185348632,
      "step": 11200
    },
    {
      "loss": 1.9253,
      "grad_norm": 22.359445571899414,
      "learning_rate": 5.195538068876077e-06,
      "epoch": 0.4964695498676081,
      "step": 11250
    },
    {
      "loss": 1.7277,
      "grad_norm": 24.88601303100586,
      "learning_rate": 5.1922659485671775e-06,
      "epoch": 0.49867608120035306,
      "step": 11300
    },
    {
      "loss": 1.9102,
      "grad_norm": 18.408756256103516,
      "learning_rate": 5.188993828258279e-06,
      "epoch": 0.500882612533098,
      "step": 11350
    },
    {
      "loss": 1.767,
      "grad_norm": 8.952868461608887,
      "learning_rate": 5.185721707949379e-06,
      "epoch": 0.5030891438658429,
      "step": 11400
    },
    {
      "loss": 1.8863,
      "grad_norm": 16.82987403869629,
      "learning_rate": 5.182449587640481e-06,
      "epoch": 0.5052956751985879,
      "step": 11450
    },
    {
      "loss": 1.7772,
      "grad_norm": 18.602920532226562,
      "learning_rate": 5.179177467331581e-06,
      "epoch": 0.5075022065313327,
      "step": 11500
    },
    {
      "loss": 1.8277,
      "grad_norm": 16.041154861450195,
      "learning_rate": 5.175905347022682e-06,
      "epoch": 0.5097087378640777,
      "step": 11550
    },
    {
      "loss": 1.7405,
      "grad_norm": 32.63491439819336,
      "learning_rate": 5.172633226713783e-06,
      "epoch": 0.5119152691968226,
      "step": 11600
    },
    {
      "loss": 1.7128,
      "grad_norm": 38.804378509521484,
      "learning_rate": 5.1693611064048845e-06,
      "epoch": 0.5141218005295676,
      "step": 11650
    },
    {
      "loss": 1.7906,
      "grad_norm": 18.850990295410156,
      "learning_rate": 5.166088986095985e-06,
      "epoch": 0.5163283318623124,
      "step": 11700
    },
    {
      "loss": 1.6536,
      "grad_norm": 9.081809043884277,
      "learning_rate": 5.162816865787086e-06,
      "epoch": 0.5185348631950574,
      "step": 11750
    },
    {
      "loss": 1.7252,
      "grad_norm": 44.41735076904297,
      "learning_rate": 5.159544745478187e-06,
      "epoch": 0.5207413945278023,
      "step": 11800
    },
    {
      "loss": 1.8045,
      "grad_norm": 27.101985931396484,
      "learning_rate": 5.156272625169288e-06,
      "epoch": 0.5229479258605472,
      "step": 11850
    },
    {
      "loss": 1.9735,
      "grad_norm": 22.02599334716797,
      "learning_rate": 5.153000504860389e-06,
      "epoch": 0.5251544571932921,
      "step": 11900
    },
    {
      "loss": 1.8355,
      "grad_norm": 25.259628295898438,
      "learning_rate": 5.14972838455149e-06,
      "epoch": 0.5273609885260371,
      "step": 11950
    },
    {
      "loss": 1.7325,
      "grad_norm": 13.818940162658691,
      "learning_rate": 5.1464562642425914e-06,
      "epoch": 0.529567519858782,
      "step": 12000
    },
    {
      "loss": 1.9292,
      "grad_norm": 25.696622848510742,
      "learning_rate": 5.143184143933692e-06,
      "epoch": 0.5317740511915269,
      "step": 12050
    },
    {
      "loss": 1.6855,
      "grad_norm": 21.522680282592773,
      "learning_rate": 5.139912023624793e-06,
      "epoch": 0.5339805825242718,
      "step": 12100
    },
    {
      "loss": 1.866,
      "grad_norm": 25.580047607421875,
      "learning_rate": 5.136639903315894e-06,
      "epoch": 0.5361871138570168,
      "step": 12150
    },
    {
      "loss": 1.7828,
      "grad_norm": 16.1530704498291,
      "learning_rate": 5.133367783006995e-06,
      "epoch": 0.5383936451897617,
      "step": 12200
    },
    {
      "loss": 1.6648,
      "grad_norm": 23.503087997436523,
      "learning_rate": 5.130095662698096e-06,
      "epoch": 0.5406001765225066,
      "step": 12250
    },
    {
      "loss": 1.72,
      "grad_norm": 24.761842727661133,
      "learning_rate": 5.126823542389197e-06,
      "epoch": 0.5428067078552515,
      "step": 12300
    },
    {
      "loss": 1.6576,
      "grad_norm": 15.814931869506836,
      "learning_rate": 5.1235514220802984e-06,
      "epoch": 0.5450132391879965,
      "step": 12350
    },
    {
      "loss": 1.6539,
      "grad_norm": 20.34991455078125,
      "learning_rate": 5.120279301771399e-06,
      "epoch": 0.5472197705207414,
      "step": 12400
    },
    {
      "loss": 1.754,
      "grad_norm": 38.472496032714844,
      "learning_rate": 5.1170071814624995e-06,
      "epoch": 0.5494263018534863,
      "step": 12450
    },
    {
      "loss": 1.7133,
      "grad_norm": 16.598857879638672,
      "learning_rate": 5.113735061153601e-06,
      "epoch": 0.5516328331862312,
      "step": 12500
    },
    {
      "loss": 1.7301,
      "grad_norm": 18.262109756469727,
      "learning_rate": 5.110462940844701e-06,
      "epoch": 0.5538393645189762,
      "step": 12550
    },
    {
      "loss": 1.9082,
      "grad_norm": 32.15773010253906,
      "learning_rate": 5.107190820535802e-06,
      "epoch": 0.556045895851721,
      "step": 12600
    },
    {
      "loss": 1.6841,
      "grad_norm": 30.83297348022461,
      "learning_rate": 5.103918700226903e-06,
      "epoch": 0.558252427184466,
      "step": 12650
    },
    {
      "loss": 1.7538,
      "grad_norm": 19.15749740600586,
      "learning_rate": 5.100646579918004e-06,
      "epoch": 0.560458958517211,
      "step": 12700
    },
    {
      "loss": 1.7776,
      "grad_norm": 12.972997665405273,
      "learning_rate": 5.097374459609105e-06,
      "epoch": 0.5626654898499559,
      "step": 12750
    },
    {
      "loss": 1.7313,
      "grad_norm": 20.091373443603516,
      "learning_rate": 5.0941023393002065e-06,
      "epoch": 0.5648720211827007,
      "step": 12800
    },
    {
      "loss": 1.6908,
      "grad_norm": 20.09058380126953,
      "learning_rate": 5.090830218991307e-06,
      "epoch": 0.5670785525154457,
      "step": 12850
    },
    {
      "loss": 1.5849,
      "grad_norm": 28.24392318725586,
      "learning_rate": 5.087558098682408e-06,
      "epoch": 0.5692850838481907,
      "step": 12900
    },
    {
      "loss": 1.7493,
      "grad_norm": 18.43592071533203,
      "learning_rate": 5.084285978373509e-06,
      "epoch": 0.5714916151809356,
      "step": 12950
    },
    {
      "loss": 1.6645,
      "grad_norm": 18.040266036987305,
      "learning_rate": 5.08101385806461e-06,
      "epoch": 0.5736981465136805,
      "step": 13000
    },
    {
      "loss": 1.5968,
      "grad_norm": 14.73608684539795,
      "learning_rate": 5.077741737755711e-06,
      "epoch": 0.5759046778464254,
      "step": 13050
    },
    {
      "loss": 1.7321,
      "grad_norm": 12.426945686340332,
      "learning_rate": 5.074469617446812e-06,
      "epoch": 0.5781112091791704,
      "step": 13100
    },
    {
      "loss": 1.7935,
      "grad_norm": 26.153736114501953,
      "learning_rate": 5.0711974971379134e-06,
      "epoch": 0.5803177405119153,
      "step": 13150
    },
    {
      "loss": 1.6909,
      "grad_norm": 25.813405990600586,
      "learning_rate": 5.067925376829014e-06,
      "epoch": 0.5825242718446602,
      "step": 13200
    },
    {
      "loss": 1.8295,
      "grad_norm": 26.615219116210938,
      "learning_rate": 5.064653256520115e-06,
      "epoch": 0.5847308031774051,
      "step": 13250
    },
    {
      "loss": 1.5792,
      "grad_norm": 22.58039665222168,
      "learning_rate": 5.061381136211216e-06,
      "epoch": 0.5869373345101501,
      "step": 13300
    },
    {
      "loss": 1.7367,
      "grad_norm": 28.46344566345215,
      "learning_rate": 5.058109015902317e-06,
      "epoch": 0.589143865842895,
      "step": 13350
    },
    {
      "loss": 1.6372,
      "grad_norm": 13.73775577545166,
      "learning_rate": 5.054836895593418e-06,
      "epoch": 0.5913503971756399,
      "step": 13400
    },
    {
      "loss": 1.6649,
      "grad_norm": 30.73116683959961,
      "learning_rate": 5.051564775284519e-06,
      "epoch": 0.5935569285083848,
      "step": 13450
    },
    {
      "loss": 1.6656,
      "grad_norm": 11.315242767333984,
      "learning_rate": 5.0482926549756204e-06,
      "epoch": 0.5957634598411298,
      "step": 13500
    },
    {
      "loss": 1.5248,
      "grad_norm": 18.380727767944336,
      "learning_rate": 5.045020534666721e-06,
      "epoch": 0.5979699911738746,
      "step": 13550
    },
    {
      "loss": 1.6286,
      "grad_norm": 13.506145477294922,
      "learning_rate": 5.0417484143578215e-06,
      "epoch": 0.6001765225066196,
      "step": 13600
    },
    {
      "loss": 1.6118,
      "grad_norm": 16.036624908447266,
      "learning_rate": 5.038476294048923e-06,
      "epoch": 0.6023830538393645,
      "step": 13650
    },
    {
      "loss": 1.7712,
      "grad_norm": 18.440689086914062,
      "learning_rate": 5.035204173740023e-06,
      "epoch": 0.6045895851721095,
      "step": 13700
    },
    {
      "loss": 1.6577,
      "grad_norm": 1.6681658029556274,
      "learning_rate": 5.031932053431124e-06,
      "epoch": 0.6067961165048543,
      "step": 13750
    },
    {
      "loss": 1.7039,
      "grad_norm": 19.297992706298828,
      "learning_rate": 5.028659933122225e-06,
      "epoch": 0.6090026478375993,
      "step": 13800
    },
    {
      "loss": 1.6738,
      "grad_norm": 24.631757736206055,
      "learning_rate": 5.0253878128133266e-06,
      "epoch": 0.6112091791703442,
      "step": 13850
    },
    {
      "loss": 1.6379,
      "grad_norm": 30.043107986450195,
      "learning_rate": 5.022115692504427e-06,
      "epoch": 0.6134157105030892,
      "step": 13900
    },
    {
      "loss": 1.7194,
      "grad_norm": 16.063678741455078,
      "learning_rate": 5.0188435721955285e-06,
      "epoch": 0.615622241835834,
      "step": 13950
    },
    {
      "loss": 1.6859,
      "grad_norm": 27.744565963745117,
      "learning_rate": 5.015571451886629e-06,
      "epoch": 0.617828773168579,
      "step": 14000
    },
    {
      "loss": 1.558,
      "grad_norm": 25.38100242614746,
      "learning_rate": 5.01229933157773e-06,
      "epoch": 0.6200353045013239,
      "step": 14050
    },
    {
      "loss": 1.685,
      "grad_norm": 16.60384178161621,
      "learning_rate": 5.009027211268831e-06,
      "epoch": 0.6222418358340689,
      "step": 14100
    },
    {
      "loss": 1.4674,
      "grad_norm": 19.890291213989258,
      "learning_rate": 5.005755090959932e-06,
      "epoch": 0.6244483671668137,
      "step": 14150
    },
    {
      "loss": 1.669,
      "grad_norm": 18.61734390258789,
      "learning_rate": 5.0024829706510336e-06,
      "epoch": 0.6266548984995587,
      "step": 14200
    },
    {
      "loss": 1.6986,
      "grad_norm": 36.40476608276367,
      "learning_rate": 4.999210850342134e-06,
      "epoch": 0.6288614298323036,
      "step": 14250
    },
    {
      "loss": 1.7221,
      "grad_norm": 25.811168670654297,
      "learning_rate": 4.9959387300332354e-06,
      "epoch": 0.6310679611650486,
      "step": 14300
    },
    {
      "loss": 1.5993,
      "grad_norm": 24.2270565032959,
      "learning_rate": 4.992666609724336e-06,
      "epoch": 0.6332744924977934,
      "step": 14350
    },
    {
      "loss": 1.8036,
      "grad_norm": 20.659114837646484,
      "learning_rate": 4.989394489415437e-06,
      "epoch": 0.6354810238305384,
      "step": 14400
    },
    {
      "loss": 1.6009,
      "grad_norm": 21.916471481323242,
      "learning_rate": 4.986122369106538e-06,
      "epoch": 0.6376875551632833,
      "step": 14450
    },
    {
      "loss": 1.5644,
      "grad_norm": 33.00043487548828,
      "learning_rate": 4.982850248797639e-06,
      "epoch": 0.6398940864960282,
      "step": 14500
    },
    {
      "loss": 1.5891,
      "grad_norm": 22.238061904907227,
      "learning_rate": 4.9795781284887406e-06,
      "epoch": 0.6421006178287731,
      "step": 14550
    },
    {
      "loss": 1.7027,
      "grad_norm": 37.41596603393555,
      "learning_rate": 4.976306008179841e-06,
      "epoch": 0.6443071491615181,
      "step": 14600
    },
    {
      "loss": 1.7125,
      "grad_norm": 25.244524002075195,
      "learning_rate": 4.9730338878709424e-06,
      "epoch": 0.646513680494263,
      "step": 14650
    },
    {
      "loss": 1.7367,
      "grad_norm": 22.262950897216797,
      "learning_rate": 4.969761767562043e-06,
      "epoch": 0.6487202118270079,
      "step": 14700
    },
    {
      "loss": 1.6652,
      "grad_norm": 15.794892311096191,
      "learning_rate": 4.9664896472531435e-06,
      "epoch": 0.6509267431597529,
      "step": 14750
    },
    {
      "loss": 1.5518,
      "grad_norm": 15.79541301727295,
      "learning_rate": 4.963217526944245e-06,
      "epoch": 0.6531332744924978,
      "step": 14800
    },
    {
      "loss": 1.6575,
      "grad_norm": 26.599002838134766,
      "learning_rate": 4.959945406635345e-06,
      "epoch": 0.6553398058252428,
      "step": 14850
    },
    {
      "loss": 1.5759,
      "grad_norm": 27.581890106201172,
      "learning_rate": 4.956673286326447e-06,
      "epoch": 0.6575463371579876,
      "step": 14900
    },
    {
      "loss": 1.5773,
      "grad_norm": 18.176111221313477,
      "learning_rate": 4.953401166017547e-06,
      "epoch": 0.6597528684907326,
      "step": 14950
    },
    {
      "loss": 1.5086,
      "grad_norm": 17.971046447753906,
      "learning_rate": 4.9501290457086486e-06,
      "epoch": 0.6619593998234775,
      "step": 15000
    },
    {
      "loss": 1.5733,
      "grad_norm": 18.436725616455078,
      "learning_rate": 4.946856925399749e-06,
      "epoch": 0.6641659311562225,
      "step": 15050
    },
    {
      "loss": 1.5396,
      "grad_norm": 27.750144958496094,
      "learning_rate": 4.9435848050908505e-06,
      "epoch": 0.6663724624889673,
      "step": 15100
    },
    {
      "loss": 1.5723,
      "grad_norm": 25.993896484375,
      "learning_rate": 4.940312684781951e-06,
      "epoch": 0.6685789938217123,
      "step": 15150
    },
    {
      "loss": 1.7127,
      "grad_norm": 17.702268600463867,
      "learning_rate": 4.937040564473052e-06,
      "epoch": 0.6707855251544572,
      "step": 15200
    },
    {
      "loss": 1.582,
      "grad_norm": 34.54214859008789,
      "learning_rate": 4.933768444164153e-06,
      "epoch": 0.6729920564872022,
      "step": 15250
    },
    {
      "loss": 1.4747,
      "grad_norm": 15.250957489013672,
      "learning_rate": 4.930496323855254e-06,
      "epoch": 0.675198587819947,
      "step": 15300
    },
    {
      "loss": 1.5876,
      "grad_norm": 26.998159408569336,
      "learning_rate": 4.9272242035463556e-06,
      "epoch": 0.677405119152692,
      "step": 15350
    },
    {
      "loss": 1.5523,
      "grad_norm": 11.363629341125488,
      "learning_rate": 4.923952083237456e-06,
      "epoch": 0.6796116504854369,
      "step": 15400
    },
    {
      "loss": 1.6269,
      "grad_norm": 19.26116180419922,
      "learning_rate": 4.9206799629285574e-06,
      "epoch": 0.6818181818181818,
      "step": 15450
    },
    {
      "loss": 1.5679,
      "grad_norm": 35.297027587890625,
      "learning_rate": 4.917407842619658e-06,
      "epoch": 0.6840247131509267,
      "step": 15500
    },
    {
      "loss": 1.6558,
      "grad_norm": 15.531116485595703,
      "learning_rate": 4.914135722310759e-06,
      "epoch": 0.6862312444836717,
      "step": 15550
    },
    {
      "loss": 1.6612,
      "grad_norm": 16.27389144897461,
      "learning_rate": 4.91086360200186e-06,
      "epoch": 0.6884377758164166,
      "step": 15600
    },
    {
      "loss": 1.7498,
      "grad_norm": 14.134651184082031,
      "learning_rate": 4.907591481692961e-06,
      "epoch": 0.6906443071491615,
      "step": 15650
    },
    {
      "loss": 1.669,
      "grad_norm": 28.308504104614258,
      "learning_rate": 4.9043193613840626e-06,
      "epoch": 0.6928508384819064,
      "step": 15700
    },
    {
      "loss": 1.5485,
      "grad_norm": 13.319241523742676,
      "learning_rate": 4.901047241075163e-06,
      "epoch": 0.6950573698146514,
      "step": 15750
    },
    {
      "loss": 1.5404,
      "grad_norm": 21.687244415283203,
      "learning_rate": 4.897775120766264e-06,
      "epoch": 0.6972639011473963,
      "step": 15800
    },
    {
      "loss": 1.7057,
      "grad_norm": 29.15412139892578,
      "learning_rate": 4.894503000457365e-06,
      "epoch": 0.6994704324801412,
      "step": 15850
    },
    {
      "loss": 1.6557,
      "grad_norm": 20.06793212890625,
      "learning_rate": 4.8912308801484655e-06,
      "epoch": 0.7016769638128861,
      "step": 15900
    },
    {
      "loss": 1.7361,
      "grad_norm": 20.863107681274414,
      "learning_rate": 4.887958759839567e-06,
      "epoch": 0.7038834951456311,
      "step": 15950
    },
    {
      "loss": 1.5583,
      "grad_norm": 23.326087951660156,
      "learning_rate": 4.884686639530667e-06,
      "epoch": 0.706090026478376,
      "step": 16000
    },
    {
      "loss": 1.4393,
      "grad_norm": 21.968036651611328,
      "learning_rate": 4.881414519221769e-06,
      "epoch": 0.7082965578111209,
      "step": 16050
    },
    {
      "loss": 1.6026,
      "grad_norm": 14.704588890075684,
      "learning_rate": 4.878142398912869e-06,
      "epoch": 0.7105030891438658,
      "step": 16100
    },
    {
      "loss": 1.5552,
      "grad_norm": 12.377983093261719,
      "learning_rate": 4.8748702786039706e-06,
      "epoch": 0.7127096204766108,
      "step": 16150
    },
    {
      "loss": 1.5298,
      "grad_norm": 19.88321876525879,
      "learning_rate": 4.871598158295071e-06,
      "epoch": 0.7149161518093556,
      "step": 16200
    },
    {
      "loss": 1.6133,
      "grad_norm": 28.89234733581543,
      "learning_rate": 4.8683260379861725e-06,
      "epoch": 0.7171226831421006,
      "step": 16250
    },
    {
      "loss": 1.618,
      "grad_norm": 21.057950973510742,
      "learning_rate": 4.865053917677273e-06,
      "epoch": 0.7193292144748455,
      "step": 16300
    },
    {
      "loss": 1.5649,
      "grad_norm": 14.591863632202148,
      "learning_rate": 4.861781797368374e-06,
      "epoch": 0.7215357458075905,
      "step": 16350
    },
    {
      "loss": 1.7621,
      "grad_norm": 18.21286392211914,
      "learning_rate": 4.858509677059476e-06,
      "epoch": 0.7237422771403353,
      "step": 16400
    },
    {
      "loss": 1.6121,
      "grad_norm": 22.064865112304688,
      "learning_rate": 4.855237556750576e-06,
      "epoch": 0.7259488084730803,
      "step": 16450
    },
    {
      "loss": 1.5308,
      "grad_norm": 35.324745178222656,
      "learning_rate": 4.8519654364416776e-06,
      "epoch": 0.7281553398058253,
      "step": 16500
    },
    {
      "loss": 1.6073,
      "grad_norm": 10.353073120117188,
      "learning_rate": 4.848693316132778e-06,
      "epoch": 0.7303618711385702,
      "step": 16550
    },
    {
      "loss": 1.5476,
      "grad_norm": 24.705224990844727,
      "learning_rate": 4.8454211958238794e-06,
      "epoch": 0.732568402471315,
      "step": 16600
    },
    {
      "loss": 1.5287,
      "grad_norm": 23.41275405883789,
      "learning_rate": 4.84214907551498e-06,
      "epoch": 0.73477493380406,
      "step": 16650
    },
    {
      "loss": 1.5527,
      "grad_norm": 18.169775009155273,
      "learning_rate": 4.838876955206081e-06,
      "epoch": 0.736981465136805,
      "step": 16700
    },
    {
      "loss": 1.4726,
      "grad_norm": 22.529815673828125,
      "learning_rate": 4.835604834897183e-06,
      "epoch": 0.7391879964695499,
      "step": 16750
    },
    {
      "loss": 1.5018,
      "grad_norm": 11.636590003967285,
      "learning_rate": 4.832332714588283e-06,
      "epoch": 0.7413945278022948,
      "step": 16800
    },
    {
      "loss": 1.6755,
      "grad_norm": 32.65230941772461,
      "learning_rate": 4.8290605942793846e-06,
      "epoch": 0.7436010591350397,
      "step": 16850
    },
    {
      "loss": 1.3277,
      "grad_norm": 20.44308853149414,
      "learning_rate": 4.825788473970485e-06,
      "epoch": 0.7458075904677847,
      "step": 16900
    },
    {
      "loss": 1.5664,
      "grad_norm": 34.905799865722656,
      "learning_rate": 4.822516353661586e-06,
      "epoch": 0.7480141218005296,
      "step": 16950
    },
    {
      "loss": 1.5507,
      "grad_norm": 25.02301597595215,
      "learning_rate": 4.819244233352687e-06,
      "epoch": 0.7502206531332745,
      "step": 17000
    },
    {
      "loss": 1.4997,
      "grad_norm": 23.891056060791016,
      "learning_rate": 4.8159721130437875e-06,
      "epoch": 0.7524271844660194,
      "step": 17050
    },
    {
      "loss": 1.5071,
      "grad_norm": 21.386980056762695,
      "learning_rate": 4.812699992734889e-06,
      "epoch": 0.7546337157987644,
      "step": 17100
    },
    {
      "loss": 1.6696,
      "grad_norm": 15.02065372467041,
      "learning_rate": 4.809427872425989e-06,
      "epoch": 0.7568402471315092,
      "step": 17150
    },
    {
      "loss": 1.4774,
      "grad_norm": 15.161887168884277,
      "learning_rate": 4.806155752117091e-06,
      "epoch": 0.7590467784642542,
      "step": 17200
    },
    {
      "loss": 1.5659,
      "grad_norm": 22.837339401245117,
      "learning_rate": 4.802883631808191e-06,
      "epoch": 0.7612533097969991,
      "step": 17250
    },
    {
      "loss": 1.5398,
      "grad_norm": 22.736408233642578,
      "learning_rate": 4.7996115114992926e-06,
      "epoch": 0.7634598411297441,
      "step": 17300
    },
    {
      "loss": 1.4732,
      "grad_norm": 19.334941864013672,
      "learning_rate": 4.796339391190393e-06,
      "epoch": 0.7656663724624889,
      "step": 17350
    },
    {
      "loss": 1.6236,
      "grad_norm": 33.020423889160156,
      "learning_rate": 4.7930672708814945e-06,
      "epoch": 0.7678729037952339,
      "step": 17400
    },
    {
      "loss": 1.5657,
      "grad_norm": 30.60841941833496,
      "learning_rate": 4.789795150572595e-06,
      "epoch": 0.7700794351279788,
      "step": 17450
    },
    {
      "loss": 1.4526,
      "grad_norm": 11.637253761291504,
      "learning_rate": 4.786523030263696e-06,
      "epoch": 0.7722859664607238,
      "step": 17500
    },
    {
      "loss": 1.5615,
      "grad_norm": 22.6117000579834,
      "learning_rate": 4.783250909954798e-06,
      "epoch": 0.7744924977934686,
      "step": 17550
    },
    {
      "loss": 1.729,
      "grad_norm": 20.13528823852539,
      "learning_rate": 4.779978789645898e-06,
      "epoch": 0.7766990291262136,
      "step": 17600
    },
    {
      "loss": 1.5601,
      "grad_norm": 13.44863510131836,
      "learning_rate": 4.7767066693369996e-06,
      "epoch": 0.7789055604589585,
      "step": 17650
    },
    {
      "loss": 1.5724,
      "grad_norm": 23.283912658691406,
      "learning_rate": 4.7734345490281e-06,
      "epoch": 0.7811120917917035,
      "step": 17700
    },
    {
      "loss": 1.5424,
      "grad_norm": 26.30906867980957,
      "learning_rate": 4.7701624287192014e-06,
      "epoch": 0.7833186231244483,
      "step": 17750
    },
    {
      "loss": 1.4871,
      "grad_norm": 15.525461196899414,
      "learning_rate": 4.766890308410302e-06,
      "epoch": 0.7855251544571933,
      "step": 17800
    },
    {
      "loss": 1.4681,
      "grad_norm": 28.131927490234375,
      "learning_rate": 4.763618188101403e-06,
      "epoch": 0.7877316857899382,
      "step": 17850
    },
    {
      "loss": 1.5062,
      "grad_norm": 25.0480899810791,
      "learning_rate": 4.760346067792505e-06,
      "epoch": 0.7899382171226832,
      "step": 17900
    },
    {
      "loss": 1.5193,
      "grad_norm": 27.57642364501953,
      "learning_rate": 4.757073947483605e-06,
      "epoch": 0.792144748455428,
      "step": 17950
    },
    {
      "loss": 1.621,
      "grad_norm": 31.534114837646484,
      "learning_rate": 4.7538018271747066e-06,
      "epoch": 0.794351279788173,
      "step": 18000
    },
    {
      "loss": 1.5907,
      "grad_norm": 29.738033294677734,
      "learning_rate": 4.750529706865807e-06,
      "epoch": 0.796557811120918,
      "step": 18050
    },
    {
      "loss": 1.5454,
      "grad_norm": 16.342201232910156,
      "learning_rate": 4.747257586556908e-06,
      "epoch": 0.7987643424536628,
      "step": 18100
    },
    {
      "loss": 1.585,
      "grad_norm": 6.377801895141602,
      "learning_rate": 4.743985466248009e-06,
      "epoch": 0.8009708737864077,
      "step": 18150
    },
    {
      "loss": 1.6124,
      "grad_norm": 17.389116287231445,
      "learning_rate": 4.7407133459391095e-06,
      "epoch": 0.8031774051191527,
      "step": 18200
    },
    {
      "loss": 1.654,
      "grad_norm": 26.435787200927734,
      "learning_rate": 4.737441225630211e-06,
      "epoch": 0.8053839364518977,
      "step": 18250
    },
    {
      "loss": 1.4999,
      "grad_norm": 19.05413246154785,
      "learning_rate": 4.734169105321311e-06,
      "epoch": 0.8075904677846425,
      "step": 18300
    },
    {
      "loss": 1.5821,
      "grad_norm": 20.99340057373047,
      "learning_rate": 4.730896985012413e-06,
      "epoch": 0.8097969991173875,
      "step": 18350
    },
    {
      "loss": 1.6421,
      "grad_norm": 30.78663444519043,
      "learning_rate": 4.727624864703513e-06,
      "epoch": 0.8120035304501324,
      "step": 18400
    },
    {
      "loss": 1.41,
      "grad_norm": 27.951717376708984,
      "learning_rate": 4.7243527443946146e-06,
      "epoch": 0.8142100617828774,
      "step": 18450
    },
    {
      "loss": 1.5582,
      "grad_norm": 25.635557174682617,
      "learning_rate": 4.721080624085715e-06,
      "epoch": 0.8164165931156222,
      "step": 18500
    },
    {
      "loss": 1.5783,
      "grad_norm": 28.41642189025879,
      "learning_rate": 4.7178085037768165e-06,
      "epoch": 0.8186231244483672,
      "step": 18550
    },
    {
      "loss": 1.3408,
      "grad_norm": 19.765636444091797,
      "learning_rate": 4.714536383467918e-06,
      "epoch": 0.8208296557811121,
      "step": 18600
    },
    {
      "loss": 1.5555,
      "grad_norm": 25.441768646240234,
      "learning_rate": 4.711264263159018e-06,
      "epoch": 0.8230361871138571,
      "step": 18650
    },
    {
      "loss": 1.5201,
      "grad_norm": 21.84955406188965,
      "learning_rate": 4.70799214285012e-06,
      "epoch": 0.8252427184466019,
      "step": 18700
    },
    {
      "loss": 1.5865,
      "grad_norm": 22.59982681274414,
      "learning_rate": 4.70472002254122e-06,
      "epoch": 0.8274492497793469,
      "step": 18750
    },
    {
      "loss": 1.6062,
      "grad_norm": 21.17105484008789,
      "learning_rate": 4.7014479022323216e-06,
      "epoch": 0.8296557811120918,
      "step": 18800
    },
    {
      "loss": 1.547,
      "grad_norm": 20.353500366210938,
      "learning_rate": 4.698175781923422e-06,
      "epoch": 0.8318623124448368,
      "step": 18850
    },
    {
      "loss": 1.5453,
      "grad_norm": 19.654329299926758,
      "learning_rate": 4.6949036616145234e-06,
      "epoch": 0.8340688437775816,
      "step": 18900
    },
    {
      "loss": 1.5478,
      "grad_norm": 18.926088333129883,
      "learning_rate": 4.691631541305625e-06,
      "epoch": 0.8362753751103266,
      "step": 18950
    },
    {
      "loss": 1.7004,
      "grad_norm": 18.591657638549805,
      "learning_rate": 4.688359420996725e-06,
      "epoch": 0.8384819064430715,
      "step": 19000
    },
    {
      "loss": 1.5811,
      "grad_norm": 20.38145637512207,
      "learning_rate": 4.685087300687827e-06,
      "epoch": 0.8406884377758164,
      "step": 19050
    },
    {
      "loss": 1.4571,
      "grad_norm": 21.27328109741211,
      "learning_rate": 4.681815180378927e-06,
      "epoch": 0.8428949691085613,
      "step": 19100
    },
    {
      "loss": 1.5205,
      "grad_norm": 28.137466430664062,
      "learning_rate": 4.6785430600700286e-06,
      "epoch": 0.8451015004413063,
      "step": 19150
    },
    {
      "loss": 1.4816,
      "grad_norm": 30.692636489868164,
      "learning_rate": 4.675270939761129e-06,
      "epoch": 0.8473080317740512,
      "step": 19200
    },
    {
      "loss": 1.6108,
      "grad_norm": 17.086593627929688,
      "learning_rate": 4.67199881945223e-06,
      "epoch": 0.8495145631067961,
      "step": 19250
    },
    {
      "loss": 1.623,
      "grad_norm": 24.7041072845459,
      "learning_rate": 4.668726699143331e-06,
      "epoch": 0.851721094439541,
      "step": 19300
    },
    {
      "loss": 1.5006,
      "grad_norm": 21.5611629486084,
      "learning_rate": 4.6654545788344315e-06,
      "epoch": 0.853927625772286,
      "step": 19350
    },
    {
      "loss": 1.4988,
      "grad_norm": 16.258760452270508,
      "learning_rate": 4.662182458525533e-06,
      "epoch": 0.8561341571050309,
      "step": 19400
    },
    {
      "loss": 1.5602,
      "grad_norm": 30.576942443847656,
      "learning_rate": 4.658910338216633e-06,
      "epoch": 0.8583406884377758,
      "step": 19450
    },
    {
      "loss": 1.3952,
      "grad_norm": 29.2199649810791,
      "learning_rate": 4.655638217907735e-06,
      "epoch": 0.8605472197705207,
      "step": 19500
    },
    {
      "loss": 1.5893,
      "grad_norm": 19.303754806518555,
      "learning_rate": 4.652366097598835e-06,
      "epoch": 0.8627537511032657,
      "step": 19550
    },
    {
      "loss": 1.5756,
      "grad_norm": 23.8349666595459,
      "learning_rate": 4.6490939772899366e-06,
      "epoch": 0.8649602824360106,
      "step": 19600
    },
    {
      "loss": 1.4645,
      "grad_norm": 24.869606018066406,
      "learning_rate": 4.645821856981037e-06,
      "epoch": 0.8671668137687555,
      "step": 19650
    },
    {
      "loss": 1.6332,
      "grad_norm": 21.16881561279297,
      "learning_rate": 4.6425497366721385e-06,
      "epoch": 0.8693733451015004,
      "step": 19700
    },
    {
      "loss": 1.5063,
      "grad_norm": 20.5465145111084,
      "learning_rate": 4.63927761636324e-06,
      "epoch": 0.8715798764342454,
      "step": 19750
    },
    {
      "loss": 1.5758,
      "grad_norm": 9.711764335632324,
      "learning_rate": 4.63600549605434e-06,
      "epoch": 0.8737864077669902,
      "step": 19800
    },
    {
      "loss": 1.5218,
      "grad_norm": 34.95069122314453,
      "learning_rate": 4.632733375745442e-06,
      "epoch": 0.8759929390997352,
      "step": 19850
    },
    {
      "loss": 1.4623,
      "grad_norm": 18.209489822387695,
      "learning_rate": 4.629461255436542e-06,
      "epoch": 0.8781994704324801,
      "step": 19900
    },
    {
      "loss": 1.4636,
      "grad_norm": 26.770414352416992,
      "learning_rate": 4.6261891351276436e-06,
      "epoch": 0.8804060017652251,
      "step": 19950
    },
    {
      "loss": 1.5068,
      "grad_norm": 17.81208038330078,
      "learning_rate": 4.622917014818744e-06,
      "epoch": 0.8826125330979699,
      "step": 20000
    },
    {
      "loss": 1.4401,
      "grad_norm": 37.98293685913086,
      "learning_rate": 4.6196448945098454e-06,
      "epoch": 0.8848190644307149,
      "step": 20050
    },
    {
      "loss": 1.5773,
      "grad_norm": 12.991283416748047,
      "learning_rate": 4.616372774200947e-06,
      "epoch": 0.8870255957634599,
      "step": 20100
    },
    {
      "loss": 1.4635,
      "grad_norm": 21.54649543762207,
      "learning_rate": 4.613100653892047e-06,
      "epoch": 0.8892321270962048,
      "step": 20150
    },
    {
      "loss": 1.4677,
      "grad_norm": 18.912694931030273,
      "learning_rate": 4.609828533583149e-06,
      "epoch": 0.8914386584289496,
      "step": 20200
    },
    {
      "loss": 1.486,
      "grad_norm": 28.650676727294922,
      "learning_rate": 4.606556413274249e-06,
      "epoch": 0.8936451897616946,
      "step": 20250
    },
    {
      "loss": 1.5678,
      "grad_norm": 26.189302444458008,
      "learning_rate": 4.6032842929653506e-06,
      "epoch": 0.8958517210944396,
      "step": 20300
    },
    {
      "loss": 1.6105,
      "grad_norm": 13.719429969787598,
      "learning_rate": 4.600012172656451e-06,
      "epoch": 0.8980582524271845,
      "step": 20350
    },
    {
      "loss": 1.5461,
      "grad_norm": 24.78067398071289,
      "learning_rate": 4.596740052347552e-06,
      "epoch": 0.9002647837599294,
      "step": 20400
    },
    {
      "loss": 1.6083,
      "grad_norm": 20.51581382751465,
      "learning_rate": 4.593467932038653e-06,
      "epoch": 0.9024713150926743,
      "step": 20450
    },
    {
      "loss": 1.4623,
      "grad_norm": 24.05550193786621,
      "learning_rate": 4.5901958117297535e-06,
      "epoch": 0.9046778464254193,
      "step": 20500
    },
    {
      "loss": 1.3874,
      "grad_norm": 35.278682708740234,
      "learning_rate": 4.586923691420855e-06,
      "epoch": 0.9068843777581642,
      "step": 20550
    },
    {
      "loss": 1.5733,
      "grad_norm": 12.303189277648926,
      "learning_rate": 4.583651571111955e-06,
      "epoch": 0.9090909090909091,
      "step": 20600
    },
    {
      "loss": 1.5264,
      "grad_norm": 17.223756790161133,
      "learning_rate": 4.580379450803057e-06,
      "epoch": 0.911297440423654,
      "step": 20650
    },
    {
      "loss": 1.3704,
      "grad_norm": 15.07812213897705,
      "learning_rate": 4.577107330494157e-06,
      "epoch": 0.913503971756399,
      "step": 20700
    },
    {
      "loss": 1.561,
      "grad_norm": 15.669853210449219,
      "learning_rate": 4.5738352101852586e-06,
      "epoch": 0.9157105030891438,
      "step": 20750
    },
    {
      "loss": 1.4826,
      "grad_norm": 16.5649471282959,
      "learning_rate": 4.57056308987636e-06,
      "epoch": 0.9179170344218888,
      "step": 20800
    },
    {
      "loss": 1.5095,
      "grad_norm": 33.949337005615234,
      "learning_rate": 4.5672909695674605e-06,
      "epoch": 0.9201235657546337,
      "step": 20850
    },
    {
      "loss": 1.4885,
      "grad_norm": 15.376331329345703,
      "learning_rate": 4.564018849258562e-06,
      "epoch": 0.9223300970873787,
      "step": 20900
    },
    {
      "loss": 1.4613,
      "grad_norm": 29.990596771240234,
      "learning_rate": 4.560746728949662e-06,
      "epoch": 0.9245366284201235,
      "step": 20950
    },
    {
      "loss": 1.5454,
      "grad_norm": 9.419761657714844,
      "learning_rate": 4.557474608640764e-06,
      "epoch": 0.9267431597528685,
      "step": 21000
    },
    {
      "loss": 1.5831,
      "grad_norm": 20.07868003845215,
      "learning_rate": 4.554202488331864e-06,
      "epoch": 0.9289496910856134,
      "step": 21050
    },
    {
      "loss": 1.4272,
      "grad_norm": 24.307811737060547,
      "learning_rate": 4.5509303680229656e-06,
      "epoch": 0.9311562224183584,
      "step": 21100
    },
    {
      "loss": 1.4493,
      "grad_norm": 15.328922271728516,
      "learning_rate": 4.547658247714067e-06,
      "epoch": 0.9333627537511032,
      "step": 21150
    },
    {
      "loss": 1.3849,
      "grad_norm": 30.41452980041504,
      "learning_rate": 4.5443861274051674e-06,
      "epoch": 0.9355692850838482,
      "step": 21200
    },
    {
      "loss": 1.4186,
      "grad_norm": 19.630226135253906,
      "learning_rate": 4.541114007096269e-06,
      "epoch": 0.9377758164165931,
      "step": 21250
    },
    {
      "loss": 1.4209,
      "grad_norm": 34.92921829223633,
      "learning_rate": 4.537841886787369e-06,
      "epoch": 0.9399823477493381,
      "step": 21300
    },
    {
      "loss": 1.5464,
      "grad_norm": 17.167577743530273,
      "learning_rate": 4.534569766478471e-06,
      "epoch": 0.9421888790820829,
      "step": 21350
    },
    {
      "loss": 1.4072,
      "grad_norm": 14.21320629119873,
      "learning_rate": 4.531297646169571e-06,
      "epoch": 0.9443954104148279,
      "step": 21400
    },
    {
      "loss": 1.5309,
      "grad_norm": 18.25126838684082,
      "learning_rate": 4.528025525860672e-06,
      "epoch": 0.9466019417475728,
      "step": 21450
    },
    {
      "loss": 1.4775,
      "grad_norm": 25.87411880493164,
      "learning_rate": 4.524753405551773e-06,
      "epoch": 0.9488084730803178,
      "step": 21500
    },
    {
      "loss": 1.3612,
      "grad_norm": 30.923301696777344,
      "learning_rate": 4.521481285242874e-06,
      "epoch": 0.9510150044130626,
      "step": 21550
    },
    {
      "loss": 1.3828,
      "grad_norm": 13.790889739990234,
      "learning_rate": 4.518209164933975e-06,
      "epoch": 0.9532215357458076,
      "step": 21600
    },
    {
      "loss": 1.4826,
      "grad_norm": 21.594310760498047,
      "learning_rate": 4.5149370446250755e-06,
      "epoch": 0.9554280670785525,
      "step": 21650
    },
    {
      "loss": 1.4732,
      "grad_norm": 20.3079891204834,
      "learning_rate": 4.511664924316177e-06,
      "epoch": 0.9576345984112974,
      "step": 21700
    },
    {
      "loss": 1.5229,
      "grad_norm": 19.694656372070312,
      "learning_rate": 4.508392804007277e-06,
      "epoch": 0.9598411297440423,
      "step": 21750
    },
    {
      "loss": 1.5305,
      "grad_norm": 17.533462524414062,
      "learning_rate": 4.505120683698379e-06,
      "epoch": 0.9620476610767873,
      "step": 21800
    },
    {
      "loss": 1.497,
      "grad_norm": 22.302112579345703,
      "learning_rate": 4.50184856338948e-06,
      "epoch": 0.9642541924095323,
      "step": 21850
    },
    {
      "loss": 1.2668,
      "grad_norm": 27.35120391845703,
      "learning_rate": 4.4985764430805806e-06,
      "epoch": 0.9664607237422771,
      "step": 21900
    },
    {
      "loss": 1.51,
      "grad_norm": 18.636560440063477,
      "learning_rate": 4.495304322771682e-06,
      "epoch": 0.968667255075022,
      "step": 21950
    },
    {
      "loss": 1.4676,
      "grad_norm": 22.769367218017578,
      "learning_rate": 4.4920322024627825e-06,
      "epoch": 0.970873786407767,
      "step": 22000
    },
    {
      "loss": 1.5425,
      "grad_norm": 17.50910186767578,
      "learning_rate": 4.488760082153884e-06,
      "epoch": 0.973080317740512,
      "step": 22050
    },
    {
      "loss": 1.428,
      "grad_norm": 25.59926986694336,
      "learning_rate": 4.485487961844984e-06,
      "epoch": 0.9752868490732568,
      "step": 22100
    },
    {
      "loss": 1.5352,
      "grad_norm": 30.767621994018555,
      "learning_rate": 4.482215841536086e-06,
      "epoch": 0.9774933804060018,
      "step": 22150
    },
    {
      "loss": 1.3969,
      "grad_norm": 35.00328063964844,
      "learning_rate": 4.478943721227186e-06,
      "epoch": 0.9796999117387467,
      "step": 22200
    },
    {
      "loss": 1.4762,
      "grad_norm": 16.579557418823242,
      "learning_rate": 4.4756716009182876e-06,
      "epoch": 0.9819064430714917,
      "step": 22250
    },
    {
      "loss": 1.521,
      "grad_norm": 20.55640411376953,
      "learning_rate": 4.472399480609389e-06,
      "epoch": 0.9841129744042365,
      "step": 22300
    },
    {
      "loss": 1.475,
      "grad_norm": 21.107913970947266,
      "learning_rate": 4.4691273603004894e-06,
      "epoch": 0.9863195057369815,
      "step": 22350
    },
    {
      "loss": 1.5224,
      "grad_norm": 24.93259048461914,
      "learning_rate": 4.465855239991591e-06,
      "epoch": 0.9885260370697264,
      "step": 22400
    },
    {
      "loss": 1.3494,
      "grad_norm": 20.734033584594727,
      "learning_rate": 4.462583119682691e-06,
      "epoch": 0.9907325684024714,
      "step": 22450
    },
    {
      "loss": 1.3525,
      "grad_norm": 26.265504837036133,
      "learning_rate": 4.459310999373793e-06,
      "epoch": 0.9929390997352162,
      "step": 22500
    },
    {
      "loss": 1.5361,
      "grad_norm": 16.2042293548584,
      "learning_rate": 4.456038879064893e-06,
      "epoch": 0.9951456310679612,
      "step": 22550
    },
    {
      "loss": 1.391,
      "grad_norm": 14.60287094116211,
      "learning_rate": 4.452766758755994e-06,
      "epoch": 0.9973521624007061,
      "step": 22600
    },
    {
      "loss": 1.4745,
      "grad_norm": 11.674302101135254,
      "learning_rate": 4.449494638447095e-06,
      "epoch": 0.999558693733451,
      "step": 22650
    },
    {
      "eval_loss": 1.2622065134191949,
      "eval_exact_match": 53.8298623367455,
      "eval_f1": 63.88806165294192,
      "eval_samples": 22720,
      "step": 22660
    },
    {
      "eval_loss": 1.2622065134191949,
      "eval_exact_match": 53.8298623367455,
      "eval_f1": 63.88806165294192,
      "eval_samples": 22720,
      "epoch": 1.0,
      "step": 22660
    },
    {
      "loss": 1.4492,
      "grad_norm": 16.201047897338867,
      "learning_rate": 4.446222518138196e-06,
      "epoch": 1.001765225066196,
      "step": 22700
    },
    {
      "loss": 1.4274,
      "grad_norm": 21.25445556640625,
      "learning_rate": 4.442950397829297e-06,
      "epoch": 1.0039717563989408,
      "step": 22750
    },
    {
      "loss": 1.4586,
      "grad_norm": 28.30666160583496,
      "learning_rate": 4.4396782775203975e-06,
      "epoch": 1.0061782877316858,
      "step": 22800
    },
    {
      "loss": 1.4431,
      "grad_norm": 21.031169891357422,
      "learning_rate": 4.436406157211499e-06,
      "epoch": 1.0083848190644307,
      "step": 22850
    },
    {
      "loss": 1.4517,
      "grad_norm": 28.790773391723633,
      "learning_rate": 4.433134036902599e-06,
      "epoch": 1.0105913503971757,
      "step": 22900
    },
    {
      "loss": 1.5439,
      "grad_norm": 14.383090019226074,
      "learning_rate": 4.429861916593701e-06,
      "epoch": 1.0127978817299206,
      "step": 22950
    },
    {
      "loss": 1.5002,
      "grad_norm": 31.986936569213867,
      "learning_rate": 4.426589796284802e-06,
      "epoch": 1.0150044130626654,
      "step": 23000
    },
    {
      "loss": 1.3544,
      "grad_norm": 7.8154215812683105,
      "learning_rate": 4.4233176759759026e-06,
      "epoch": 1.0172109443954105,
      "step": 23050
    },
    {
      "loss": 1.3914,
      "grad_norm": 27.06605339050293,
      "learning_rate": 4.420045555667004e-06,
      "epoch": 1.0194174757281553,
      "step": 23100
    },
    {
      "loss": 1.4723,
      "grad_norm": 22.412452697753906,
      "learning_rate": 4.4167734353581045e-06,
      "epoch": 1.0216240070609002,
      "step": 23150
    },
    {
      "loss": 1.4372,
      "grad_norm": 31.155662536621094,
      "learning_rate": 4.413501315049206e-06,
      "epoch": 1.0238305383936452,
      "step": 23200
    },
    {
      "loss": 1.4109,
      "grad_norm": 15.848639488220215,
      "learning_rate": 4.410229194740306e-06,
      "epoch": 1.02603706972639,
      "step": 23250
    },
    {
      "loss": 1.5436,
      "grad_norm": 21.680553436279297,
      "learning_rate": 4.406957074431408e-06,
      "epoch": 1.0282436010591351,
      "step": 23300
    },
    {
      "loss": 1.3093,
      "grad_norm": 22.83926773071289,
      "learning_rate": 4.403684954122509e-06,
      "epoch": 1.03045013239188,
      "step": 23350
    },
    {
      "loss": 1.472,
      "grad_norm": 21.77777862548828,
      "learning_rate": 4.4004128338136096e-06,
      "epoch": 1.0326566637246248,
      "step": 23400
    },
    {
      "loss": 1.4715,
      "grad_norm": 16.024574279785156,
      "learning_rate": 4.397140713504711e-06,
      "epoch": 1.03486319505737,
      "step": 23450
    },
    {
      "loss": 1.3391,
      "grad_norm": 9.082822799682617,
      "learning_rate": 4.3938685931958114e-06,
      "epoch": 1.0370697263901147,
      "step": 23500
    },
    {
      "loss": 1.5191,
      "grad_norm": 21.031450271606445,
      "learning_rate": 4.390596472886913e-06,
      "epoch": 1.0392762577228596,
      "step": 23550
    },
    {
      "loss": 1.3579,
      "grad_norm": 27.272809982299805,
      "learning_rate": 4.387324352578013e-06,
      "epoch": 1.0414827890556047,
      "step": 23600
    },
    {
      "loss": 1.3729,
      "grad_norm": 20.67935562133789,
      "learning_rate": 4.384052232269115e-06,
      "epoch": 1.0436893203883495,
      "step": 23650
    },
    {
      "loss": 1.3405,
      "grad_norm": 14.032135009765625,
      "learning_rate": 4.380780111960215e-06,
      "epoch": 1.0458958517210943,
      "step": 23700
    },
    {
      "loss": 1.3912,
      "grad_norm": 24.63427734375,
      "learning_rate": 4.377507991651316e-06,
      "epoch": 1.0481023830538394,
      "step": 23750
    },
    {
      "loss": 1.5035,
      "grad_norm": 24.5936222076416,
      "learning_rate": 4.374235871342417e-06,
      "epoch": 1.0503089143865842,
      "step": 23800
    },
    {
      "loss": 1.3873,
      "grad_norm": 26.58757209777832,
      "learning_rate": 4.370963751033518e-06,
      "epoch": 1.0525154457193293,
      "step": 23850
    },
    {
      "loss": 1.3483,
      "grad_norm": 19.15392303466797,
      "learning_rate": 4.367691630724619e-06,
      "epoch": 1.0547219770520742,
      "step": 23900
    },
    {
      "loss": 1.3947,
      "grad_norm": 21.351709365844727,
      "learning_rate": 4.3644195104157195e-06,
      "epoch": 1.056928508384819,
      "step": 23950
    },
    {
      "loss": 1.4422,
      "grad_norm": 20.610595703125,
      "learning_rate": 4.361147390106821e-06,
      "epoch": 1.059135039717564,
      "step": 24000
    },
    {
      "loss": 1.3872,
      "grad_norm": 21.66008949279785,
      "learning_rate": 4.357875269797922e-06,
      "epoch": 1.061341571050309,
      "step": 24050
    },
    {
      "loss": 1.374,
      "grad_norm": 9.766149520874023,
      "learning_rate": 4.354603149489023e-06,
      "epoch": 1.0635481023830538,
      "step": 24100
    },
    {
      "loss": 1.3365,
      "grad_norm": 26.237024307250977,
      "learning_rate": 4.351331029180124e-06,
      "epoch": 1.0657546337157988,
      "step": 24150
    },
    {
      "loss": 1.4595,
      "grad_norm": 15.23189640045166,
      "learning_rate": 4.3480589088712246e-06,
      "epoch": 1.0679611650485437,
      "step": 24200
    },
    {
      "loss": 1.4423,
      "grad_norm": 25.072996139526367,
      "learning_rate": 4.344786788562326e-06,
      "epoch": 1.0701676963812887,
      "step": 24250
    },
    {
      "loss": 1.304,
      "grad_norm": 28.80927276611328,
      "learning_rate": 4.3415146682534264e-06,
      "epoch": 1.0723742277140336,
      "step": 24300
    },
    {
      "loss": 1.4672,
      "grad_norm": 15.202470779418945,
      "learning_rate": 4.338242547944528e-06,
      "epoch": 1.0745807590467784,
      "step": 24350
    },
    {
      "loss": 1.4049,
      "grad_norm": 18.249187469482422,
      "learning_rate": 4.334970427635628e-06,
      "epoch": 1.0767872903795235,
      "step": 24400
    },
    {
      "loss": 1.4622,
      "grad_norm": 22.65648651123047,
      "learning_rate": 4.33169830732673e-06,
      "epoch": 1.0789938217122683,
      "step": 24450
    },
    {
      "loss": 1.3769,
      "grad_norm": 12.114228248596191,
      "learning_rate": 4.328426187017831e-06,
      "epoch": 1.0812003530450132,
      "step": 24500
    },
    {
      "loss": 1.5434,
      "grad_norm": 18.354427337646484,
      "learning_rate": 4.3251540667089316e-06,
      "epoch": 1.0834068843777582,
      "step": 24550
    },
    {
      "loss": 1.3251,
      "grad_norm": 1.8214442729949951,
      "learning_rate": 4.321881946400033e-06,
      "epoch": 1.085613415710503,
      "step": 24600
    },
    {
      "loss": 1.5558,
      "grad_norm": 28.558679580688477,
      "learning_rate": 4.3186098260911334e-06,
      "epoch": 1.087819947043248,
      "step": 24650
    },
    {
      "loss": 1.4441,
      "grad_norm": 21.376972198486328,
      "learning_rate": 4.315337705782235e-06,
      "epoch": 1.090026478375993,
      "step": 24700
    },
    {
      "loss": 1.3376,
      "grad_norm": 11.411849975585938,
      "learning_rate": 4.312065585473335e-06,
      "epoch": 1.0922330097087378,
      "step": 24750
    },
    {
      "loss": 1.3628,
      "grad_norm": 17.210859298706055,
      "learning_rate": 4.308793465164437e-06,
      "epoch": 1.0944395410414829,
      "step": 24800
    },
    {
      "loss": 1.4339,
      "grad_norm": 22.263845443725586,
      "learning_rate": 4.305521344855537e-06,
      "epoch": 1.0966460723742277,
      "step": 24850
    },
    {
      "loss": 1.5397,
      "grad_norm": 13.425599098205566,
      "learning_rate": 4.302249224546638e-06,
      "epoch": 1.0988526037069726,
      "step": 24900
    },
    {
      "loss": 1.4747,
      "grad_norm": 16.68035125732422,
      "learning_rate": 4.298977104237739e-06,
      "epoch": 1.1010591350397176,
      "step": 24950
    },
    {
      "loss": 1.4464,
      "grad_norm": 32.2862663269043,
      "learning_rate": 4.29570498392884e-06,
      "epoch": 1.1032656663724625,
      "step": 25000
    },
    {
      "loss": 1.3771,
      "grad_norm": 25.986902236938477,
      "learning_rate": 4.292432863619941e-06,
      "epoch": 1.1054721977052073,
      "step": 25050
    },
    {
      "loss": 1.3563,
      "grad_norm": 21.411314010620117,
      "learning_rate": 4.2891607433110415e-06,
      "epoch": 1.1076787290379524,
      "step": 25100
    },
    {
      "loss": 1.3529,
      "grad_norm": 26.538270950317383,
      "learning_rate": 4.285888623002143e-06,
      "epoch": 1.1098852603706972,
      "step": 25150
    },
    {
      "loss": 1.4669,
      "grad_norm": 15.536763191223145,
      "learning_rate": 4.282616502693244e-06,
      "epoch": 1.1120917917034423,
      "step": 25200
    },
    {
      "loss": 1.4883,
      "grad_norm": 26.613414764404297,
      "learning_rate": 4.279344382384345e-06,
      "epoch": 1.1142983230361871,
      "step": 25250
    },
    {
      "loss": 1.4039,
      "grad_norm": 21.35454559326172,
      "learning_rate": 4.276072262075446e-06,
      "epoch": 1.116504854368932,
      "step": 25300
    },
    {
      "loss": 1.4113,
      "grad_norm": 16.922449111938477,
      "learning_rate": 4.2728001417665466e-06,
      "epoch": 1.118711385701677,
      "step": 25350
    },
    {
      "loss": 1.3683,
      "grad_norm": 24.93329429626465,
      "learning_rate": 4.269528021457648e-06,
      "epoch": 1.120917917034422,
      "step": 25400
    },
    {
      "loss": 1.4303,
      "grad_norm": 17.70174789428711,
      "learning_rate": 4.2662559011487484e-06,
      "epoch": 1.1231244483671667,
      "step": 25450
    },
    {
      "loss": 1.5406,
      "grad_norm": 17.574283599853516,
      "learning_rate": 4.26298378083985e-06,
      "epoch": 1.1253309796999118,
      "step": 25500
    },
    {
      "loss": 1.5015,
      "grad_norm": 28.035511016845703,
      "learning_rate": 4.259711660530951e-06,
      "epoch": 1.1275375110326566,
      "step": 25550
    },
    {
      "loss": 1.4142,
      "grad_norm": 30.492204666137695,
      "learning_rate": 4.256439540222052e-06,
      "epoch": 1.1297440423654015,
      "step": 25600
    },
    {
      "loss": 1.4294,
      "grad_norm": 41.72080612182617,
      "learning_rate": 4.253167419913153e-06,
      "epoch": 1.1319505736981466,
      "step": 25650
    },
    {
      "loss": 1.4008,
      "grad_norm": 21.268394470214844,
      "learning_rate": 4.2498952996042536e-06,
      "epoch": 1.1341571050308914,
      "step": 25700
    },
    {
      "loss": 1.2864,
      "grad_norm": 26.402423858642578,
      "learning_rate": 4.246623179295355e-06,
      "epoch": 1.1363636363636362,
      "step": 25750
    },
    {
      "loss": 1.4106,
      "grad_norm": 12.533533096313477,
      "learning_rate": 4.2433510589864554e-06,
      "epoch": 1.1385701676963813,
      "step": 25800
    },
    {
      "loss": 1.4698,
      "grad_norm": 24.534452438354492,
      "learning_rate": 4.240078938677557e-06,
      "epoch": 1.1407766990291262,
      "step": 25850
    },
    {
      "loss": 1.3747,
      "grad_norm": 20.322999954223633,
      "learning_rate": 4.236806818368657e-06,
      "epoch": 1.1429832303618712,
      "step": 25900
    },
    {
      "loss": 1.4766,
      "grad_norm": 44.93467712402344,
      "learning_rate": 4.233534698059759e-06,
      "epoch": 1.145189761694616,
      "step": 25950
    },
    {
      "loss": 1.338,
      "grad_norm": 10.866883277893066,
      "learning_rate": 4.230262577750859e-06,
      "epoch": 1.147396293027361,
      "step": 26000
    },
    {
      "loss": 1.3005,
      "grad_norm": 10.031245231628418,
      "learning_rate": 4.22699045744196e-06,
      "epoch": 1.149602824360106,
      "step": 26050
    },
    {
      "loss": 1.6172,
      "grad_norm": 23.475080490112305,
      "learning_rate": 4.223718337133061e-06,
      "epoch": 1.1518093556928508,
      "step": 26100
    },
    {
      "loss": 1.3738,
      "grad_norm": 28.559814453125,
      "learning_rate": 4.220446216824162e-06,
      "epoch": 1.1540158870255959,
      "step": 26150
    },
    {
      "loss": 1.484,
      "grad_norm": 22.02140998840332,
      "learning_rate": 4.217174096515263e-06,
      "epoch": 1.1562224183583407,
      "step": 26200
    },
    {
      "loss": 1.4327,
      "grad_norm": 22.36731719970703,
      "learning_rate": 4.213901976206364e-06,
      "epoch": 1.1584289496910856,
      "step": 26250
    },
    {
      "loss": 1.4603,
      "grad_norm": 24.545516967773438,
      "learning_rate": 4.210629855897465e-06,
      "epoch": 1.1606354810238306,
      "step": 26300
    },
    {
      "loss": 1.3985,
      "grad_norm": 20.342824935913086,
      "learning_rate": 4.207357735588566e-06,
      "epoch": 1.1628420123565755,
      "step": 26350
    },
    {
      "loss": 1.4125,
      "grad_norm": 16.2406063079834,
      "learning_rate": 4.204085615279667e-06,
      "epoch": 1.1650485436893203,
      "step": 26400
    },
    {
      "loss": 1.3908,
      "grad_norm": 23.338577270507812,
      "learning_rate": 4.200813494970768e-06,
      "epoch": 1.1672550750220654,
      "step": 26450
    },
    {
      "loss": 1.4325,
      "grad_norm": 20.64753532409668,
      "learning_rate": 4.1975413746618686e-06,
      "epoch": 1.1694616063548102,
      "step": 26500
    },
    {
      "loss": 1.3218,
      "grad_norm": 21.713272094726562,
      "learning_rate": 4.19426925435297e-06,
      "epoch": 1.171668137687555,
      "step": 26550
    },
    {
      "loss": 1.4161,
      "grad_norm": 18.7224063873291,
      "learning_rate": 4.1909971340440704e-06,
      "epoch": 1.1738746690203001,
      "step": 26600
    },
    {
      "loss": 1.4233,
      "grad_norm": 29.909420013427734,
      "learning_rate": 4.187725013735172e-06,
      "epoch": 1.176081200353045,
      "step": 26650
    },
    {
      "loss": 1.2765,
      "grad_norm": 18.70299530029297,
      "learning_rate": 4.184452893426273e-06,
      "epoch": 1.1782877316857898,
      "step": 26700
    },
    {
      "loss": 1.3954,
      "grad_norm": 60.497947692871094,
      "learning_rate": 4.181180773117374e-06,
      "epoch": 1.1804942630185349,
      "step": 26750
    },
    {
      "loss": 1.3777,
      "grad_norm": 22.578813552856445,
      "learning_rate": 4.177908652808475e-06,
      "epoch": 1.1827007943512797,
      "step": 26800
    },
    {
      "loss": 1.2607,
      "grad_norm": 29.114952087402344,
      "learning_rate": 4.1746365324995756e-06,
      "epoch": 1.1849073256840248,
      "step": 26850
    },
    {
      "loss": 1.3753,
      "grad_norm": 27.22344970703125,
      "learning_rate": 4.171364412190677e-06,
      "epoch": 1.1871138570167696,
      "step": 26900
    },
    {
      "loss": 1.3215,
      "grad_norm": 15.535439491271973,
      "learning_rate": 4.1680922918817774e-06,
      "epoch": 1.1893203883495145,
      "step": 26950
    },
    {
      "loss": 1.557,
      "grad_norm": 14.820600509643555,
      "learning_rate": 4.164820171572879e-06,
      "epoch": 1.1915269196822595,
      "step": 27000
    },
    {
      "loss": 1.376,
      "grad_norm": 30.44509506225586,
      "learning_rate": 4.161548051263979e-06,
      "epoch": 1.1937334510150044,
      "step": 27050
    },
    {
      "loss": 1.4096,
      "grad_norm": 18.514568328857422,
      "learning_rate": 4.158275930955081e-06,
      "epoch": 1.1959399823477495,
      "step": 27100
    },
    {
      "loss": 1.2772,
      "grad_norm": 24.638742446899414,
      "learning_rate": 4.155003810646181e-06,
      "epoch": 1.1981465136804943,
      "step": 27150
    },
    {
      "loss": 1.292,
      "grad_norm": 22.77286720275879,
      "learning_rate": 4.151731690337282e-06,
      "epoch": 1.2003530450132391,
      "step": 27200
    },
    {
      "loss": 1.5497,
      "grad_norm": 19.305723190307617,
      "learning_rate": 4.148459570028383e-06,
      "epoch": 1.2025595763459842,
      "step": 27250
    },
    {
      "loss": 1.4929,
      "grad_norm": 19.189443588256836,
      "learning_rate": 4.145187449719484e-06,
      "epoch": 1.204766107678729,
      "step": 27300
    },
    {
      "loss": 1.2863,
      "grad_norm": 30.455642700195312,
      "learning_rate": 4.141915329410585e-06,
      "epoch": 1.206972639011474,
      "step": 27350
    },
    {
      "loss": 1.3928,
      "grad_norm": 37.03040313720703,
      "learning_rate": 4.138643209101686e-06,
      "epoch": 1.209179170344219,
      "step": 27400
    },
    {
      "loss": 1.4208,
      "grad_norm": 20.611257553100586,
      "learning_rate": 4.135371088792787e-06,
      "epoch": 1.2113857016769638,
      "step": 27450
    },
    {
      "loss": 1.5305,
      "grad_norm": 26.235334396362305,
      "learning_rate": 4.132098968483888e-06,
      "epoch": 1.2135922330097086,
      "step": 27500
    },
    {
      "loss": 1.4108,
      "grad_norm": 15.27243423461914,
      "learning_rate": 4.128826848174989e-06,
      "epoch": 1.2157987643424537,
      "step": 27550
    },
    {
      "loss": 1.3708,
      "grad_norm": 27.887697219848633,
      "learning_rate": 4.12555472786609e-06,
      "epoch": 1.2180052956751986,
      "step": 27600
    },
    {
      "loss": 1.2682,
      "grad_norm": 19.446882247924805,
      "learning_rate": 4.1222826075571906e-06,
      "epoch": 1.2202118270079434,
      "step": 27650
    },
    {
      "loss": 1.3922,
      "grad_norm": 25.681541442871094,
      "learning_rate": 4.119010487248292e-06,
      "epoch": 1.2224183583406885,
      "step": 27700
    },
    {
      "loss": 1.2975,
      "grad_norm": 15.536162376403809,
      "learning_rate": 4.115738366939393e-06,
      "epoch": 1.2246248896734333,
      "step": 27750
    },
    {
      "loss": 1.4513,
      "grad_norm": 25.890335083007812,
      "learning_rate": 4.112466246630494e-06,
      "epoch": 1.2268314210061784,
      "step": 27800
    },
    {
      "loss": 1.3296,
      "grad_norm": 17.896562576293945,
      "learning_rate": 4.109194126321595e-06,
      "epoch": 1.2290379523389232,
      "step": 27850
    },
    {
      "loss": 1.4017,
      "grad_norm": 35.09124755859375,
      "learning_rate": 4.105922006012696e-06,
      "epoch": 1.231244483671668,
      "step": 27900
    },
    {
      "loss": 1.3514,
      "grad_norm": 15.83703899383545,
      "learning_rate": 4.102649885703797e-06,
      "epoch": 1.2334510150044131,
      "step": 27950
    },
    {
      "loss": 1.3851,
      "grad_norm": 60.02134704589844,
      "learning_rate": 4.0993777653948976e-06,
      "epoch": 1.235657546337158,
      "step": 28000
    },
    {
      "loss": 1.404,
      "grad_norm": 27.267662048339844,
      "learning_rate": 4.096105645085999e-06,
      "epoch": 1.237864077669903,
      "step": 28050
    },
    {
      "loss": 1.5071,
      "grad_norm": 16.17198944091797,
      "learning_rate": 4.0928335247770994e-06,
      "epoch": 1.2400706090026479,
      "step": 28100
    },
    {
      "loss": 1.1898,
      "grad_norm": 18.558246612548828,
      "learning_rate": 4.089561404468201e-06,
      "epoch": 1.2422771403353927,
      "step": 28150
    },
    {
      "loss": 1.289,
      "grad_norm": 13.90682315826416,
      "learning_rate": 4.086289284159301e-06,
      "epoch": 1.2444836716681378,
      "step": 28200
    },
    {
      "loss": 1.4798,
      "grad_norm": 33.27017593383789,
      "learning_rate": 4.083017163850402e-06,
      "epoch": 1.2466902030008826,
      "step": 28250
    },
    {
      "loss": 1.4551,
      "grad_norm": 26.653018951416016,
      "learning_rate": 4.079745043541503e-06,
      "epoch": 1.2488967343336275,
      "step": 28300
    },
    {
      "loss": 1.409,
      "grad_norm": 31.191919326782227,
      "learning_rate": 4.076472923232604e-06,
      "epoch": 1.2511032656663725,
      "step": 28350
    },
    {
      "loss": 1.3278,
      "grad_norm": 17.357656478881836,
      "learning_rate": 4.073200802923705e-06,
      "epoch": 1.2533097969991174,
      "step": 28400
    },
    {
      "loss": 1.3309,
      "grad_norm": 20.419160842895508,
      "learning_rate": 4.0699286826148064e-06,
      "epoch": 1.2555163283318622,
      "step": 28450
    },
    {
      "loss": 1.4763,
      "grad_norm": 19.577224731445312,
      "learning_rate": 4.066656562305907e-06,
      "epoch": 1.2577228596646073,
      "step": 28500
    },
    {
      "loss": 1.4102,
      "grad_norm": 20.72106170654297,
      "learning_rate": 4.063384441997008e-06,
      "epoch": 1.2599293909973521,
      "step": 28550
    },
    {
      "loss": 1.3742,
      "grad_norm": 15.179304122924805,
      "learning_rate": 4.060112321688109e-06,
      "epoch": 1.262135922330097,
      "step": 28600
    },
    {
      "loss": 1.3223,
      "grad_norm": 15.763845443725586,
      "learning_rate": 4.05684020137921e-06,
      "epoch": 1.264342453662842,
      "step": 28650
    },
    {
      "loss": 1.3608,
      "grad_norm": 41.928707122802734,
      "learning_rate": 4.053568081070311e-06,
      "epoch": 1.2665489849955869,
      "step": 28700
    },
    {
      "loss": 1.3363,
      "grad_norm": 25.833295822143555,
      "learning_rate": 4.050295960761412e-06,
      "epoch": 1.268755516328332,
      "step": 28750
    },
    {
      "loss": 1.222,
      "grad_norm": 21.179887771606445,
      "learning_rate": 4.0470238404525126e-06,
      "epoch": 1.2709620476610768,
      "step": 28800
    },
    {
      "loss": 1.3856,
      "grad_norm": 19.87717628479004,
      "learning_rate": 4.043751720143614e-06,
      "epoch": 1.2731685789938216,
      "step": 28850
    },
    {
      "loss": 1.3629,
      "grad_norm": 21.602293014526367,
      "learning_rate": 4.040479599834715e-06,
      "epoch": 1.2753751103265667,
      "step": 28900
    },
    {
      "loss": 1.3267,
      "grad_norm": 20.539520263671875,
      "learning_rate": 4.037207479525816e-06,
      "epoch": 1.2775816416593115,
      "step": 28950
    },
    {
      "loss": 1.3516,
      "grad_norm": 30.622575759887695,
      "learning_rate": 4.033935359216917e-06,
      "epoch": 1.2797881729920566,
      "step": 29000
    },
    {
      "loss": 1.4335,
      "grad_norm": 16.478246688842773,
      "learning_rate": 4.030663238908018e-06,
      "epoch": 1.2819947043248014,
      "step": 29050
    },
    {
      "loss": 1.4228,
      "grad_norm": 21.80516242980957,
      "learning_rate": 4.027391118599119e-06,
      "epoch": 1.2842012356575463,
      "step": 29100
    },
    {
      "loss": 1.4413,
      "grad_norm": 20.29803466796875,
      "learning_rate": 4.0241189982902196e-06,
      "epoch": 1.2864077669902914,
      "step": 29150
    },
    {
      "loss": 1.5245,
      "grad_norm": 17.639087677001953,
      "learning_rate": 4.020846877981321e-06,
      "epoch": 1.2886142983230362,
      "step": 29200
    },
    {
      "loss": 1.3148,
      "grad_norm": 17.723037719726562,
      "learning_rate": 4.0175747576724214e-06,
      "epoch": 1.290820829655781,
      "step": 29250
    },
    {
      "loss": 1.2974,
      "grad_norm": 19.28066635131836,
      "learning_rate": 4.014302637363523e-06,
      "epoch": 1.293027360988526,
      "step": 29300
    },
    {
      "loss": 1.3835,
      "grad_norm": 27.18601417541504,
      "learning_rate": 4.011030517054623e-06,
      "epoch": 1.295233892321271,
      "step": 29350
    },
    {
      "loss": 1.3642,
      "grad_norm": 21.384803771972656,
      "learning_rate": 4.007758396745724e-06,
      "epoch": 1.2974404236540158,
      "step": 29400
    },
    {
      "loss": 1.341,
      "grad_norm": 18.355844497680664,
      "learning_rate": 4.004486276436825e-06,
      "epoch": 1.2996469549867609,
      "step": 29450
    },
    {
      "loss": 1.4421,
      "grad_norm": 17.818445205688477,
      "learning_rate": 4.001214156127926e-06,
      "epoch": 1.3018534863195057,
      "step": 29500
    },
    {
      "loss": 1.4604,
      "grad_norm": 21.812122344970703,
      "learning_rate": 3.997942035819027e-06,
      "epoch": 1.3040600176522505,
      "step": 29550
    },
    {
      "loss": 1.2956,
      "grad_norm": 15.654036521911621,
      "learning_rate": 3.9946699155101284e-06,
      "epoch": 1.3062665489849956,
      "step": 29600
    },
    {
      "loss": 1.2994,
      "grad_norm": 31.408275604248047,
      "learning_rate": 3.991397795201229e-06,
      "epoch": 1.3084730803177405,
      "step": 29650
    },
    {
      "loss": 1.4514,
      "grad_norm": 19.368642807006836,
      "learning_rate": 3.98812567489233e-06,
      "epoch": 1.3106796116504853,
      "step": 29700
    },
    {
      "loss": 1.2984,
      "grad_norm": 32.94569778442383,
      "learning_rate": 3.984853554583431e-06,
      "epoch": 1.3128861429832304,
      "step": 29750
    },
    {
      "loss": 1.3125,
      "grad_norm": 12.867264747619629,
      "learning_rate": 3.981581434274532e-06,
      "epoch": 1.3150926743159752,
      "step": 29800
    },
    {
      "loss": 1.3532,
      "grad_norm": 25.308061599731445,
      "learning_rate": 3.978309313965633e-06,
      "epoch": 1.3172992056487203,
      "step": 29850
    },
    {
      "loss": 1.305,
      "grad_norm": 22.413257598876953,
      "learning_rate": 3.975037193656734e-06,
      "epoch": 1.3195057369814651,
      "step": 29900
    },
    {
      "loss": 1.4996,
      "grad_norm": 19.626798629760742,
      "learning_rate": 3.971765073347835e-06,
      "epoch": 1.3217122683142102,
      "step": 29950
    },
    {
      "loss": 1.2876,
      "grad_norm": 25.603073120117188,
      "learning_rate": 3.968492953038936e-06,
      "epoch": 1.323918799646955,
      "step": 30000
    },
    {
      "loss": 1.2234,
      "grad_norm": 13.03966999053955,
      "learning_rate": 3.965220832730037e-06,
      "epoch": 1.3261253309796999,
      "step": 30050
    },
    {
      "loss": 1.3748,
      "grad_norm": 16.984058380126953,
      "learning_rate": 3.961948712421138e-06,
      "epoch": 1.328331862312445,
      "step": 30100
    },
    {
      "loss": 1.336,
      "grad_norm": 33.59394836425781,
      "learning_rate": 3.958676592112239e-06,
      "epoch": 1.3305383936451898,
      "step": 30150
    },
    {
      "loss": 1.2755,
      "grad_norm": 19.593276977539062,
      "learning_rate": 3.95540447180334e-06,
      "epoch": 1.3327449249779346,
      "step": 30200
    },
    {
      "loss": 1.279,
      "grad_norm": 15.559518814086914,
      "learning_rate": 3.952132351494441e-06,
      "epoch": 1.3349514563106797,
      "step": 30250
    },
    {
      "loss": 1.3458,
      "grad_norm": 25.144718170166016,
      "learning_rate": 3.948860231185542e-06,
      "epoch": 1.3371579876434245,
      "step": 30300
    },
    {
      "loss": 1.2389,
      "grad_norm": 23.297677993774414,
      "learning_rate": 3.945588110876643e-06,
      "epoch": 1.3393645189761694,
      "step": 30350
    },
    {
      "loss": 1.4353,
      "grad_norm": 24.629993438720703,
      "learning_rate": 3.9423159905677434e-06,
      "epoch": 1.3415710503089144,
      "step": 30400
    },
    {
      "loss": 1.3599,
      "grad_norm": 14.730428695678711,
      "learning_rate": 3.939043870258845e-06,
      "epoch": 1.3437775816416593,
      "step": 30450
    },
    {
      "loss": 1.3397,
      "grad_norm": 22.864797592163086,
      "learning_rate": 3.935771749949945e-06,
      "epoch": 1.3459841129744041,
      "step": 30500
    },
    {
      "loss": 1.3858,
      "grad_norm": 15.207995414733887,
      "learning_rate": 3.932499629641046e-06,
      "epoch": 1.3481906443071492,
      "step": 30550
    },
    {
      "loss": 1.3685,
      "grad_norm": 28.657102584838867,
      "learning_rate": 3.929227509332147e-06,
      "epoch": 1.350397175639894,
      "step": 30600
    },
    {
      "loss": 1.3791,
      "grad_norm": 19.119882583618164,
      "learning_rate": 3.9259553890232486e-06,
      "epoch": 1.3526037069726389,
      "step": 30650
    },
    {
      "loss": 1.3148,
      "grad_norm": 16.11676025390625,
      "learning_rate": 3.922683268714349e-06,
      "epoch": 1.354810238305384,
      "step": 30700
    },
    {
      "loss": 1.233,
      "grad_norm": 27.533105850219727,
      "learning_rate": 3.9194111484054504e-06,
      "epoch": 1.3570167696381288,
      "step": 30750
    },
    {
      "loss": 1.3918,
      "grad_norm": 20.880136489868164,
      "learning_rate": 3.916139028096551e-06,
      "epoch": 1.3592233009708738,
      "step": 30800
    },
    {
      "loss": 1.4063,
      "grad_norm": 10.971713066101074,
      "learning_rate": 3.912866907787652e-06,
      "epoch": 1.3614298323036187,
      "step": 30850
    },
    {
      "loss": 1.2876,
      "grad_norm": 16.150808334350586,
      "learning_rate": 3.909594787478753e-06,
      "epoch": 1.3636363636363638,
      "step": 30900
    },
    {
      "loss": 1.3066,
      "grad_norm": 21.296306610107422,
      "learning_rate": 3.906322667169854e-06,
      "epoch": 1.3658428949691086,
      "step": 30950
    },
    {
      "loss": 1.3273,
      "grad_norm": 26.677181243896484,
      "learning_rate": 3.9030505468609555e-06,
      "epoch": 1.3680494263018534,
      "step": 31000
    },
    {
      "loss": 1.2269,
      "grad_norm": 26.066612243652344,
      "learning_rate": 3.899778426552056e-06,
      "epoch": 1.3702559576345985,
      "step": 31050
    },
    {
      "loss": 1.2523,
      "grad_norm": 21.894014358520508,
      "learning_rate": 3.896506306243157e-06,
      "epoch": 1.3724624889673434,
      "step": 31100
    },
    {
      "loss": 1.3471,
      "grad_norm": 11.913310050964355,
      "learning_rate": 3.893234185934258e-06,
      "epoch": 1.3746690203000882,
      "step": 31150
    },
    {
      "loss": 1.2917,
      "grad_norm": 19.47330665588379,
      "learning_rate": 3.889962065625359e-06,
      "epoch": 1.3768755516328333,
      "step": 31200
    },
    {
      "loss": 1.3072,
      "grad_norm": 27.424545288085938,
      "learning_rate": 3.88668994531646e-06,
      "epoch": 1.379082082965578,
      "step": 31250
    },
    {
      "loss": 1.5079,
      "grad_norm": 25.54329490661621,
      "learning_rate": 3.883417825007561e-06,
      "epoch": 1.381288614298323,
      "step": 31300
    },
    {
      "loss": 1.3383,
      "grad_norm": 19.255908966064453,
      "learning_rate": 3.880145704698662e-06,
      "epoch": 1.383495145631068,
      "step": 31350
    },
    {
      "loss": 1.3924,
      "grad_norm": 26.661991119384766,
      "learning_rate": 3.876873584389763e-06,
      "epoch": 1.3857016769638129,
      "step": 31400
    },
    {
      "loss": 1.3515,
      "grad_norm": 21.88423728942871,
      "learning_rate": 3.8736014640808636e-06,
      "epoch": 1.3879082082965577,
      "step": 31450
    },
    {
      "loss": 1.3527,
      "grad_norm": 22.043678283691406,
      "learning_rate": 3.870329343771965e-06,
      "epoch": 1.3901147396293028,
      "step": 31500
    },
    {
      "loss": 1.3452,
      "grad_norm": 26.426950454711914,
      "learning_rate": 3.8670572234630654e-06,
      "epoch": 1.3923212709620476,
      "step": 31550
    },
    {
      "loss": 1.2524,
      "grad_norm": 14.38165283203125,
      "learning_rate": 3.863785103154167e-06,
      "epoch": 1.3945278022947925,
      "step": 31600
    },
    {
      "loss": 1.3929,
      "grad_norm": 24.7807559967041,
      "learning_rate": 3.860512982845267e-06,
      "epoch": 1.3967343336275375,
      "step": 31650
    },
    {
      "loss": 1.3829,
      "grad_norm": 23.48749542236328,
      "learning_rate": 3.857240862536368e-06,
      "epoch": 1.3989408649602824,
      "step": 31700
    },
    {
      "loss": 1.389,
      "grad_norm": 30.572229385375977,
      "learning_rate": 3.853968742227469e-06,
      "epoch": 1.4011473962930274,
      "step": 31750
    },
    {
      "loss": 1.4432,
      "grad_norm": 17.55294418334961,
      "learning_rate": 3.8506966219185706e-06,
      "epoch": 1.4033539276257723,
      "step": 31800
    },
    {
      "loss": 1.3667,
      "grad_norm": 23.641218185424805,
      "learning_rate": 3.847424501609671e-06,
      "epoch": 1.4055604589585173,
      "step": 31850
    },
    {
      "loss": 1.3477,
      "grad_norm": 21.67448616027832,
      "learning_rate": 3.8441523813007724e-06,
      "epoch": 1.4077669902912622,
      "step": 31900
    },
    {
      "loss": 1.3975,
      "grad_norm": 27.994516372680664,
      "learning_rate": 3.840880260991873e-06,
      "epoch": 1.409973521624007,
      "step": 31950
    },
    {
      "loss": 1.3936,
      "grad_norm": 16.559335708618164,
      "learning_rate": 3.837608140682974e-06,
      "epoch": 1.412180052956752,
      "step": 32000
    },
    {
      "loss": 1.3511,
      "grad_norm": 10.808372497558594,
      "learning_rate": 3.834336020374075e-06,
      "epoch": 1.414386584289497,
      "step": 32050
    },
    {
      "loss": 1.3789,
      "grad_norm": 11.382528305053711,
      "learning_rate": 3.831063900065176e-06,
      "epoch": 1.4165931156222418,
      "step": 32100
    },
    {
      "loss": 1.2714,
      "grad_norm": 26.287242889404297,
      "learning_rate": 3.8277917797562775e-06,
      "epoch": 1.4187996469549868,
      "step": 32150
    },
    {
      "loss": 1.3721,
      "grad_norm": 18.888010025024414,
      "learning_rate": 3.824519659447378e-06,
      "epoch": 1.4210061782877317,
      "step": 32200
    },
    {
      "loss": 1.3758,
      "grad_norm": 30.140972137451172,
      "learning_rate": 3.821247539138479e-06,
      "epoch": 1.4232127096204765,
      "step": 32250
    },
    {
      "loss": 1.419,
      "grad_norm": 30.336448669433594,
      "learning_rate": 3.81797541882958e-06,
      "epoch": 1.4254192409532216,
      "step": 32300
    },
    {
      "loss": 1.3901,
      "grad_norm": 18.36545753479004,
      "learning_rate": 3.814703298520681e-06,
      "epoch": 1.4276257722859664,
      "step": 32350
    },
    {
      "loss": 1.3392,
      "grad_norm": 27.296863555908203,
      "learning_rate": 3.811431178211782e-06,
      "epoch": 1.4298323036187113,
      "step": 32400
    },
    {
      "loss": 1.4549,
      "grad_norm": 8.456241607666016,
      "learning_rate": 3.8081590579028827e-06,
      "epoch": 1.4320388349514563,
      "step": 32450
    },
    {
      "loss": 1.3407,
      "grad_norm": 19.04498291015625,
      "learning_rate": 3.804886937593984e-06,
      "epoch": 1.4342453662842012,
      "step": 32500
    },
    {
      "loss": 1.2012,
      "grad_norm": 16.10472869873047,
      "learning_rate": 3.8016148172850846e-06,
      "epoch": 1.436451897616946,
      "step": 32550
    },
    {
      "loss": 1.3177,
      "grad_norm": 22.556777954101562,
      "learning_rate": 3.798342696976186e-06,
      "epoch": 1.438658428949691,
      "step": 32600
    },
    {
      "loss": 1.3365,
      "grad_norm": 25.65643310546875,
      "learning_rate": 3.7950705766672865e-06,
      "epoch": 1.440864960282436,
      "step": 32650
    },
    {
      "loss": 1.3769,
      "grad_norm": 26.668054580688477,
      "learning_rate": 3.791798456358388e-06,
      "epoch": 1.443071491615181,
      "step": 32700
    },
    {
      "loss": 1.3155,
      "grad_norm": 21.32025146484375,
      "learning_rate": 3.7885263360494884e-06,
      "epoch": 1.4452780229479258,
      "step": 32750
    },
    {
      "loss": 1.3819,
      "grad_norm": 31.5184383392334,
      "learning_rate": 3.7852542157405897e-06,
      "epoch": 1.447484554280671,
      "step": 32800
    },
    {
      "loss": 1.3016,
      "grad_norm": 32.53925323486328,
      "learning_rate": 3.7819820954316907e-06,
      "epoch": 1.4496910856134158,
      "step": 32850
    },
    {
      "loss": 1.2808,
      "grad_norm": 19.459928512573242,
      "learning_rate": 3.7787099751227916e-06,
      "epoch": 1.4518976169461606,
      "step": 32900
    },
    {
      "loss": 1.5203,
      "grad_norm": 18.734310150146484,
      "learning_rate": 3.7754378548138926e-06,
      "epoch": 1.4541041482789057,
      "step": 32950
    },
    {
      "loss": 1.4263,
      "grad_norm": 26.689388275146484,
      "learning_rate": 3.772165734504993e-06,
      "epoch": 1.4563106796116505,
      "step": 33000
    },
    {
      "loss": 1.3302,
      "grad_norm": 22.362380981445312,
      "learning_rate": 3.7688936141960944e-06,
      "epoch": 1.4585172109443953,
      "step": 33050
    },
    {
      "loss": 1.4109,
      "grad_norm": 27.021554946899414,
      "learning_rate": 3.765621493887195e-06,
      "epoch": 1.4607237422771404,
      "step": 33100
    },
    {
      "loss": 1.3228,
      "grad_norm": 20.448755264282227,
      "learning_rate": 3.7623493735782963e-06,
      "epoch": 1.4629302736098853,
      "step": 33150
    },
    {
      "loss": 1.3515,
      "grad_norm": 12.661932945251465,
      "learning_rate": 3.7590772532693977e-06,
      "epoch": 1.46513680494263,
      "step": 33200
    },
    {
      "loss": 1.3562,
      "grad_norm": 22.948392868041992,
      "learning_rate": 3.755805132960498e-06,
      "epoch": 1.4673433362753752,
      "step": 33250
    },
    {
      "loss": 1.3553,
      "grad_norm": 15.392362594604492,
      "learning_rate": 3.7525330126515995e-06,
      "epoch": 1.46954986760812,
      "step": 33300
    },
    {
      "loss": 1.3243,
      "grad_norm": 29.11105728149414,
      "learning_rate": 3.7492608923427e-06,
      "epoch": 1.4717563989408649,
      "step": 33350
    },
    {
      "loss": 1.3597,
      "grad_norm": 26.665897369384766,
      "learning_rate": 3.7459887720338014e-06,
      "epoch": 1.47396293027361,
      "step": 33400
    },
    {
      "loss": 1.3705,
      "grad_norm": 19.631011962890625,
      "learning_rate": 3.742716651724902e-06,
      "epoch": 1.4761694616063548,
      "step": 33450
    },
    {
      "loss": 1.2874,
      "grad_norm": 28.179468154907227,
      "learning_rate": 3.739444531416003e-06,
      "epoch": 1.4783759929390996,
      "step": 33500
    },
    {
      "loss": 1.4157,
      "grad_norm": 23.419954299926758,
      "learning_rate": 3.736172411107104e-06,
      "epoch": 1.4805825242718447,
      "step": 33550
    },
    {
      "loss": 1.3783,
      "grad_norm": 22.466318130493164,
      "learning_rate": 3.7329002907982047e-06,
      "epoch": 1.4827890556045895,
      "step": 33600
    },
    {
      "loss": 1.4031,
      "grad_norm": 14.805731773376465,
      "learning_rate": 3.729628170489306e-06,
      "epoch": 1.4849955869373346,
      "step": 33650
    },
    {
      "loss": 1.2569,
      "grad_norm": 217.2013702392578,
      "learning_rate": 3.7263560501804066e-06,
      "epoch": 1.4872021182700794,
      "step": 33700
    },
    {
      "loss": 1.3668,
      "grad_norm": 24.373449325561523,
      "learning_rate": 3.723083929871508e-06,
      "epoch": 1.4894086496028245,
      "step": 33750
    },
    {
      "loss": 1.3288,
      "grad_norm": 25.9580078125,
      "learning_rate": 3.7198118095626085e-06,
      "epoch": 1.4916151809355693,
      "step": 33800
    },
    {
      "loss": 1.3388,
      "grad_norm": 12.517720222473145,
      "learning_rate": 3.71653968925371e-06,
      "epoch": 1.4938217122683142,
      "step": 33850
    },
    {
      "loss": 1.4067,
      "grad_norm": 10.972637176513672,
      "learning_rate": 3.7132675689448104e-06,
      "epoch": 1.4960282436010592,
      "step": 33900
    },
    {
      "loss": 1.3634,
      "grad_norm": 14.28968620300293,
      "learning_rate": 3.7099954486359117e-06,
      "epoch": 1.498234774933804,
      "step": 33950
    },
    {
      "loss": 1.4162,
      "grad_norm": 23.008817672729492,
      "learning_rate": 3.7067233283270127e-06,
      "epoch": 1.500441306266549,
      "step": 34000
    },
    {
      "loss": 1.3573,
      "grad_norm": 10.998602867126465,
      "learning_rate": 3.7034512080181136e-06,
      "epoch": 1.502647837599294,
      "step": 34050
    },
    {
      "loss": 1.228,
      "grad_norm": 31.046449661254883,
      "learning_rate": 3.7001790877092146e-06,
      "epoch": 1.5048543689320388,
      "step": 34100
    },
    {
      "loss": 1.3341,
      "grad_norm": 14.295619010925293,
      "learning_rate": 3.696906967400315e-06,
      "epoch": 1.5070609002647837,
      "step": 34150
    },
    {
      "loss": 1.3374,
      "grad_norm": 29.063961029052734,
      "learning_rate": 3.6936348470914164e-06,
      "epoch": 1.5092674315975287,
      "step": 34200
    },
    {
      "loss": 1.3626,
      "grad_norm": 22.91530990600586,
      "learning_rate": 3.690362726782517e-06,
      "epoch": 1.5114739629302736,
      "step": 34250
    },
    {
      "loss": 1.3648,
      "grad_norm": 16.981233596801758,
      "learning_rate": 3.6870906064736183e-06,
      "epoch": 1.5136804942630184,
      "step": 34300
    },
    {
      "loss": 1.2716,
      "grad_norm": 23.702058792114258,
      "learning_rate": 3.6838184861647197e-06,
      "epoch": 1.5158870255957635,
      "step": 34350
    },
    {
      "loss": 1.3329,
      "grad_norm": 12.963465690612793,
      "learning_rate": 3.68054636585582e-06,
      "epoch": 1.5180935569285083,
      "step": 34400
    },
    {
      "loss": 1.414,
      "grad_norm": 19.960290908813477,
      "learning_rate": 3.6772742455469215e-06,
      "epoch": 1.5203000882612532,
      "step": 34450
    },
    {
      "loss": 1.2505,
      "grad_norm": 25.174304962158203,
      "learning_rate": 3.674002125238022e-06,
      "epoch": 1.5225066195939982,
      "step": 34500
    },
    {
      "loss": 1.4315,
      "grad_norm": 28.186861038208008,
      "learning_rate": 3.6707300049291234e-06,
      "epoch": 1.5247131509267433,
      "step": 34550
    },
    {
      "loss": 1.3229,
      "grad_norm": 12.52834701538086,
      "learning_rate": 3.667457884620224e-06,
      "epoch": 1.526919682259488,
      "step": 34600
    },
    {
      "loss": 1.326,
      "grad_norm": 20.07948112487793,
      "learning_rate": 3.664185764311325e-06,
      "epoch": 1.529126213592233,
      "step": 34650
    },
    {
      "loss": 1.3818,
      "grad_norm": 34.06313705444336,
      "learning_rate": 3.6609136440024262e-06,
      "epoch": 1.531332744924978,
      "step": 34700
    },
    {
      "loss": 1.3267,
      "grad_norm": 20.986835479736328,
      "learning_rate": 3.6576415236935267e-06,
      "epoch": 1.533539276257723,
      "step": 34750
    },
    {
      "loss": 1.3836,
      "grad_norm": 29.56397247314453,
      "learning_rate": 3.654369403384628e-06,
      "epoch": 1.5357458075904677,
      "step": 34800
    },
    {
      "loss": 1.3896,
      "grad_norm": 23.580276489257812,
      "learning_rate": 3.6510972830757286e-06,
      "epoch": 1.5379523389232128,
      "step": 34850
    },
    {
      "loss": 1.5154,
      "grad_norm": 11.261370658874512,
      "learning_rate": 3.64782516276683e-06,
      "epoch": 1.5401588702559577,
      "step": 34900
    },
    {
      "loss": 1.3749,
      "grad_norm": 24.808916091918945,
      "learning_rate": 3.6445530424579305e-06,
      "epoch": 1.5423654015887025,
      "step": 34950
    },
    {
      "loss": 1.3172,
      "grad_norm": 36.089962005615234,
      "learning_rate": 3.641280922149032e-06,
      "epoch": 1.5445719329214476,
      "step": 35000
    },
    {
      "loss": 1.4152,
      "grad_norm": 23.765626907348633,
      "learning_rate": 3.6380088018401332e-06,
      "epoch": 1.5467784642541924,
      "step": 35050
    },
    {
      "loss": 1.3941,
      "grad_norm": 16.83013343811035,
      "learning_rate": 3.6347366815312337e-06,
      "epoch": 1.5489849955869373,
      "step": 35100
    },
    {
      "loss": 1.2543,
      "grad_norm": 15.337807655334473,
      "learning_rate": 3.6314645612223347e-06,
      "epoch": 1.5511915269196823,
      "step": 35150
    },
    {
      "loss": 1.3733,
      "grad_norm": 21.839933395385742,
      "learning_rate": 3.6281924409134356e-06,
      "epoch": 1.5533980582524272,
      "step": 35200
    },
    {
      "loss": 1.4034,
      "grad_norm": 17.24666404724121,
      "learning_rate": 3.6249203206045366e-06,
      "epoch": 1.555604589585172,
      "step": 35250
    },
    {
      "loss": 1.2099,
      "grad_norm": 21.202157974243164,
      "learning_rate": 3.621648200295637e-06,
      "epoch": 1.557811120917917,
      "step": 35300
    },
    {
      "loss": 1.3573,
      "grad_norm": 26.244123458862305,
      "learning_rate": 3.6183760799867384e-06,
      "epoch": 1.560017652250662,
      "step": 35350
    },
    {
      "loss": 1.2607,
      "grad_norm": 30.64592933654785,
      "learning_rate": 3.61510395967784e-06,
      "epoch": 1.5622241835834068,
      "step": 35400
    },
    {
      "loss": 1.2771,
      "grad_norm": 29.92780876159668,
      "learning_rate": 3.6118318393689403e-06,
      "epoch": 1.5644307149161518,
      "step": 35450
    },
    {
      "loss": 1.3824,
      "grad_norm": 34.3279914855957,
      "learning_rate": 3.6085597190600417e-06,
      "epoch": 1.5666372462488969,
      "step": 35500
    },
    {
      "loss": 1.265,
      "grad_norm": 19.41233253479004,
      "learning_rate": 3.605287598751142e-06,
      "epoch": 1.5688437775816415,
      "step": 35550
    },
    {
      "loss": 1.2908,
      "grad_norm": 25.87089729309082,
      "learning_rate": 3.6020154784422435e-06,
      "epoch": 1.5710503089143866,
      "step": 35600
    },
    {
      "loss": 1.3439,
      "grad_norm": 16.575220108032227,
      "learning_rate": 3.598743358133344e-06,
      "epoch": 1.5732568402471316,
      "step": 35650
    },
    {
      "loss": 1.407,
      "grad_norm": 15.633942604064941,
      "learning_rate": 3.5954712378244454e-06,
      "epoch": 1.5754633715798765,
      "step": 35700
    },
    {
      "loss": 1.2445,
      "grad_norm": 18.91392707824707,
      "learning_rate": 3.592199117515546e-06,
      "epoch": 1.5776699029126213,
      "step": 35750
    },
    {
      "loss": 1.3619,
      "grad_norm": 22.346914291381836,
      "learning_rate": 3.588926997206647e-06,
      "epoch": 1.5798764342453664,
      "step": 35800
    },
    {
      "loss": 1.258,
      "grad_norm": 31.730024337768555,
      "learning_rate": 3.5856548768977482e-06,
      "epoch": 1.5820829655781112,
      "step": 35850
    },
    {
      "loss": 1.3975,
      "grad_norm": 30.73594093322754,
      "learning_rate": 3.5823827565888487e-06,
      "epoch": 1.584289496910856,
      "step": 35900
    },
    {
      "loss": 1.2297,
      "grad_norm": 19.560148239135742,
      "learning_rate": 3.57911063627995e-06,
      "epoch": 1.5864960282436011,
      "step": 35950
    },
    {
      "loss": 1.3895,
      "grad_norm": 29.855955123901367,
      "learning_rate": 3.5758385159710506e-06,
      "epoch": 1.588702559576346,
      "step": 36000
    },
    {
      "loss": 1.2897,
      "grad_norm": 16.7652645111084,
      "learning_rate": 3.572566395662152e-06,
      "epoch": 1.5909090909090908,
      "step": 36050
    },
    {
      "loss": 1.2147,
      "grad_norm": 25.204076766967773,
      "learning_rate": 3.5692942753532525e-06,
      "epoch": 1.593115622241836,
      "step": 36100
    },
    {
      "loss": 1.2288,
      "grad_norm": 32.285579681396484,
      "learning_rate": 3.566022155044354e-06,
      "epoch": 1.5953221535745807,
      "step": 36150
    },
    {
      "loss": 1.1876,
      "grad_norm": 18.228038787841797,
      "learning_rate": 3.562750034735455e-06,
      "epoch": 1.5975286849073256,
      "step": 36200
    },
    {
      "loss": 1.2576,
      "grad_norm": 24.117382049560547,
      "learning_rate": 3.5594779144265557e-06,
      "epoch": 1.5997352162400706,
      "step": 36250
    },
    {
      "loss": 1.2802,
      "grad_norm": 20.44672966003418,
      "learning_rate": 3.5562057941176567e-06,
      "epoch": 1.6019417475728155,
      "step": 36300
    },
    {
      "loss": 1.329,
      "grad_norm": 23.456087112426758,
      "learning_rate": 3.5529336738087576e-06,
      "epoch": 1.6041482789055603,
      "step": 36350
    },
    {
      "loss": 1.2378,
      "grad_norm": 23.48164176940918,
      "learning_rate": 3.5496615534998586e-06,
      "epoch": 1.6063548102383054,
      "step": 36400
    },
    {
      "loss": 1.1857,
      "grad_norm": 16.33972930908203,
      "learning_rate": 3.546389433190959e-06,
      "epoch": 1.6085613415710505,
      "step": 36450
    },
    {
      "loss": 1.2909,
      "grad_norm": 14.71507453918457,
      "learning_rate": 3.5431173128820604e-06,
      "epoch": 1.610767872903795,
      "step": 36500
    },
    {
      "loss": 1.2636,
      "grad_norm": 32.28422164916992,
      "learning_rate": 3.539845192573162e-06,
      "epoch": 1.6129744042365401,
      "step": 36550
    },
    {
      "loss": 1.3664,
      "grad_norm": 17.19865608215332,
      "learning_rate": 3.5365730722642623e-06,
      "epoch": 1.6151809355692852,
      "step": 36600
    },
    {
      "loss": 1.3463,
      "grad_norm": 21.637842178344727,
      "learning_rate": 3.5333009519553637e-06,
      "epoch": 1.61738746690203,
      "step": 36650
    },
    {
      "loss": 1.273,
      "grad_norm": 35.265647888183594,
      "learning_rate": 3.530028831646464e-06,
      "epoch": 1.619593998234775,
      "step": 36700
    },
    {
      "loss": 1.3566,
      "grad_norm": 24.20524787902832,
      "learning_rate": 3.5267567113375655e-06,
      "epoch": 1.62180052956752,
      "step": 36750
    },
    {
      "loss": 1.2548,
      "grad_norm": 25.930023193359375,
      "learning_rate": 3.523484591028666e-06,
      "epoch": 1.6240070609002648,
      "step": 36800
    },
    {
      "loss": 1.2451,
      "grad_norm": 25.503589630126953,
      "learning_rate": 3.5202124707197674e-06,
      "epoch": 1.6262135922330097,
      "step": 36850
    },
    {
      "loss": 1.2923,
      "grad_norm": 25.436880111694336,
      "learning_rate": 3.5169403504108684e-06,
      "epoch": 1.6284201235657547,
      "step": 36900
    },
    {
      "loss": 1.3715,
      "grad_norm": 16.852066040039062,
      "learning_rate": 3.513668230101969e-06,
      "epoch": 1.6306266548984996,
      "step": 36950
    },
    {
      "loss": 1.4426,
      "grad_norm": 35.278018951416016,
      "learning_rate": 3.5103961097930702e-06,
      "epoch": 1.6328331862312444,
      "step": 37000
    },
    {
      "loss": 1.2317,
      "grad_norm": 19.103483200073242,
      "learning_rate": 3.5071239894841707e-06,
      "epoch": 1.6350397175639895,
      "step": 37050
    },
    {
      "loss": 1.1684,
      "grad_norm": 19.705486297607422,
      "learning_rate": 3.503851869175272e-06,
      "epoch": 1.6372462488967343,
      "step": 37100
    },
    {
      "loss": 1.2652,
      "grad_norm": 13.374428749084473,
      "learning_rate": 3.5005797488663726e-06,
      "epoch": 1.6394527802294792,
      "step": 37150
    },
    {
      "loss": 1.2701,
      "grad_norm": 21.734569549560547,
      "learning_rate": 3.497307628557474e-06,
      "epoch": 1.6416593115622242,
      "step": 37200
    },
    {
      "loss": 1.2761,
      "grad_norm": 24.830028533935547,
      "learning_rate": 3.4940355082485753e-06,
      "epoch": 1.643865842894969,
      "step": 37250
    },
    {
      "loss": 1.3286,
      "grad_norm": 18.972423553466797,
      "learning_rate": 3.490763387939676e-06,
      "epoch": 1.646072374227714,
      "step": 37300
    },
    {
      "loss": 1.3385,
      "grad_norm": 17.63018035888672,
      "learning_rate": 3.487491267630777e-06,
      "epoch": 1.648278905560459,
      "step": 37350
    },
    {
      "loss": 1.4607,
      "grad_norm": 24.614913940429688,
      "learning_rate": 3.4842191473218777e-06,
      "epoch": 1.650485436893204,
      "step": 37400
    },
    {
      "loss": 1.2407,
      "grad_norm": 28.36293601989746,
      "learning_rate": 3.4809470270129787e-06,
      "epoch": 1.6526919682259487,
      "step": 37450
    },
    {
      "loss": 1.4332,
      "grad_norm": 28.14466094970703,
      "learning_rate": 3.4776749067040796e-06,
      "epoch": 1.6548984995586937,
      "step": 37500
    },
    {
      "loss": 1.2115,
      "grad_norm": 28.441049575805664,
      "learning_rate": 3.4744027863951806e-06,
      "epoch": 1.6571050308914388,
      "step": 37550
    },
    {
      "loss": 1.3558,
      "grad_norm": 16.743267059326172,
      "learning_rate": 3.471130666086282e-06,
      "epoch": 1.6593115622241836,
      "step": 37600
    },
    {
      "loss": 1.3703,
      "grad_norm": 29.324459075927734,
      "learning_rate": 3.4678585457773824e-06,
      "epoch": 1.6615180935569285,
      "step": 37650
    },
    {
      "loss": 1.3642,
      "grad_norm": 18.7281494140625,
      "learning_rate": 3.464586425468484e-06,
      "epoch": 1.6637246248896735,
      "step": 37700
    },
    {
      "loss": 1.4467,
      "grad_norm": 15.41933536529541,
      "learning_rate": 3.4613143051595843e-06,
      "epoch": 1.6659311562224184,
      "step": 37750
    },
    {
      "loss": 1.2619,
      "grad_norm": 18.934255599975586,
      "learning_rate": 3.4580421848506857e-06,
      "epoch": 1.6681376875551632,
      "step": 37800
    },
    {
      "loss": 1.181,
      "grad_norm": 21.24393653869629,
      "learning_rate": 3.454770064541786e-06,
      "epoch": 1.6703442188879083,
      "step": 37850
    },
    {
      "loss": 1.4684,
      "grad_norm": 58.99828338623047,
      "learning_rate": 3.4514979442328875e-06,
      "epoch": 1.6725507502206531,
      "step": 37900
    },
    {
      "loss": 1.2483,
      "grad_norm": 24.411453247070312,
      "learning_rate": 3.4482258239239885e-06,
      "epoch": 1.674757281553398,
      "step": 37950
    },
    {
      "loss": 1.2535,
      "grad_norm": 21.3690242767334,
      "learning_rate": 3.444953703615089e-06,
      "epoch": 1.676963812886143,
      "step": 38000
    },
    {
      "loss": 1.4426,
      "grad_norm": 15.405234336853027,
      "learning_rate": 3.4416815833061904e-06,
      "epoch": 1.679170344218888,
      "step": 38050
    },
    {
      "loss": 1.4216,
      "grad_norm": 16.074729919433594,
      "learning_rate": 3.438409462997291e-06,
      "epoch": 1.6813768755516327,
      "step": 38100
    },
    {
      "loss": 1.2596,
      "grad_norm": 11.524907112121582,
      "learning_rate": 3.4351373426883922e-06,
      "epoch": 1.6835834068843778,
      "step": 38150
    },
    {
      "loss": 1.1649,
      "grad_norm": 25.03992462158203,
      "learning_rate": 3.4318652223794927e-06,
      "epoch": 1.6857899382171226,
      "step": 38200
    },
    {
      "loss": 1.2773,
      "grad_norm": 22.058006286621094,
      "learning_rate": 3.428593102070594e-06,
      "epoch": 1.6879964695498675,
      "step": 38250
    },
    {
      "loss": 1.2535,
      "grad_norm": 40.43721008300781,
      "learning_rate": 3.4253209817616946e-06,
      "epoch": 1.6902030008826125,
      "step": 38300
    },
    {
      "loss": 1.223,
      "grad_norm": 24.2928409576416,
      "learning_rate": 3.422048861452796e-06,
      "epoch": 1.6924095322153576,
      "step": 38350
    },
    {
      "loss": 1.3153,
      "grad_norm": 27.802133560180664,
      "learning_rate": 3.4187767411438973e-06,
      "epoch": 1.6946160635481022,
      "step": 38400
    },
    {
      "loss": 1.3101,
      "grad_norm": 21.71299171447754,
      "learning_rate": 3.415504620834998e-06,
      "epoch": 1.6968225948808473,
      "step": 38450
    },
    {
      "loss": 1.2987,
      "grad_norm": 13.069104194641113,
      "learning_rate": 3.412232500526099e-06,
      "epoch": 1.6990291262135924,
      "step": 38500
    },
    {
      "loss": 1.3495,
      "grad_norm": 24.855321884155273,
      "learning_rate": 3.4089603802171997e-06,
      "epoch": 1.7012356575463372,
      "step": 38550
    },
    {
      "loss": 1.2581,
      "grad_norm": 20.46748161315918,
      "learning_rate": 3.4056882599083007e-06,
      "epoch": 1.703442188879082,
      "step": 38600
    },
    {
      "loss": 1.2679,
      "grad_norm": 22.351213455200195,
      "learning_rate": 3.402416139599401e-06,
      "epoch": 1.7056487202118271,
      "step": 38650
    },
    {
      "loss": 1.2659,
      "grad_norm": 21.89521026611328,
      "learning_rate": 3.3991440192905026e-06,
      "epoch": 1.707855251544572,
      "step": 38700
    },
    {
      "loss": 1.2429,
      "grad_norm": 15.878700256347656,
      "learning_rate": 3.395871898981604e-06,
      "epoch": 1.7100617828773168,
      "step": 38750
    },
    {
      "loss": 1.288,
      "grad_norm": 26.129865646362305,
      "learning_rate": 3.3925997786727044e-06,
      "epoch": 1.7122683142100619,
      "step": 38800
    },
    {
      "loss": 1.366,
      "grad_norm": 23.672422409057617,
      "learning_rate": 3.389327658363806e-06,
      "epoch": 1.7144748455428067,
      "step": 38850
    },
    {
      "loss": 1.2788,
      "grad_norm": 11.971772193908691,
      "learning_rate": 3.3860555380549063e-06,
      "epoch": 1.7166813768755516,
      "step": 38900
    },
    {
      "loss": 1.3185,
      "grad_norm": 28.050418853759766,
      "learning_rate": 3.3827834177460077e-06,
      "epoch": 1.7188879082082966,
      "step": 38950
    },
    {
      "loss": 1.3181,
      "grad_norm": 21.847848892211914,
      "learning_rate": 3.379511297437108e-06,
      "epoch": 1.7210944395410415,
      "step": 39000
    },
    {
      "loss": 1.4087,
      "grad_norm": 26.5921573638916,
      "learning_rate": 3.3762391771282095e-06,
      "epoch": 1.7233009708737863,
      "step": 39050
    },
    {
      "loss": 1.3458,
      "grad_norm": 20.838319778442383,
      "learning_rate": 3.3729670568193105e-06,
      "epoch": 1.7255075022065314,
      "step": 39100
    },
    {
      "loss": 1.361,
      "grad_norm": 47.060791015625,
      "learning_rate": 3.369694936510411e-06,
      "epoch": 1.7277140335392762,
      "step": 39150
    },
    {
      "loss": 1.3201,
      "grad_norm": 24.701440811157227,
      "learning_rate": 3.3664228162015124e-06,
      "epoch": 1.729920564872021,
      "step": 39200
    },
    {
      "loss": 1.2635,
      "grad_norm": 9.202779769897461,
      "learning_rate": 3.363150695892613e-06,
      "epoch": 1.7321270962047661,
      "step": 39250
    },
    {
      "loss": 1.3143,
      "grad_norm": 19.95332145690918,
      "learning_rate": 3.3598785755837142e-06,
      "epoch": 1.7343336275375112,
      "step": 39300
    },
    {
      "loss": 1.461,
      "grad_norm": 37.545082092285156,
      "learning_rate": 3.3566064552748147e-06,
      "epoch": 1.7365401588702558,
      "step": 39350
    },
    {
      "loss": 1.264,
      "grad_norm": 25.833450317382812,
      "learning_rate": 3.353334334965916e-06,
      "epoch": 1.7387466902030009,
      "step": 39400
    },
    {
      "loss": 1.3803,
      "grad_norm": 17.947391510009766,
      "learning_rate": 3.3500622146570175e-06,
      "epoch": 1.740953221535746,
      "step": 39450
    },
    {
      "loss": 1.3965,
      "grad_norm": 14.610252380371094,
      "learning_rate": 3.346790094348118e-06,
      "epoch": 1.7431597528684908,
      "step": 39500
    },
    {
      "loss": 1.28,
      "grad_norm": 14.52613639831543,
      "learning_rate": 3.3435179740392193e-06,
      "epoch": 1.7453662842012356,
      "step": 39550
    },
    {
      "loss": 1.2533,
      "grad_norm": 26.074108123779297,
      "learning_rate": 3.34024585373032e-06,
      "epoch": 1.7475728155339807,
      "step": 39600
    },
    {
      "loss": 1.2357,
      "grad_norm": 15.385676383972168,
      "learning_rate": 3.336973733421421e-06,
      "epoch": 1.7497793468667255,
      "step": 39650
    },
    {
      "loss": 1.3169,
      "grad_norm": 29.53054428100586,
      "learning_rate": 3.3337016131125217e-06,
      "epoch": 1.7519858781994704,
      "step": 39700
    },
    {
      "loss": 1.1854,
      "grad_norm": 10.584758758544922,
      "learning_rate": 3.3304294928036227e-06,
      "epoch": 1.7541924095322154,
      "step": 39750
    },
    {
      "loss": 1.2902,
      "grad_norm": 24.61505699157715,
      "learning_rate": 3.327157372494724e-06,
      "epoch": 1.7563989408649603,
      "step": 39800
    },
    {
      "loss": 1.3215,
      "grad_norm": 16.004859924316406,
      "learning_rate": 3.3238852521858246e-06,
      "epoch": 1.7586054721977051,
      "step": 39850
    },
    {
      "loss": 1.2004,
      "grad_norm": 22.459291458129883,
      "learning_rate": 3.320613131876926e-06,
      "epoch": 1.7608120035304502,
      "step": 39900
    },
    {
      "loss": 1.2951,
      "grad_norm": 40.893768310546875,
      "learning_rate": 3.3173410115680264e-06,
      "epoch": 1.763018534863195,
      "step": 39950
    },
    {
      "loss": 1.2319,
      "grad_norm": 23.068458557128906,
      "learning_rate": 3.314068891259128e-06,
      "epoch": 1.7652250661959399,
      "step": 40000
    },
    {
      "loss": 1.1791,
      "grad_norm": 27.64384651184082,
      "learning_rate": 3.3107967709502283e-06,
      "epoch": 1.767431597528685,
      "step": 40050
    },
    {
      "loss": 1.2066,
      "grad_norm": 16.63459014892578,
      "learning_rate": 3.3075246506413297e-06,
      "epoch": 1.7696381288614298,
      "step": 40100
    },
    {
      "loss": 1.3935,
      "grad_norm": 20.075057983398438,
      "learning_rate": 3.3042525303324306e-06,
      "epoch": 1.7718446601941746,
      "step": 40150
    },
    {
      "loss": 1.3623,
      "grad_norm": 20.47230339050293,
      "learning_rate": 3.3009804100235315e-06,
      "epoch": 1.7740511915269197,
      "step": 40200
    },
    {
      "loss": 1.2502,
      "grad_norm": 19.786422729492188,
      "learning_rate": 3.2977082897146325e-06,
      "epoch": 1.7762577228596648,
      "step": 40250
    },
    {
      "loss": 1.3113,
      "grad_norm": 16.784019470214844,
      "learning_rate": 3.294436169405733e-06,
      "epoch": 1.7784642541924094,
      "step": 40300
    },
    {
      "loss": 1.1328,
      "grad_norm": 13.355510711669922,
      "learning_rate": 3.2911640490968344e-06,
      "epoch": 1.7806707855251545,
      "step": 40350
    },
    {
      "loss": 1.1988,
      "grad_norm": 28.516155242919922,
      "learning_rate": 3.287891928787935e-06,
      "epoch": 1.7828773168578995,
      "step": 40400
    },
    {
      "loss": 1.2991,
      "grad_norm": 33.91203308105469,
      "learning_rate": 3.2846198084790362e-06,
      "epoch": 1.7850838481906444,
      "step": 40450
    },
    {
      "loss": 1.4189,
      "grad_norm": 34.9853630065918,
      "learning_rate": 3.2813476881701367e-06,
      "epoch": 1.7872903795233892,
      "step": 40500
    },
    {
      "loss": 1.3677,
      "grad_norm": 32.37791061401367,
      "learning_rate": 3.278075567861238e-06,
      "epoch": 1.7894969108561343,
      "step": 40550
    },
    {
      "loss": 1.1822,
      "grad_norm": 18.49043846130371,
      "learning_rate": 3.2748034475523395e-06,
      "epoch": 1.7917034421888791,
      "step": 40600
    },
    {
      "loss": 1.2819,
      "grad_norm": 18.497961044311523,
      "learning_rate": 3.27153132724344e-06,
      "epoch": 1.793909973521624,
      "step": 40650
    },
    {
      "loss": 1.249,
      "grad_norm": 21.698579788208008,
      "learning_rate": 3.2682592069345413e-06,
      "epoch": 1.796116504854369,
      "step": 40700
    },
    {
      "loss": 1.2661,
      "grad_norm": 18.11994171142578,
      "learning_rate": 3.264987086625642e-06,
      "epoch": 1.7983230361871139,
      "step": 40750
    },
    {
      "loss": 1.3092,
      "grad_norm": 39.056209564208984,
      "learning_rate": 3.261714966316743e-06,
      "epoch": 1.8005295675198587,
      "step": 40800
    },
    {
      "loss": 1.2292,
      "grad_norm": 13.830270767211914,
      "learning_rate": 3.2584428460078437e-06,
      "epoch": 1.8027360988526038,
      "step": 40850
    },
    {
      "loss": 1.4659,
      "grad_norm": 19.5644474029541,
      "learning_rate": 3.2551707256989447e-06,
      "epoch": 1.8049426301853486,
      "step": 40900
    },
    {
      "loss": 1.2656,
      "grad_norm": 23.00431251525879,
      "learning_rate": 3.251898605390046e-06,
      "epoch": 1.8071491615180935,
      "step": 40950
    },
    {
      "loss": 1.2221,
      "grad_norm": 28.21721839904785,
      "learning_rate": 3.2486264850811466e-06,
      "epoch": 1.8093556928508385,
      "step": 41000
    },
    {
      "loss": 1.2998,
      "grad_norm": 21.130186080932617,
      "learning_rate": 3.245354364772248e-06,
      "epoch": 1.8115622241835834,
      "step": 41050
    },
    {
      "loss": 1.2767,
      "grad_norm": 34.43202209472656,
      "learning_rate": 3.2420822444633484e-06,
      "epoch": 1.8137687555163282,
      "step": 41100
    },
    {
      "loss": 1.3462,
      "grad_norm": 15.08858871459961,
      "learning_rate": 3.23881012415445e-06,
      "epoch": 1.8159752868490733,
      "step": 41150
    },
    {
      "loss": 1.311,
      "grad_norm": 7.553313732147217,
      "learning_rate": 3.2355380038455503e-06,
      "epoch": 1.8181818181818183,
      "step": 41200
    },
    {
      "loss": 1.2076,
      "grad_norm": 24.151575088500977,
      "learning_rate": 3.2322658835366517e-06,
      "epoch": 1.820388349514563,
      "step": 41250
    },
    {
      "loss": 1.2432,
      "grad_norm": 17.38654899597168,
      "learning_rate": 3.2289937632277526e-06,
      "epoch": 1.822594880847308,
      "step": 41300
    },
    {
      "loss": 1.2241,
      "grad_norm": 15.527009963989258,
      "learning_rate": 3.2257216429188535e-06,
      "epoch": 1.824801412180053,
      "step": 41350
    },
    {
      "loss": 1.3697,
      "grad_norm": 23.088010787963867,
      "learning_rate": 3.2224495226099545e-06,
      "epoch": 1.8270079435127977,
      "step": 41400
    },
    {
      "loss": 1.1717,
      "grad_norm": 25.522506713867188,
      "learning_rate": 3.219177402301055e-06,
      "epoch": 1.8292144748455428,
      "step": 41450
    },
    {
      "loss": 1.2405,
      "grad_norm": 17.850419998168945,
      "learning_rate": 3.2159052819921564e-06,
      "epoch": 1.8314210061782878,
      "step": 41500
    },
    {
      "loss": 1.2654,
      "grad_norm": 30.534894943237305,
      "learning_rate": 3.212633161683257e-06,
      "epoch": 1.8336275375110327,
      "step": 41550
    },
    {
      "loss": 1.2398,
      "grad_norm": 23.889083862304688,
      "learning_rate": 3.2093610413743582e-06,
      "epoch": 1.8358340688437775,
      "step": 41600
    },
    {
      "loss": 1.347,
      "grad_norm": 25.69422149658203,
      "learning_rate": 3.2060889210654596e-06,
      "epoch": 1.8380406001765226,
      "step": 41650
    },
    {
      "loss": 1.3241,
      "grad_norm": 20.07309341430664,
      "learning_rate": 3.20281680075656e-06,
      "epoch": 1.8402471315092674,
      "step": 41700
    },
    {
      "loss": 1.2724,
      "grad_norm": 28.408363342285156,
      "learning_rate": 3.1995446804476615e-06,
      "epoch": 1.8424536628420123,
      "step": 41750
    },
    {
      "loss": 1.3517,
      "grad_norm": 24.461458206176758,
      "learning_rate": 3.196272560138762e-06,
      "epoch": 1.8446601941747574,
      "step": 41800
    },
    {
      "loss": 1.2838,
      "grad_norm": 33.2829475402832,
      "learning_rate": 3.193000439829863e-06,
      "epoch": 1.8468667255075022,
      "step": 41850
    },
    {
      "loss": 1.1899,
      "grad_norm": 20.2508602142334,
      "learning_rate": 3.189728319520964e-06,
      "epoch": 1.849073256840247,
      "step": 41900
    },
    {
      "loss": 1.3276,
      "grad_norm": 28.82522201538086,
      "learning_rate": 3.186456199212065e-06,
      "epoch": 1.851279788172992,
      "step": 41950
    },
    {
      "loss": 1.3602,
      "grad_norm": 22.5196533203125,
      "learning_rate": 3.183184078903166e-06,
      "epoch": 1.853486319505737,
      "step": 42000
    },
    {
      "loss": 1.2455,
      "grad_norm": 33.484832763671875,
      "learning_rate": 3.1799119585942667e-06,
      "epoch": 1.8556928508384818,
      "step": 42050
    },
    {
      "loss": 1.2762,
      "grad_norm": 75.71472930908203,
      "learning_rate": 3.176639838285368e-06,
      "epoch": 1.8578993821712269,
      "step": 42100
    },
    {
      "loss": 1.2975,
      "grad_norm": 43.49506378173828,
      "learning_rate": 3.1733677179764686e-06,
      "epoch": 1.860105913503972,
      "step": 42150
    },
    {
      "loss": 1.2327,
      "grad_norm": 35.202247619628906,
      "learning_rate": 3.17009559766757e-06,
      "epoch": 1.8623124448367165,
      "step": 42200
    },
    {
      "loss": 1.165,
      "grad_norm": 12.178420066833496,
      "learning_rate": 3.1668234773586704e-06,
      "epoch": 1.8645189761694616,
      "step": 42250
    },
    {
      "loss": 1.2537,
      "grad_norm": 12.912301063537598,
      "learning_rate": 3.163551357049772e-06,
      "epoch": 1.8667255075022067,
      "step": 42300
    },
    {
      "loss": 1.2915,
      "grad_norm": 24.23040008544922,
      "learning_rate": 3.1602792367408727e-06,
      "epoch": 1.8689320388349513,
      "step": 42350
    },
    {
      "loss": 1.173,
      "grad_norm": 21.284496307373047,
      "learning_rate": 3.1570071164319737e-06,
      "epoch": 1.8711385701676964,
      "step": 42400
    },
    {
      "loss": 1.1878,
      "grad_norm": 26.841285705566406,
      "learning_rate": 3.1537349961230746e-06,
      "epoch": 1.8733451015004414,
      "step": 42450
    },
    {
      "loss": 1.22,
      "grad_norm": 25.137283325195312,
      "learning_rate": 3.1504628758141755e-06,
      "epoch": 1.8755516328331863,
      "step": 42500
    },
    {
      "loss": 1.2494,
      "grad_norm": 19.4161434173584,
      "learning_rate": 3.1471907555052765e-06,
      "epoch": 1.877758164165931,
      "step": 42550
    },
    {
      "loss": 1.3392,
      "grad_norm": 13.28465747833252,
      "learning_rate": 3.143918635196377e-06,
      "epoch": 1.8799646954986762,
      "step": 42600
    },
    {
      "loss": 1.2462,
      "grad_norm": 15.214344024658203,
      "learning_rate": 3.1406465148874784e-06,
      "epoch": 1.882171226831421,
      "step": 42650
    },
    {
      "loss": 1.1798,
      "grad_norm": 30.874357223510742,
      "learning_rate": 3.137374394578579e-06,
      "epoch": 1.8843777581641659,
      "step": 42700
    },
    {
      "loss": 1.2685,
      "grad_norm": 21.812715530395508,
      "learning_rate": 3.1341022742696802e-06,
      "epoch": 1.886584289496911,
      "step": 42750
    },
    {
      "loss": 1.2887,
      "grad_norm": 19.167287826538086,
      "learning_rate": 3.1308301539607816e-06,
      "epoch": 1.8887908208296558,
      "step": 42800
    },
    {
      "loss": 1.2581,
      "grad_norm": 22.448617935180664,
      "learning_rate": 3.127558033651882e-06,
      "epoch": 1.8909973521624006,
      "step": 42850
    },
    {
      "loss": 1.1357,
      "grad_norm": 25.529083251953125,
      "learning_rate": 3.1242859133429835e-06,
      "epoch": 1.8932038834951457,
      "step": 42900
    },
    {
      "loss": 1.295,
      "grad_norm": 26.2919921875,
      "learning_rate": 3.121013793034084e-06,
      "epoch": 1.8954104148278905,
      "step": 42950
    },
    {
      "loss": 1.2617,
      "grad_norm": 34.773189544677734,
      "learning_rate": 3.117741672725185e-06,
      "epoch": 1.8976169461606354,
      "step": 43000
    },
    {
      "loss": 1.2438,
      "grad_norm": 27.85482406616211,
      "learning_rate": 3.114469552416286e-06,
      "epoch": 1.8998234774933804,
      "step": 43050
    },
    {
      "loss": 1.2437,
      "grad_norm": 30.421865463256836,
      "learning_rate": 3.111197432107387e-06,
      "epoch": 1.9020300088261255,
      "step": 43100
    },
    {
      "loss": 1.2955,
      "grad_norm": 19.97467803955078,
      "learning_rate": 3.107925311798488e-06,
      "epoch": 1.9042365401588701,
      "step": 43150
    },
    {
      "loss": 1.3936,
      "grad_norm": 19.810096740722656,
      "learning_rate": 3.1046531914895887e-06,
      "epoch": 1.9064430714916152,
      "step": 43200
    },
    {
      "loss": 1.2539,
      "grad_norm": 18.546476364135742,
      "learning_rate": 3.10138107118069e-06,
      "epoch": 1.9086496028243602,
      "step": 43250
    },
    {
      "loss": 1.1955,
      "grad_norm": 27.697324752807617,
      "learning_rate": 3.0981089508717906e-06,
      "epoch": 1.9108561341571049,
      "step": 43300
    },
    {
      "loss": 1.2717,
      "grad_norm": 21.774150848388672,
      "learning_rate": 3.094836830562892e-06,
      "epoch": 1.91306266548985,
      "step": 43350
    },
    {
      "loss": 1.3796,
      "grad_norm": 177.111328125,
      "learning_rate": 3.0915647102539924e-06,
      "epoch": 1.915269196822595,
      "step": 43400
    },
    {
      "loss": 1.2294,
      "grad_norm": 17.51169204711914,
      "learning_rate": 3.088292589945094e-06,
      "epoch": 1.9174757281553398,
      "step": 43450
    },
    {
      "loss": 1.3646,
      "grad_norm": 17.001893997192383,
      "learning_rate": 3.0850204696361947e-06,
      "epoch": 1.9196822594880847,
      "step": 43500
    },
    {
      "loss": 1.3679,
      "grad_norm": 21.36176872253418,
      "learning_rate": 3.0817483493272957e-06,
      "epoch": 1.9218887908208298,
      "step": 43550
    },
    {
      "loss": 1.2437,
      "grad_norm": 17.251785278320312,
      "learning_rate": 3.0784762290183966e-06,
      "epoch": 1.9240953221535746,
      "step": 43600
    },
    {
      "loss": 1.282,
      "grad_norm": 15.114310264587402,
      "learning_rate": 3.075204108709497e-06,
      "epoch": 1.9263018534863194,
      "step": 43650
    },
    {
      "loss": 1.3184,
      "grad_norm": 31.963214874267578,
      "learning_rate": 3.0719319884005985e-06,
      "epoch": 1.9285083848190645,
      "step": 43700
    },
    {
      "loss": 1.2458,
      "grad_norm": 14.380293846130371,
      "learning_rate": 3.068659868091699e-06,
      "epoch": 1.9307149161518093,
      "step": 43750
    },
    {
      "loss": 1.1652,
      "grad_norm": 23.498577117919922,
      "learning_rate": 3.0653877477828004e-06,
      "epoch": 1.9329214474845542,
      "step": 43800
    },
    {
      "loss": 1.3119,
      "grad_norm": 23.51892852783203,
      "learning_rate": 3.0621156274739017e-06,
      "epoch": 1.9351279788172993,
      "step": 43850
    },
    {
      "loss": 1.4768,
      "grad_norm": 13.706789016723633,
      "learning_rate": 3.0588435071650022e-06,
      "epoch": 1.937334510150044,
      "step": 43900
    },
    {
      "loss": 1.2113,
      "grad_norm": 29.929895401000977,
      "learning_rate": 3.0555713868561036e-06,
      "epoch": 1.939541041482789,
      "step": 43950
    },
    {
      "loss": 1.2512,
      "grad_norm": 20.24454116821289,
      "learning_rate": 3.052299266547204e-06,
      "epoch": 1.941747572815534,
      "step": 44000
    },
    {
      "loss": 1.1892,
      "grad_norm": 15.934918403625488,
      "learning_rate": 3.0490271462383055e-06,
      "epoch": 1.943954104148279,
      "step": 44050
    },
    {
      "loss": 1.2925,
      "grad_norm": 20.1813907623291,
      "learning_rate": 3.045755025929406e-06,
      "epoch": 1.9461606354810237,
      "step": 44100
    },
    {
      "loss": 1.2117,
      "grad_norm": 24.800931930541992,
      "learning_rate": 3.042482905620507e-06,
      "epoch": 1.9483671668137688,
      "step": 44150
    },
    {
      "loss": 1.1747,
      "grad_norm": 34.12669372558594,
      "learning_rate": 3.0392107853116083e-06,
      "epoch": 1.9505736981465138,
      "step": 44200
    },
    {
      "loss": 1.3486,
      "grad_norm": 28.256145477294922,
      "learning_rate": 3.035938665002709e-06,
      "epoch": 1.9527802294792584,
      "step": 44250
    },
    {
      "loss": 1.2798,
      "grad_norm": 22.943222045898438,
      "learning_rate": 3.03266654469381e-06,
      "epoch": 1.9549867608120035,
      "step": 44300
    },
    {
      "loss": 1.2563,
      "grad_norm": 16.763246536254883,
      "learning_rate": 3.0293944243849107e-06,
      "epoch": 1.9571932921447486,
      "step": 44350
    },
    {
      "loss": 1.3218,
      "grad_norm": 32.98924255371094,
      "learning_rate": 3.026122304076012e-06,
      "epoch": 1.9593998234774934,
      "step": 44400
    },
    {
      "loss": 1.1906,
      "grad_norm": 22.57782554626465,
      "learning_rate": 3.0228501837671126e-06,
      "epoch": 1.9616063548102383,
      "step": 44450
    },
    {
      "loss": 1.2034,
      "grad_norm": 27.385223388671875,
      "learning_rate": 3.019578063458214e-06,
      "epoch": 1.9638128861429833,
      "step": 44500
    },
    {
      "loss": 1.2749,
      "grad_norm": 22.32032012939453,
      "learning_rate": 3.0163059431493153e-06,
      "epoch": 1.9660194174757282,
      "step": 44550
    },
    {
      "loss": 1.2016,
      "grad_norm": 22.97812843322754,
      "learning_rate": 3.013033822840416e-06,
      "epoch": 1.968225948808473,
      "step": 44600
    },
    {
      "loss": 1.4009,
      "grad_norm": 23.853548049926758,
      "learning_rate": 3.0097617025315167e-06,
      "epoch": 1.970432480141218,
      "step": 44650
    },
    {
      "loss": 1.1156,
      "grad_norm": 15.05942153930664,
      "learning_rate": 3.0064895822226177e-06,
      "epoch": 1.972639011473963,
      "step": 44700
    },
    {
      "loss": 1.2542,
      "grad_norm": 16.268352508544922,
      "learning_rate": 3.0032174619137186e-06,
      "epoch": 1.9748455428067078,
      "step": 44750
    },
    {
      "loss": 1.2602,
      "grad_norm": 18.002580642700195,
      "learning_rate": 2.999945341604819e-06,
      "epoch": 1.9770520741394528,
      "step": 44800
    },
    {
      "loss": 1.2637,
      "grad_norm": 11.007455825805664,
      "learning_rate": 2.9966732212959205e-06,
      "epoch": 1.9792586054721977,
      "step": 44850
    },
    {
      "loss": 1.4107,
      "grad_norm": 21.009803771972656,
      "learning_rate": 2.993401100987022e-06,
      "epoch": 1.9814651368049425,
      "step": 44900
    },
    {
      "loss": 1.3106,
      "grad_norm": 12.331023216247559,
      "learning_rate": 2.9901289806781224e-06,
      "epoch": 1.9836716681376876,
      "step": 44950
    },
    {
      "loss": 1.197,
      "grad_norm": 22.92192840576172,
      "learning_rate": 2.9868568603692237e-06,
      "epoch": 1.9858781994704324,
      "step": 45000
    },
    {
      "loss": 1.2386,
      "grad_norm": 10.793285369873047,
      "learning_rate": 2.9835847400603242e-06,
      "epoch": 1.9880847308031773,
      "step": 45050
    },
    {
      "loss": 1.3058,
      "grad_norm": 23.868579864501953,
      "learning_rate": 2.9803126197514256e-06,
      "epoch": 1.9902912621359223,
      "step": 45100
    },
    {
      "loss": 1.2741,
      "grad_norm": 21.82026481628418,
      "learning_rate": 2.977040499442526e-06,
      "epoch": 1.9924977934686674,
      "step": 45150
    },
    {
      "loss": 1.2157,
      "grad_norm": 26.1727294921875,
      "learning_rate": 2.9737683791336275e-06,
      "epoch": 1.994704324801412,
      "step": 45200
    },
    {
      "loss": 1.331,
      "grad_norm": 26.384849548339844,
      "learning_rate": 2.970496258824728e-06,
      "epoch": 1.996910856134157,
      "step": 45250
    },
    {
      "loss": 1.3186,
      "grad_norm": 20.431894302368164,
      "learning_rate": 2.967224138515829e-06,
      "epoch": 1.9991173874669022,
      "step": 45300
    },
    {
      "eval_loss": 1.0515155003668861,
      "eval_exact_match": 69.48905753618072,
      "eval_f1": 75.4162686848286,
      "eval_samples": 22720,
      "step": 45320
    },
    {
      "eval_loss": 1.0515155003668861,
      "eval_exact_match": 69.48905753618072,
      "eval_f1": 75.4162686848286,
      "eval_samples": 22720,
      "epoch": 2.0,
      "step": 45320
    },
    {
      "loss": 1.3293,
      "grad_norm": 27.852325439453125,
      "learning_rate": 2.9639520182069303e-06,
      "epoch": 2.0013239187996468,
      "step": 45350
    },
    {
      "loss": 1.1056,
      "grad_norm": 29.26703643798828,
      "learning_rate": 2.960679897898031e-06,
      "epoch": 2.003530450132392,
      "step": 45400
    },
    {
      "loss": 1.1728,
      "grad_norm": 7.727910041809082,
      "learning_rate": 2.957407777589132e-06,
      "epoch": 2.005736981465137,
      "step": 45450
    },
    {
      "loss": 1.1607,
      "grad_norm": 22.439661026000977,
      "learning_rate": 2.9541356572802327e-06,
      "epoch": 2.0079435127978815,
      "step": 45500
    },
    {
      "loss": 1.2659,
      "grad_norm": 18.2895565032959,
      "learning_rate": 2.950863536971334e-06,
      "epoch": 2.0101500441306266,
      "step": 45550
    },
    {
      "loss": 1.151,
      "grad_norm": 23.42038345336914,
      "learning_rate": 2.947591416662435e-06,
      "epoch": 2.0123565754633717,
      "step": 45600
    },
    {
      "loss": 1.1635,
      "grad_norm": 5.011713027954102,
      "learning_rate": 2.944319296353536e-06,
      "epoch": 2.0145631067961167,
      "step": 45650
    },
    {
      "loss": 1.1979,
      "grad_norm": 17.44904136657715,
      "learning_rate": 2.941047176044637e-06,
      "epoch": 2.0167696381288613,
      "step": 45700
    },
    {
      "loss": 1.2193,
      "grad_norm": 27.214141845703125,
      "learning_rate": 2.937775055735738e-06,
      "epoch": 2.0189761694616064,
      "step": 45750
    },
    {
      "loss": 1.1756,
      "grad_norm": 6.34040641784668,
      "learning_rate": 2.9345029354268387e-06,
      "epoch": 2.0211827007943515,
      "step": 45800
    },
    {
      "loss": 1.1958,
      "grad_norm": 25.532451629638672,
      "learning_rate": 2.9312308151179397e-06,
      "epoch": 2.023389232127096,
      "step": 45850
    },
    {
      "loss": 1.2006,
      "grad_norm": 19.949682235717773,
      "learning_rate": 2.9279586948090406e-06,
      "epoch": 2.025595763459841,
      "step": 45900
    },
    {
      "loss": 1.3626,
      "grad_norm": 21.69321632385254,
      "learning_rate": 2.9246865745001415e-06,
      "epoch": 2.0278022947925862,
      "step": 45950
    },
    {
      "loss": 1.0958,
      "grad_norm": 11.837038040161133,
      "learning_rate": 2.9214144541912425e-06,
      "epoch": 2.030008826125331,
      "step": 46000
    },
    {
      "loss": 1.1615,
      "grad_norm": 30.97052764892578,
      "learning_rate": 2.9181423338823434e-06,
      "epoch": 2.032215357458076,
      "step": 46050
    },
    {
      "loss": 1.1614,
      "grad_norm": 39.58248519897461,
      "learning_rate": 2.9148702135734444e-06,
      "epoch": 2.034421888790821,
      "step": 46100
    },
    {
      "loss": 1.0694,
      "grad_norm": 16.533790588378906,
      "learning_rate": 2.9115980932645453e-06,
      "epoch": 2.0366284201235656,
      "step": 46150
    },
    {
      "loss": 1.2449,
      "grad_norm": 28.83057975769043,
      "learning_rate": 2.9083259729556467e-06,
      "epoch": 2.0388349514563107,
      "step": 46200
    },
    {
      "loss": 1.1558,
      "grad_norm": 16.998762130737305,
      "learning_rate": 2.9050538526467476e-06,
      "epoch": 2.0410414827890557,
      "step": 46250
    },
    {
      "loss": 1.3101,
      "grad_norm": 16.3194522857666,
      "learning_rate": 2.9017817323378485e-06,
      "epoch": 2.0432480141218003,
      "step": 46300
    },
    {
      "loss": 1.1453,
      "grad_norm": 28.875722885131836,
      "learning_rate": 2.8985096120289495e-06,
      "epoch": 2.0454545454545454,
      "step": 46350
    },
    {
      "loss": 1.2329,
      "grad_norm": 18.386775970458984,
      "learning_rate": 2.89523749172005e-06,
      "epoch": 2.0476610767872905,
      "step": 46400
    },
    {
      "loss": 1.2643,
      "grad_norm": 25.311763763427734,
      "learning_rate": 2.891965371411151e-06,
      "epoch": 2.049867608120035,
      "step": 46450
    },
    {
      "loss": 1.1361,
      "grad_norm": 15.5642671585083,
      "learning_rate": 2.888693251102252e-06,
      "epoch": 2.05207413945278,
      "step": 46500
    },
    {
      "loss": 1.1448,
      "grad_norm": 42.185516357421875,
      "learning_rate": 2.8854211307933532e-06,
      "epoch": 2.0542806707855252,
      "step": 46550
    },
    {
      "loss": 1.102,
      "grad_norm": 26.823993682861328,
      "learning_rate": 2.882149010484454e-06,
      "epoch": 2.0564872021182703,
      "step": 46600
    },
    {
      "loss": 1.1807,
      "grad_norm": 25.682964324951172,
      "learning_rate": 2.878876890175555e-06,
      "epoch": 2.058693733451015,
      "step": 46650
    },
    {
      "loss": 1.2587,
      "grad_norm": 17.376365661621094,
      "learning_rate": 2.875604769866656e-06,
      "epoch": 2.06090026478376,
      "step": 46700
    },
    {
      "loss": 1.249,
      "grad_norm": 30.215185165405273,
      "learning_rate": 2.872332649557757e-06,
      "epoch": 2.063106796116505,
      "step": 46750
    },
    {
      "loss": 1.1623,
      "grad_norm": 32.22914123535156,
      "learning_rate": 2.869060529248858e-06,
      "epoch": 2.0653133274492497,
      "step": 46800
    },
    {
      "loss": 1.2429,
      "grad_norm": 31.24538803100586,
      "learning_rate": 2.865788408939959e-06,
      "epoch": 2.0675198587819947,
      "step": 46850
    },
    {
      "loss": 1.1606,
      "grad_norm": 26.657394409179688,
      "learning_rate": 2.86251628863106e-06,
      "epoch": 2.06972639011474,
      "step": 46900
    },
    {
      "loss": 1.1102,
      "grad_norm": 35.29161834716797,
      "learning_rate": 2.8592441683221607e-06,
      "epoch": 2.0719329214474844,
      "step": 46950
    },
    {
      "loss": 1.2336,
      "grad_norm": 17.83814239501953,
      "learning_rate": 2.8559720480132617e-06,
      "epoch": 2.0741394527802295,
      "step": 47000
    },
    {
      "loss": 1.2551,
      "grad_norm": 10.72620964050293,
      "learning_rate": 2.8526999277043626e-06,
      "epoch": 2.0763459841129746,
      "step": 47050
    },
    {
      "loss": 1.2386,
      "grad_norm": 20.579530715942383,
      "learning_rate": 2.8494278073954635e-06,
      "epoch": 2.078552515445719,
      "step": 47100
    },
    {
      "loss": 1.2049,
      "grad_norm": 39.859649658203125,
      "learning_rate": 2.8461556870865645e-06,
      "epoch": 2.0807590467784642,
      "step": 47150
    },
    {
      "loss": 1.1262,
      "grad_norm": 33.19674301147461,
      "learning_rate": 2.8428835667776654e-06,
      "epoch": 2.0829655781112093,
      "step": 47200
    },
    {
      "loss": 1.0226,
      "grad_norm": 34.15089416503906,
      "learning_rate": 2.8396114464687664e-06,
      "epoch": 2.085172109443954,
      "step": 47250
    },
    {
      "loss": 1.0802,
      "grad_norm": 19.63448715209961,
      "learning_rate": 2.8363393261598677e-06,
      "epoch": 2.087378640776699,
      "step": 47300
    },
    {
      "loss": 1.156,
      "grad_norm": 28.232545852661133,
      "learning_rate": 2.8330672058509687e-06,
      "epoch": 2.089585172109444,
      "step": 47350
    },
    {
      "loss": 1.1738,
      "grad_norm": 11.354400634765625,
      "learning_rate": 2.8297950855420696e-06,
      "epoch": 2.0917917034421887,
      "step": 47400
    },
    {
      "loss": 1.2388,
      "grad_norm": 24.34602165222168,
      "learning_rate": 2.8265229652331705e-06,
      "epoch": 2.0939982347749337,
      "step": 47450
    },
    {
      "loss": 1.0881,
      "grad_norm": 15.571423530578613,
      "learning_rate": 2.8232508449242715e-06,
      "epoch": 2.096204766107679,
      "step": 47500
    },
    {
      "loss": 1.1918,
      "grad_norm": 10.9227933883667,
      "learning_rate": 2.819978724615372e-06,
      "epoch": 2.098411297440424,
      "step": 47550
    },
    {
      "loss": 1.1872,
      "grad_norm": 27.61475944519043,
      "learning_rate": 2.816706604306473e-06,
      "epoch": 2.1006178287731685,
      "step": 47600
    },
    {
      "loss": 1.1344,
      "grad_norm": 21.394723892211914,
      "learning_rate": 2.8134344839975743e-06,
      "epoch": 2.1028243601059136,
      "step": 47650
    },
    {
      "loss": 0.9935,
      "grad_norm": 15.821016311645508,
      "learning_rate": 2.8101623636886752e-06,
      "epoch": 2.1050308914386586,
      "step": 47700
    },
    {
      "loss": 1.1425,
      "grad_norm": 36.0771484375,
      "learning_rate": 2.806890243379776e-06,
      "epoch": 2.1072374227714032,
      "step": 47750
    },
    {
      "loss": 1.3352,
      "grad_norm": 24.604520797729492,
      "learning_rate": 2.803618123070877e-06,
      "epoch": 2.1094439541041483,
      "step": 47800
    },
    {
      "loss": 1.2992,
      "grad_norm": 15.68787956237793,
      "learning_rate": 2.800346002761978e-06,
      "epoch": 2.1116504854368934,
      "step": 47850
    },
    {
      "loss": 1.2175,
      "grad_norm": 22.18707847595215,
      "learning_rate": 2.797073882453079e-06,
      "epoch": 2.113857016769638,
      "step": 47900
    },
    {
      "loss": 1.2169,
      "grad_norm": 18.798017501831055,
      "learning_rate": 2.79380176214418e-06,
      "epoch": 2.116063548102383,
      "step": 47950
    },
    {
      "loss": 1.3176,
      "grad_norm": 20.974647521972656,
      "learning_rate": 2.790529641835281e-06,
      "epoch": 2.118270079435128,
      "step": 48000
    },
    {
      "loss": 1.2473,
      "grad_norm": 24.224794387817383,
      "learning_rate": 2.787257521526382e-06,
      "epoch": 2.1204766107678727,
      "step": 48050
    },
    {
      "loss": 1.1813,
      "grad_norm": 21.06804656982422,
      "learning_rate": 2.7839854012174827e-06,
      "epoch": 2.122683142100618,
      "step": 48100
    },
    {
      "loss": 1.2859,
      "grad_norm": 26.91755485534668,
      "learning_rate": 2.7807132809085837e-06,
      "epoch": 2.124889673433363,
      "step": 48150
    },
    {
      "loss": 1.3287,
      "grad_norm": 14.942996978759766,
      "learning_rate": 2.7774411605996846e-06,
      "epoch": 2.1270962047661075,
      "step": 48200
    },
    {
      "loss": 1.1063,
      "grad_norm": 14.039791107177734,
      "learning_rate": 2.7741690402907855e-06,
      "epoch": 2.1293027360988526,
      "step": 48250
    },
    {
      "loss": 1.1687,
      "grad_norm": 21.4069766998291,
      "learning_rate": 2.7708969199818865e-06,
      "epoch": 2.1315092674315976,
      "step": 48300
    },
    {
      "loss": 1.1865,
      "grad_norm": 34.642356872558594,
      "learning_rate": 2.7676247996729874e-06,
      "epoch": 2.1337157987643423,
      "step": 48350
    },
    {
      "loss": 1.0942,
      "grad_norm": 23.557941436767578,
      "learning_rate": 2.7643526793640888e-06,
      "epoch": 2.1359223300970873,
      "step": 48400
    },
    {
      "loss": 1.1333,
      "grad_norm": 23.728097915649414,
      "learning_rate": 2.7610805590551897e-06,
      "epoch": 2.1381288614298324,
      "step": 48450
    },
    {
      "loss": 1.2674,
      "grad_norm": 25.588422775268555,
      "learning_rate": 2.7578084387462907e-06,
      "epoch": 2.1403353927625774,
      "step": 48500
    },
    {
      "loss": 1.0983,
      "grad_norm": 27.497814178466797,
      "learning_rate": 2.7545363184373916e-06,
      "epoch": 2.142541924095322,
      "step": 48550
    },
    {
      "loss": 1.1532,
      "grad_norm": 19.64242172241211,
      "learning_rate": 2.7512641981284925e-06,
      "epoch": 2.144748455428067,
      "step": 48600
    },
    {
      "loss": 1.197,
      "grad_norm": 26.076305389404297,
      "learning_rate": 2.747992077819593e-06,
      "epoch": 2.146954986760812,
      "step": 48650
    },
    {
      "loss": 1.2574,
      "grad_norm": 20.606935501098633,
      "learning_rate": 2.744719957510694e-06,
      "epoch": 2.149161518093557,
      "step": 48700
    },
    {
      "loss": 1.0889,
      "grad_norm": 7.688675403594971,
      "learning_rate": 2.7414478372017953e-06,
      "epoch": 2.151368049426302,
      "step": 48750
    },
    {
      "loss": 1.1599,
      "grad_norm": 24.56781768798828,
      "learning_rate": 2.7381757168928963e-06,
      "epoch": 2.153574580759047,
      "step": 48800
    },
    {
      "loss": 1.1502,
      "grad_norm": 19.682764053344727,
      "learning_rate": 2.7349035965839972e-06,
      "epoch": 2.1557811120917916,
      "step": 48850
    },
    {
      "loss": 1.1043,
      "grad_norm": 26.64209747314453,
      "learning_rate": 2.731631476275098e-06,
      "epoch": 2.1579876434245366,
      "step": 48900
    },
    {
      "loss": 1.0447,
      "grad_norm": 30.84337043762207,
      "learning_rate": 2.728359355966199e-06,
      "epoch": 2.1601941747572817,
      "step": 48950
    },
    {
      "loss": 1.2177,
      "grad_norm": 54.402191162109375,
      "learning_rate": 2.7250872356573e-06,
      "epoch": 2.1624007060900263,
      "step": 49000
    },
    {
      "loss": 1.1708,
      "grad_norm": 26.694211959838867,
      "learning_rate": 2.721815115348401e-06,
      "epoch": 2.1646072374227714,
      "step": 49050
    },
    {
      "loss": 1.1456,
      "grad_norm": 30.168275833129883,
      "learning_rate": 2.718542995039502e-06,
      "epoch": 2.1668137687555165,
      "step": 49100
    },
    {
      "loss": 1.2348,
      "grad_norm": 12.403615951538086,
      "learning_rate": 2.715270874730603e-06,
      "epoch": 2.169020300088261,
      "step": 49150
    },
    {
      "loss": 1.1081,
      "grad_norm": 18.015552520751953,
      "learning_rate": 2.711998754421704e-06,
      "epoch": 2.171226831421006,
      "step": 49200
    },
    {
      "loss": 1.2625,
      "grad_norm": 26.00575065612793,
      "learning_rate": 2.7087266341128047e-06,
      "epoch": 2.173433362753751,
      "step": 49250
    },
    {
      "loss": 1.2038,
      "grad_norm": 29.99835777282715,
      "learning_rate": 2.7054545138039057e-06,
      "epoch": 2.175639894086496,
      "step": 49300
    },
    {
      "loss": 1.1896,
      "grad_norm": 19.569400787353516,
      "learning_rate": 2.7021823934950066e-06,
      "epoch": 2.177846425419241,
      "step": 49350
    },
    {
      "loss": 1.233,
      "grad_norm": 45.6925163269043,
      "learning_rate": 2.6989102731861075e-06,
      "epoch": 2.180052956751986,
      "step": 49400
    },
    {
      "loss": 1.157,
      "grad_norm": 8.834189414978027,
      "learning_rate": 2.6956381528772085e-06,
      "epoch": 2.182259488084731,
      "step": 49450
    },
    {
      "loss": 1.218,
      "grad_norm": 29.60230827331543,
      "learning_rate": 2.69236603256831e-06,
      "epoch": 2.1844660194174756,
      "step": 49500
    },
    {
      "loss": 1.202,
      "grad_norm": 22.598670959472656,
      "learning_rate": 2.6890939122594108e-06,
      "epoch": 2.1866725507502207,
      "step": 49550
    },
    {
      "loss": 1.1717,
      "grad_norm": 41.53567886352539,
      "learning_rate": 2.6858217919505117e-06,
      "epoch": 2.1888790820829658,
      "step": 49600
    },
    {
      "loss": 1.2643,
      "grad_norm": 17.48468017578125,
      "learning_rate": 2.6825496716416127e-06,
      "epoch": 2.1910856134157104,
      "step": 49650
    },
    {
      "loss": 1.0464,
      "grad_norm": 16.742883682250977,
      "learning_rate": 2.6792775513327136e-06,
      "epoch": 2.1932921447484555,
      "step": 49700
    },
    {
      "loss": 1.127,
      "grad_norm": 20.833148956298828,
      "learning_rate": 2.6760054310238145e-06,
      "epoch": 2.1954986760812005,
      "step": 49750
    },
    {
      "loss": 1.262,
      "grad_norm": 28.875185012817383,
      "learning_rate": 2.672733310714915e-06,
      "epoch": 2.197705207413945,
      "step": 49800
    },
    {
      "loss": 1.2192,
      "grad_norm": 11.473128318786621,
      "learning_rate": 2.6694611904060164e-06,
      "epoch": 2.19991173874669,
      "step": 49850
    },
    {
      "loss": 1.2645,
      "grad_norm": 4.789980411529541,
      "learning_rate": 2.6661890700971173e-06,
      "epoch": 2.2021182700794353,
      "step": 49900
    },
    {
      "loss": 1.182,
      "grad_norm": 39.966121673583984,
      "learning_rate": 2.6629169497882183e-06,
      "epoch": 2.20432480141218,
      "step": 49950
    },
    {
      "loss": 1.142,
      "grad_norm": 25.71742057800293,
      "learning_rate": 2.6596448294793192e-06,
      "epoch": 2.206531332744925,
      "step": 50000
    },
    {
      "loss": 1.1432,
      "grad_norm": 27.729785919189453,
      "learning_rate": 2.65637270917042e-06,
      "epoch": 2.20873786407767,
      "step": 50050
    },
    {
      "loss": 1.2316,
      "grad_norm": 27.11564826965332,
      "learning_rate": 2.653100588861521e-06,
      "epoch": 2.2109443954104147,
      "step": 50100
    },
    {
      "loss": 1.186,
      "grad_norm": 19.932872772216797,
      "learning_rate": 2.649828468552622e-06,
      "epoch": 2.2131509267431597,
      "step": 50150
    },
    {
      "loss": 1.1977,
      "grad_norm": 18.917638778686523,
      "learning_rate": 2.646556348243723e-06,
      "epoch": 2.215357458075905,
      "step": 50200
    },
    {
      "loss": 1.1575,
      "grad_norm": 23.402437210083008,
      "learning_rate": 2.643284227934824e-06,
      "epoch": 2.2175639894086494,
      "step": 50250
    },
    {
      "loss": 1.1538,
      "grad_norm": 14.764177322387695,
      "learning_rate": 2.640012107625925e-06,
      "epoch": 2.2197705207413945,
      "step": 50300
    },
    {
      "loss": 1.0855,
      "grad_norm": 41.84907913208008,
      "learning_rate": 2.6367399873170258e-06,
      "epoch": 2.2219770520741395,
      "step": 50350
    },
    {
      "loss": 1.1188,
      "grad_norm": 16.660446166992188,
      "learning_rate": 2.6334678670081267e-06,
      "epoch": 2.2241835834068846,
      "step": 50400
    },
    {
      "loss": 1.2599,
      "grad_norm": 32.57265090942383,
      "learning_rate": 2.6301957466992277e-06,
      "epoch": 2.2263901147396292,
      "step": 50450
    },
    {
      "loss": 1.1515,
      "grad_norm": 10.463756561279297,
      "learning_rate": 2.6269236263903286e-06,
      "epoch": 2.2285966460723743,
      "step": 50500
    },
    {
      "loss": 1.11,
      "grad_norm": 49.05817413330078,
      "learning_rate": 2.6236515060814295e-06,
      "epoch": 2.2308031774051194,
      "step": 50550
    },
    {
      "loss": 1.256,
      "grad_norm": 30.078472137451172,
      "learning_rate": 2.620379385772531e-06,
      "epoch": 2.233009708737864,
      "step": 50600
    },
    {
      "loss": 1.1909,
      "grad_norm": 5.911118984222412,
      "learning_rate": 2.617107265463632e-06,
      "epoch": 2.235216240070609,
      "step": 50650
    },
    {
      "loss": 1.2693,
      "grad_norm": 20.865623474121094,
      "learning_rate": 2.6138351451547328e-06,
      "epoch": 2.237422771403354,
      "step": 50700
    },
    {
      "loss": 0.9749,
      "grad_norm": 25.667076110839844,
      "learning_rate": 2.6105630248458337e-06,
      "epoch": 2.2396293027360987,
      "step": 50750
    },
    {
      "loss": 1.1147,
      "grad_norm": 25.59583854675293,
      "learning_rate": 2.6072909045369347e-06,
      "epoch": 2.241835834068844,
      "step": 50800
    },
    {
      "loss": 1.3209,
      "grad_norm": 22.673952102661133,
      "learning_rate": 2.6040187842280356e-06,
      "epoch": 2.244042365401589,
      "step": 50850
    },
    {
      "loss": 1.2469,
      "grad_norm": 19.465171813964844,
      "learning_rate": 2.600746663919136e-06,
      "epoch": 2.2462488967343335,
      "step": 50900
    },
    {
      "loss": 1.2804,
      "grad_norm": 22.61818504333496,
      "learning_rate": 2.5974745436102375e-06,
      "epoch": 2.2484554280670785,
      "step": 50950
    },
    {
      "loss": 1.0978,
      "grad_norm": 19.18931007385254,
      "learning_rate": 2.5942024233013384e-06,
      "epoch": 2.2506619593998236,
      "step": 51000
    },
    {
      "loss": 1.19,
      "grad_norm": 12.878805160522461,
      "learning_rate": 2.5909303029924393e-06,
      "epoch": 2.2528684907325682,
      "step": 51050
    },
    {
      "loss": 1.2768,
      "grad_norm": 19.043872833251953,
      "learning_rate": 2.5876581826835403e-06,
      "epoch": 2.2550750220653133,
      "step": 51100
    },
    {
      "loss": 1.1659,
      "grad_norm": 48.68365478515625,
      "learning_rate": 2.5843860623746412e-06,
      "epoch": 2.2572815533980584,
      "step": 51150
    },
    {
      "loss": 1.1491,
      "grad_norm": 28.202499389648438,
      "learning_rate": 2.581113942065742e-06,
      "epoch": 2.259488084730803,
      "step": 51200
    },
    {
      "loss": 1.0751,
      "grad_norm": 43.24957275390625,
      "learning_rate": 2.577841821756843e-06,
      "epoch": 2.261694616063548,
      "step": 51250
    },
    {
      "loss": 1.129,
      "grad_norm": 20.348201751708984,
      "learning_rate": 2.574569701447944e-06,
      "epoch": 2.263901147396293,
      "step": 51300
    },
    {
      "loss": 1.2488,
      "grad_norm": 16.523361206054688,
      "learning_rate": 2.5712975811390454e-06,
      "epoch": 2.266107678729038,
      "step": 51350
    },
    {
      "loss": 1.1611,
      "grad_norm": 18.034313201904297,
      "learning_rate": 2.568025460830146e-06,
      "epoch": 2.268314210061783,
      "step": 51400
    },
    {
      "loss": 1.2422,
      "grad_norm": 25.792911529541016,
      "learning_rate": 2.564753340521247e-06,
      "epoch": 2.270520741394528,
      "step": 51450
    },
    {
      "loss": 1.1801,
      "grad_norm": 26.015283584594727,
      "learning_rate": 2.5614812202123478e-06,
      "epoch": 2.2727272727272725,
      "step": 51500
    },
    {
      "loss": 1.1083,
      "grad_norm": 22.867202758789062,
      "learning_rate": 2.5582090999034487e-06,
      "epoch": 2.2749338040600176,
      "step": 51550
    },
    {
      "loss": 1.1466,
      "grad_norm": 13.064117431640625,
      "learning_rate": 2.5549369795945497e-06,
      "epoch": 2.2771403353927626,
      "step": 51600
    },
    {
      "loss": 1.1323,
      "grad_norm": 21.303964614868164,
      "learning_rate": 2.5516648592856506e-06,
      "epoch": 2.2793468667255077,
      "step": 51650
    },
    {
      "loss": 1.21,
      "grad_norm": 14.910782814025879,
      "learning_rate": 2.548392738976752e-06,
      "epoch": 2.2815533980582523,
      "step": 51700
    },
    {
      "loss": 1.1057,
      "grad_norm": 18.162052154541016,
      "learning_rate": 2.545120618667853e-06,
      "epoch": 2.2837599293909974,
      "step": 51750
    },
    {
      "loss": 1.1658,
      "grad_norm": 25.322790145874023,
      "learning_rate": 2.541848498358954e-06,
      "epoch": 2.2859664607237424,
      "step": 51800
    },
    {
      "loss": 1.2332,
      "grad_norm": 18.060598373413086,
      "learning_rate": 2.5385763780500548e-06,
      "epoch": 2.288172992056487,
      "step": 51850
    },
    {
      "loss": 1.0232,
      "grad_norm": 13.645977020263672,
      "learning_rate": 2.5353042577411557e-06,
      "epoch": 2.290379523389232,
      "step": 51900
    },
    {
      "loss": 1.1364,
      "grad_norm": 17.71357536315918,
      "learning_rate": 2.5320321374322567e-06,
      "epoch": 2.292586054721977,
      "step": 51950
    },
    {
      "loss": 1.1613,
      "grad_norm": 20.82261848449707,
      "learning_rate": 2.5287600171233576e-06,
      "epoch": 2.294792586054722,
      "step": 52000
    },
    {
      "loss": 1.2347,
      "grad_norm": 18.69586944580078,
      "learning_rate": 2.5254878968144585e-06,
      "epoch": 2.296999117387467,
      "step": 52050
    },
    {
      "loss": 1.1779,
      "grad_norm": 28.24388313293457,
      "learning_rate": 2.5222157765055595e-06,
      "epoch": 2.299205648720212,
      "step": 52100
    },
    {
      "loss": 1.1842,
      "grad_norm": 18.63637924194336,
      "learning_rate": 2.5189436561966604e-06,
      "epoch": 2.3014121800529566,
      "step": 52150
    },
    {
      "loss": 1.2362,
      "grad_norm": 36.083595275878906,
      "learning_rate": 2.5156715358877613e-06,
      "epoch": 2.3036187113857016,
      "step": 52200
    },
    {
      "loss": 1.0374,
      "grad_norm": 25.238073348999023,
      "learning_rate": 2.5123994155788623e-06,
      "epoch": 2.3058252427184467,
      "step": 52250
    },
    {
      "loss": 1.2203,
      "grad_norm": 14.280339241027832,
      "learning_rate": 2.5091272952699632e-06,
      "epoch": 2.3080317740511918,
      "step": 52300
    },
    {
      "loss": 1.1677,
      "grad_norm": 16.747148513793945,
      "learning_rate": 2.505855174961064e-06,
      "epoch": 2.3102383053839364,
      "step": 52350
    },
    {
      "loss": 1.1214,
      "grad_norm": 25.66275978088379,
      "learning_rate": 2.5025830546521655e-06,
      "epoch": 2.3124448367166814,
      "step": 52400
    },
    {
      "loss": 1.2571,
      "grad_norm": 20.047584533691406,
      "learning_rate": 2.4993109343432665e-06,
      "epoch": 2.314651368049426,
      "step": 52450
    },
    {
      "loss": 1.1225,
      "grad_norm": 43.34012222290039,
      "learning_rate": 2.496038814034367e-06,
      "epoch": 2.316857899382171,
      "step": 52500
    },
    {
      "loss": 1.1797,
      "grad_norm": 23.846057891845703,
      "learning_rate": 2.492766693725468e-06,
      "epoch": 2.319064430714916,
      "step": 52550
    },
    {
      "loss": 1.2441,
      "grad_norm": 20.612863540649414,
      "learning_rate": 2.489494573416569e-06,
      "epoch": 2.3212709620476613,
      "step": 52600
    },
    {
      "loss": 1.2138,
      "grad_norm": 31.33572006225586,
      "learning_rate": 2.4862224531076698e-06,
      "epoch": 2.323477493380406,
      "step": 52650
    },
    {
      "loss": 1.165,
      "grad_norm": 21.813777923583984,
      "learning_rate": 2.4829503327987707e-06,
      "epoch": 2.325684024713151,
      "step": 52700
    },
    {
      "loss": 1.2951,
      "grad_norm": 21.97625160217285,
      "learning_rate": 2.4796782124898717e-06,
      "epoch": 2.327890556045896,
      "step": 52750
    },
    {
      "loss": 1.2207,
      "grad_norm": 29.569805145263672,
      "learning_rate": 2.476406092180973e-06,
      "epoch": 2.3300970873786406,
      "step": 52800
    },
    {
      "loss": 1.1918,
      "grad_norm": 20.760971069335938,
      "learning_rate": 2.473133971872074e-06,
      "epoch": 2.3323036187113857,
      "step": 52850
    },
    {
      "loss": 1.1989,
      "grad_norm": 32.146583557128906,
      "learning_rate": 2.469861851563175e-06,
      "epoch": 2.3345101500441308,
      "step": 52900
    },
    {
      "loss": 1.1918,
      "grad_norm": 17.266862869262695,
      "learning_rate": 2.466589731254276e-06,
      "epoch": 2.3367166813768754,
      "step": 52950
    },
    {
      "loss": 1.0253,
      "grad_norm": 26.049821853637695,
      "learning_rate": 2.4633176109453768e-06,
      "epoch": 2.3389232127096204,
      "step": 53000
    },
    {
      "loss": 1.0929,
      "grad_norm": 15.125266075134277,
      "learning_rate": 2.4600454906364777e-06,
      "epoch": 2.3411297440423655,
      "step": 53050
    },
    {
      "loss": 1.2239,
      "grad_norm": 18.692272186279297,
      "learning_rate": 2.4567733703275787e-06,
      "epoch": 2.34333627537511,
      "step": 53100
    },
    {
      "loss": 1.2238,
      "grad_norm": 13.920869827270508,
      "learning_rate": 2.4535012500186796e-06,
      "epoch": 2.345542806707855,
      "step": 53150
    },
    {
      "loss": 1.1591,
      "grad_norm": 21.760061264038086,
      "learning_rate": 2.4502291297097805e-06,
      "epoch": 2.3477493380406003,
      "step": 53200
    },
    {
      "loss": 1.2604,
      "grad_norm": 20.53011131286621,
      "learning_rate": 2.4469570094008815e-06,
      "epoch": 2.3499558693733453,
      "step": 53250
    },
    {
      "loss": 1.2179,
      "grad_norm": 17.106300354003906,
      "learning_rate": 2.4436848890919824e-06,
      "epoch": 2.35216240070609,
      "step": 53300
    },
    {
      "loss": 1.224,
      "grad_norm": 17.59023666381836,
      "learning_rate": 2.4404127687830833e-06,
      "epoch": 2.354368932038835,
      "step": 53350
    },
    {
      "loss": 1.1763,
      "grad_norm": 19.371566772460938,
      "learning_rate": 2.4371406484741843e-06,
      "epoch": 2.3565754633715796,
      "step": 53400
    },
    {
      "loss": 1.2669,
      "grad_norm": 26.116371154785156,
      "learning_rate": 2.4338685281652852e-06,
      "epoch": 2.3587819947043247,
      "step": 53450
    },
    {
      "loss": 1.159,
      "grad_norm": 26.441831588745117,
      "learning_rate": 2.4305964078563866e-06,
      "epoch": 2.3609885260370698,
      "step": 53500
    },
    {
      "loss": 1.0998,
      "grad_norm": 21.897478103637695,
      "learning_rate": 2.4273242875474875e-06,
      "epoch": 2.363195057369815,
      "step": 53550
    },
    {
      "loss": 1.0547,
      "grad_norm": 34.57830810546875,
      "learning_rate": 2.4240521672385885e-06,
      "epoch": 2.3654015887025595,
      "step": 53600
    },
    {
      "loss": 1.2651,
      "grad_norm": 24.817768096923828,
      "learning_rate": 2.420780046929689e-06,
      "epoch": 2.3676081200353045,
      "step": 53650
    },
    {
      "loss": 0.9844,
      "grad_norm": 31.47054672241211,
      "learning_rate": 2.41750792662079e-06,
      "epoch": 2.3698146513680496,
      "step": 53700
    },
    {
      "loss": 1.2825,
      "grad_norm": 25.5706844329834,
      "learning_rate": 2.414235806311891e-06,
      "epoch": 2.372021182700794,
      "step": 53750
    },
    {
      "loss": 1.4184,
      "grad_norm": 25.58424949645996,
      "learning_rate": 2.4109636860029918e-06,
      "epoch": 2.3742277140335393,
      "step": 53800
    },
    {
      "loss": 1.2306,
      "grad_norm": 24.938207626342773,
      "learning_rate": 2.4076915656940927e-06,
      "epoch": 2.3764342453662843,
      "step": 53850
    },
    {
      "loss": 1.1344,
      "grad_norm": 17.449474334716797,
      "learning_rate": 2.404419445385194e-06,
      "epoch": 2.378640776699029,
      "step": 53900
    },
    {
      "loss": 1.2338,
      "grad_norm": 14.833317756652832,
      "learning_rate": 2.401147325076295e-06,
      "epoch": 2.380847308031774,
      "step": 53950
    },
    {
      "loss": 1.0394,
      "grad_norm": 16.302322387695312,
      "learning_rate": 2.397875204767396e-06,
      "epoch": 2.383053839364519,
      "step": 54000
    },
    {
      "loss": 1.2934,
      "grad_norm": 25.20867347717285,
      "learning_rate": 2.394603084458497e-06,
      "epoch": 2.3852603706972637,
      "step": 54050
    },
    {
      "loss": 1.188,
      "grad_norm": 16.220144271850586,
      "learning_rate": 2.391330964149598e-06,
      "epoch": 2.3874669020300088,
      "step": 54100
    },
    {
      "loss": 1.1706,
      "grad_norm": 21.327510833740234,
      "learning_rate": 2.3880588438406988e-06,
      "epoch": 2.389673433362754,
      "step": 54150
    },
    {
      "loss": 1.2311,
      "grad_norm": 17.912471771240234,
      "learning_rate": 2.3847867235317997e-06,
      "epoch": 2.391879964695499,
      "step": 54200
    },
    {
      "loss": 1.301,
      "grad_norm": 36.01835250854492,
      "learning_rate": 2.3815146032229007e-06,
      "epoch": 2.3940864960282435,
      "step": 54250
    },
    {
      "loss": 1.1458,
      "grad_norm": 8.427715301513672,
      "learning_rate": 2.3782424829140016e-06,
      "epoch": 2.3962930273609886,
      "step": 54300
    },
    {
      "loss": 1.1425,
      "grad_norm": 30.55771827697754,
      "learning_rate": 2.3749703626051025e-06,
      "epoch": 2.398499558693733,
      "step": 54350
    },
    {
      "loss": 1.2542,
      "grad_norm": 16.214923858642578,
      "learning_rate": 2.3716982422962035e-06,
      "epoch": 2.4007060900264783,
      "step": 54400
    },
    {
      "loss": 1.2648,
      "grad_norm": 21.154508590698242,
      "learning_rate": 2.3684261219873044e-06,
      "epoch": 2.4029126213592233,
      "step": 54450
    },
    {
      "loss": 1.078,
      "grad_norm": 25.32659912109375,
      "learning_rate": 2.3651540016784053e-06,
      "epoch": 2.4051191526919684,
      "step": 54500
    },
    {
      "loss": 1.1207,
      "grad_norm": 19.886756896972656,
      "learning_rate": 2.3618818813695063e-06,
      "epoch": 2.407325684024713,
      "step": 54550
    },
    {
      "loss": 1.1242,
      "grad_norm": 18.100915908813477,
      "learning_rate": 2.3586097610606076e-06,
      "epoch": 2.409532215357458,
      "step": 54600
    },
    {
      "loss": 1.0899,
      "grad_norm": 18.223796844482422,
      "learning_rate": 2.3553376407517086e-06,
      "epoch": 2.411738746690203,
      "step": 54650
    },
    {
      "loss": 1.1417,
      "grad_norm": 15.614689826965332,
      "learning_rate": 2.3520655204428095e-06,
      "epoch": 2.413945278022948,
      "step": 54700
    },
    {
      "loss": 1.1364,
      "grad_norm": 32.63701629638672,
      "learning_rate": 2.3487934001339105e-06,
      "epoch": 2.416151809355693,
      "step": 54750
    },
    {
      "loss": 1.1784,
      "grad_norm": 25.250394821166992,
      "learning_rate": 2.345521279825011e-06,
      "epoch": 2.418358340688438,
      "step": 54800
    },
    {
      "loss": 1.2261,
      "grad_norm": 28.794483184814453,
      "learning_rate": 2.342249159516112e-06,
      "epoch": 2.4205648720211825,
      "step": 54850
    },
    {
      "loss": 1.188,
      "grad_norm": 33.26399230957031,
      "learning_rate": 2.338977039207213e-06,
      "epoch": 2.4227714033539276,
      "step": 54900
    },
    {
      "loss": 1.2147,
      "grad_norm": 7.601927280426025,
      "learning_rate": 2.3357049188983138e-06,
      "epoch": 2.4249779346866727,
      "step": 54950
    },
    {
      "loss": 1.0718,
      "grad_norm": 31.080358505249023,
      "learning_rate": 2.332432798589415e-06,
      "epoch": 2.4271844660194173,
      "step": 55000
    },
    {
      "loss": 1.2206,
      "grad_norm": 22.07943344116211,
      "learning_rate": 2.329160678280516e-06,
      "epoch": 2.4293909973521624,
      "step": 55050
    },
    {
      "loss": 1.0987,
      "grad_norm": 29.50687599182129,
      "learning_rate": 2.325888557971617e-06,
      "epoch": 2.4315975286849074,
      "step": 55100
    },
    {
      "loss": 1.155,
      "grad_norm": 31.042028427124023,
      "learning_rate": 2.322616437662718e-06,
      "epoch": 2.4338040600176525,
      "step": 55150
    },
    {
      "loss": 1.2402,
      "grad_norm": 24.454076766967773,
      "learning_rate": 2.319344317353819e-06,
      "epoch": 2.436010591350397,
      "step": 55200
    },
    {
      "loss": 1.1778,
      "grad_norm": 25.174484252929688,
      "learning_rate": 2.31607219704492e-06,
      "epoch": 2.438217122683142,
      "step": 55250
    },
    {
      "loss": 1.3299,
      "grad_norm": 23.952049255371094,
      "learning_rate": 2.3128000767360208e-06,
      "epoch": 2.440423654015887,
      "step": 55300
    },
    {
      "loss": 1.1764,
      "grad_norm": 27.542125701904297,
      "learning_rate": 2.3095279564271217e-06,
      "epoch": 2.442630185348632,
      "step": 55350
    },
    {
      "loss": 1.1184,
      "grad_norm": 14.109543800354004,
      "learning_rate": 2.3062558361182227e-06,
      "epoch": 2.444836716681377,
      "step": 55400
    },
    {
      "loss": 1.0486,
      "grad_norm": 28.03803253173828,
      "learning_rate": 2.3029837158093236e-06,
      "epoch": 2.447043248014122,
      "step": 55450
    },
    {
      "loss": 0.9869,
      "grad_norm": 39.82667541503906,
      "learning_rate": 2.2997115955004245e-06,
      "epoch": 2.4492497793468666,
      "step": 55500
    },
    {
      "loss": 1.1675,
      "grad_norm": 12.390617370605469,
      "learning_rate": 2.2964394751915255e-06,
      "epoch": 2.4514563106796117,
      "step": 55550
    },
    {
      "loss": 1.0707,
      "grad_norm": 24.07919692993164,
      "learning_rate": 2.2931673548826264e-06,
      "epoch": 2.4536628420123567,
      "step": 55600
    },
    {
      "loss": 1.0294,
      "grad_norm": 20.1710147857666,
      "learning_rate": 2.2898952345737273e-06,
      "epoch": 2.4558693733451014,
      "step": 55650
    },
    {
      "loss": 1.1123,
      "grad_norm": 23.52911376953125,
      "learning_rate": 2.2866231142648287e-06,
      "epoch": 2.4580759046778464,
      "step": 55700
    },
    {
      "loss": 1.0411,
      "grad_norm": 22.73066520690918,
      "learning_rate": 2.2833509939559296e-06,
      "epoch": 2.4602824360105915,
      "step": 55750
    },
    {
      "loss": 1.2236,
      "grad_norm": 10.719816207885742,
      "learning_rate": 2.2800788736470306e-06,
      "epoch": 2.462488967343336,
      "step": 55800
    },
    {
      "loss": 1.0939,
      "grad_norm": 29.94329071044922,
      "learning_rate": 2.2768067533381315e-06,
      "epoch": 2.464695498676081,
      "step": 55850
    },
    {
      "loss": 1.2468,
      "grad_norm": 10.134987831115723,
      "learning_rate": 2.273534633029232e-06,
      "epoch": 2.4669020300088262,
      "step": 55900
    },
    {
      "loss": 1.2204,
      "grad_norm": 16.57068634033203,
      "learning_rate": 2.270262512720333e-06,
      "epoch": 2.469108561341571,
      "step": 55950
    },
    {
      "loss": 1.2168,
      "grad_norm": 17.6002254486084,
      "learning_rate": 2.266990392411434e-06,
      "epoch": 2.471315092674316,
      "step": 56000
    },
    {
      "loss": 1.1951,
      "grad_norm": 16.441089630126953,
      "learning_rate": 2.263718272102535e-06,
      "epoch": 2.473521624007061,
      "step": 56050
    },
    {
      "loss": 1.006,
      "grad_norm": 23.248077392578125,
      "learning_rate": 2.260446151793636e-06,
      "epoch": 2.475728155339806,
      "step": 56100
    },
    {
      "loss": 1.1552,
      "grad_norm": 37.28020095825195,
      "learning_rate": 2.257174031484737e-06,
      "epoch": 2.4779346866725507,
      "step": 56150
    },
    {
      "loss": 1.0638,
      "grad_norm": 20.604251861572266,
      "learning_rate": 2.253901911175838e-06,
      "epoch": 2.4801412180052957,
      "step": 56200
    },
    {
      "loss": 1.133,
      "grad_norm": 24.53850746154785,
      "learning_rate": 2.250629790866939e-06,
      "epoch": 2.4823477493380404,
      "step": 56250
    },
    {
      "loss": 1.1967,
      "grad_norm": 16.8745174407959,
      "learning_rate": 2.24735767055804e-06,
      "epoch": 2.4845542806707854,
      "step": 56300
    },
    {
      "loss": 1.26,
      "grad_norm": 25.82158851623535,
      "learning_rate": 2.244085550249141e-06,
      "epoch": 2.4867608120035305,
      "step": 56350
    },
    {
      "loss": 1.1189,
      "grad_norm": 27.067235946655273,
      "learning_rate": 2.240813429940242e-06,
      "epoch": 2.4889673433362756,
      "step": 56400
    },
    {
      "loss": 1.128,
      "grad_norm": 24.34698486328125,
      "learning_rate": 2.2375413096313428e-06,
      "epoch": 2.49117387466902,
      "step": 56450
    },
    {
      "loss": 1.1112,
      "grad_norm": 67.57962036132812,
      "learning_rate": 2.2342691893224437e-06,
      "epoch": 2.4933804060017652,
      "step": 56500
    },
    {
      "loss": 1.0086,
      "grad_norm": 17.844453811645508,
      "learning_rate": 2.2309970690135447e-06,
      "epoch": 2.4955869373345103,
      "step": 56550
    },
    {
      "loss": 1.1072,
      "grad_norm": 20.365795135498047,
      "learning_rate": 2.2277249487046456e-06,
      "epoch": 2.497793468667255,
      "step": 56600
    },
    {
      "loss": 1.1428,
      "grad_norm": 18.100465774536133,
      "learning_rate": 2.2244528283957465e-06,
      "epoch": 2.5,
      "step": 56650
    },
    {
      "loss": 1.1996,
      "grad_norm": 49.251644134521484,
      "learning_rate": 2.2211807080868475e-06,
      "epoch": 2.502206531332745,
      "step": 56700
    },
    {
      "loss": 1.0917,
      "grad_norm": 33.235713958740234,
      "learning_rate": 2.2179085877779484e-06,
      "epoch": 2.5044130626654897,
      "step": 56750
    },
    {
      "loss": 1.1654,
      "grad_norm": 32.770450592041016,
      "learning_rate": 2.2146364674690498e-06,
      "epoch": 2.5066195939982348,
      "step": 56800
    },
    {
      "loss": 1.1729,
      "grad_norm": 25.958984375,
      "learning_rate": 2.2113643471601507e-06,
      "epoch": 2.50882612533098,
      "step": 56850
    },
    {
      "loss": 1.1671,
      "grad_norm": 48.881858825683594,
      "learning_rate": 2.2080922268512516e-06,
      "epoch": 2.5110326566637244,
      "step": 56900
    },
    {
      "loss": 1.1165,
      "grad_norm": 25.073820114135742,
      "learning_rate": 2.2048201065423526e-06,
      "epoch": 2.5132391879964695,
      "step": 56950
    },
    {
      "loss": 1.1733,
      "grad_norm": 19.59745979309082,
      "learning_rate": 2.2015479862334535e-06,
      "epoch": 2.5154457193292146,
      "step": 57000
    },
    {
      "loss": 1.2392,
      "grad_norm": 16.718168258666992,
      "learning_rate": 2.198275865924554e-06,
      "epoch": 2.5176522506619596,
      "step": 57050
    },
    {
      "loss": 1.1659,
      "grad_norm": 9.647706031799316,
      "learning_rate": 2.195003745615655e-06,
      "epoch": 2.5198587819947043,
      "step": 57100
    },
    {
      "loss": 1.179,
      "grad_norm": 11.009333610534668,
      "learning_rate": 2.191731625306756e-06,
      "epoch": 2.5220653133274493,
      "step": 57150
    },
    {
      "loss": 1.1829,
      "grad_norm": 20.437606811523438,
      "learning_rate": 2.1884595049978573e-06,
      "epoch": 2.524271844660194,
      "step": 57200
    },
    {
      "loss": 1.0091,
      "grad_norm": 13.383108139038086,
      "learning_rate": 2.185187384688958e-06,
      "epoch": 2.526478375992939,
      "step": 57250
    },
    {
      "loss": 1.165,
      "grad_norm": 13.075759887695312,
      "learning_rate": 2.181915264380059e-06,
      "epoch": 2.528684907325684,
      "step": 57300
    },
    {
      "loss": 1.193,
      "grad_norm": 23.511260986328125,
      "learning_rate": 2.17864314407116e-06,
      "epoch": 2.530891438658429,
      "step": 57350
    },
    {
      "loss": 1.09,
      "grad_norm": 20.86782455444336,
      "learning_rate": 2.175371023762261e-06,
      "epoch": 2.5330979699911738,
      "step": 57400
    },
    {
      "loss": 1.2075,
      "grad_norm": 33.15971374511719,
      "learning_rate": 2.172098903453362e-06,
      "epoch": 2.535304501323919,
      "step": 57450
    },
    {
      "loss": 1.2153,
      "grad_norm": 18.52787208557129,
      "learning_rate": 2.168826783144463e-06,
      "epoch": 2.537511032656664,
      "step": 57500
    },
    {
      "loss": 1.0568,
      "grad_norm": 31.290781021118164,
      "learning_rate": 2.165554662835564e-06,
      "epoch": 2.5397175639894085,
      "step": 57550
    },
    {
      "loss": 1.1242,
      "grad_norm": 42.86588668823242,
      "learning_rate": 2.1622825425266648e-06,
      "epoch": 2.5419240953221536,
      "step": 57600
    },
    {
      "loss": 1.1759,
      "grad_norm": 19.58753776550293,
      "learning_rate": 2.1590104222177657e-06,
      "epoch": 2.5441306266548986,
      "step": 57650
    },
    {
      "loss": 1.2112,
      "grad_norm": 20.325632095336914,
      "learning_rate": 2.1557383019088667e-06,
      "epoch": 2.5463371579876433,
      "step": 57700
    },
    {
      "loss": 1.0668,
      "grad_norm": 20.1483154296875,
      "learning_rate": 2.1524661815999676e-06,
      "epoch": 2.5485436893203883,
      "step": 57750
    },
    {
      "loss": 1.1395,
      "grad_norm": 24.9744930267334,
      "learning_rate": 2.1491940612910685e-06,
      "epoch": 2.5507502206531334,
      "step": 57800
    },
    {
      "loss": 1.2826,
      "grad_norm": 28.140853881835938,
      "learning_rate": 2.1459219409821695e-06,
      "epoch": 2.552956751985878,
      "step": 57850
    },
    {
      "loss": 0.9814,
      "grad_norm": 41.866703033447266,
      "learning_rate": 2.142649820673271e-06,
      "epoch": 2.555163283318623,
      "step": 57900
    },
    {
      "loss": 1.1206,
      "grad_norm": 27.98712158203125,
      "learning_rate": 2.1393777003643718e-06,
      "epoch": 2.557369814651368,
      "step": 57950
    },
    {
      "loss": 1.0629,
      "grad_norm": 16.20729637145996,
      "learning_rate": 2.1361055800554727e-06,
      "epoch": 2.559576345984113,
      "step": 58000
    },
    {
      "loss": 1.1002,
      "grad_norm": 42.76677703857422,
      "learning_rate": 2.1328334597465736e-06,
      "epoch": 2.561782877316858,
      "step": 58050
    },
    {
      "loss": 1.0712,
      "grad_norm": 31.995847702026367,
      "learning_rate": 2.1295613394376746e-06,
      "epoch": 2.563989408649603,
      "step": 58100
    },
    {
      "loss": 1.0472,
      "grad_norm": 87.2163314819336,
      "learning_rate": 2.126289219128775e-06,
      "epoch": 2.5661959399823475,
      "step": 58150
    },
    {
      "loss": 1.0874,
      "grad_norm": 14.56381893157959,
      "learning_rate": 2.123017098819876e-06,
      "epoch": 2.5684024713150926,
      "step": 58200
    },
    {
      "loss": 1.178,
      "grad_norm": 39.58084487915039,
      "learning_rate": 2.119744978510977e-06,
      "epoch": 2.5706090026478376,
      "step": 58250
    },
    {
      "loss": 1.1858,
      "grad_norm": 26.845552444458008,
      "learning_rate": 2.1164728582020783e-06,
      "epoch": 2.5728155339805827,
      "step": 58300
    },
    {
      "loss": 1.1861,
      "grad_norm": 22.21795082092285,
      "learning_rate": 2.1132007378931793e-06,
      "epoch": 2.5750220653133273,
      "step": 58350
    },
    {
      "loss": 1.0749,
      "grad_norm": 20.869726181030273,
      "learning_rate": 2.10992861758428e-06,
      "epoch": 2.5772285966460724,
      "step": 58400
    },
    {
      "loss": 1.2629,
      "grad_norm": 23.051542282104492,
      "learning_rate": 2.106656497275381e-06,
      "epoch": 2.579435127978817,
      "step": 58450
    },
    {
      "loss": 1.3239,
      "grad_norm": 32.21169662475586,
      "learning_rate": 2.103384376966482e-06,
      "epoch": 2.581641659311562,
      "step": 58500
    },
    {
      "loss": 1.0837,
      "grad_norm": 19.747913360595703,
      "learning_rate": 2.100112256657583e-06,
      "epoch": 2.583848190644307,
      "step": 58550
    },
    {
      "loss": 1.1371,
      "grad_norm": 33.306304931640625,
      "learning_rate": 2.096840136348684e-06,
      "epoch": 2.586054721977052,
      "step": 58600
    },
    {
      "loss": 1.1612,
      "grad_norm": 16.085901260375977,
      "learning_rate": 2.093568016039785e-06,
      "epoch": 2.588261253309797,
      "step": 58650
    },
    {
      "loss": 1.1622,
      "grad_norm": 30.357635498046875,
      "learning_rate": 2.090295895730886e-06,
      "epoch": 2.590467784642542,
      "step": 58700
    },
    {
      "loss": 1.1239,
      "grad_norm": 27.586652755737305,
      "learning_rate": 2.0870237754219868e-06,
      "epoch": 2.592674315975287,
      "step": 58750
    },
    {
      "loss": 1.2094,
      "grad_norm": 15.818526268005371,
      "learning_rate": 2.0837516551130877e-06,
      "epoch": 2.5948808473080316,
      "step": 58800
    },
    {
      "loss": 1.2523,
      "grad_norm": 18.276567459106445,
      "learning_rate": 2.0804795348041887e-06,
      "epoch": 2.5970873786407767,
      "step": 58850
    },
    {
      "loss": 1.1001,
      "grad_norm": 22.333751678466797,
      "learning_rate": 2.0772074144952896e-06,
      "epoch": 2.5992939099735217,
      "step": 58900
    },
    {
      "loss": 1.1132,
      "grad_norm": 6.975386619567871,
      "learning_rate": 2.0739352941863905e-06,
      "epoch": 2.601500441306267,
      "step": 58950
    },
    {
      "loss": 1.1281,
      "grad_norm": 14.599218368530273,
      "learning_rate": 2.070663173877492e-06,
      "epoch": 2.6037069726390114,
      "step": 59000
    },
    {
      "loss": 1.1015,
      "grad_norm": 36.779903411865234,
      "learning_rate": 2.067391053568593e-06,
      "epoch": 2.6059135039717565,
      "step": 59050
    },
    {
      "loss": 1.0564,
      "grad_norm": 21.365217208862305,
      "learning_rate": 2.0641189332596938e-06,
      "epoch": 2.608120035304501,
      "step": 59100
    },
    {
      "loss": 1.2707,
      "grad_norm": 18.657007217407227,
      "learning_rate": 2.0608468129507947e-06,
      "epoch": 2.610326566637246,
      "step": 59150
    },
    {
      "loss": 1.1952,
      "grad_norm": 25.901386260986328,
      "learning_rate": 2.0575746926418956e-06,
      "epoch": 2.6125330979699912,
      "step": 59200
    },
    {
      "loss": 0.999,
      "grad_norm": 18.82260513305664,
      "learning_rate": 2.0543025723329966e-06,
      "epoch": 2.6147396293027363,
      "step": 59250
    },
    {
      "loss": 1.1964,
      "grad_norm": 25.326366424560547,
      "learning_rate": 2.051030452024097e-06,
      "epoch": 2.616946160635481,
      "step": 59300
    },
    {
      "loss": 1.0382,
      "grad_norm": 25.604080200195312,
      "learning_rate": 2.047758331715198e-06,
      "epoch": 2.619152691968226,
      "step": 59350
    },
    {
      "loss": 1.0504,
      "grad_norm": 12.565322875976562,
      "learning_rate": 2.0444862114062994e-06,
      "epoch": 2.6213592233009706,
      "step": 59400
    },
    {
      "loss": 1.0922,
      "grad_norm": 25.282922744750977,
      "learning_rate": 2.0412140910974003e-06,
      "epoch": 2.6235657546337157,
      "step": 59450
    },
    {
      "loss": 1.287,
      "grad_norm": 67.79703521728516,
      "learning_rate": 2.0379419707885013e-06,
      "epoch": 2.6257722859664607,
      "step": 59500
    },
    {
      "loss": 1.2047,
      "grad_norm": 24.29188346862793,
      "learning_rate": 2.034669850479602e-06,
      "epoch": 2.627978817299206,
      "step": 59550
    },
    {
      "loss": 1.1819,
      "grad_norm": 30.536197662353516,
      "learning_rate": 2.031397730170703e-06,
      "epoch": 2.6301853486319504,
      "step": 59600
    },
    {
      "loss": 1.1359,
      "grad_norm": 45.02919006347656,
      "learning_rate": 2.028125609861804e-06,
      "epoch": 2.6323918799646955,
      "step": 59650
    },
    {
      "loss": 1.1203,
      "grad_norm": 14.628766059875488,
      "learning_rate": 2.024853489552905e-06,
      "epoch": 2.6345984112974405,
      "step": 59700
    },
    {
      "loss": 1.027,
      "grad_norm": 29.858600616455078,
      "learning_rate": 2.021581369244006e-06,
      "epoch": 2.636804942630185,
      "step": 59750
    },
    {
      "loss": 1.1645,
      "grad_norm": 19.354354858398438,
      "learning_rate": 2.018309248935107e-06,
      "epoch": 2.6390114739629302,
      "step": 59800
    },
    {
      "loss": 1.1577,
      "grad_norm": 24.167110443115234,
      "learning_rate": 2.015037128626208e-06,
      "epoch": 2.6412180052956753,
      "step": 59850
    },
    {
      "loss": 1.0649,
      "grad_norm": 28.40052032470703,
      "learning_rate": 2.0117650083173088e-06,
      "epoch": 2.6434245366284204,
      "step": 59900
    },
    {
      "loss": 1.1556,
      "grad_norm": 19.725202560424805,
      "learning_rate": 2.0084928880084097e-06,
      "epoch": 2.645631067961165,
      "step": 59950
    },
    {
      "loss": 1.1033,
      "grad_norm": 26.301027297973633,
      "learning_rate": 2.0052207676995107e-06,
      "epoch": 2.64783759929391,
      "step": 60000
    },
    {
      "loss": 1.115,
      "grad_norm": 22.76738166809082,
      "learning_rate": 2.0019486473906116e-06,
      "epoch": 2.6500441306266547,
      "step": 60050
    },
    {
      "loss": 1.1776,
      "grad_norm": 18.6464900970459,
      "learning_rate": 1.998676527081713e-06,
      "epoch": 2.6522506619593997,
      "step": 60100
    },
    {
      "loss": 1.1614,
      "grad_norm": 26.703432083129883,
      "learning_rate": 1.995404406772814e-06,
      "epoch": 2.654457193292145,
      "step": 60150
    },
    {
      "loss": 1.0792,
      "grad_norm": 24.56484603881836,
      "learning_rate": 1.992132286463915e-06,
      "epoch": 2.65666372462489,
      "step": 60200
    },
    {
      "loss": 0.9846,
      "grad_norm": 18.31639289855957,
      "learning_rate": 1.9888601661550158e-06,
      "epoch": 2.6588702559576345,
      "step": 60250
    },
    {
      "loss": 1.1145,
      "grad_norm": 10.786421775817871,
      "learning_rate": 1.9855880458461167e-06,
      "epoch": 2.6610767872903796,
      "step": 60300
    },
    {
      "loss": 1.1382,
      "grad_norm": 19.981287002563477,
      "learning_rate": 1.9823159255372176e-06,
      "epoch": 2.663283318623124,
      "step": 60350
    },
    {
      "loss": 1.1518,
      "grad_norm": 20.175540924072266,
      "learning_rate": 1.9790438052283186e-06,
      "epoch": 2.6654898499558692,
      "step": 60400
    },
    {
      "loss": 1.0213,
      "grad_norm": 32.289268493652344,
      "learning_rate": 1.9757716849194195e-06,
      "epoch": 2.6676963812886143,
      "step": 60450
    },
    {
      "loss": 1.1185,
      "grad_norm": 21.84658432006836,
      "learning_rate": 1.9724995646105205e-06,
      "epoch": 2.6699029126213594,
      "step": 60500
    },
    {
      "loss": 1.059,
      "grad_norm": 16.686351776123047,
      "learning_rate": 1.9692274443016214e-06,
      "epoch": 2.672109443954104,
      "step": 60550
    },
    {
      "loss": 1.0873,
      "grad_norm": 31.22789192199707,
      "learning_rate": 1.9659553239927223e-06,
      "epoch": 2.674315975286849,
      "step": 60600
    },
    {
      "loss": 1.0972,
      "grad_norm": 40.009979248046875,
      "learning_rate": 1.9626832036838233e-06,
      "epoch": 2.676522506619594,
      "step": 60650
    },
    {
      "loss": 1.0486,
      "grad_norm": 22.707061767578125,
      "learning_rate": 1.959411083374924e-06,
      "epoch": 2.6787290379523387,
      "step": 60700
    },
    {
      "loss": 1.1804,
      "grad_norm": 29.46249008178711,
      "learning_rate": 1.956138963066025e-06,
      "epoch": 2.680935569285084,
      "step": 60750
    },
    {
      "loss": 1.1908,
      "grad_norm": 27.613069534301758,
      "learning_rate": 1.952866842757126e-06,
      "epoch": 2.683142100617829,
      "step": 60800
    },
    {
      "loss": 1.038,
      "grad_norm": 8.040393829345703,
      "learning_rate": 1.9495947224482274e-06,
      "epoch": 2.685348631950574,
      "step": 60850
    },
    {
      "loss": 1.1303,
      "grad_norm": 18.679319381713867,
      "learning_rate": 1.946322602139328e-06,
      "epoch": 2.6875551632833186,
      "step": 60900
    },
    {
      "loss": 1.0767,
      "grad_norm": 17.472702026367188,
      "learning_rate": 1.943050481830429e-06,
      "epoch": 2.6897616946160636,
      "step": 60950
    },
    {
      "loss": 1.14,
      "grad_norm": 36.778228759765625,
      "learning_rate": 1.93977836152153e-06,
      "epoch": 2.6919682259488082,
      "step": 61000
    },
    {
      "loss": 1.0129,
      "grad_norm": 35.636863708496094,
      "learning_rate": 1.9365062412126308e-06,
      "epoch": 2.6941747572815533,
      "step": 61050
    },
    {
      "loss": 1.1545,
      "grad_norm": 16.84021759033203,
      "learning_rate": 1.9332341209037317e-06,
      "epoch": 2.6963812886142984,
      "step": 61100
    },
    {
      "loss": 1.0502,
      "grad_norm": 13.901752471923828,
      "learning_rate": 1.9299620005948327e-06,
      "epoch": 2.6985878199470434,
      "step": 61150
    },
    {
      "loss": 1.2398,
      "grad_norm": 33.93457794189453,
      "learning_rate": 1.926689880285934e-06,
      "epoch": 2.700794351279788,
      "step": 61200
    },
    {
      "loss": 1.0937,
      "grad_norm": 23.57395362854004,
      "learning_rate": 1.923417759977035e-06,
      "epoch": 2.703000882612533,
      "step": 61250
    },
    {
      "loss": 1.2252,
      "grad_norm": 34.58843231201172,
      "learning_rate": 1.920145639668136e-06,
      "epoch": 2.7052074139452778,
      "step": 61300
    },
    {
      "loss": 1.0762,
      "grad_norm": 23.918331146240234,
      "learning_rate": 1.916873519359237e-06,
      "epoch": 2.707413945278023,
      "step": 61350
    },
    {
      "loss": 1.0415,
      "grad_norm": 16.467212677001953,
      "learning_rate": 1.9136013990503378e-06,
      "epoch": 2.709620476610768,
      "step": 61400
    },
    {
      "loss": 1.0828,
      "grad_norm": 27.96018409729004,
      "learning_rate": 1.9103292787414387e-06,
      "epoch": 2.711827007943513,
      "step": 61450
    },
    {
      "loss": 1.1959,
      "grad_norm": 38.416534423828125,
      "learning_rate": 1.9070571584325394e-06,
      "epoch": 2.7140335392762576,
      "step": 61500
    },
    {
      "loss": 1.1927,
      "grad_norm": 33.204891204833984,
      "learning_rate": 1.9037850381236408e-06,
      "epoch": 2.7162400706090026,
      "step": 61550
    },
    {
      "loss": 1.1987,
      "grad_norm": 27.283493041992188,
      "learning_rate": 1.9005129178147415e-06,
      "epoch": 2.7184466019417477,
      "step": 61600
    },
    {
      "loss": 1.2338,
      "grad_norm": 23.484111785888672,
      "learning_rate": 1.8972407975058425e-06,
      "epoch": 2.7206531332744923,
      "step": 61650
    },
    {
      "loss": 1.211,
      "grad_norm": 25.438203811645508,
      "learning_rate": 1.8939686771969434e-06,
      "epoch": 2.7228596646072374,
      "step": 61700
    },
    {
      "loss": 1.2101,
      "grad_norm": 26.105634689331055,
      "learning_rate": 1.8906965568880443e-06,
      "epoch": 2.7250661959399824,
      "step": 61750
    },
    {
      "loss": 1.095,
      "grad_norm": 18.40983009338379,
      "learning_rate": 1.8874244365791453e-06,
      "epoch": 2.7272727272727275,
      "step": 61800
    },
    {
      "loss": 1.1501,
      "grad_norm": 34.45099639892578,
      "learning_rate": 1.8841523162702462e-06,
      "epoch": 2.729479258605472,
      "step": 61850
    },
    {
      "loss": 1.1733,
      "grad_norm": 9.309779167175293,
      "learning_rate": 1.8808801959613471e-06,
      "epoch": 2.731685789938217,
      "step": 61900
    },
    {
      "loss": 1.1465,
      "grad_norm": 71.0528564453125,
      "learning_rate": 1.8776080756524483e-06,
      "epoch": 2.733892321270962,
      "step": 61950
    },
    {
      "loss": 1.0662,
      "grad_norm": 22.03141975402832,
      "learning_rate": 1.8743359553435492e-06,
      "epoch": 2.736098852603707,
      "step": 62000
    },
    {
      "loss": 1.0071,
      "grad_norm": 16.037092208862305,
      "learning_rate": 1.8710638350346502e-06,
      "epoch": 2.738305383936452,
      "step": 62050
    },
    {
      "loss": 1.2157,
      "grad_norm": 20.938379287719727,
      "learning_rate": 1.8677917147257511e-06,
      "epoch": 2.740511915269197,
      "step": 62100
    },
    {
      "loss": 1.1893,
      "grad_norm": 22.189655303955078,
      "learning_rate": 1.864519594416852e-06,
      "epoch": 2.7427184466019416,
      "step": 62150
    },
    {
      "loss": 1.0225,
      "grad_norm": 28.956283569335938,
      "learning_rate": 1.861247474107953e-06,
      "epoch": 2.7449249779346867,
      "step": 62200
    },
    {
      "loss": 1.0296,
      "grad_norm": 9.826994895935059,
      "learning_rate": 1.8579753537990537e-06,
      "epoch": 2.7471315092674313,
      "step": 62250
    },
    {
      "loss": 1.2291,
      "grad_norm": 73.77635192871094,
      "learning_rate": 1.854703233490155e-06,
      "epoch": 2.7493380406001764,
      "step": 62300
    },
    {
      "loss": 1.0707,
      "grad_norm": 12.566363334655762,
      "learning_rate": 1.851431113181256e-06,
      "epoch": 2.7515445719329215,
      "step": 62350
    },
    {
      "loss": 1.0646,
      "grad_norm": 9.60952091217041,
      "learning_rate": 1.848158992872357e-06,
      "epoch": 2.7537511032656665,
      "step": 62400
    },
    {
      "loss": 1.1906,
      "grad_norm": 81.67378997802734,
      "learning_rate": 1.8448868725634579e-06,
      "epoch": 2.755957634598411,
      "step": 62450
    },
    {
      "loss": 1.0811,
      "grad_norm": 20.813339233398438,
      "learning_rate": 1.8416147522545586e-06,
      "epoch": 2.758164165931156,
      "step": 62500
    },
    {
      "loss": 1.1035,
      "grad_norm": 30.261249542236328,
      "learning_rate": 1.8383426319456596e-06,
      "epoch": 2.7603706972639013,
      "step": 62550
    },
    {
      "loss": 1.2642,
      "grad_norm": 28.730426788330078,
      "learning_rate": 1.8350705116367605e-06,
      "epoch": 2.762577228596646,
      "step": 62600
    },
    {
      "loss": 1.09,
      "grad_norm": 22.512422561645508,
      "learning_rate": 1.8317983913278619e-06,
      "epoch": 2.764783759929391,
      "step": 62650
    },
    {
      "loss": 1.1336,
      "grad_norm": 14.78815746307373,
      "learning_rate": 1.8285262710189626e-06,
      "epoch": 2.766990291262136,
      "step": 62700
    },
    {
      "loss": 1.0941,
      "grad_norm": 24.943378448486328,
      "learning_rate": 1.8252541507100635e-06,
      "epoch": 2.769196822594881,
      "step": 62750
    },
    {
      "loss": 1.1196,
      "grad_norm": 17.458906173706055,
      "learning_rate": 1.8219820304011645e-06,
      "epoch": 2.7714033539276257,
      "step": 62800
    },
    {
      "loss": 1.157,
      "grad_norm": 13.876550674438477,
      "learning_rate": 1.8187099100922654e-06,
      "epoch": 2.7736098852603708,
      "step": 62850
    },
    {
      "loss": 1.1292,
      "grad_norm": 18.39837074279785,
      "learning_rate": 1.8154377897833663e-06,
      "epoch": 2.7758164165931154,
      "step": 62900
    },
    {
      "loss": 1.0375,
      "grad_norm": 22.314180374145508,
      "learning_rate": 1.8121656694744673e-06,
      "epoch": 2.7780229479258605,
      "step": 62950
    },
    {
      "loss": 1.1887,
      "grad_norm": 65.36487579345703,
      "learning_rate": 1.8088935491655682e-06,
      "epoch": 2.7802294792586055,
      "step": 63000
    },
    {
      "loss": 1.0319,
      "grad_norm": 33.19770050048828,
      "learning_rate": 1.8056214288566694e-06,
      "epoch": 2.7824360105913506,
      "step": 63050
    },
    {
      "loss": 1.1998,
      "grad_norm": 26.43755531311035,
      "learning_rate": 1.8023493085477703e-06,
      "epoch": 2.784642541924095,
      "step": 63100
    },
    {
      "loss": 1.1265,
      "grad_norm": 16.14394760131836,
      "learning_rate": 1.7990771882388712e-06,
      "epoch": 2.7868490732568403,
      "step": 63150
    },
    {
      "loss": 1.1881,
      "grad_norm": 9.265788078308105,
      "learning_rate": 1.7958050679299722e-06,
      "epoch": 2.789055604589585,
      "step": 63200
    },
    {
      "loss": 1.2662,
      "grad_norm": 32.968299865722656,
      "learning_rate": 1.7925329476210731e-06,
      "epoch": 2.79126213592233,
      "step": 63250
    },
    {
      "loss": 1.2451,
      "grad_norm": 28.70530891418457,
      "learning_rate": 1.789260827312174e-06,
      "epoch": 2.793468667255075,
      "step": 63300
    },
    {
      "loss": 1.2222,
      "grad_norm": 26.43067169189453,
      "learning_rate": 1.785988707003275e-06,
      "epoch": 2.79567519858782,
      "step": 63350
    },
    {
      "loss": 0.9669,
      "grad_norm": 15.949237823486328,
      "learning_rate": 1.7827165866943761e-06,
      "epoch": 2.7978817299205647,
      "step": 63400
    },
    {
      "loss": 0.9435,
      "grad_norm": 25.493358612060547,
      "learning_rate": 1.779444466385477e-06,
      "epoch": 2.80008826125331,
      "step": 63450
    },
    {
      "loss": 1.0986,
      "grad_norm": 23.51239776611328,
      "learning_rate": 1.776172346076578e-06,
      "epoch": 2.802294792586055,
      "step": 63500
    },
    {
      "loss": 1.0333,
      "grad_norm": 22.63317108154297,
      "learning_rate": 1.772900225767679e-06,
      "epoch": 2.8045013239187995,
      "step": 63550
    },
    {
      "loss": 1.0705,
      "grad_norm": 27.359912872314453,
      "learning_rate": 1.7696281054587797e-06,
      "epoch": 2.8067078552515445,
      "step": 63600
    },
    {
      "loss": 1.0191,
      "grad_norm": 36.4469108581543,
      "learning_rate": 1.7663559851498806e-06,
      "epoch": 2.8089143865842896,
      "step": 63650
    },
    {
      "loss": 1.0998,
      "grad_norm": 50.435428619384766,
      "learning_rate": 1.7630838648409816e-06,
      "epoch": 2.8111209179170347,
      "step": 63700
    },
    {
      "loss": 1.0666,
      "grad_norm": 31.67999839782715,
      "learning_rate": 1.759811744532083e-06,
      "epoch": 2.8133274492497793,
      "step": 63750
    },
    {
      "loss": 1.2069,
      "grad_norm": 27.844507217407227,
      "learning_rate": 1.7565396242231839e-06,
      "epoch": 2.8155339805825244,
      "step": 63800
    },
    {
      "loss": 1.1156,
      "grad_norm": 14.148427963256836,
      "learning_rate": 1.7532675039142846e-06,
      "epoch": 2.817740511915269,
      "step": 63850
    },
    {
      "loss": 1.0479,
      "grad_norm": 24.84440040588379,
      "learning_rate": 1.7499953836053855e-06,
      "epoch": 2.819947043248014,
      "step": 63900
    },
    {
      "loss": 1.155,
      "grad_norm": 20.618743896484375,
      "learning_rate": 1.7467232632964865e-06,
      "epoch": 2.822153574580759,
      "step": 63950
    },
    {
      "loss": 1.2325,
      "grad_norm": 25.886117935180664,
      "learning_rate": 1.7434511429875874e-06,
      "epoch": 2.824360105913504,
      "step": 64000
    },
    {
      "loss": 1.0407,
      "grad_norm": 18.429542541503906,
      "learning_rate": 1.7401790226786883e-06,
      "epoch": 2.826566637246249,
      "step": 64050
    },
    {
      "loss": 1.0482,
      "grad_norm": 24.23175048828125,
      "learning_rate": 1.7369069023697893e-06,
      "epoch": 2.828773168578994,
      "step": 64100
    },
    {
      "loss": 1.0592,
      "grad_norm": 22.432830810546875,
      "learning_rate": 1.7336347820608904e-06,
      "epoch": 2.8309796999117385,
      "step": 64150
    },
    {
      "loss": 1.0997,
      "grad_norm": 16.82198715209961,
      "learning_rate": 1.7303626617519914e-06,
      "epoch": 2.8331862312444835,
      "step": 64200
    },
    {
      "loss": 1.2017,
      "grad_norm": 53.121883392333984,
      "learning_rate": 1.7270905414430923e-06,
      "epoch": 2.8353927625772286,
      "step": 64250
    },
    {
      "loss": 1.074,
      "grad_norm": 31.661657333374023,
      "learning_rate": 1.7238184211341932e-06,
      "epoch": 2.8375992939099737,
      "step": 64300
    },
    {
      "loss": 0.9362,
      "grad_norm": 15.116230010986328,
      "learning_rate": 1.7205463008252942e-06,
      "epoch": 2.8398058252427183,
      "step": 64350
    },
    {
      "loss": 1.0481,
      "grad_norm": 20.746667861938477,
      "learning_rate": 1.7172741805163951e-06,
      "epoch": 2.8420123565754634,
      "step": 64400
    },
    {
      "loss": 1.075,
      "grad_norm": 57.57740020751953,
      "learning_rate": 1.714002060207496e-06,
      "epoch": 2.8442188879082084,
      "step": 64450
    },
    {
      "loss": 0.9776,
      "grad_norm": 22.04708480834961,
      "learning_rate": 1.7107299398985972e-06,
      "epoch": 2.846425419240953,
      "step": 64500
    },
    {
      "loss": 1.0059,
      "grad_norm": 22.63074493408203,
      "learning_rate": 1.7074578195896981e-06,
      "epoch": 2.848631950573698,
      "step": 64550
    },
    {
      "loss": 1.1796,
      "grad_norm": 20.156661987304688,
      "learning_rate": 1.704185699280799e-06,
      "epoch": 2.850838481906443,
      "step": 64600
    },
    {
      "loss": 1.1215,
      "grad_norm": 33.38210678100586,
      "learning_rate": 1.7009135789719e-06,
      "epoch": 2.8530450132391882,
      "step": 64650
    },
    {
      "loss": 1.2038,
      "grad_norm": 30.755754470825195,
      "learning_rate": 1.697641458663001e-06,
      "epoch": 2.855251544571933,
      "step": 64700
    },
    {
      "loss": 1.2248,
      "grad_norm": 25.980478286743164,
      "learning_rate": 1.6943693383541017e-06,
      "epoch": 2.857458075904678,
      "step": 64750
    },
    {
      "loss": 1.196,
      "grad_norm": 23.11224937438965,
      "learning_rate": 1.6910972180452026e-06,
      "epoch": 2.8596646072374226,
      "step": 64800
    },
    {
      "loss": 1.0724,
      "grad_norm": 17.86078453063965,
      "learning_rate": 1.687825097736304e-06,
      "epoch": 2.8618711385701676,
      "step": 64850
    },
    {
      "loss": 1.0596,
      "grad_norm": 16.725818634033203,
      "learning_rate": 1.684552977427405e-06,
      "epoch": 2.8640776699029127,
      "step": 64900
    },
    {
      "loss": 1.0613,
      "grad_norm": 24.532224655151367,
      "learning_rate": 1.6812808571185059e-06,
      "epoch": 2.8662842012356577,
      "step": 64950
    },
    {
      "loss": 1.0411,
      "grad_norm": 17.2821102142334,
      "learning_rate": 1.6780087368096066e-06,
      "epoch": 2.8684907325684024,
      "step": 65000
    },
    {
      "loss": 1.0213,
      "grad_norm": 26.56055450439453,
      "learning_rate": 1.6747366165007075e-06,
      "epoch": 2.8706972639011474,
      "step": 65050
    },
    {
      "loss": 1.2643,
      "grad_norm": 31.492456436157227,
      "learning_rate": 1.6714644961918085e-06,
      "epoch": 2.872903795233892,
      "step": 65100
    },
    {
      "loss": 1.0222,
      "grad_norm": 13.961538314819336,
      "learning_rate": 1.6681923758829094e-06,
      "epoch": 2.875110326566637,
      "step": 65150
    },
    {
      "loss": 1.0737,
      "grad_norm": 15.670974731445312,
      "learning_rate": 1.6649202555740103e-06,
      "epoch": 2.877316857899382,
      "step": 65200
    },
    {
      "loss": 1.1227,
      "grad_norm": 22.15361213684082,
      "learning_rate": 1.6616481352651115e-06,
      "epoch": 2.8795233892321273,
      "step": 65250
    },
    {
      "loss": 1.214,
      "grad_norm": 15.945138931274414,
      "learning_rate": 1.6583760149562124e-06,
      "epoch": 2.881729920564872,
      "step": 65300
    },
    {
      "loss": 1.1594,
      "grad_norm": 26.317323684692383,
      "learning_rate": 1.6551038946473134e-06,
      "epoch": 2.883936451897617,
      "step": 65350
    },
    {
      "loss": 1.3328,
      "grad_norm": 18.1229305267334,
      "learning_rate": 1.6518317743384143e-06,
      "epoch": 2.886142983230362,
      "step": 65400
    },
    {
      "loss": 1.1113,
      "grad_norm": 14.470083236694336,
      "learning_rate": 1.6485596540295152e-06,
      "epoch": 2.8883495145631066,
      "step": 65450
    },
    {
      "loss": 1.0712,
      "grad_norm": 32.667686462402344,
      "learning_rate": 1.6452875337206162e-06,
      "epoch": 2.8905560458958517,
      "step": 65500
    },
    {
      "loss": 1.1349,
      "grad_norm": 15.798456192016602,
      "learning_rate": 1.6420154134117171e-06,
      "epoch": 2.8927625772285968,
      "step": 65550
    },
    {
      "loss": 1.1606,
      "grad_norm": 17.87438201904297,
      "learning_rate": 1.6387432931028183e-06,
      "epoch": 2.894969108561342,
      "step": 65600
    },
    {
      "loss": 1.0887,
      "grad_norm": 8.951169967651367,
      "learning_rate": 1.6354711727939192e-06,
      "epoch": 2.8971756398940864,
      "step": 65650
    },
    {
      "loss": 1.0394,
      "grad_norm": 20.758602142333984,
      "learning_rate": 1.6321990524850201e-06,
      "epoch": 2.8993821712268315,
      "step": 65700
    },
    {
      "loss": 1.1496,
      "grad_norm": 33.90602493286133,
      "learning_rate": 1.628926932176121e-06,
      "epoch": 2.901588702559576,
      "step": 65750
    },
    {
      "loss": 0.9637,
      "grad_norm": 28.559797286987305,
      "learning_rate": 1.625654811867222e-06,
      "epoch": 2.903795233892321,
      "step": 65800
    },
    {
      "loss": 1.1373,
      "grad_norm": 31.333179473876953,
      "learning_rate": 1.622382691558323e-06,
      "epoch": 2.9060017652250663,
      "step": 65850
    },
    {
      "loss": 1.0232,
      "grad_norm": 11.166081428527832,
      "learning_rate": 1.6191105712494237e-06,
      "epoch": 2.9082082965578113,
      "step": 65900
    },
    {
      "loss": 1.1085,
      "grad_norm": 25.81727409362793,
      "learning_rate": 1.615838450940525e-06,
      "epoch": 2.910414827890556,
      "step": 65950
    },
    {
      "loss": 1.1644,
      "grad_norm": 21.85568618774414,
      "learning_rate": 1.612566330631626e-06,
      "epoch": 2.912621359223301,
      "step": 66000
    },
    {
      "loss": 1.0442,
      "grad_norm": 27.39341163635254,
      "learning_rate": 1.609294210322727e-06,
      "epoch": 2.9148278905560456,
      "step": 66050
    },
    {
      "loss": 1.0311,
      "grad_norm": 25.16053009033203,
      "learning_rate": 1.6060220900138276e-06,
      "epoch": 2.9170344218887907,
      "step": 66100
    },
    {
      "loss": 1.1031,
      "grad_norm": 26.178447723388672,
      "learning_rate": 1.6027499697049286e-06,
      "epoch": 2.9192409532215358,
      "step": 66150
    },
    {
      "loss": 1.111,
      "grad_norm": 12.366061210632324,
      "learning_rate": 1.5994778493960295e-06,
      "epoch": 2.921447484554281,
      "step": 66200
    },
    {
      "loss": 1.0082,
      "grad_norm": 19.97764015197754,
      "learning_rate": 1.5962057290871305e-06,
      "epoch": 2.9236540158870254,
      "step": 66250
    },
    {
      "loss": 1.1428,
      "grad_norm": 18.896717071533203,
      "learning_rate": 1.5929336087782314e-06,
      "epoch": 2.9258605472197705,
      "step": 66300
    },
    {
      "loss": 1.1258,
      "grad_norm": 18.651777267456055,
      "learning_rate": 1.5896614884693325e-06,
      "epoch": 2.9280670785525156,
      "step": 66350
    },
    {
      "loss": 1.1683,
      "grad_norm": 17.259313583374023,
      "learning_rate": 1.5863893681604335e-06,
      "epoch": 2.93027360988526,
      "step": 66400
    },
    {
      "loss": 1.1114,
      "grad_norm": 11.49545669555664,
      "learning_rate": 1.5831172478515344e-06,
      "epoch": 2.9324801412180053,
      "step": 66450
    },
    {
      "loss": 1.1118,
      "grad_norm": 25.827585220336914,
      "learning_rate": 1.5798451275426354e-06,
      "epoch": 2.9346866725507503,
      "step": 66500
    },
    {
      "loss": 1.0261,
      "grad_norm": 18.64551544189453,
      "learning_rate": 1.5765730072337363e-06,
      "epoch": 2.9368932038834954,
      "step": 66550
    },
    {
      "loss": 1.1487,
      "grad_norm": 21.371620178222656,
      "learning_rate": 1.5733008869248372e-06,
      "epoch": 2.93909973521624,
      "step": 66600
    },
    {
      "loss": 1.115,
      "grad_norm": 23.419116973876953,
      "learning_rate": 1.5700287666159382e-06,
      "epoch": 2.941306266548985,
      "step": 66650
    },
    {
      "loss": 1.0193,
      "grad_norm": 3.8378632068634033,
      "learning_rate": 1.5667566463070393e-06,
      "epoch": 2.9435127978817297,
      "step": 66700
    },
    {
      "loss": 0.8344,
      "grad_norm": 26.88840675354004,
      "learning_rate": 1.5634845259981403e-06,
      "epoch": 2.9457193292144748,
      "step": 66750
    },
    {
      "loss": 1.021,
      "grad_norm": 18.567487716674805,
      "learning_rate": 1.5602124056892412e-06,
      "epoch": 2.94792586054722,
      "step": 66800
    },
    {
      "loss": 1.0486,
      "grad_norm": 42.30558395385742,
      "learning_rate": 1.5569402853803421e-06,
      "epoch": 2.950132391879965,
      "step": 66850
    },
    {
      "loss": 1.1927,
      "grad_norm": 28.243526458740234,
      "learning_rate": 1.553668165071443e-06,
      "epoch": 2.9523389232127095,
      "step": 66900
    },
    {
      "loss": 0.9843,
      "grad_norm": 17.58324432373047,
      "learning_rate": 1.550396044762544e-06,
      "epoch": 2.9545454545454546,
      "step": 66950
    },
    {
      "loss": 1.1188,
      "grad_norm": 26.413541793823242,
      "learning_rate": 1.5471239244536447e-06,
      "epoch": 2.956751985878199,
      "step": 67000
    },
    {
      "loss": 1.1216,
      "grad_norm": 27.367177963256836,
      "learning_rate": 1.543851804144746e-06,
      "epoch": 2.9589585172109443,
      "step": 67050
    },
    {
      "loss": 1.2091,
      "grad_norm": 35.427730560302734,
      "learning_rate": 1.540579683835847e-06,
      "epoch": 2.9611650485436893,
      "step": 67100
    },
    {
      "loss": 1.2276,
      "grad_norm": 35.11365509033203,
      "learning_rate": 1.537307563526948e-06,
      "epoch": 2.9633715798764344,
      "step": 67150
    },
    {
      "loss": 0.9956,
      "grad_norm": 17.283552169799805,
      "learning_rate": 1.534035443218049e-06,
      "epoch": 2.965578111209179,
      "step": 67200
    },
    {
      "loss": 1.1257,
      "grad_norm": 25.124032974243164,
      "learning_rate": 1.5307633229091496e-06,
      "epoch": 2.967784642541924,
      "step": 67250
    },
    {
      "loss": 1.0218,
      "grad_norm": 9.834685325622559,
      "learning_rate": 1.5274912026002506e-06,
      "epoch": 2.969991173874669,
      "step": 67300
    },
    {
      "loss": 1.0574,
      "grad_norm": 17.75939178466797,
      "learning_rate": 1.5242190822913515e-06,
      "epoch": 2.9721977052074138,
      "step": 67350
    },
    {
      "loss": 0.985,
      "grad_norm": 5.069798469543457,
      "learning_rate": 1.5209469619824525e-06,
      "epoch": 2.974404236540159,
      "step": 67400
    },
    {
      "loss": 0.9941,
      "grad_norm": 26.755767822265625,
      "learning_rate": 1.5176748416735538e-06,
      "epoch": 2.976610767872904,
      "step": 67450
    },
    {
      "loss": 1.1471,
      "grad_norm": 25.232879638671875,
      "learning_rate": 1.5144027213646545e-06,
      "epoch": 2.978817299205649,
      "step": 67500
    },
    {
      "loss": 1.1789,
      "grad_norm": 24.054115295410156,
      "learning_rate": 1.5111306010557555e-06,
      "epoch": 2.9810238305383936,
      "step": 67550
    },
    {
      "loss": 1.0081,
      "grad_norm": 16.83559226989746,
      "learning_rate": 1.5078584807468564e-06,
      "epoch": 2.9832303618711387,
      "step": 67600
    },
    {
      "loss": 1.0754,
      "grad_norm": 23.935091018676758,
      "learning_rate": 1.5045863604379574e-06,
      "epoch": 2.9854368932038833,
      "step": 67650
    },
    {
      "loss": 1.0423,
      "grad_norm": 20.950925827026367,
      "learning_rate": 1.5013142401290583e-06,
      "epoch": 2.9876434245366283,
      "step": 67700
    },
    {
      "loss": 1.223,
      "grad_norm": 25.146181106567383,
      "learning_rate": 1.4980421198201592e-06,
      "epoch": 2.9898499558693734,
      "step": 67750
    },
    {
      "loss": 1.227,
      "grad_norm": 19.32878875732422,
      "learning_rate": 1.4947699995112604e-06,
      "epoch": 2.9920564872021185,
      "step": 67800
    },
    {
      "loss": 1.0407,
      "grad_norm": 21.424957275390625,
      "learning_rate": 1.4914978792023613e-06,
      "epoch": 2.994263018534863,
      "step": 67850
    },
    {
      "loss": 1.1163,
      "grad_norm": 24.69568634033203,
      "learning_rate": 1.4882257588934623e-06,
      "epoch": 2.996469549867608,
      "step": 67900
    },
    {
      "loss": 0.9922,
      "grad_norm": 16.77021598815918,
      "learning_rate": 1.4849536385845632e-06,
      "epoch": 2.998676081200353,
      "step": 67950
    },
    {
      "eval_loss": 0.9282973543694488,
      "eval_exact_match": 75.99276385457112,
      "eval_f1": 81.58162861988517,
      "eval_samples": 22720,
      "step": 67980
    },
    {
      "eval_loss": 0.9282973543694488,
      "eval_exact_match": 75.99276385457112,
      "eval_f1": 81.58162861988517,
      "eval_samples": 22720,
      "epoch": 3.0,
      "step": 67980
    },
    {
      "loss": 1.1233,
      "grad_norm": 14.404770851135254,
      "learning_rate": 1.4816815182756641e-06,
      "epoch": 3.000882612533098,
      "step": 68000
    },
    {
      "loss": 1.1752,
      "grad_norm": 22.995946884155273,
      "learning_rate": 1.478409397966765e-06,
      "epoch": 3.003089143865843,
      "step": 68050
    },
    {
      "loss": 1.1202,
      "grad_norm": 16.78536033630371,
      "learning_rate": 1.475137277657866e-06,
      "epoch": 3.005295675198588,
      "step": 68100
    },
    {
      "loss": 1.042,
      "grad_norm": 10.887554168701172,
      "learning_rate": 1.471865157348967e-06,
      "epoch": 3.0075022065313326,
      "step": 68150
    },
    {
      "loss": 1.0472,
      "grad_norm": 21.670621871948242,
      "learning_rate": 1.4685930370400679e-06,
      "epoch": 3.0097087378640777,
      "step": 68200
    },
    {
      "loss": 1.0611,
      "grad_norm": 22.222227096557617,
      "learning_rate": 1.465320916731169e-06,
      "epoch": 3.0119152691968227,
      "step": 68250
    },
    {
      "loss": 1.1258,
      "grad_norm": 11.3891019821167,
      "learning_rate": 1.46204879642227e-06,
      "epoch": 3.0141218005295674,
      "step": 68300
    },
    {
      "loss": 0.9953,
      "grad_norm": 29.767919540405273,
      "learning_rate": 1.4587766761133707e-06,
      "epoch": 3.0163283318623124,
      "step": 68350
    },
    {
      "loss": 1.0,
      "grad_norm": 33.22203826904297,
      "learning_rate": 1.4555045558044716e-06,
      "epoch": 3.0185348631950575,
      "step": 68400
    },
    {
      "loss": 1.2257,
      "grad_norm": 26.079402923583984,
      "learning_rate": 1.4522324354955728e-06,
      "epoch": 3.020741394527802,
      "step": 68450
    },
    {
      "loss": 1.077,
      "grad_norm": 14.13645076751709,
      "learning_rate": 1.4489603151866737e-06,
      "epoch": 3.022947925860547,
      "step": 68500
    },
    {
      "loss": 1.1134,
      "grad_norm": 29.656536102294922,
      "learning_rate": 1.4456881948777747e-06,
      "epoch": 3.0251544571932922,
      "step": 68550
    },
    {
      "loss": 1.0973,
      "grad_norm": 37.06850051879883,
      "learning_rate": 1.4424160745688756e-06,
      "epoch": 3.027360988526037,
      "step": 68600
    },
    {
      "loss": 1.0446,
      "grad_norm": 14.796854972839355,
      "learning_rate": 1.4391439542599765e-06,
      "epoch": 3.029567519858782,
      "step": 68650
    },
    {
      "loss": 1.0632,
      "grad_norm": 17.525508880615234,
      "learning_rate": 1.4358718339510775e-06,
      "epoch": 3.031774051191527,
      "step": 68700
    },
    {
      "loss": 1.0258,
      "grad_norm": 35.868682861328125,
      "learning_rate": 1.4325997136421784e-06,
      "epoch": 3.033980582524272,
      "step": 68750
    },
    {
      "loss": 1.073,
      "grad_norm": 21.85617446899414,
      "learning_rate": 1.4293275933332796e-06,
      "epoch": 3.0361871138570167,
      "step": 68800
    },
    {
      "loss": 1.0364,
      "grad_norm": 18.305191040039062,
      "learning_rate": 1.4260554730243805e-06,
      "epoch": 3.0383936451897617,
      "step": 68850
    },
    {
      "loss": 1.1057,
      "grad_norm": 28.11566925048828,
      "learning_rate": 1.4227833527154814e-06,
      "epoch": 3.040600176522507,
      "step": 68900
    },
    {
      "loss": 1.0246,
      "grad_norm": 14.54894733428955,
      "learning_rate": 1.4195112324065822e-06,
      "epoch": 3.0428067078552514,
      "step": 68950
    },
    {
      "loss": 1.092,
      "grad_norm": 17.761560440063477,
      "learning_rate": 1.4162391120976833e-06,
      "epoch": 3.0450132391879965,
      "step": 69000
    },
    {
      "loss": 0.9686,
      "grad_norm": 18.197765350341797,
      "learning_rate": 1.4129669917887843e-06,
      "epoch": 3.0472197705207416,
      "step": 69050
    },
    {
      "loss": 1.1809,
      "grad_norm": 38.09287643432617,
      "learning_rate": 1.4096948714798852e-06,
      "epoch": 3.049426301853486,
      "step": 69100
    },
    {
      "loss": 0.9627,
      "grad_norm": 26.824121475219727,
      "learning_rate": 1.4064227511709861e-06,
      "epoch": 3.0516328331862312,
      "step": 69150
    },
    {
      "loss": 1.0575,
      "grad_norm": 28.109352111816406,
      "learning_rate": 1.403150630862087e-06,
      "epoch": 3.0538393645189763,
      "step": 69200
    },
    {
      "loss": 1.196,
      "grad_norm": 29.427894592285156,
      "learning_rate": 1.399878510553188e-06,
      "epoch": 3.056045895851721,
      "step": 69250
    },
    {
      "loss": 0.9943,
      "grad_norm": 18.870386123657227,
      "learning_rate": 1.396606390244289e-06,
      "epoch": 3.058252427184466,
      "step": 69300
    },
    {
      "loss": 1.0596,
      "grad_norm": 26.081214904785156,
      "learning_rate": 1.39333426993539e-06,
      "epoch": 3.060458958517211,
      "step": 69350
    },
    {
      "loss": 1.0708,
      "grad_norm": 29.930049896240234,
      "learning_rate": 1.390062149626491e-06,
      "epoch": 3.0626654898499557,
      "step": 69400
    },
    {
      "loss": 1.0352,
      "grad_norm": 19.08453369140625,
      "learning_rate": 1.386790029317592e-06,
      "epoch": 3.0648720211827007,
      "step": 69450
    },
    {
      "loss": 1.1938,
      "grad_norm": 24.839509963989258,
      "learning_rate": 1.3835179090086927e-06,
      "epoch": 3.067078552515446,
      "step": 69500
    },
    {
      "loss": 1.1518,
      "grad_norm": 18.473230361938477,
      "learning_rate": 1.3802457886997939e-06,
      "epoch": 3.0692850838481904,
      "step": 69550
    },
    {
      "loss": 1.3053,
      "grad_norm": 20.743026733398438,
      "learning_rate": 1.3769736683908948e-06,
      "epoch": 3.0714916151809355,
      "step": 69600
    },
    {
      "loss": 1.1086,
      "grad_norm": 17.25867462158203,
      "learning_rate": 1.3737015480819957e-06,
      "epoch": 3.0736981465136806,
      "step": 69650
    },
    {
      "loss": 0.9948,
      "grad_norm": 21.757007598876953,
      "learning_rate": 1.3704294277730969e-06,
      "epoch": 3.0759046778464256,
      "step": 69700
    },
    {
      "loss": 1.1886,
      "grad_norm": 14.80937671661377,
      "learning_rate": 1.3671573074641976e-06,
      "epoch": 3.0781112091791702,
      "step": 69750
    },
    {
      "loss": 0.919,
      "grad_norm": 20.726791381835938,
      "learning_rate": 1.3638851871552985e-06,
      "epoch": 3.0803177405119153,
      "step": 69800
    },
    {
      "loss": 1.1145,
      "grad_norm": 34.52809524536133,
      "learning_rate": 1.3606130668463995e-06,
      "epoch": 3.0825242718446604,
      "step": 69850
    },
    {
      "loss": 1.0756,
      "grad_norm": 22.437307357788086,
      "learning_rate": 1.3573409465375006e-06,
      "epoch": 3.084730803177405,
      "step": 69900
    },
    {
      "loss": 1.0584,
      "grad_norm": 21.854854583740234,
      "learning_rate": 1.3540688262286016e-06,
      "epoch": 3.08693733451015,
      "step": 69950
    },
    {
      "loss": 0.971,
      "grad_norm": 15.227179527282715,
      "learning_rate": 1.3507967059197025e-06,
      "epoch": 3.089143865842895,
      "step": 70000
    },
    {
      "loss": 1.1171,
      "grad_norm": 17.975481033325195,
      "learning_rate": 1.3475245856108032e-06,
      "epoch": 3.0913503971756398,
      "step": 70050
    },
    {
      "loss": 1.1691,
      "grad_norm": 20.742111206054688,
      "learning_rate": 1.3442524653019044e-06,
      "epoch": 3.093556928508385,
      "step": 70100
    },
    {
      "loss": 1.0973,
      "grad_norm": 26.15471839904785,
      "learning_rate": 1.3409803449930053e-06,
      "epoch": 3.09576345984113,
      "step": 70150
    },
    {
      "loss": 1.0442,
      "grad_norm": 28.442033767700195,
      "learning_rate": 1.3377082246841063e-06,
      "epoch": 3.0979699911738745,
      "step": 70200
    },
    {
      "loss": 1.1311,
      "grad_norm": 21.354427337646484,
      "learning_rate": 1.3344361043752074e-06,
      "epoch": 3.1001765225066196,
      "step": 70250
    },
    {
      "loss": 0.9639,
      "grad_norm": 18.998851776123047,
      "learning_rate": 1.3311639840663081e-06,
      "epoch": 3.1023830538393646,
      "step": 70300
    },
    {
      "loss": 1.0651,
      "grad_norm": 31.11602020263672,
      "learning_rate": 1.327891863757409e-06,
      "epoch": 3.1045895851721093,
      "step": 70350
    },
    {
      "loss": 1.1117,
      "grad_norm": 27.53518295288086,
      "learning_rate": 1.32461974344851e-06,
      "epoch": 3.1067961165048543,
      "step": 70400
    },
    {
      "loss": 1.1529,
      "grad_norm": 16.617572784423828,
      "learning_rate": 1.3213476231396112e-06,
      "epoch": 3.1090026478375994,
      "step": 70450
    },
    {
      "loss": 1.0418,
      "grad_norm": 28.146766662597656,
      "learning_rate": 1.318075502830712e-06,
      "epoch": 3.111209179170344,
      "step": 70500
    },
    {
      "loss": 1.0634,
      "grad_norm": 31.338443756103516,
      "learning_rate": 1.314803382521813e-06,
      "epoch": 3.113415710503089,
      "step": 70550
    },
    {
      "loss": 1.1227,
      "grad_norm": 27.985403060913086,
      "learning_rate": 1.311531262212914e-06,
      "epoch": 3.115622241835834,
      "step": 70600
    },
    {
      "loss": 1.1688,
      "grad_norm": 19.96172332763672,
      "learning_rate": 1.308259141904015e-06,
      "epoch": 3.117828773168579,
      "step": 70650
    },
    {
      "loss": 1.1282,
      "grad_norm": 13.265572547912598,
      "learning_rate": 1.3049870215951159e-06,
      "epoch": 3.120035304501324,
      "step": 70700
    },
    {
      "loss": 0.9425,
      "grad_norm": 19.078168869018555,
      "learning_rate": 1.3017149012862168e-06,
      "epoch": 3.122241835834069,
      "step": 70750
    },
    {
      "loss": 1.1175,
      "grad_norm": 22.51769256591797,
      "learning_rate": 1.298442780977318e-06,
      "epoch": 3.124448367166814,
      "step": 70800
    },
    {
      "loss": 1.1037,
      "grad_norm": 19.191020965576172,
      "learning_rate": 1.2951706606684187e-06,
      "epoch": 3.1266548984995586,
      "step": 70850
    },
    {
      "loss": 0.9452,
      "grad_norm": 21.51598358154297,
      "learning_rate": 1.2918985403595196e-06,
      "epoch": 3.1288614298323036,
      "step": 70900
    },
    {
      "loss": 1.0124,
      "grad_norm": 28.719690322875977,
      "learning_rate": 1.2886264200506205e-06,
      "epoch": 3.1310679611650487,
      "step": 70950
    },
    {
      "loss": 1.0099,
      "grad_norm": 4.703481197357178,
      "learning_rate": 1.2853542997417217e-06,
      "epoch": 3.1332744924977933,
      "step": 71000
    },
    {
      "loss": 1.0316,
      "grad_norm": 15.379703521728516,
      "learning_rate": 1.2820821794328226e-06,
      "epoch": 3.1354810238305384,
      "step": 71050
    },
    {
      "loss": 1.0689,
      "grad_norm": 24.71782112121582,
      "learning_rate": 1.2788100591239236e-06,
      "epoch": 3.1376875551632835,
      "step": 71100
    },
    {
      "loss": 1.0468,
      "grad_norm": 20.08192253112793,
      "learning_rate": 1.2755379388150245e-06,
      "epoch": 3.139894086496028,
      "step": 71150
    },
    {
      "loss": 1.019,
      "grad_norm": 7.349277496337891,
      "learning_rate": 1.2722658185061254e-06,
      "epoch": 3.142100617828773,
      "step": 71200
    },
    {
      "loss": 1.0858,
      "grad_norm": 15.456969261169434,
      "learning_rate": 1.2689936981972264e-06,
      "epoch": 3.144307149161518,
      "step": 71250
    },
    {
      "loss": 1.1343,
      "grad_norm": 20.301177978515625,
      "learning_rate": 1.2657215778883273e-06,
      "epoch": 3.146513680494263,
      "step": 71300
    },
    {
      "loss": 1.0598,
      "grad_norm": 14.894110679626465,
      "learning_rate": 1.2624494575794285e-06,
      "epoch": 3.148720211827008,
      "step": 71350
    },
    {
      "loss": 0.9757,
      "grad_norm": 18.268613815307617,
      "learning_rate": 1.2591773372705294e-06,
      "epoch": 3.150926743159753,
      "step": 71400
    },
    {
      "loss": 1.0756,
      "grad_norm": 5.89878511428833,
      "learning_rate": 1.2559052169616301e-06,
      "epoch": 3.1531332744924976,
      "step": 71450
    },
    {
      "loss": 1.0679,
      "grad_norm": 30.457988739013672,
      "learning_rate": 1.252633096652731e-06,
      "epoch": 3.1553398058252426,
      "step": 71500
    },
    {
      "loss": 1.0393,
      "grad_norm": 21.98659896850586,
      "learning_rate": 1.2493609763438322e-06,
      "epoch": 3.1575463371579877,
      "step": 71550
    },
    {
      "loss": 0.991,
      "grad_norm": 7.169116973876953,
      "learning_rate": 1.2460888560349332e-06,
      "epoch": 3.159752868490733,
      "step": 71600
    },
    {
      "loss": 0.9802,
      "grad_norm": 21.927387237548828,
      "learning_rate": 1.242816735726034e-06,
      "epoch": 3.1619593998234774,
      "step": 71650
    },
    {
      "loss": 1.1029,
      "grad_norm": 22.072561264038086,
      "learning_rate": 1.239544615417135e-06,
      "epoch": 3.1641659311562225,
      "step": 71700
    },
    {
      "loss": 0.9288,
      "grad_norm": 25.715974807739258,
      "learning_rate": 1.236272495108236e-06,
      "epoch": 3.1663724624889675,
      "step": 71750
    },
    {
      "loss": 0.9068,
      "grad_norm": 50.875030517578125,
      "learning_rate": 1.233000374799337e-06,
      "epoch": 3.168578993821712,
      "step": 71800
    },
    {
      "loss": 1.0402,
      "grad_norm": 34.595489501953125,
      "learning_rate": 1.2297282544904379e-06,
      "epoch": 3.170785525154457,
      "step": 71850
    },
    {
      "loss": 1.1637,
      "grad_norm": 17.367158889770508,
      "learning_rate": 1.226456134181539e-06,
      "epoch": 3.1729920564872023,
      "step": 71900
    },
    {
      "loss": 1.0057,
      "grad_norm": 24.994361877441406,
      "learning_rate": 1.22318401387264e-06,
      "epoch": 3.175198587819947,
      "step": 71950
    },
    {
      "loss": 1.1104,
      "grad_norm": 29.21828269958496,
      "learning_rate": 1.2199118935637407e-06,
      "epoch": 3.177405119152692,
      "step": 72000
    },
    {
      "loss": 1.0603,
      "grad_norm": 12.754873275756836,
      "learning_rate": 1.2166397732548416e-06,
      "epoch": 3.179611650485437,
      "step": 72050
    },
    {
      "loss": 0.9144,
      "grad_norm": 20.65883445739746,
      "learning_rate": 1.2133676529459428e-06,
      "epoch": 3.1818181818181817,
      "step": 72100
    },
    {
      "loss": 1.1342,
      "grad_norm": 36.30744171142578,
      "learning_rate": 1.2100955326370437e-06,
      "epoch": 3.1840247131509267,
      "step": 72150
    },
    {
      "loss": 1.1763,
      "grad_norm": 56.41006851196289,
      "learning_rate": 1.2068234123281446e-06,
      "epoch": 3.186231244483672,
      "step": 72200
    },
    {
      "loss": 1.047,
      "grad_norm": 21.800352096557617,
      "learning_rate": 1.2035512920192456e-06,
      "epoch": 3.1884377758164164,
      "step": 72250
    },
    {
      "loss": 1.07,
      "grad_norm": 11.865325927734375,
      "learning_rate": 1.2002791717103465e-06,
      "epoch": 3.1906443071491615,
      "step": 72300
    },
    {
      "loss": 1.1509,
      "grad_norm": 18.832828521728516,
      "learning_rate": 1.1970070514014474e-06,
      "epoch": 3.1928508384819065,
      "step": 72350
    },
    {
      "loss": 1.0266,
      "grad_norm": 19.39922332763672,
      "learning_rate": 1.1937349310925484e-06,
      "epoch": 3.195057369814651,
      "step": 72400
    },
    {
      "loss": 1.03,
      "grad_norm": 25.291587829589844,
      "learning_rate": 1.1904628107836495e-06,
      "epoch": 3.1972639011473962,
      "step": 72450
    },
    {
      "loss": 0.9967,
      "grad_norm": 26.222280502319336,
      "learning_rate": 1.1871906904747505e-06,
      "epoch": 3.1994704324801413,
      "step": 72500
    },
    {
      "loss": 1.0891,
      "grad_norm": 11.494888305664062,
      "learning_rate": 1.1839185701658512e-06,
      "epoch": 3.2016769638128864,
      "step": 72550
    },
    {
      "loss": 1.1202,
      "grad_norm": 16.321205139160156,
      "learning_rate": 1.1806464498569521e-06,
      "epoch": 3.203883495145631,
      "step": 72600
    },
    {
      "loss": 1.0935,
      "grad_norm": 18.925683975219727,
      "learning_rate": 1.1773743295480533e-06,
      "epoch": 3.206090026478376,
      "step": 72650
    },
    {
      "loss": 1.1525,
      "grad_norm": 11.040059089660645,
      "learning_rate": 1.1741022092391542e-06,
      "epoch": 3.208296557811121,
      "step": 72700
    },
    {
      "loss": 1.0503,
      "grad_norm": 24.90818977355957,
      "learning_rate": 1.1708300889302552e-06,
      "epoch": 3.2105030891438657,
      "step": 72750
    },
    {
      "loss": 1.1093,
      "grad_norm": 23.053686141967773,
      "learning_rate": 1.167557968621356e-06,
      "epoch": 3.212709620476611,
      "step": 72800
    },
    {
      "loss": 1.0064,
      "grad_norm": 12.340974807739258,
      "learning_rate": 1.164285848312457e-06,
      "epoch": 3.214916151809356,
      "step": 72850
    },
    {
      "loss": 1.0849,
      "grad_norm": 38.432334899902344,
      "learning_rate": 1.161013728003558e-06,
      "epoch": 3.2171226831421005,
      "step": 72900
    },
    {
      "loss": 0.9456,
      "grad_norm": 8.653133392333984,
      "learning_rate": 1.157741607694659e-06,
      "epoch": 3.2193292144748455,
      "step": 72950
    },
    {
      "loss": 1.0958,
      "grad_norm": 16.403038024902344,
      "learning_rate": 1.15446948738576e-06,
      "epoch": 3.2215357458075906,
      "step": 73000
    },
    {
      "loss": 1.089,
      "grad_norm": 31.208221435546875,
      "learning_rate": 1.151197367076861e-06,
      "epoch": 3.2237422771403352,
      "step": 73050
    },
    {
      "loss": 1.0095,
      "grad_norm": 21.70680046081543,
      "learning_rate": 1.147925246767962e-06,
      "epoch": 3.2259488084730803,
      "step": 73100
    },
    {
      "loss": 0.9851,
      "grad_norm": 32.39901351928711,
      "learning_rate": 1.1446531264590627e-06,
      "epoch": 3.2281553398058254,
      "step": 73150
    },
    {
      "loss": 1.1845,
      "grad_norm": 19.119829177856445,
      "learning_rate": 1.1413810061501638e-06,
      "epoch": 3.23036187113857,
      "step": 73200
    },
    {
      "loss": 1.1379,
      "grad_norm": 28.295379638671875,
      "learning_rate": 1.1381088858412648e-06,
      "epoch": 3.232568402471315,
      "step": 73250
    },
    {
      "loss": 0.9189,
      "grad_norm": 24.863574981689453,
      "learning_rate": 1.1348367655323657e-06,
      "epoch": 3.23477493380406,
      "step": 73300
    },
    {
      "loss": 1.2172,
      "grad_norm": 8.983933448791504,
      "learning_rate": 1.1315646452234666e-06,
      "epoch": 3.2369814651368047,
      "step": 73350
    },
    {
      "loss": 1.0161,
      "grad_norm": 31.28391456604004,
      "learning_rate": 1.1282925249145676e-06,
      "epoch": 3.23918799646955,
      "step": 73400
    },
    {
      "loss": 1.0095,
      "grad_norm": 12.073098182678223,
      "learning_rate": 1.1250204046056685e-06,
      "epoch": 3.241394527802295,
      "step": 73450
    },
    {
      "loss": 1.0703,
      "grad_norm": 15.545112609863281,
      "learning_rate": 1.1217482842967694e-06,
      "epoch": 3.24360105913504,
      "step": 73500
    },
    {
      "loss": 1.0339,
      "grad_norm": 40.938209533691406,
      "learning_rate": 1.1184761639878706e-06,
      "epoch": 3.2458075904677846,
      "step": 73550
    },
    {
      "loss": 1.053,
      "grad_norm": 21.025463104248047,
      "learning_rate": 1.1152040436789715e-06,
      "epoch": 3.2480141218005296,
      "step": 73600
    },
    {
      "loss": 1.1492,
      "grad_norm": 37.93056869506836,
      "learning_rate": 1.1119319233700725e-06,
      "epoch": 3.2502206531332747,
      "step": 73650
    },
    {
      "loss": 1.1288,
      "grad_norm": 32.49374008178711,
      "learning_rate": 1.1086598030611732e-06,
      "epoch": 3.2524271844660193,
      "step": 73700
    },
    {
      "loss": 1.1194,
      "grad_norm": 24.058666229248047,
      "learning_rate": 1.1053876827522743e-06,
      "epoch": 3.2546337157987644,
      "step": 73750
    },
    {
      "loss": 1.0802,
      "grad_norm": 15.056147575378418,
      "learning_rate": 1.1021155624433753e-06,
      "epoch": 3.2568402471315094,
      "step": 73800
    },
    {
      "loss": 1.0834,
      "grad_norm": 20.158845901489258,
      "learning_rate": 1.0988434421344762e-06,
      "epoch": 3.259046778464254,
      "step": 73850
    },
    {
      "loss": 1.0362,
      "grad_norm": 40.266136169433594,
      "learning_rate": 1.0955713218255774e-06,
      "epoch": 3.261253309796999,
      "step": 73900
    },
    {
      "loss": 1.0781,
      "grad_norm": 11.511809349060059,
      "learning_rate": 1.092299201516678e-06,
      "epoch": 3.263459841129744,
      "step": 73950
    },
    {
      "loss": 1.0665,
      "grad_norm": 12.658175468444824,
      "learning_rate": 1.089027081207779e-06,
      "epoch": 3.265666372462489,
      "step": 74000
    },
    {
      "loss": 1.3299,
      "grad_norm": 28.991106033325195,
      "learning_rate": 1.08575496089888e-06,
      "epoch": 3.267872903795234,
      "step": 74050
    },
    {
      "loss": 1.1787,
      "grad_norm": 25.7463321685791,
      "learning_rate": 1.0824828405899811e-06,
      "epoch": 3.270079435127979,
      "step": 74100
    },
    {
      "loss": 1.0494,
      "grad_norm": 7.810160160064697,
      "learning_rate": 1.079210720281082e-06,
      "epoch": 3.2722859664607236,
      "step": 74150
    },
    {
      "loss": 1.0984,
      "grad_norm": 34.945716857910156,
      "learning_rate": 1.075938599972183e-06,
      "epoch": 3.2744924977934686,
      "step": 74200
    },
    {
      "loss": 1.0218,
      "grad_norm": 26.285980224609375,
      "learning_rate": 1.0726664796632837e-06,
      "epoch": 3.2766990291262137,
      "step": 74250
    },
    {
      "loss": 0.9779,
      "grad_norm": 20.077016830444336,
      "learning_rate": 1.0693943593543849e-06,
      "epoch": 3.2789055604589583,
      "step": 74300
    },
    {
      "loss": 0.9997,
      "grad_norm": 35.60486602783203,
      "learning_rate": 1.0661222390454858e-06,
      "epoch": 3.2811120917917034,
      "step": 74350
    },
    {
      "loss": 1.1152,
      "grad_norm": 46.970237731933594,
      "learning_rate": 1.0628501187365868e-06,
      "epoch": 3.2833186231244484,
      "step": 74400
    },
    {
      "loss": 1.0381,
      "grad_norm": 14.27922534942627,
      "learning_rate": 1.059577998427688e-06,
      "epoch": 3.2855251544571935,
      "step": 74450
    },
    {
      "loss": 1.1621,
      "grad_norm": 22.300691604614258,
      "learning_rate": 1.0563058781187886e-06,
      "epoch": 3.287731685789938,
      "step": 74500
    },
    {
      "loss": 1.0398,
      "grad_norm": 20.920791625976562,
      "learning_rate": 1.0530337578098896e-06,
      "epoch": 3.289938217122683,
      "step": 74550
    },
    {
      "loss": 1.061,
      "grad_norm": 20.824365615844727,
      "learning_rate": 1.0497616375009905e-06,
      "epoch": 3.2921447484554283,
      "step": 74600
    },
    {
      "loss": 1.0207,
      "grad_norm": 28.13869857788086,
      "learning_rate": 1.0464895171920917e-06,
      "epoch": 3.294351279788173,
      "step": 74650
    },
    {
      "loss": 1.0457,
      "grad_norm": 24.254472732543945,
      "learning_rate": 1.0432173968831926e-06,
      "epoch": 3.296557811120918,
      "step": 74700
    },
    {
      "loss": 1.1495,
      "grad_norm": 30.417551040649414,
      "learning_rate": 1.0399452765742935e-06,
      "epoch": 3.298764342453663,
      "step": 74750
    },
    {
      "loss": 1.0658,
      "grad_norm": 16.02052879333496,
      "learning_rate": 1.0366731562653945e-06,
      "epoch": 3.3009708737864076,
      "step": 74800
    },
    {
      "loss": 1.1843,
      "grad_norm": 23.497684478759766,
      "learning_rate": 1.0334010359564954e-06,
      "epoch": 3.3031774051191527,
      "step": 74850
    },
    {
      "loss": 1.1493,
      "grad_norm": 16.027267456054688,
      "learning_rate": 1.0301289156475963e-06,
      "epoch": 3.3053839364518978,
      "step": 74900
    },
    {
      "loss": 1.0483,
      "grad_norm": 12.96102523803711,
      "learning_rate": 1.0268567953386973e-06,
      "epoch": 3.3075904677846424,
      "step": 74950
    },
    {
      "loss": 1.1717,
      "grad_norm": 23.67012596130371,
      "learning_rate": 1.0235846750297984e-06,
      "epoch": 3.3097969991173875,
      "step": 75000
    },
    {
      "loss": 1.1507,
      "grad_norm": 26.77642250061035,
      "learning_rate": 1.0203125547208992e-06,
      "epoch": 3.3120035304501325,
      "step": 75050
    },
    {
      "loss": 1.0653,
      "grad_norm": 42.25575637817383,
      "learning_rate": 1.017040434412e-06,
      "epoch": 3.314210061782877,
      "step": 75100
    },
    {
      "loss": 1.0088,
      "grad_norm": 19.255277633666992,
      "learning_rate": 1.013768314103101e-06,
      "epoch": 3.316416593115622,
      "step": 75150
    },
    {
      "loss": 0.9704,
      "grad_norm": 7.906763553619385,
      "learning_rate": 1.0104961937942022e-06,
      "epoch": 3.3186231244483673,
      "step": 75200
    },
    {
      "loss": 1.1199,
      "grad_norm": 22.608652114868164,
      "learning_rate": 1.0072240734853031e-06,
      "epoch": 3.320829655781112,
      "step": 75250
    },
    {
      "loss": 1.0661,
      "grad_norm": 17.169464111328125,
      "learning_rate": 1.003951953176404e-06,
      "epoch": 3.323036187113857,
      "step": 75300
    },
    {
      "loss": 1.1082,
      "grad_norm": 31.626808166503906,
      "learning_rate": 1.000679832867505e-06,
      "epoch": 3.325242718446602,
      "step": 75350
    },
    {
      "loss": 1.1203,
      "grad_norm": 30.8035945892334,
      "learning_rate": 9.97407712558606e-07,
      "epoch": 3.327449249779347,
      "step": 75400
    },
    {
      "loss": 1.1388,
      "grad_norm": 18.398818969726562,
      "learning_rate": 9.941355922497069e-07,
      "epoch": 3.3296557811120917,
      "step": 75450
    },
    {
      "loss": 1.0369,
      "grad_norm": 10.155871391296387,
      "learning_rate": 9.908634719408078e-07,
      "epoch": 3.3318623124448368,
      "step": 75500
    },
    {
      "loss": 1.057,
      "grad_norm": 11.438424110412598,
      "learning_rate": 9.87591351631909e-07,
      "epoch": 3.3340688437775814,
      "step": 75550
    },
    {
      "loss": 1.0215,
      "grad_norm": 63.38629150390625,
      "learning_rate": 9.8431923132301e-07,
      "epoch": 3.3362753751103265,
      "step": 75600
    },
    {
      "loss": 0.9238,
      "grad_norm": 18.206554412841797,
      "learning_rate": 9.810471110141106e-07,
      "epoch": 3.3384819064430715,
      "step": 75650
    },
    {
      "loss": 1.1173,
      "grad_norm": 31.5111026763916,
      "learning_rate": 9.777749907052116e-07,
      "epoch": 3.3406884377758166,
      "step": 75700
    },
    {
      "loss": 0.9498,
      "grad_norm": 20.67830467224121,
      "learning_rate": 9.745028703963127e-07,
      "epoch": 3.342894969108561,
      "step": 75750
    },
    {
      "loss": 1.041,
      "grad_norm": 10.821419715881348,
      "learning_rate": 9.712307500874137e-07,
      "epoch": 3.3451015004413063,
      "step": 75800
    },
    {
      "loss": 1.0357,
      "grad_norm": 18.334054946899414,
      "learning_rate": 9.679586297785146e-07,
      "epoch": 3.3473080317740513,
      "step": 75850
    },
    {
      "loss": 1.0217,
      "grad_norm": 23.508895874023438,
      "learning_rate": 9.646865094696155e-07,
      "epoch": 3.349514563106796,
      "step": 75900
    },
    {
      "loss": 1.1043,
      "grad_norm": 32.653682708740234,
      "learning_rate": 9.614143891607165e-07,
      "epoch": 3.351721094439541,
      "step": 75950
    },
    {
      "loss": 1.0119,
      "grad_norm": 20.24822425842285,
      "learning_rate": 9.581422688518174e-07,
      "epoch": 3.353927625772286,
      "step": 76000
    },
    {
      "loss": 1.175,
      "grad_norm": 25.74156379699707,
      "learning_rate": 9.548701485429183e-07,
      "epoch": 3.3561341571050307,
      "step": 76050
    },
    {
      "loss": 1.2031,
      "grad_norm": 30.861101150512695,
      "learning_rate": 9.515980282340194e-07,
      "epoch": 3.358340688437776,
      "step": 76100
    },
    {
      "loss": 1.0662,
      "grad_norm": 14.043560028076172,
      "learning_rate": 9.483259079251203e-07,
      "epoch": 3.360547219770521,
      "step": 76150
    },
    {
      "loss": 1.0628,
      "grad_norm": 20.131776809692383,
      "learning_rate": 9.450537876162213e-07,
      "epoch": 3.3627537511032655,
      "step": 76200
    },
    {
      "loss": 0.9271,
      "grad_norm": 11.437685012817383,
      "learning_rate": 9.417816673073222e-07,
      "epoch": 3.3649602824360105,
      "step": 76250
    },
    {
      "loss": 0.9648,
      "grad_norm": 14.988186836242676,
      "learning_rate": 9.385095469984233e-07,
      "epoch": 3.3671668137687556,
      "step": 76300
    },
    {
      "loss": 1.1412,
      "grad_norm": 15.746150016784668,
      "learning_rate": 9.352374266895242e-07,
      "epoch": 3.3693733451015007,
      "step": 76350
    },
    {
      "loss": 1.1487,
      "grad_norm": 17.554885864257812,
      "learning_rate": 9.31965306380625e-07,
      "epoch": 3.3715798764342453,
      "step": 76400
    },
    {
      "loss": 1.1716,
      "grad_norm": 25.98724937438965,
      "learning_rate": 9.28693186071726e-07,
      "epoch": 3.3737864077669903,
      "step": 76450
    },
    {
      "loss": 1.1324,
      "grad_norm": 19.89057731628418,
      "learning_rate": 9.254210657628271e-07,
      "epoch": 3.375992939099735,
      "step": 76500
    },
    {
      "loss": 1.0176,
      "grad_norm": 15.53968334197998,
      "learning_rate": 9.221489454539279e-07,
      "epoch": 3.37819947043248,
      "step": 76550
    },
    {
      "loss": 1.0695,
      "grad_norm": 25.7409610748291,
      "learning_rate": 9.188768251450289e-07,
      "epoch": 3.380406001765225,
      "step": 76600
    },
    {
      "loss": 1.0734,
      "grad_norm": 7.303250312805176,
      "learning_rate": 9.156047048361299e-07,
      "epoch": 3.38261253309797,
      "step": 76650
    },
    {
      "loss": 0.931,
      "grad_norm": 22.277610778808594,
      "learning_rate": 9.123325845272309e-07,
      "epoch": 3.384819064430715,
      "step": 76700
    },
    {
      "loss": 1.0338,
      "grad_norm": 15.090282440185547,
      "learning_rate": 9.090604642183318e-07,
      "epoch": 3.38702559576346,
      "step": 76750
    },
    {
      "loss": 1.0145,
      "grad_norm": 20.315746307373047,
      "learning_rate": 9.057883439094327e-07,
      "epoch": 3.389232127096205,
      "step": 76800
    },
    {
      "loss": 0.9736,
      "grad_norm": 29.87127685546875,
      "learning_rate": 9.025162236005338e-07,
      "epoch": 3.3914386584289495,
      "step": 76850
    },
    {
      "loss": 1.0124,
      "grad_norm": 12.038961410522461,
      "learning_rate": 8.992441032916347e-07,
      "epoch": 3.3936451897616946,
      "step": 76900
    },
    {
      "loss": 1.0774,
      "grad_norm": 64.37372589111328,
      "learning_rate": 8.959719829827357e-07,
      "epoch": 3.3958517210944397,
      "step": 76950
    },
    {
      "loss": 1.0006,
      "grad_norm": 21.049535751342773,
      "learning_rate": 8.926998626738365e-07,
      "epoch": 3.3980582524271843,
      "step": 77000
    },
    {
      "loss": 1.1632,
      "grad_norm": 18.231054306030273,
      "learning_rate": 8.894277423649376e-07,
      "epoch": 3.4002647837599294,
      "step": 77050
    },
    {
      "loss": 1.095,
      "grad_norm": 36.69856262207031,
      "learning_rate": 8.861556220560385e-07,
      "epoch": 3.4024713150926744,
      "step": 77100
    },
    {
      "loss": 1.0875,
      "grad_norm": 26.811368942260742,
      "learning_rate": 8.828835017471394e-07,
      "epoch": 3.404677846425419,
      "step": 77150
    },
    {
      "loss": 1.1775,
      "grad_norm": 18.901348114013672,
      "learning_rate": 8.796113814382405e-07,
      "epoch": 3.406884377758164,
      "step": 77200
    },
    {
      "loss": 1.108,
      "grad_norm": 28.481639862060547,
      "learning_rate": 8.763392611293414e-07,
      "epoch": 3.409090909090909,
      "step": 77250
    },
    {
      "loss": 1.0922,
      "grad_norm": 19.380388259887695,
      "learning_rate": 8.730671408204423e-07,
      "epoch": 3.4112974404236542,
      "step": 77300
    },
    {
      "loss": 1.0794,
      "grad_norm": 30.682170867919922,
      "learning_rate": 8.697950205115433e-07,
      "epoch": 3.413503971756399,
      "step": 77350
    },
    {
      "loss": 1.0591,
      "grad_norm": 24.96678352355957,
      "learning_rate": 8.665229002026443e-07,
      "epoch": 3.415710503089144,
      "step": 77400
    },
    {
      "loss": 1.0808,
      "grad_norm": 20.51513671875,
      "learning_rate": 8.632507798937453e-07,
      "epoch": 3.4179170344218885,
      "step": 77450
    },
    {
      "loss": 1.1034,
      "grad_norm": 16.798404693603516,
      "learning_rate": 8.599786595848462e-07,
      "epoch": 3.4201235657546336,
      "step": 77500
    },
    {
      "loss": 1.0136,
      "grad_norm": 20.503761291503906,
      "learning_rate": 8.56706539275947e-07,
      "epoch": 3.4223300970873787,
      "step": 77550
    },
    {
      "loss": 1.1297,
      "grad_norm": 14.644449234008789,
      "learning_rate": 8.534344189670482e-07,
      "epoch": 3.4245366284201237,
      "step": 77600
    },
    {
      "loss": 1.0375,
      "grad_norm": 39.957862854003906,
      "learning_rate": 8.50162298658149e-07,
      "epoch": 3.4267431597528684,
      "step": 77650
    },
    {
      "loss": 1.1592,
      "grad_norm": 19.547670364379883,
      "learning_rate": 8.468901783492499e-07,
      "epoch": 3.4289496910856134,
      "step": 77700
    },
    {
      "loss": 1.0254,
      "grad_norm": 18.872289657592773,
      "learning_rate": 8.436180580403511e-07,
      "epoch": 3.4311562224183585,
      "step": 77750
    },
    {
      "loss": 1.1243,
      "grad_norm": 43.00674819946289,
      "learning_rate": 8.403459377314519e-07,
      "epoch": 3.433362753751103,
      "step": 77800
    },
    {
      "loss": 1.0866,
      "grad_norm": 27.542020797729492,
      "learning_rate": 8.370738174225529e-07,
      "epoch": 3.435569285083848,
      "step": 77850
    },
    {
      "loss": 1.0086,
      "grad_norm": 26.74544334411621,
      "learning_rate": 8.338016971136538e-07,
      "epoch": 3.4377758164165932,
      "step": 77900
    },
    {
      "loss": 1.1243,
      "grad_norm": 11.92277717590332,
      "learning_rate": 8.305295768047548e-07,
      "epoch": 3.439982347749338,
      "step": 77950
    },
    {
      "loss": 1.1249,
      "grad_norm": 32.13193130493164,
      "learning_rate": 8.272574564958558e-07,
      "epoch": 3.442188879082083,
      "step": 78000
    },
    {
      "loss": 1.2,
      "grad_norm": 13.947853088378906,
      "learning_rate": 8.239853361869567e-07,
      "epoch": 3.444395410414828,
      "step": 78050
    },
    {
      "loss": 1.1518,
      "grad_norm": 14.572589874267578,
      "learning_rate": 8.207132158780576e-07,
      "epoch": 3.4466019417475726,
      "step": 78100
    },
    {
      "loss": 1.0668,
      "grad_norm": 12.533488273620605,
      "learning_rate": 8.174410955691587e-07,
      "epoch": 3.4488084730803177,
      "step": 78150
    },
    {
      "loss": 1.1156,
      "grad_norm": 17.645296096801758,
      "learning_rate": 8.141689752602596e-07,
      "epoch": 3.4510150044130627,
      "step": 78200
    },
    {
      "loss": 1.1135,
      "grad_norm": 18.818077087402344,
      "learning_rate": 8.108968549513605e-07,
      "epoch": 3.453221535745808,
      "step": 78250
    },
    {
      "loss": 1.0318,
      "grad_norm": 27.766738891601562,
      "learning_rate": 8.076247346424616e-07,
      "epoch": 3.4554280670785524,
      "step": 78300
    },
    {
      "loss": 1.0197,
      "grad_norm": 27.57276153564453,
      "learning_rate": 8.043526143335625e-07,
      "epoch": 3.4576345984112975,
      "step": 78350
    },
    {
      "loss": 1.1292,
      "grad_norm": 24.044490814208984,
      "learning_rate": 8.010804940246634e-07,
      "epoch": 3.459841129744042,
      "step": 78400
    },
    {
      "loss": 1.1472,
      "grad_norm": 27.73189926147461,
      "learning_rate": 7.978083737157643e-07,
      "epoch": 3.462047661076787,
      "step": 78450
    },
    {
      "loss": 1.055,
      "grad_norm": 31.238365173339844,
      "learning_rate": 7.945362534068654e-07,
      "epoch": 3.4642541924095323,
      "step": 78500
    },
    {
      "loss": 0.9358,
      "grad_norm": 21.04081153869629,
      "learning_rate": 7.912641330979663e-07,
      "epoch": 3.4664607237422773,
      "step": 78550
    },
    {
      "loss": 1.112,
      "grad_norm": 28.603744506835938,
      "learning_rate": 7.879920127890673e-07,
      "epoch": 3.468667255075022,
      "step": 78600
    },
    {
      "loss": 1.1293,
      "grad_norm": 23.349773406982422,
      "learning_rate": 7.847198924801682e-07,
      "epoch": 3.470873786407767,
      "step": 78650
    },
    {
      "loss": 0.9749,
      "grad_norm": 20.890811920166016,
      "learning_rate": 7.814477721712692e-07,
      "epoch": 3.473080317740512,
      "step": 78700
    },
    {
      "loss": 1.0261,
      "grad_norm": 35.22372055053711,
      "learning_rate": 7.781756518623702e-07,
      "epoch": 3.4752868490732567,
      "step": 78750
    },
    {
      "loss": 1.0106,
      "grad_norm": 25.527809143066406,
      "learning_rate": 7.74903531553471e-07,
      "epoch": 3.4774933804060018,
      "step": 78800
    },
    {
      "loss": 0.9907,
      "grad_norm": 17.21865463256836,
      "learning_rate": 7.716314112445722e-07,
      "epoch": 3.479699911738747,
      "step": 78850
    },
    {
      "loss": 1.0266,
      "grad_norm": 19.518417358398438,
      "learning_rate": 7.68359290935673e-07,
      "epoch": 3.4819064430714914,
      "step": 78900
    },
    {
      "loss": 0.952,
      "grad_norm": 2.128260850906372,
      "learning_rate": 7.650871706267739e-07,
      "epoch": 3.4841129744042365,
      "step": 78950
    },
    {
      "loss": 1.258,
      "grad_norm": 27.921415328979492,
      "learning_rate": 7.618150503178749e-07,
      "epoch": 3.4863195057369816,
      "step": 79000
    },
    {
      "loss": 1.0271,
      "grad_norm": 29.59867286682129,
      "learning_rate": 7.585429300089759e-07,
      "epoch": 3.488526037069726,
      "step": 79050
    },
    {
      "loss": 1.0344,
      "grad_norm": 24.16611671447754,
      "learning_rate": 7.552708097000768e-07,
      "epoch": 3.4907325684024713,
      "step": 79100
    },
    {
      "loss": 1.1876,
      "grad_norm": 19.088531494140625,
      "learning_rate": 7.519986893911778e-07,
      "epoch": 3.4929390997352163,
      "step": 79150
    },
    {
      "loss": 0.9803,
      "grad_norm": 20.71743392944336,
      "learning_rate": 7.487265690822787e-07,
      "epoch": 3.4951456310679614,
      "step": 79200
    },
    {
      "loss": 1.0811,
      "grad_norm": 26.235363006591797,
      "learning_rate": 7.454544487733798e-07,
      "epoch": 3.497352162400706,
      "step": 79250
    },
    {
      "loss": 1.103,
      "grad_norm": 26.82477378845215,
      "learning_rate": 7.421823284644807e-07,
      "epoch": 3.499558693733451,
      "step": 79300
    },
    {
      "loss": 1.1351,
      "grad_norm": 17.792375564575195,
      "learning_rate": 7.389102081555815e-07,
      "epoch": 3.5017652250661957,
      "step": 79350
    },
    {
      "loss": 1.0121,
      "grad_norm": 11.381427764892578,
      "learning_rate": 7.356380878466826e-07,
      "epoch": 3.5039717563989408,
      "step": 79400
    },
    {
      "loss": 1.0734,
      "grad_norm": 24.35458755493164,
      "learning_rate": 7.323659675377836e-07,
      "epoch": 3.506178287731686,
      "step": 79450
    },
    {
      "loss": 1.0749,
      "grad_norm": 17.582918167114258,
      "learning_rate": 7.290938472288845e-07,
      "epoch": 3.508384819064431,
      "step": 79500
    },
    {
      "loss": 1.0934,
      "grad_norm": 17.346553802490234,
      "learning_rate": 7.258217269199855e-07,
      "epoch": 3.5105913503971755,
      "step": 79550
    },
    {
      "loss": 1.1172,
      "grad_norm": 10.372916221618652,
      "learning_rate": 7.225496066110864e-07,
      "epoch": 3.5127978817299206,
      "step": 79600
    },
    {
      "loss": 0.9635,
      "grad_norm": 12.18027400970459,
      "learning_rate": 7.192774863021874e-07,
      "epoch": 3.5150044130626656,
      "step": 79650
    },
    {
      "loss": 0.9549,
      "grad_norm": 23.075664520263672,
      "learning_rate": 7.160053659932883e-07,
      "epoch": 3.5172109443954103,
      "step": 79700
    },
    {
      "loss": 1.0164,
      "grad_norm": 16.75835609436035,
      "learning_rate": 7.127332456843892e-07,
      "epoch": 3.5194174757281553,
      "step": 79750
    },
    {
      "loss": 1.0865,
      "grad_norm": 30.424428939819336,
      "learning_rate": 7.094611253754903e-07,
      "epoch": 3.5216240070609004,
      "step": 79800
    },
    {
      "loss": 1.0932,
      "grad_norm": 18.70686912536621,
      "learning_rate": 7.061890050665912e-07,
      "epoch": 3.5238305383936455,
      "step": 79850
    },
    {
      "loss": 1.0312,
      "grad_norm": 26.486778259277344,
      "learning_rate": 7.029168847576922e-07,
      "epoch": 3.52603706972639,
      "step": 79900
    },
    {
      "loss": 1.0566,
      "grad_norm": 24.42619514465332,
      "learning_rate": 6.996447644487931e-07,
      "epoch": 3.528243601059135,
      "step": 79950
    },
    {
      "loss": 1.0905,
      "grad_norm": 16.29871940612793,
      "learning_rate": 6.963726441398942e-07,
      "epoch": 3.5304501323918798,
      "step": 80000
    },
    {
      "loss": 1.118,
      "grad_norm": 12.278078079223633,
      "learning_rate": 6.93100523830995e-07,
      "epoch": 3.532656663724625,
      "step": 80050
    },
    {
      "loss": 1.058,
      "grad_norm": 25.556644439697266,
      "learning_rate": 6.89828403522096e-07,
      "epoch": 3.53486319505737,
      "step": 80100
    },
    {
      "loss": 1.0523,
      "grad_norm": 24.720239639282227,
      "learning_rate": 6.86556283213197e-07,
      "epoch": 3.537069726390115,
      "step": 80150
    },
    {
      "loss": 1.0104,
      "grad_norm": 29.86736488342285,
      "learning_rate": 6.832841629042979e-07,
      "epoch": 3.5392762577228596,
      "step": 80200
    },
    {
      "loss": 1.1349,
      "grad_norm": 8.517216682434082,
      "learning_rate": 6.800120425953988e-07,
      "epoch": 3.5414827890556047,
      "step": 80250
    },
    {
      "loss": 1.035,
      "grad_norm": 20.830856323242188,
      "learning_rate": 6.767399222864999e-07,
      "epoch": 3.5436893203883493,
      "step": 80300
    },
    {
      "loss": 1.1116,
      "grad_norm": 26.942197799682617,
      "learning_rate": 6.734678019776008e-07,
      "epoch": 3.5458958517210943,
      "step": 80350
    },
    {
      "loss": 1.1716,
      "grad_norm": 11.06795597076416,
      "learning_rate": 6.701956816687018e-07,
      "epoch": 3.5481023830538394,
      "step": 80400
    },
    {
      "loss": 1.0344,
      "grad_norm": 22.66185188293457,
      "learning_rate": 6.669235613598027e-07,
      "epoch": 3.5503089143865845,
      "step": 80450
    },
    {
      "loss": 1.1216,
      "grad_norm": 20.83220672607422,
      "learning_rate": 6.636514410509036e-07,
      "epoch": 3.552515445719329,
      "step": 80500
    },
    {
      "loss": 1.0939,
      "grad_norm": 44.384132385253906,
      "learning_rate": 6.603793207420047e-07,
      "epoch": 3.554721977052074,
      "step": 80550
    },
    {
      "loss": 1.004,
      "grad_norm": 12.97776985168457,
      "learning_rate": 6.571072004331055e-07,
      "epoch": 3.556928508384819,
      "step": 80600
    },
    {
      "loss": 1.0472,
      "grad_norm": 20.3196964263916,
      "learning_rate": 6.538350801242066e-07,
      "epoch": 3.559135039717564,
      "step": 80650
    },
    {
      "loss": 1.0784,
      "grad_norm": 21.29190444946289,
      "learning_rate": 6.505629598153075e-07,
      "epoch": 3.561341571050309,
      "step": 80700
    },
    {
      "loss": 1.0845,
      "grad_norm": 26.683996200561523,
      "learning_rate": 6.472908395064084e-07,
      "epoch": 3.563548102383054,
      "step": 80750
    },
    {
      "loss": 1.1219,
      "grad_norm": 17.820219039916992,
      "learning_rate": 6.440187191975094e-07,
      "epoch": 3.565754633715799,
      "step": 80800
    },
    {
      "loss": 1.1441,
      "grad_norm": 20.439176559448242,
      "learning_rate": 6.407465988886104e-07,
      "epoch": 3.5679611650485437,
      "step": 80850
    },
    {
      "loss": 1.0882,
      "grad_norm": 28.07246971130371,
      "learning_rate": 6.374744785797114e-07,
      "epoch": 3.5701676963812887,
      "step": 80900
    },
    {
      "loss": 1.1246,
      "grad_norm": 17.049623489379883,
      "learning_rate": 6.342023582708123e-07,
      "epoch": 3.5723742277140333,
      "step": 80950
    },
    {
      "loss": 0.9341,
      "grad_norm": 18.767879486083984,
      "learning_rate": 6.309302379619132e-07,
      "epoch": 3.5745807590467784,
      "step": 81000
    },
    {
      "loss": 1.1203,
      "grad_norm": 20.838193893432617,
      "learning_rate": 6.276581176530142e-07,
      "epoch": 3.5767872903795235,
      "step": 81050
    },
    {
      "loss": 1.118,
      "grad_norm": 24.236114501953125,
      "learning_rate": 6.243859973441152e-07,
      "epoch": 3.5789938217122685,
      "step": 81100
    },
    {
      "loss": 1.0291,
      "grad_norm": 22.787487030029297,
      "learning_rate": 6.21113877035216e-07,
      "epoch": 3.581200353045013,
      "step": 81150
    },
    {
      "loss": 1.0366,
      "grad_norm": 78.82022857666016,
      "learning_rate": 6.178417567263171e-07,
      "epoch": 3.5834068843777582,
      "step": 81200
    },
    {
      "loss": 1.0374,
      "grad_norm": 22.352367401123047,
      "learning_rate": 6.14569636417418e-07,
      "epoch": 3.585613415710503,
      "step": 81250
    },
    {
      "loss": 1.1611,
      "grad_norm": 23.460163116455078,
      "learning_rate": 6.11297516108519e-07,
      "epoch": 3.587819947043248,
      "step": 81300
    },
    {
      "loss": 1.0753,
      "grad_norm": 23.826805114746094,
      "learning_rate": 6.0802539579962e-07,
      "epoch": 3.590026478375993,
      "step": 81350
    },
    {
      "loss": 1.0359,
      "grad_norm": 20.069364547729492,
      "learning_rate": 6.04753275490721e-07,
      "epoch": 3.592233009708738,
      "step": 81400
    },
    {
      "loss": 0.9707,
      "grad_norm": 16.96755027770996,
      "learning_rate": 6.014811551818219e-07,
      "epoch": 3.5944395410414827,
      "step": 81450
    },
    {
      "loss": 0.8901,
      "grad_norm": 24.32573127746582,
      "learning_rate": 5.982090348729228e-07,
      "epoch": 3.5966460723742277,
      "step": 81500
    },
    {
      "loss": 1.1101,
      "grad_norm": 47.29060745239258,
      "learning_rate": 5.949369145640238e-07,
      "epoch": 3.598852603706973,
      "step": 81550
    },
    {
      "loss": 0.9728,
      "grad_norm": 21.178783416748047,
      "learning_rate": 5.916647942551247e-07,
      "epoch": 3.6010591350397174,
      "step": 81600
    },
    {
      "loss": 1.0993,
      "grad_norm": 25.24443244934082,
      "learning_rate": 5.883926739462257e-07,
      "epoch": 3.6032656663724625,
      "step": 81650
    },
    {
      "loss": 1.1952,
      "grad_norm": 18.633811950683594,
      "learning_rate": 5.851205536373267e-07,
      "epoch": 3.6054721977052075,
      "step": 81700
    },
    {
      "loss": 1.0278,
      "grad_norm": 16.706199645996094,
      "learning_rate": 5.818484333284276e-07,
      "epoch": 3.6076787290379526,
      "step": 81750
    },
    {
      "loss": 1.1177,
      "grad_norm": 24.300249099731445,
      "learning_rate": 5.785763130195286e-07,
      "epoch": 3.6098852603706972,
      "step": 81800
    },
    {
      "loss": 1.044,
      "grad_norm": 15.574190139770508,
      "learning_rate": 5.753041927106295e-07,
      "epoch": 3.6120917917034423,
      "step": 81850
    },
    {
      "loss": 1.067,
      "grad_norm": 21.593839645385742,
      "learning_rate": 5.720320724017305e-07,
      "epoch": 3.614298323036187,
      "step": 81900
    },
    {
      "loss": 1.1357,
      "grad_norm": 12.02381706237793,
      "learning_rate": 5.687599520928315e-07,
      "epoch": 3.616504854368932,
      "step": 81950
    },
    {
      "loss": 1.0865,
      "grad_norm": 28.288875579833984,
      "learning_rate": 5.654878317839324e-07,
      "epoch": 3.618711385701677,
      "step": 82000
    },
    {
      "loss": 1.0517,
      "grad_norm": 48.0111083984375,
      "learning_rate": 5.622157114750334e-07,
      "epoch": 3.620917917034422,
      "step": 82050
    },
    {
      "loss": 1.0244,
      "grad_norm": 17.571680068969727,
      "learning_rate": 5.589435911661344e-07,
      "epoch": 3.6231244483671667,
      "step": 82100
    },
    {
      "loss": 1.1081,
      "grad_norm": 109.78961181640625,
      "learning_rate": 5.556714708572352e-07,
      "epoch": 3.625330979699912,
      "step": 82150
    },
    {
      "loss": 1.0792,
      "grad_norm": 29.331378936767578,
      "learning_rate": 5.523993505483363e-07,
      "epoch": 3.6275375110326564,
      "step": 82200
    },
    {
      "loss": 1.1113,
      "grad_norm": 23.457155227661133,
      "learning_rate": 5.491272302394372e-07,
      "epoch": 3.6297440423654015,
      "step": 82250
    },
    {
      "loss": 1.1679,
      "grad_norm": 14.595743179321289,
      "learning_rate": 5.458551099305382e-07,
      "epoch": 3.6319505736981466,
      "step": 82300
    },
    {
      "loss": 1.0676,
      "grad_norm": 37.72846221923828,
      "learning_rate": 5.425829896216391e-07,
      "epoch": 3.6341571050308916,
      "step": 82350
    },
    {
      "loss": 1.0553,
      "grad_norm": 29.765186309814453,
      "learning_rate": 5.3931086931274e-07,
      "epoch": 3.6363636363636362,
      "step": 82400
    },
    {
      "loss": 0.9967,
      "grad_norm": 23.497577667236328,
      "learning_rate": 5.360387490038411e-07,
      "epoch": 3.6385701676963813,
      "step": 82450
    },
    {
      "loss": 1.0786,
      "grad_norm": 19.636627197265625,
      "learning_rate": 5.32766628694942e-07,
      "epoch": 3.6407766990291264,
      "step": 82500
    },
    {
      "loss": 1.1107,
      "grad_norm": 18.293737411499023,
      "learning_rate": 5.29494508386043e-07,
      "epoch": 3.642983230361871,
      "step": 82550
    },
    {
      "loss": 0.9552,
      "grad_norm": 16.547515869140625,
      "learning_rate": 5.262223880771439e-07,
      "epoch": 3.645189761694616,
      "step": 82600
    },
    {
      "loss": 1.1659,
      "grad_norm": 20.46694564819336,
      "learning_rate": 5.229502677682449e-07,
      "epoch": 3.647396293027361,
      "step": 82650
    },
    {
      "loss": 1.0176,
      "grad_norm": 18.87681007385254,
      "learning_rate": 5.196781474593458e-07,
      "epoch": 3.649602824360106,
      "step": 82700
    },
    {
      "loss": 1.0486,
      "grad_norm": 31.551000595092773,
      "learning_rate": 5.164060271504468e-07,
      "epoch": 3.651809355692851,
      "step": 82750
    },
    {
      "loss": 1.2132,
      "grad_norm": 17.510112762451172,
      "learning_rate": 5.131339068415477e-07,
      "epoch": 3.654015887025596,
      "step": 82800
    },
    {
      "loss": 1.0027,
      "grad_norm": 35.33711624145508,
      "learning_rate": 5.098617865326487e-07,
      "epoch": 3.6562224183583405,
      "step": 82850
    },
    {
      "loss": 1.1018,
      "grad_norm": 22.935562133789062,
      "learning_rate": 5.065896662237496e-07,
      "epoch": 3.6584289496910856,
      "step": 82900
    },
    {
      "loss": 0.9536,
      "grad_norm": 52.62080764770508,
      "learning_rate": 5.033175459148507e-07,
      "epoch": 3.6606354810238306,
      "step": 82950
    },
    {
      "loss": 0.9257,
      "grad_norm": 20.45958709716797,
      "learning_rate": 5.000454256059516e-07,
      "epoch": 3.6628420123565757,
      "step": 83000
    },
    {
      "loss": 1.1748,
      "grad_norm": 23.201793670654297,
      "learning_rate": 4.967733052970525e-07,
      "epoch": 3.6650485436893203,
      "step": 83050
    },
    {
      "loss": 1.1356,
      "grad_norm": 26.2418155670166,
      "learning_rate": 4.935011849881535e-07,
      "epoch": 3.6672550750220654,
      "step": 83100
    },
    {
      "loss": 0.9347,
      "grad_norm": 27.035829544067383,
      "learning_rate": 4.902290646792544e-07,
      "epoch": 3.66946160635481,
      "step": 83150
    },
    {
      "loss": 1.1417,
      "grad_norm": 47.681758880615234,
      "learning_rate": 4.869569443703555e-07,
      "epoch": 3.671668137687555,
      "step": 83200
    },
    {
      "loss": 0.9858,
      "grad_norm": 28.440570831298828,
      "learning_rate": 4.836848240614563e-07,
      "epoch": 3.6738746690203,
      "step": 83250
    },
    {
      "loss": 1.0039,
      "grad_norm": 23.5518798828125,
      "learning_rate": 4.804127037525573e-07,
      "epoch": 3.676081200353045,
      "step": 83300
    },
    {
      "loss": 1.0942,
      "grad_norm": 31.09003448486328,
      "learning_rate": 4.771405834436583e-07,
      "epoch": 3.67828773168579,
      "step": 83350
    },
    {
      "loss": 1.0523,
      "grad_norm": 17.363176345825195,
      "learning_rate": 4.7386846313475927e-07,
      "epoch": 3.680494263018535,
      "step": 83400
    },
    {
      "loss": 1.0402,
      "grad_norm": 22.989532470703125,
      "learning_rate": 4.7059634282586015e-07,
      "epoch": 3.68270079435128,
      "step": 83450
    },
    {
      "loss": 1.0631,
      "grad_norm": 23.280649185180664,
      "learning_rate": 4.6732422251696114e-07,
      "epoch": 3.6849073256840246,
      "step": 83500
    },
    {
      "loss": 1.0947,
      "grad_norm": 27.38829803466797,
      "learning_rate": 4.6405210220806213e-07,
      "epoch": 3.6871138570167696,
      "step": 83550
    },
    {
      "loss": 1.0264,
      "grad_norm": 16.151763916015625,
      "learning_rate": 4.6077998189916307e-07,
      "epoch": 3.6893203883495147,
      "step": 83600
    },
    {
      "loss": 1.1156,
      "grad_norm": 11.143376350402832,
      "learning_rate": 4.5750786159026406e-07,
      "epoch": 3.6915269196822593,
      "step": 83650
    },
    {
      "loss": 1.071,
      "grad_norm": 24.60650634765625,
      "learning_rate": 4.5423574128136495e-07,
      "epoch": 3.6937334510150044,
      "step": 83700
    },
    {
      "loss": 0.9845,
      "grad_norm": 17.74664878845215,
      "learning_rate": 4.50963620972466e-07,
      "epoch": 3.6959399823477495,
      "step": 83750
    },
    {
      "loss": 1.043,
      "grad_norm": 25.065933227539062,
      "learning_rate": 4.476915006635669e-07,
      "epoch": 3.698146513680494,
      "step": 83800
    },
    {
      "loss": 1.0873,
      "grad_norm": 28.161155700683594,
      "learning_rate": 4.4441938035466787e-07,
      "epoch": 3.700353045013239,
      "step": 83850
    },
    {
      "loss": 1.0705,
      "grad_norm": 32.784122467041016,
      "learning_rate": 4.411472600457688e-07,
      "epoch": 3.702559576345984,
      "step": 83900
    },
    {
      "loss": 0.9529,
      "grad_norm": 20.060922622680664,
      "learning_rate": 4.378751397368698e-07,
      "epoch": 3.7047661076787293,
      "step": 83950
    },
    {
      "loss": 1.0896,
      "grad_norm": 33.96259689331055,
      "learning_rate": 4.346030194279707e-07,
      "epoch": 3.706972639011474,
      "step": 84000
    },
    {
      "loss": 1.1501,
      "grad_norm": 19.240678787231445,
      "learning_rate": 4.313308991190717e-07,
      "epoch": 3.709179170344219,
      "step": 84050
    },
    {
      "loss": 1.0884,
      "grad_norm": 22.716163635253906,
      "learning_rate": 4.2805877881017266e-07,
      "epoch": 3.7113857016769636,
      "step": 84100
    },
    {
      "loss": 1.0816,
      "grad_norm": 26.24176788330078,
      "learning_rate": 4.247866585012736e-07,
      "epoch": 3.7135922330097086,
      "step": 84150
    },
    {
      "loss": 1.0732,
      "grad_norm": 23.739639282226562,
      "learning_rate": 4.215145381923746e-07,
      "epoch": 3.7157987643424537,
      "step": 84200
    },
    {
      "loss": 0.9755,
      "grad_norm": 21.506994247436523,
      "learning_rate": 4.1824241788347553e-07,
      "epoch": 3.7180052956751988,
      "step": 84250
    },
    {
      "loss": 1.0553,
      "grad_norm": 19.110803604125977,
      "learning_rate": 4.149702975745765e-07,
      "epoch": 3.7202118270079434,
      "step": 84300
    },
    {
      "loss": 1.069,
      "grad_norm": 23.184125900268555,
      "learning_rate": 4.116981772656774e-07,
      "epoch": 3.7224183583406885,
      "step": 84350
    },
    {
      "loss": 1.1174,
      "grad_norm": 14.334431648254395,
      "learning_rate": 4.084260569567784e-07,
      "epoch": 3.7246248896734335,
      "step": 84400
    },
    {
      "loss": 1.1508,
      "grad_norm": 21.461458206176758,
      "learning_rate": 4.0515393664787934e-07,
      "epoch": 3.726831421006178,
      "step": 84450
    },
    {
      "loss": 1.0531,
      "grad_norm": 9.694454193115234,
      "learning_rate": 4.0188181633898033e-07,
      "epoch": 3.729037952338923,
      "step": 84500
    },
    {
      "loss": 1.1681,
      "grad_norm": 12.929716110229492,
      "learning_rate": 3.986096960300812e-07,
      "epoch": 3.7312444836716683,
      "step": 84550
    },
    {
      "loss": 1.1251,
      "grad_norm": 35.268577575683594,
      "learning_rate": 3.9533757572118226e-07,
      "epoch": 3.733451015004413,
      "step": 84600
    },
    {
      "loss": 1.1473,
      "grad_norm": 24.840726852416992,
      "learning_rate": 3.9206545541228325e-07,
      "epoch": 3.735657546337158,
      "step": 84650
    },
    {
      "loss": 1.1351,
      "grad_norm": 32.977054595947266,
      "learning_rate": 3.8879333510338413e-07,
      "epoch": 3.737864077669903,
      "step": 84700
    },
    {
      "loss": 1.1553,
      "grad_norm": 36.57769775390625,
      "learning_rate": 3.855212147944851e-07,
      "epoch": 3.7400706090026477,
      "step": 84750
    },
    {
      "loss": 1.0422,
      "grad_norm": 26.155996322631836,
      "learning_rate": 3.8224909448558606e-07,
      "epoch": 3.7422771403353927,
      "step": 84800
    },
    {
      "loss": 1.0074,
      "grad_norm": 49.694557189941406,
      "learning_rate": 3.7897697417668705e-07,
      "epoch": 3.744483671668138,
      "step": 84850
    },
    {
      "loss": 0.8434,
      "grad_norm": 12.703492164611816,
      "learning_rate": 3.7570485386778794e-07,
      "epoch": 3.746690203000883,
      "step": 84900
    },
    {
      "loss": 1.1695,
      "grad_norm": 34.72416687011719,
      "learning_rate": 3.7243273355888893e-07,
      "epoch": 3.7488967343336275,
      "step": 84950
    },
    {
      "loss": 1.0289,
      "grad_norm": 31.627328872680664,
      "learning_rate": 3.6916061324998987e-07,
      "epoch": 3.7511032656663725,
      "step": 85000
    },
    {
      "loss": 1.1056,
      "grad_norm": 14.004815101623535,
      "learning_rate": 3.6588849294109086e-07,
      "epoch": 3.753309796999117,
      "step": 85050
    },
    {
      "loss": 1.0289,
      "grad_norm": 15.283597946166992,
      "learning_rate": 3.626163726321918e-07,
      "epoch": 3.755516328331862,
      "step": 85100
    },
    {
      "loss": 1.0258,
      "grad_norm": 17.114225387573242,
      "learning_rate": 3.593442523232928e-07,
      "epoch": 3.7577228596646073,
      "step": 85150
    },
    {
      "loss": 0.9631,
      "grad_norm": 22.205812454223633,
      "learning_rate": 3.560721320143937e-07,
      "epoch": 3.7599293909973523,
      "step": 85200
    },
    {
      "loss": 0.9429,
      "grad_norm": 14.464529991149902,
      "learning_rate": 3.5280001170549466e-07,
      "epoch": 3.762135922330097,
      "step": 85250
    },
    {
      "loss": 0.9966,
      "grad_norm": 28.62388801574707,
      "learning_rate": 3.4952789139659566e-07,
      "epoch": 3.764342453662842,
      "step": 85300
    },
    {
      "loss": 1.1001,
      "grad_norm": 9.059029579162598,
      "learning_rate": 3.462557710876966e-07,
      "epoch": 3.766548984995587,
      "step": 85350
    },
    {
      "loss": 1.0774,
      "grad_norm": 10.217240333557129,
      "learning_rate": 3.429836507787976e-07,
      "epoch": 3.7687555163283317,
      "step": 85400
    },
    {
      "loss": 1.0633,
      "grad_norm": 56.13359069824219,
      "learning_rate": 3.397115304698985e-07,
      "epoch": 3.770962047661077,
      "step": 85450
    },
    {
      "loss": 1.1018,
      "grad_norm": 26.451801300048828,
      "learning_rate": 3.364394101609995e-07,
      "epoch": 3.773168578993822,
      "step": 85500
    },
    {
      "loss": 0.9791,
      "grad_norm": 23.26984214782715,
      "learning_rate": 3.3316728985210045e-07,
      "epoch": 3.7753751103265665,
      "step": 85550
    },
    {
      "loss": 1.0768,
      "grad_norm": 27.124515533447266,
      "learning_rate": 3.298951695432014e-07,
      "epoch": 3.7775816416593115,
      "step": 85600
    },
    {
      "loss": 1.0915,
      "grad_norm": 22.15643310546875,
      "learning_rate": 3.266230492343024e-07,
      "epoch": 3.7797881729920566,
      "step": 85650
    },
    {
      "loss": 1.1876,
      "grad_norm": 19.584819793701172,
      "learning_rate": 3.233509289254033e-07,
      "epoch": 3.7819947043248012,
      "step": 85700
    },
    {
      "loss": 1.051,
      "grad_norm": 27.823501586914062,
      "learning_rate": 3.2007880861650426e-07,
      "epoch": 3.7842012356575463,
      "step": 85750
    },
    {
      "loss": 1.0328,
      "grad_norm": 30.726625442504883,
      "learning_rate": 3.168066883076052e-07,
      "epoch": 3.7864077669902914,
      "step": 85800
    },
    {
      "loss": 1.113,
      "grad_norm": 26.524686813354492,
      "learning_rate": 3.135345679987062e-07,
      "epoch": 3.7886142983230364,
      "step": 85850
    },
    {
      "loss": 1.093,
      "grad_norm": 11.339323997497559,
      "learning_rate": 3.102624476898071e-07,
      "epoch": 3.790820829655781,
      "step": 85900
    },
    {
      "loss": 1.0907,
      "grad_norm": 16.982372283935547,
      "learning_rate": 3.069903273809081e-07,
      "epoch": 3.793027360988526,
      "step": 85950
    },
    {
      "loss": 1.0784,
      "grad_norm": 23.89915657043457,
      "learning_rate": 3.0371820707200905e-07,
      "epoch": 3.7952338923212707,
      "step": 86000
    },
    {
      "loss": 1.0841,
      "grad_norm": 43.87611770629883,
      "learning_rate": 3.0044608676311004e-07,
      "epoch": 3.797440423654016,
      "step": 86050
    },
    {
      "loss": 0.9966,
      "grad_norm": 34.088104248046875,
      "learning_rate": 2.97173966454211e-07,
      "epoch": 3.799646954986761,
      "step": 86100
    },
    {
      "loss": 1.016,
      "grad_norm": 31.892379760742188,
      "learning_rate": 2.939018461453119e-07,
      "epoch": 3.801853486319506,
      "step": 86150
    },
    {
      "loss": 0.96,
      "grad_norm": 26.500362396240234,
      "learning_rate": 2.906297258364129e-07,
      "epoch": 3.8040600176522505,
      "step": 86200
    },
    {
      "loss": 1.1716,
      "grad_norm": 11.899147033691406,
      "learning_rate": 2.8735760552751385e-07,
      "epoch": 3.8062665489849956,
      "step": 86250
    },
    {
      "loss": 1.0849,
      "grad_norm": 17.812143325805664,
      "learning_rate": 2.840854852186148e-07,
      "epoch": 3.8084730803177407,
      "step": 86300
    },
    {
      "loss": 0.9599,
      "grad_norm": 22.242431640625,
      "learning_rate": 2.808133649097158e-07,
      "epoch": 3.8106796116504853,
      "step": 86350
    },
    {
      "loss": 1.1495,
      "grad_norm": 22.39906883239746,
      "learning_rate": 2.775412446008167e-07,
      "epoch": 3.8128861429832304,
      "step": 86400
    },
    {
      "loss": 1.0898,
      "grad_norm": 13.745279312133789,
      "learning_rate": 2.742691242919177e-07,
      "epoch": 3.8150926743159754,
      "step": 86450
    },
    {
      "loss": 0.9371,
      "grad_norm": 28.206506729125977,
      "learning_rate": 2.7099700398301865e-07,
      "epoch": 3.81729920564872,
      "step": 86500
    },
    {
      "loss": 1.1212,
      "grad_norm": 12.279268264770508,
      "learning_rate": 2.6772488367411964e-07,
      "epoch": 3.819505736981465,
      "step": 86550
    },
    {
      "loss": 1.0691,
      "grad_norm": 19.169536590576172,
      "learning_rate": 2.644527633652206e-07,
      "epoch": 3.82171226831421,
      "step": 86600
    },
    {
      "loss": 0.9953,
      "grad_norm": 24.859413146972656,
      "learning_rate": 2.611806430563215e-07,
      "epoch": 3.823918799646955,
      "step": 86650
    },
    {
      "loss": 1.0205,
      "grad_norm": 28.526643753051758,
      "learning_rate": 2.579085227474225e-07,
      "epoch": 3.8261253309797,
      "step": 86700
    },
    {
      "loss": 1.0045,
      "grad_norm": 24.86954116821289,
      "learning_rate": 2.5463640243852344e-07,
      "epoch": 3.828331862312445,
      "step": 86750
    },
    {
      "loss": 0.9863,
      "grad_norm": 19.655445098876953,
      "learning_rate": 2.513642821296244e-07,
      "epoch": 3.83053839364519,
      "step": 86800
    },
    {
      "loss": 1.1192,
      "grad_norm": 19.0996150970459,
      "learning_rate": 2.480921618207253e-07,
      "epoch": 3.8327449249779346,
      "step": 86850
    },
    {
      "loss": 0.9814,
      "grad_norm": 16.561981201171875,
      "learning_rate": 2.448200415118263e-07,
      "epoch": 3.8349514563106797,
      "step": 86900
    },
    {
      "loss": 1.0943,
      "grad_norm": 9.899139404296875,
      "learning_rate": 2.4154792120292725e-07,
      "epoch": 3.8371579876434243,
      "step": 86950
    },
    {
      "loss": 1.2229,
      "grad_norm": 18.412601470947266,
      "learning_rate": 2.3827580089402824e-07,
      "epoch": 3.8393645189761694,
      "step": 87000
    },
    {
      "loss": 1.0212,
      "grad_norm": 30.64730453491211,
      "learning_rate": 2.350036805851292e-07,
      "epoch": 3.8415710503089144,
      "step": 87050
    },
    {
      "loss": 0.9922,
      "grad_norm": 19.85483169555664,
      "learning_rate": 2.3173156027623017e-07,
      "epoch": 3.8437775816416595,
      "step": 87100
    },
    {
      "loss": 1.0326,
      "grad_norm": 17.960918426513672,
      "learning_rate": 2.284594399673311e-07,
      "epoch": 3.845984112974404,
      "step": 87150
    },
    {
      "loss": 1.0851,
      "grad_norm": 20.877185821533203,
      "learning_rate": 2.2518731965843207e-07,
      "epoch": 3.848190644307149,
      "step": 87200
    },
    {
      "loss": 1.1474,
      "grad_norm": 6.325530529022217,
      "learning_rate": 2.21915199349533e-07,
      "epoch": 3.850397175639894,
      "step": 87250
    },
    {
      "loss": 1.0055,
      "grad_norm": 17.580617904663086,
      "learning_rate": 2.1864307904063397e-07,
      "epoch": 3.852603706972639,
      "step": 87300
    },
    {
      "loss": 1.0686,
      "grad_norm": 15.814029693603516,
      "learning_rate": 2.1537095873173494e-07,
      "epoch": 3.854810238305384,
      "step": 87350
    },
    {
      "loss": 1.0997,
      "grad_norm": 19.363433837890625,
      "learning_rate": 2.1209883842283588e-07,
      "epoch": 3.857016769638129,
      "step": 87400
    },
    {
      "loss": 1.1314,
      "grad_norm": 31.143571853637695,
      "learning_rate": 2.0882671811393684e-07,
      "epoch": 3.8592233009708736,
      "step": 87450
    },
    {
      "loss": 1.012,
      "grad_norm": 15.196701049804688,
      "learning_rate": 2.0555459780503778e-07,
      "epoch": 3.8614298323036187,
      "step": 87500
    },
    {
      "loss": 1.0,
      "grad_norm": 39.86362075805664,
      "learning_rate": 2.022824774961388e-07,
      "epoch": 3.8636363636363638,
      "step": 87550
    },
    {
      "loss": 1.0723,
      "grad_norm": 25.25932502746582,
      "learning_rate": 1.9901035718723973e-07,
      "epoch": 3.8658428949691084,
      "step": 87600
    },
    {
      "loss": 1.0503,
      "grad_norm": 21.298032760620117,
      "learning_rate": 1.957382368783407e-07,
      "epoch": 3.8680494263018534,
      "step": 87650
    },
    {
      "loss": 1.0564,
      "grad_norm": 27.624399185180664,
      "learning_rate": 1.9246611656944164e-07,
      "epoch": 3.8702559576345985,
      "step": 87700
    },
    {
      "loss": 1.1014,
      "grad_norm": 17.327226638793945,
      "learning_rate": 1.891939962605426e-07,
      "epoch": 3.8724624889673436,
      "step": 87750
    },
    {
      "loss": 1.0954,
      "grad_norm": 13.349093437194824,
      "learning_rate": 1.8592187595164357e-07,
      "epoch": 3.874669020300088,
      "step": 87800
    },
    {
      "loss": 1.0217,
      "grad_norm": 18.483318328857422,
      "learning_rate": 1.826497556427445e-07,
      "epoch": 3.8768755516328333,
      "step": 87850
    },
    {
      "loss": 1.0469,
      "grad_norm": 12.696819305419922,
      "learning_rate": 1.7937763533384547e-07,
      "epoch": 3.879082082965578,
      "step": 87900
    },
    {
      "loss": 1.144,
      "grad_norm": 35.92387771606445,
      "learning_rate": 1.7610551502494643e-07,
      "epoch": 3.881288614298323,
      "step": 87950
    },
    {
      "loss": 1.0427,
      "grad_norm": 12.725078582763672,
      "learning_rate": 1.728333947160474e-07,
      "epoch": 3.883495145631068,
      "step": 88000
    },
    {
      "loss": 1.0259,
      "grad_norm": 27.55927848815918,
      "learning_rate": 1.6956127440714834e-07,
      "epoch": 3.885701676963813,
      "step": 88050
    },
    {
      "loss": 0.9245,
      "grad_norm": 27.665084838867188,
      "learning_rate": 1.662891540982493e-07,
      "epoch": 3.8879082082965577,
      "step": 88100
    },
    {
      "loss": 1.0114,
      "grad_norm": 20.469514846801758,
      "learning_rate": 1.6301703378935027e-07,
      "epoch": 3.8901147396293028,
      "step": 88150
    },
    {
      "loss": 1.1604,
      "grad_norm": 17.545488357543945,
      "learning_rate": 1.5974491348045123e-07,
      "epoch": 3.8923212709620474,
      "step": 88200
    },
    {
      "loss": 1.1474,
      "grad_norm": 6.321816444396973,
      "learning_rate": 1.564727931715522e-07,
      "epoch": 3.8945278022947925,
      "step": 88250
    },
    {
      "loss": 0.9912,
      "grad_norm": 24.967483520507812,
      "learning_rate": 1.5320067286265313e-07,
      "epoch": 3.8967343336275375,
      "step": 88300
    },
    {
      "loss": 1.1038,
      "grad_norm": 21.217302322387695,
      "learning_rate": 1.499285525537541e-07,
      "epoch": 3.8989408649602826,
      "step": 88350
    },
    {
      "loss": 0.9887,
      "grad_norm": 20.42879867553711,
      "learning_rate": 1.4665643224485506e-07,
      "epoch": 3.901147396293027,
      "step": 88400
    },
    {
      "loss": 0.9509,
      "grad_norm": 26.814727783203125,
      "learning_rate": 1.4338431193595603e-07,
      "epoch": 3.9033539276257723,
      "step": 88450
    },
    {
      "loss": 1.2166,
      "grad_norm": 6.275712966918945,
      "learning_rate": 1.40112191627057e-07,
      "epoch": 3.9055604589585173,
      "step": 88500
    },
    {
      "loss": 1.1094,
      "grad_norm": 23.85308837890625,
      "learning_rate": 1.3684007131815793e-07,
      "epoch": 3.907766990291262,
      "step": 88550
    },
    {
      "loss": 1.0191,
      "grad_norm": 31.865129470825195,
      "learning_rate": 1.335679510092589e-07,
      "epoch": 3.909973521624007,
      "step": 88600
    },
    {
      "loss": 1.1059,
      "grad_norm": 23.08898162841797,
      "learning_rate": 1.3029583070035983e-07,
      "epoch": 3.912180052956752,
      "step": 88650
    },
    {
      "loss": 0.9606,
      "grad_norm": 14.048737525939941,
      "learning_rate": 1.270237103914608e-07,
      "epoch": 3.914386584289497,
      "step": 88700
    },
    {
      "loss": 1.0995,
      "grad_norm": 16.09276008605957,
      "learning_rate": 1.2375159008256176e-07,
      "epoch": 3.9165931156222418,
      "step": 88750
    },
    {
      "loss": 1.1886,
      "grad_norm": 23.839584350585938,
      "learning_rate": 1.2047946977366273e-07,
      "epoch": 3.918799646954987,
      "step": 88800
    },
    {
      "loss": 1.1216,
      "grad_norm": 13.944255828857422,
      "learning_rate": 1.1720734946476368e-07,
      "epoch": 3.9210061782877315,
      "step": 88850
    },
    {
      "loss": 1.0148,
      "grad_norm": 27.345008850097656,
      "learning_rate": 1.1393522915586463e-07,
      "epoch": 3.9232127096204765,
      "step": 88900
    },
    {
      "loss": 1.0872,
      "grad_norm": 22.527462005615234,
      "learning_rate": 1.1066310884696559e-07,
      "epoch": 3.9254192409532216,
      "step": 88950
    },
    {
      "loss": 1.0525,
      "grad_norm": 27.25005531311035,
      "learning_rate": 1.0739098853806656e-07,
      "epoch": 3.9276257722859667,
      "step": 89000
    },
    {
      "loss": 1.102,
      "grad_norm": 28.60861587524414,
      "learning_rate": 1.0411886822916752e-07,
      "epoch": 3.9298323036187113,
      "step": 89050
    },
    {
      "loss": 1.0631,
      "grad_norm": 22.19217300415039,
      "learning_rate": 1.0084674792026847e-07,
      "epoch": 3.9320388349514563,
      "step": 89100
    },
    {
      "loss": 0.9813,
      "grad_norm": 27.93310546875,
      "learning_rate": 9.757462761136942e-08,
      "epoch": 3.934245366284201,
      "step": 89150
    },
    {
      "loss": 0.9756,
      "grad_norm": 23.628503799438477,
      "learning_rate": 9.430250730247038e-08,
      "epoch": 3.936451897616946,
      "step": 89200
    },
    {
      "loss": 1.0748,
      "grad_norm": 17.243392944335938,
      "learning_rate": 9.103038699357134e-08,
      "epoch": 3.938658428949691,
      "step": 89250
    },
    {
      "loss": 1.0643,
      "grad_norm": 12.786816596984863,
      "learning_rate": 8.77582666846723e-08,
      "epoch": 3.940864960282436,
      "step": 89300
    },
    {
      "loss": 1.109,
      "grad_norm": 10.150195121765137,
      "learning_rate": 8.448614637577327e-08,
      "epoch": 3.943071491615181,
      "step": 89350
    },
    {
      "loss": 0.9258,
      "grad_norm": 19.518583297729492,
      "learning_rate": 8.121402606687422e-08,
      "epoch": 3.945278022947926,
      "step": 89400
    },
    {
      "loss": 1.1851,
      "grad_norm": 21.433185577392578,
      "learning_rate": 7.794190575797517e-08,
      "epoch": 3.947484554280671,
      "step": 89450
    },
    {
      "loss": 1.1157,
      "grad_norm": 29.129528045654297,
      "learning_rate": 7.466978544907614e-08,
      "epoch": 3.9496910856134155,
      "step": 89500
    },
    {
      "loss": 1.0664,
      "grad_norm": 23.262619018554688,
      "learning_rate": 7.139766514017709e-08,
      "epoch": 3.9518976169461606,
      "step": 89550
    },
    {
      "loss": 1.0568,
      "grad_norm": 94.7167739868164,
      "learning_rate": 6.812554483127805e-08,
      "epoch": 3.9541041482789057,
      "step": 89600
    },
    {
      "loss": 1.043,
      "grad_norm": 9.57487964630127,
      "learning_rate": 6.4853424522379e-08,
      "epoch": 3.9563106796116507,
      "step": 89650
    },
    {
      "loss": 1.1338,
      "grad_norm": 22.36676025390625,
      "learning_rate": 6.158130421347997e-08,
      "epoch": 3.9585172109443953,
      "step": 89700
    },
    {
      "loss": 1.0901,
      "grad_norm": 12.197407722473145,
      "learning_rate": 5.8309183904580926e-08,
      "epoch": 3.9607237422771404,
      "step": 89750
    },
    {
      "loss": 1.0751,
      "grad_norm": 15.758573532104492,
      "learning_rate": 5.5037063595681884e-08,
      "epoch": 3.962930273609885,
      "step": 89800
    },
    {
      "loss": 1.1256,
      "grad_norm": 25.5523738861084,
      "learning_rate": 5.1764943286782836e-08,
      "epoch": 3.96513680494263,
      "step": 89850
    },
    {
      "loss": 1.0398,
      "grad_norm": 23.159828186035156,
      "learning_rate": 4.84928229778838e-08,
      "epoch": 3.967343336275375,
      "step": 89900
    },
    {
      "loss": 1.0518,
      "grad_norm": 20.68575668334961,
      "learning_rate": 4.522070266898476e-08,
      "epoch": 3.9695498676081202,
      "step": 89950
    },
    {
      "loss": 1.1792,
      "grad_norm": 36.749267578125,
      "learning_rate": 4.1948582360085716e-08,
      "epoch": 3.971756398940865,
      "step": 90000
    },
    {
      "loss": 1.0969,
      "grad_norm": 19.691099166870117,
      "learning_rate": 3.8676462051186674e-08,
      "epoch": 3.97396293027361,
      "step": 90050
    },
    {
      "loss": 1.0024,
      "grad_norm": 9.448711395263672,
      "learning_rate": 3.540434174228763e-08,
      "epoch": 3.9761694616063545,
      "step": 90100
    },
    {
      "loss": 1.0602,
      "grad_norm": 13.675857543945312,
      "learning_rate": 3.213222143338859e-08,
      "epoch": 3.9783759929390996,
      "step": 90150
    },
    {
      "loss": 1.0693,
      "grad_norm": 21.849349975585938,
      "learning_rate": 2.8860101124489548e-08,
      "epoch": 3.9805825242718447,
      "step": 90200
    },
    {
      "loss": 1.0878,
      "grad_norm": 14.953470230102539,
      "learning_rate": 2.558798081559051e-08,
      "epoch": 3.9827890556045897,
      "step": 90250
    },
    {
      "loss": 1.0924,
      "grad_norm": 26.83106803894043,
      "learning_rate": 2.2315860506691464e-08,
      "epoch": 3.9849955869373344,
      "step": 90300
    },
    {
      "loss": 1.0235,
      "grad_norm": 24.3897762298584,
      "learning_rate": 1.9043740197792425e-08,
      "epoch": 3.9872021182700794,
      "step": 90350
    },
    {
      "loss": 1.006,
      "grad_norm": 19.246124267578125,
      "learning_rate": 1.577161988889338e-08,
      "epoch": 3.9894086496028245,
      "step": 90400
    },
    {
      "loss": 1.1331,
      "grad_norm": 25.235734939575195,
      "learning_rate": 1.2499499579994341e-08,
      "epoch": 3.991615180935569,
      "step": 90450
    },
    {
      "loss": 0.9568,
      "grad_norm": 11.946321487426758,
      "learning_rate": 9.227379271095297e-09,
      "epoch": 3.993821712268314,
      "step": 90500
    },
    {
      "loss": 1.1641,
      "grad_norm": 30.319751739501953,
      "learning_rate": 5.955258962196255e-09,
      "epoch": 3.9960282436010592,
      "step": 90550
    },
    {
      "loss": 1.0442,
      "grad_norm": 9.063669204711914,
      "learning_rate": 2.6831386532972146e-09,
      "epoch": 3.9982347749338043,
      "step": 90600
    },
    {
      "eval_loss": 0.9211010773595544,
      "eval_exact_match": 76.4516413695729,
      "eval_f1": 81.96464829364392,
      "eval_samples": 22720,
      "step": 90640
    },
    {
      "eval_loss": 0.9211010773595544,
      "eval_exact_match": 76.4516413695729,
      "eval_f1": 81.96464829364392,
      "eval_samples": 22720,
      "epoch": 4.0,
      "step": 90640
    },
    {
      "train_runtime": 28671.1822,
      "train_samples_per_second": 25.291,
      "train_steps_per_second": 3.161,
      "total_flos": 2.1185980023914496e+16,
      "train_loss": 1.376882006105657,
      "epoch": 4.0,
      "step": 90640
    }
  ]
}
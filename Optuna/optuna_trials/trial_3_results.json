{
  "trial_number": 3,
  "hyperparameters": {
    "learning_rate": 1.3636348496602555e-05,
    "per_device_train_batch_size": 16,
    "num_train_epochs": 3,
    "warmup_steps": 572,
    "per_device_eval_batch_size": 32
  },
  "best_f1": 83.3270978704618,
  "all_eval_f1_scores": [
    69.48406889337166,
    69.48406889337166,
    82.03021130290776,
    82.03021130290776,
    83.3270978704618,
    83.3270978704618
  ],
  "training_logs": [
    {
      "loss": 6.3542,
      "grad_norm": 9.633011817932129,
      "learning_rate": 1.1681487348488202e-06,
      "epoch": 0.00441306266548985,
      "step": 50
    },
    {
      "loss": 6.1814,
      "grad_norm": 7.914832592010498,
      "learning_rate": 2.360137239796596e-06,
      "epoch": 0.0088261253309797,
      "step": 100
    },
    {
      "loss": 5.7493,
      "grad_norm": 7.579014301300049,
      "learning_rate": 3.5521257447443718e-06,
      "epoch": 0.01323918799646955,
      "step": 150
    },
    {
      "loss": 5.2146,
      "grad_norm": 5.867730140686035,
      "learning_rate": 4.744114249692148e-06,
      "epoch": 0.0176522506619594,
      "step": 200
    },
    {
      "loss": 4.6295,
      "grad_norm": 6.354702949523926,
      "learning_rate": 5.9361027546399235e-06,
      "epoch": 0.02206531332744925,
      "step": 250
    },
    {
      "loss": 4.2054,
      "grad_norm": 6.976072311401367,
      "learning_rate": 7.1280912595876996e-06,
      "epoch": 0.0264783759929391,
      "step": 300
    },
    {
      "loss": 3.8615,
      "grad_norm": 5.374253749847412,
      "learning_rate": 8.320079764535475e-06,
      "epoch": 0.03089143865842895,
      "step": 350
    },
    {
      "loss": 3.6001,
      "grad_norm": 7.455139636993408,
      "learning_rate": 9.512068269483252e-06,
      "epoch": 0.0353045013239188,
      "step": 400
    },
    {
      "loss": 3.438,
      "grad_norm": 9.504347801208496,
      "learning_rate": 1.0704056774431027e-05,
      "epoch": 0.03971756398940865,
      "step": 450
    },
    {
      "loss": 3.2836,
      "grad_norm": 6.435079574584961,
      "learning_rate": 1.1896045279378804e-05,
      "epoch": 0.0441306266548985,
      "step": 500
    },
    {
      "loss": 3.1271,
      "grad_norm": 9.160845756530762,
      "learning_rate": 1.3088033784326579e-05,
      "epoch": 0.04854368932038835,
      "step": 550
    },
    {
      "loss": 3.0944,
      "grad_norm": 11.277053833007812,
      "learning_rate": 1.3625331038663472e-05,
      "epoch": 0.0529567519858782,
      "step": 600
    },
    {
      "loss": 2.8549,
      "grad_norm": 9.440730094909668,
      "learning_rate": 1.3604928338776281e-05,
      "epoch": 0.05736981465136805,
      "step": 650
    },
    {
      "loss": 2.7457,
      "grad_norm": 15.911848068237305,
      "learning_rate": 1.3584525638889092e-05,
      "epoch": 0.0617828773168579,
      "step": 700
    },
    {
      "loss": 2.7408,
      "grad_norm": 15.89117431640625,
      "learning_rate": 1.35641229390019e-05,
      "epoch": 0.06619593998234775,
      "step": 750
    },
    {
      "loss": 2.5141,
      "grad_norm": 15.770398139953613,
      "learning_rate": 1.3543720239114711e-05,
      "epoch": 0.0706090026478376,
      "step": 800
    },
    {
      "loss": 2.6154,
      "grad_norm": 20.550058364868164,
      "learning_rate": 1.3523317539227521e-05,
      "epoch": 0.07502206531332745,
      "step": 850
    },
    {
      "loss": 2.571,
      "grad_norm": 18.365537643432617,
      "learning_rate": 1.350291483934033e-05,
      "epoch": 0.0794351279788173,
      "step": 900
    },
    {
      "loss": 2.506,
      "grad_norm": 17.079620361328125,
      "learning_rate": 1.348251213945314e-05,
      "epoch": 0.08384819064430715,
      "step": 950
    },
    {
      "loss": 2.4802,
      "grad_norm": 11.88174819946289,
      "learning_rate": 1.346210943956595e-05,
      "epoch": 0.088261253309797,
      "step": 1000
    },
    {
      "loss": 2.4844,
      "grad_norm": 15.33433723449707,
      "learning_rate": 1.344170673967876e-05,
      "epoch": 0.09267431597528684,
      "step": 1050
    },
    {
      "loss": 2.3932,
      "grad_norm": 13.567448616027832,
      "learning_rate": 1.3421304039791569e-05,
      "epoch": 0.0970873786407767,
      "step": 1100
    },
    {
      "loss": 2.3914,
      "grad_norm": 17.66469955444336,
      "learning_rate": 1.3400901339904378e-05,
      "epoch": 0.10150044130626655,
      "step": 1150
    },
    {
      "loss": 2.2932,
      "grad_norm": 15.886123657226562,
      "learning_rate": 1.3380498640017188e-05,
      "epoch": 0.1059135039717564,
      "step": 1200
    },
    {
      "loss": 2.2662,
      "grad_norm": 16.169776916503906,
      "learning_rate": 1.3360095940129997e-05,
      "epoch": 0.11032656663724624,
      "step": 1250
    },
    {
      "loss": 2.3433,
      "grad_norm": 9.138205528259277,
      "learning_rate": 1.3339693240242807e-05,
      "epoch": 0.1147396293027361,
      "step": 1300
    },
    {
      "loss": 2.1894,
      "grad_norm": 20.884695053100586,
      "learning_rate": 1.3319290540355618e-05,
      "epoch": 0.11915269196822595,
      "step": 1350
    },
    {
      "loss": 2.2183,
      "grad_norm": 14.51710033416748,
      "learning_rate": 1.3298887840468427e-05,
      "epoch": 0.1235657546337158,
      "step": 1400
    },
    {
      "loss": 2.2309,
      "grad_norm": 18.359399795532227,
      "learning_rate": 1.3278485140581237e-05,
      "epoch": 0.12797881729920565,
      "step": 1450
    },
    {
      "loss": 2.1609,
      "grad_norm": 18.620046615600586,
      "learning_rate": 1.3258082440694046e-05,
      "epoch": 0.1323918799646955,
      "step": 1500
    },
    {
      "loss": 2.1102,
      "grad_norm": 29.016891479492188,
      "learning_rate": 1.3237679740806857e-05,
      "epoch": 0.13680494263018536,
      "step": 1550
    },
    {
      "loss": 2.1815,
      "grad_norm": 14.60159683227539,
      "learning_rate": 1.3217277040919665e-05,
      "epoch": 0.1412180052956752,
      "step": 1600
    },
    {
      "loss": 2.1596,
      "grad_norm": 17.809396743774414,
      "learning_rate": 1.3196874341032474e-05,
      "epoch": 0.14563106796116504,
      "step": 1650
    },
    {
      "loss": 2.1878,
      "grad_norm": 11.567070007324219,
      "learning_rate": 1.3176471641145285e-05,
      "epoch": 0.1500441306266549,
      "step": 1700
    },
    {
      "loss": 2.1195,
      "grad_norm": 16.314348220825195,
      "learning_rate": 1.3156068941258093e-05,
      "epoch": 0.15445719329214475,
      "step": 1750
    },
    {
      "loss": 2.12,
      "grad_norm": 19.934871673583984,
      "learning_rate": 1.3135666241370904e-05,
      "epoch": 0.1588702559576346,
      "step": 1800
    },
    {
      "loss": 2.1245,
      "grad_norm": 15.197840690612793,
      "learning_rate": 1.3115263541483713e-05,
      "epoch": 0.16328331862312445,
      "step": 1850
    },
    {
      "loss": 2.0645,
      "grad_norm": 14.173867225646973,
      "learning_rate": 1.3094860841596523e-05,
      "epoch": 0.1676963812886143,
      "step": 1900
    },
    {
      "loss": 2.0597,
      "grad_norm": 14.263736724853516,
      "learning_rate": 1.3074458141709334e-05,
      "epoch": 0.17210944395410416,
      "step": 1950
    },
    {
      "loss": 2.0405,
      "grad_norm": 17.473482131958008,
      "learning_rate": 1.3054055441822143e-05,
      "epoch": 0.176522506619594,
      "step": 2000
    },
    {
      "loss": 2.0209,
      "grad_norm": 20.71295166015625,
      "learning_rate": 1.3033652741934953e-05,
      "epoch": 0.18093556928508384,
      "step": 2050
    },
    {
      "loss": 2.0703,
      "grad_norm": 9.59339714050293,
      "learning_rate": 1.3013250042047762e-05,
      "epoch": 0.1853486319505737,
      "step": 2100
    },
    {
      "loss": 2.0596,
      "grad_norm": 15.951716423034668,
      "learning_rate": 1.299284734216057e-05,
      "epoch": 0.18976169461606354,
      "step": 2150
    },
    {
      "loss": 1.9849,
      "grad_norm": 14.380820274353027,
      "learning_rate": 1.2972444642273381e-05,
      "epoch": 0.1941747572815534,
      "step": 2200
    },
    {
      "loss": 1.8886,
      "grad_norm": 15.472697257995605,
      "learning_rate": 1.295204194238619e-05,
      "epoch": 0.19858781994704325,
      "step": 2250
    },
    {
      "loss": 1.9787,
      "grad_norm": 15.152546882629395,
      "learning_rate": 1.2931639242498999e-05,
      "epoch": 0.2030008826125331,
      "step": 2300
    },
    {
      "loss": 1.997,
      "grad_norm": 19.25718879699707,
      "learning_rate": 1.291123654261181e-05,
      "epoch": 0.20741394527802295,
      "step": 2350
    },
    {
      "loss": 1.9089,
      "grad_norm": 17.615131378173828,
      "learning_rate": 1.2890833842724618e-05,
      "epoch": 0.2118270079435128,
      "step": 2400
    },
    {
      "loss": 1.8565,
      "grad_norm": 10.856733322143555,
      "learning_rate": 1.287043114283743e-05,
      "epoch": 0.21624007060900266,
      "step": 2450
    },
    {
      "loss": 1.9701,
      "grad_norm": 19.824989318847656,
      "learning_rate": 1.2850028442950239e-05,
      "epoch": 0.22065313327449249,
      "step": 2500
    },
    {
      "loss": 1.9794,
      "grad_norm": 12.680989265441895,
      "learning_rate": 1.2829625743063048e-05,
      "epoch": 0.22506619593998234,
      "step": 2550
    },
    {
      "loss": 1.8163,
      "grad_norm": 11.395636558532715,
      "learning_rate": 1.2809223043175858e-05,
      "epoch": 0.2294792586054722,
      "step": 2600
    },
    {
      "loss": 1.8591,
      "grad_norm": 16.195514678955078,
      "learning_rate": 1.2788820343288667e-05,
      "epoch": 0.23389232127096204,
      "step": 2650
    },
    {
      "loss": 1.9379,
      "grad_norm": 19.268552780151367,
      "learning_rate": 1.2768417643401478e-05,
      "epoch": 0.2383053839364519,
      "step": 2700
    },
    {
      "loss": 1.854,
      "grad_norm": 12.6498384475708,
      "learning_rate": 1.2748014943514286e-05,
      "epoch": 0.24271844660194175,
      "step": 2750
    },
    {
      "loss": 1.9466,
      "grad_norm": 17.4202938079834,
      "learning_rate": 1.2727612243627095e-05,
      "epoch": 0.2471315092674316,
      "step": 2800
    },
    {
      "loss": 1.8956,
      "grad_norm": 16.876970291137695,
      "learning_rate": 1.2707209543739906e-05,
      "epoch": 0.25154457193292146,
      "step": 2850
    },
    {
      "loss": 1.8896,
      "grad_norm": 16.87806510925293,
      "learning_rate": 1.2686806843852715e-05,
      "epoch": 0.2559576345984113,
      "step": 2900
    },
    {
      "loss": 1.7991,
      "grad_norm": 20.194217681884766,
      "learning_rate": 1.2666404143965525e-05,
      "epoch": 0.26037069726390116,
      "step": 2950
    },
    {
      "loss": 1.8594,
      "grad_norm": 13.915084838867188,
      "learning_rate": 1.2646001444078336e-05,
      "epoch": 0.264783759929391,
      "step": 3000
    },
    {
      "loss": 1.8719,
      "grad_norm": 17.87457847595215,
      "learning_rate": 1.2625598744191144e-05,
      "epoch": 0.26919682259488087,
      "step": 3050
    },
    {
      "loss": 1.7908,
      "grad_norm": 13.687372207641602,
      "learning_rate": 1.2605196044303955e-05,
      "epoch": 0.2736098852603707,
      "step": 3100
    },
    {
      "loss": 1.8316,
      "grad_norm": 17.16006851196289,
      "learning_rate": 1.2584793344416764e-05,
      "epoch": 0.2780229479258605,
      "step": 3150
    },
    {
      "loss": 1.775,
      "grad_norm": 21.438919067382812,
      "learning_rate": 1.2564390644529574e-05,
      "epoch": 0.2824360105913504,
      "step": 3200
    },
    {
      "loss": 1.6507,
      "grad_norm": 14.4509916305542,
      "learning_rate": 1.2543987944642383e-05,
      "epoch": 0.2868490732568402,
      "step": 3250
    },
    {
      "loss": 1.7485,
      "grad_norm": 15.808652877807617,
      "learning_rate": 1.2523585244755192e-05,
      "epoch": 0.2912621359223301,
      "step": 3300
    },
    {
      "loss": 1.6611,
      "grad_norm": 17.78793716430664,
      "learning_rate": 1.2503182544868002e-05,
      "epoch": 0.29567519858781993,
      "step": 3350
    },
    {
      "loss": 1.7958,
      "grad_norm": 16.963735580444336,
      "learning_rate": 1.2482779844980811e-05,
      "epoch": 0.3000882612533098,
      "step": 3400
    },
    {
      "loss": 1.6601,
      "grad_norm": 13.532291412353516,
      "learning_rate": 1.2462377145093622e-05,
      "epoch": 0.30450132391879964,
      "step": 3450
    },
    {
      "loss": 1.631,
      "grad_norm": 12.218854904174805,
      "learning_rate": 1.244197444520643e-05,
      "epoch": 0.3089143865842895,
      "step": 3500
    },
    {
      "loss": 1.6954,
      "grad_norm": 13.943641662597656,
      "learning_rate": 1.2421571745319241e-05,
      "epoch": 0.31332744924977934,
      "step": 3550
    },
    {
      "loss": 1.6252,
      "grad_norm": 16.526607513427734,
      "learning_rate": 1.2401169045432051e-05,
      "epoch": 0.3177405119152692,
      "step": 3600
    },
    {
      "loss": 1.5807,
      "grad_norm": 22.908960342407227,
      "learning_rate": 1.238076634554486e-05,
      "epoch": 0.32215357458075905,
      "step": 3650
    },
    {
      "loss": 1.7255,
      "grad_norm": 17.004701614379883,
      "learning_rate": 1.236036364565767e-05,
      "epoch": 0.3265666372462489,
      "step": 3700
    },
    {
      "loss": 1.6403,
      "grad_norm": 15.60498046875,
      "learning_rate": 1.233996094577048e-05,
      "epoch": 0.33097969991173876,
      "step": 3750
    },
    {
      "loss": 1.6223,
      "grad_norm": 15.72801399230957,
      "learning_rate": 1.2319558245883288e-05,
      "epoch": 0.3353927625772286,
      "step": 3800
    },
    {
      "loss": 1.684,
      "grad_norm": 10.423686027526855,
      "learning_rate": 1.2299155545996099e-05,
      "epoch": 0.33980582524271846,
      "step": 3850
    },
    {
      "loss": 1.6527,
      "grad_norm": 12.415821075439453,
      "learning_rate": 1.2278752846108908e-05,
      "epoch": 0.3442188879082083,
      "step": 3900
    },
    {
      "loss": 1.5166,
      "grad_norm": 12.29996395111084,
      "learning_rate": 1.2258350146221718e-05,
      "epoch": 0.34863195057369817,
      "step": 3950
    },
    {
      "loss": 1.6341,
      "grad_norm": 13.488451957702637,
      "learning_rate": 1.2237947446334527e-05,
      "epoch": 0.353045013239188,
      "step": 4000
    },
    {
      "loss": 1.5685,
      "grad_norm": 24.988140106201172,
      "learning_rate": 1.2217544746447337e-05,
      "epoch": 0.3574580759046778,
      "step": 4050
    },
    {
      "loss": 1.7433,
      "grad_norm": 15.977781295776367,
      "learning_rate": 1.2197142046560148e-05,
      "epoch": 0.36187113857016767,
      "step": 4100
    },
    {
      "loss": 1.5784,
      "grad_norm": 15.976883888244629,
      "learning_rate": 1.2176739346672957e-05,
      "epoch": 0.3662842012356575,
      "step": 4150
    },
    {
      "loss": 1.6745,
      "grad_norm": 16.988330841064453,
      "learning_rate": 1.2156336646785767e-05,
      "epoch": 0.3706972639011474,
      "step": 4200
    },
    {
      "loss": 1.6463,
      "grad_norm": 11.023069381713867,
      "learning_rate": 1.2135933946898576e-05,
      "epoch": 0.37511032656663723,
      "step": 4250
    },
    {
      "loss": 1.5901,
      "grad_norm": 14.049068450927734,
      "learning_rate": 1.2115531247011385e-05,
      "epoch": 0.3795233892321271,
      "step": 4300
    },
    {
      "loss": 1.5283,
      "grad_norm": 13.177523612976074,
      "learning_rate": 1.2095128547124195e-05,
      "epoch": 0.38393645189761694,
      "step": 4350
    },
    {
      "loss": 1.6459,
      "grad_norm": 13.816516876220703,
      "learning_rate": 1.2074725847237004e-05,
      "epoch": 0.3883495145631068,
      "step": 4400
    },
    {
      "loss": 1.5945,
      "grad_norm": 13.014790534973145,
      "learning_rate": 1.2054323147349815e-05,
      "epoch": 0.39276257722859664,
      "step": 4450
    },
    {
      "loss": 1.5621,
      "grad_norm": 17.29477882385254,
      "learning_rate": 1.2033920447462623e-05,
      "epoch": 0.3971756398940865,
      "step": 4500
    },
    {
      "loss": 1.5532,
      "grad_norm": 16.355268478393555,
      "learning_rate": 1.2013517747575432e-05,
      "epoch": 0.40158870255957635,
      "step": 4550
    },
    {
      "loss": 1.5533,
      "grad_norm": 16.505252838134766,
      "learning_rate": 1.1993115047688243e-05,
      "epoch": 0.4060017652250662,
      "step": 4600
    },
    {
      "loss": 1.5492,
      "grad_norm": 10.471786499023438,
      "learning_rate": 1.1972712347801053e-05,
      "epoch": 0.41041482789055606,
      "step": 4650
    },
    {
      "loss": 1.6958,
      "grad_norm": 15.04953670501709,
      "learning_rate": 1.1952309647913864e-05,
      "epoch": 0.4148278905560459,
      "step": 4700
    },
    {
      "loss": 1.5676,
      "grad_norm": 15.059996604919434,
      "learning_rate": 1.1931906948026672e-05,
      "epoch": 0.41924095322153576,
      "step": 4750
    },
    {
      "loss": 1.6712,
      "grad_norm": 15.941828727722168,
      "learning_rate": 1.1911504248139481e-05,
      "epoch": 0.4236540158870256,
      "step": 4800
    },
    {
      "loss": 1.5565,
      "grad_norm": 18.096294403076172,
      "learning_rate": 1.1891101548252292e-05,
      "epoch": 0.42806707855251547,
      "step": 4850
    },
    {
      "loss": 1.5153,
      "grad_norm": 14.80591106414795,
      "learning_rate": 1.18706988483651e-05,
      "epoch": 0.4324801412180053,
      "step": 4900
    },
    {
      "loss": 1.6031,
      "grad_norm": 13.304049491882324,
      "learning_rate": 1.185029614847791e-05,
      "epoch": 0.4368932038834951,
      "step": 4950
    },
    {
      "loss": 1.5459,
      "grad_norm": 16.929555892944336,
      "learning_rate": 1.182989344859072e-05,
      "epoch": 0.44130626654898497,
      "step": 5000
    },
    {
      "loss": 1.5977,
      "grad_norm": 18.08610725402832,
      "learning_rate": 1.1809490748703529e-05,
      "epoch": 0.4457193292144748,
      "step": 5050
    },
    {
      "loss": 1.4651,
      "grad_norm": 13.528371810913086,
      "learning_rate": 1.178908804881634e-05,
      "epoch": 0.4501323918799647,
      "step": 5100
    },
    {
      "loss": 1.519,
      "grad_norm": 18.247699737548828,
      "learning_rate": 1.176868534892915e-05,
      "epoch": 0.45454545454545453,
      "step": 5150
    },
    {
      "loss": 1.5539,
      "grad_norm": 13.097143173217773,
      "learning_rate": 1.1748282649041958e-05,
      "epoch": 0.4589585172109444,
      "step": 5200
    },
    {
      "loss": 1.5373,
      "grad_norm": 11.260603904724121,
      "learning_rate": 1.1727879949154769e-05,
      "epoch": 0.46337157987643424,
      "step": 5250
    },
    {
      "loss": 1.5427,
      "grad_norm": 17.116985321044922,
      "learning_rate": 1.1707477249267578e-05,
      "epoch": 0.4677846425419241,
      "step": 5300
    },
    {
      "loss": 1.4837,
      "grad_norm": 12.992411613464355,
      "learning_rate": 1.1687074549380388e-05,
      "epoch": 0.47219770520741394,
      "step": 5350
    },
    {
      "loss": 1.4444,
      "grad_norm": 10.520135879516602,
      "learning_rate": 1.1666671849493197e-05,
      "epoch": 0.4766107678729038,
      "step": 5400
    },
    {
      "loss": 1.4737,
      "grad_norm": 13.1035795211792,
      "learning_rate": 1.1646269149606006e-05,
      "epoch": 0.48102383053839365,
      "step": 5450
    },
    {
      "loss": 1.5135,
      "grad_norm": 16.93153190612793,
      "learning_rate": 1.1625866449718816e-05,
      "epoch": 0.4854368932038835,
      "step": 5500
    },
    {
      "loss": 1.5259,
      "grad_norm": 11.461222648620605,
      "learning_rate": 1.1605463749831625e-05,
      "epoch": 0.48984995586937335,
      "step": 5550
    },
    {
      "loss": 1.4981,
      "grad_norm": 20.15288734436035,
      "learning_rate": 1.1585061049944436e-05,
      "epoch": 0.4942630185348632,
      "step": 5600
    },
    {
      "loss": 1.5305,
      "grad_norm": 11.10851001739502,
      "learning_rate": 1.1564658350057245e-05,
      "epoch": 0.49867608120035306,
      "step": 5650
    },
    {
      "loss": 1.5312,
      "grad_norm": 14.5559720993042,
      "learning_rate": 1.1544255650170055e-05,
      "epoch": 0.5030891438658429,
      "step": 5700
    },
    {
      "loss": 1.5282,
      "grad_norm": 12.39291000366211,
      "learning_rate": 1.1523852950282865e-05,
      "epoch": 0.5075022065313327,
      "step": 5750
    },
    {
      "loss": 1.518,
      "grad_norm": 17.157394409179688,
      "learning_rate": 1.1503450250395674e-05,
      "epoch": 0.5119152691968226,
      "step": 5800
    },
    {
      "loss": 1.4571,
      "grad_norm": 17.48003387451172,
      "learning_rate": 1.1483047550508485e-05,
      "epoch": 0.5163283318623124,
      "step": 5850
    },
    {
      "loss": 1.4388,
      "grad_norm": 12.29148006439209,
      "learning_rate": 1.1462644850621294e-05,
      "epoch": 0.5207413945278023,
      "step": 5900
    },
    {
      "loss": 1.6018,
      "grad_norm": 17.53702735900879,
      "learning_rate": 1.1442242150734102e-05,
      "epoch": 0.5251544571932921,
      "step": 5950
    },
    {
      "loss": 1.4886,
      "grad_norm": 11.471940994262695,
      "learning_rate": 1.1421839450846913e-05,
      "epoch": 0.529567519858782,
      "step": 6000
    },
    {
      "loss": 1.527,
      "grad_norm": 15.632393836975098,
      "learning_rate": 1.1401436750959722e-05,
      "epoch": 0.5339805825242718,
      "step": 6050
    },
    {
      "loss": 1.5492,
      "grad_norm": 13.680931091308594,
      "learning_rate": 1.1381034051072532e-05,
      "epoch": 0.5383936451897617,
      "step": 6100
    },
    {
      "loss": 1.4504,
      "grad_norm": 14.54514217376709,
      "learning_rate": 1.1360631351185341e-05,
      "epoch": 0.5428067078552515,
      "step": 6150
    },
    {
      "loss": 1.4115,
      "grad_norm": 15.133511543273926,
      "learning_rate": 1.1340228651298151e-05,
      "epoch": 0.5472197705207414,
      "step": 6200
    },
    {
      "loss": 1.4844,
      "grad_norm": 11.041407585144043,
      "learning_rate": 1.1319825951410962e-05,
      "epoch": 0.5516328331862312,
      "step": 6250
    },
    {
      "loss": 1.5533,
      "grad_norm": 24.451223373413086,
      "learning_rate": 1.129942325152377e-05,
      "epoch": 0.556045895851721,
      "step": 6300
    },
    {
      "loss": 1.4576,
      "grad_norm": 11.5262451171875,
      "learning_rate": 1.1279020551636581e-05,
      "epoch": 0.560458958517211,
      "step": 6350
    },
    {
      "loss": 1.5053,
      "grad_norm": 12.18303394317627,
      "learning_rate": 1.125861785174939e-05,
      "epoch": 0.5648720211827007,
      "step": 6400
    },
    {
      "loss": 1.4207,
      "grad_norm": 17.5033016204834,
      "learning_rate": 1.1238215151862199e-05,
      "epoch": 0.5692850838481907,
      "step": 6450
    },
    {
      "loss": 1.4612,
      "grad_norm": 10.832321166992188,
      "learning_rate": 1.121781245197501e-05,
      "epoch": 0.5736981465136805,
      "step": 6500
    },
    {
      "loss": 1.4239,
      "grad_norm": 8.157819747924805,
      "learning_rate": 1.1197409752087818e-05,
      "epoch": 0.5781112091791704,
      "step": 6550
    },
    {
      "loss": 1.5712,
      "grad_norm": 11.767350196838379,
      "learning_rate": 1.1177007052200629e-05,
      "epoch": 0.5825242718446602,
      "step": 6600
    },
    {
      "loss": 1.4744,
      "grad_norm": 16.80333709716797,
      "learning_rate": 1.1156604352313438e-05,
      "epoch": 0.5869373345101501,
      "step": 6650
    },
    {
      "loss": 1.462,
      "grad_norm": 10.87524700164795,
      "learning_rate": 1.1136201652426246e-05,
      "epoch": 0.5913503971756399,
      "step": 6700
    },
    {
      "loss": 1.4826,
      "grad_norm": 25.28164291381836,
      "learning_rate": 1.1115798952539057e-05,
      "epoch": 0.5957634598411298,
      "step": 6750
    },
    {
      "loss": 1.3947,
      "grad_norm": 14.471281051635742,
      "learning_rate": 1.1095396252651867e-05,
      "epoch": 0.6001765225066196,
      "step": 6800
    },
    {
      "loss": 1.5053,
      "grad_norm": 16.53110122680664,
      "learning_rate": 1.1074993552764678e-05,
      "epoch": 0.6045895851721095,
      "step": 6850
    },
    {
      "loss": 1.444,
      "grad_norm": 11.944790840148926,
      "learning_rate": 1.1054590852877487e-05,
      "epoch": 0.6090026478375993,
      "step": 6900
    },
    {
      "loss": 1.4607,
      "grad_norm": 14.970499992370605,
      "learning_rate": 1.1034188152990295e-05,
      "epoch": 0.6134157105030892,
      "step": 6950
    },
    {
      "loss": 1.5461,
      "grad_norm": 16.413843154907227,
      "learning_rate": 1.1013785453103106e-05,
      "epoch": 0.617828773168579,
      "step": 7000
    },
    {
      "loss": 1.4574,
      "grad_norm": 12.585189819335938,
      "learning_rate": 1.0993382753215915e-05,
      "epoch": 0.6222418358340689,
      "step": 7050
    },
    {
      "loss": 1.34,
      "grad_norm": 13.668793678283691,
      "learning_rate": 1.0972980053328725e-05,
      "epoch": 0.6266548984995587,
      "step": 7100
    },
    {
      "loss": 1.5174,
      "grad_norm": 12.633788108825684,
      "learning_rate": 1.0952577353441534e-05,
      "epoch": 0.6310679611650486,
      "step": 7150
    },
    {
      "loss": 1.4816,
      "grad_norm": 13.331578254699707,
      "learning_rate": 1.0932174653554343e-05,
      "epoch": 0.6354810238305384,
      "step": 7200
    },
    {
      "loss": 1.376,
      "grad_norm": 16.131181716918945,
      "learning_rate": 1.0911771953667153e-05,
      "epoch": 0.6398940864960282,
      "step": 7250
    },
    {
      "loss": 1.4698,
      "grad_norm": 15.00512409210205,
      "learning_rate": 1.0891369253779964e-05,
      "epoch": 0.6443071491615181,
      "step": 7300
    },
    {
      "loss": 1.5055,
      "grad_norm": 12.152202606201172,
      "learning_rate": 1.0870966553892774e-05,
      "epoch": 0.6487202118270079,
      "step": 7350
    },
    {
      "loss": 1.4377,
      "grad_norm": 12.107271194458008,
      "learning_rate": 1.0850563854005583e-05,
      "epoch": 0.6531332744924978,
      "step": 7400
    },
    {
      "loss": 1.4352,
      "grad_norm": 12.962149620056152,
      "learning_rate": 1.0830161154118392e-05,
      "epoch": 0.6575463371579876,
      "step": 7450
    },
    {
      "loss": 1.4067,
      "grad_norm": 14.970553398132324,
      "learning_rate": 1.0809758454231202e-05,
      "epoch": 0.6619593998234775,
      "step": 7500
    },
    {
      "loss": 1.441,
      "grad_norm": 18.57045555114746,
      "learning_rate": 1.0789355754344011e-05,
      "epoch": 0.6663724624889673,
      "step": 7550
    },
    {
      "loss": 1.4608,
      "grad_norm": 15.382078170776367,
      "learning_rate": 1.076895305445682e-05,
      "epoch": 0.6707855251544572,
      "step": 7600
    },
    {
      "loss": 1.3707,
      "grad_norm": 11.939228057861328,
      "learning_rate": 1.074855035456963e-05,
      "epoch": 0.675198587819947,
      "step": 7650
    },
    {
      "loss": 1.4138,
      "grad_norm": 10.318439483642578,
      "learning_rate": 1.072814765468244e-05,
      "epoch": 0.6796116504854369,
      "step": 7700
    },
    {
      "loss": 1.4429,
      "grad_norm": 15.337074279785156,
      "learning_rate": 1.070774495479525e-05,
      "epoch": 0.6840247131509267,
      "step": 7750
    },
    {
      "loss": 1.4574,
      "grad_norm": 10.037968635559082,
      "learning_rate": 1.0687342254908059e-05,
      "epoch": 0.6884377758164166,
      "step": 7800
    },
    {
      "loss": 1.5182,
      "grad_norm": 17.431062698364258,
      "learning_rate": 1.0666939555020869e-05,
      "epoch": 0.6928508384819064,
      "step": 7850
    },
    {
      "loss": 1.3793,
      "grad_norm": 12.626648902893066,
      "learning_rate": 1.064653685513368e-05,
      "epoch": 0.6972639011473963,
      "step": 7900
    },
    {
      "loss": 1.5154,
      "grad_norm": 16.204330444335938,
      "learning_rate": 1.0626134155246488e-05,
      "epoch": 0.7016769638128861,
      "step": 7950
    },
    {
      "loss": 1.4866,
      "grad_norm": 9.36548900604248,
      "learning_rate": 1.0605731455359299e-05,
      "epoch": 0.706090026478376,
      "step": 8000
    },
    {
      "loss": 1.3636,
      "grad_norm": 13.302675247192383,
      "learning_rate": 1.0585328755472108e-05,
      "epoch": 0.7105030891438658,
      "step": 8050
    },
    {
      "loss": 1.4099,
      "grad_norm": 15.320762634277344,
      "learning_rate": 1.0564926055584917e-05,
      "epoch": 0.7149161518093556,
      "step": 8100
    },
    {
      "loss": 1.4683,
      "grad_norm": 20.2357234954834,
      "learning_rate": 1.0544523355697727e-05,
      "epoch": 0.7193292144748455,
      "step": 8150
    },
    {
      "loss": 1.4828,
      "grad_norm": 13.306221008300781,
      "learning_rate": 1.0524120655810536e-05,
      "epoch": 0.7237422771403353,
      "step": 8200
    },
    {
      "loss": 1.4178,
      "grad_norm": 19.729204177856445,
      "learning_rate": 1.0503717955923346e-05,
      "epoch": 0.7281553398058253,
      "step": 8250
    },
    {
      "loss": 1.4501,
      "grad_norm": 11.913211822509766,
      "learning_rate": 1.0483315256036155e-05,
      "epoch": 0.732568402471315,
      "step": 8300
    },
    {
      "loss": 1.399,
      "grad_norm": 9.852944374084473,
      "learning_rate": 1.0462912556148964e-05,
      "epoch": 0.736981465136805,
      "step": 8350
    },
    {
      "loss": 1.378,
      "grad_norm": 12.238624572753906,
      "learning_rate": 1.0442509856261776e-05,
      "epoch": 0.7413945278022948,
      "step": 8400
    },
    {
      "loss": 1.3779,
      "grad_norm": 13.239027976989746,
      "learning_rate": 1.0422107156374585e-05,
      "epoch": 0.7458075904677847,
      "step": 8450
    },
    {
      "loss": 1.3791,
      "grad_norm": 12.43116283416748,
      "learning_rate": 1.0401704456487395e-05,
      "epoch": 0.7502206531332745,
      "step": 8500
    },
    {
      "loss": 1.3413,
      "grad_norm": 12.541815757751465,
      "learning_rate": 1.0381301756600204e-05,
      "epoch": 0.7546337157987644,
      "step": 8550
    },
    {
      "loss": 1.4516,
      "grad_norm": 12.875128746032715,
      "learning_rate": 1.0360899056713013e-05,
      "epoch": 0.7590467784642542,
      "step": 8600
    },
    {
      "loss": 1.3802,
      "grad_norm": 19.321121215820312,
      "learning_rate": 1.0340496356825824e-05,
      "epoch": 0.7634598411297441,
      "step": 8650
    },
    {
      "loss": 1.4474,
      "grad_norm": 13.339765548706055,
      "learning_rate": 1.0320093656938632e-05,
      "epoch": 0.7678729037952339,
      "step": 8700
    },
    {
      "loss": 1.3754,
      "grad_norm": 10.0039644241333,
      "learning_rate": 1.0299690957051443e-05,
      "epoch": 0.7722859664607238,
      "step": 8750
    },
    {
      "loss": 1.4998,
      "grad_norm": 13.41710090637207,
      "learning_rate": 1.0279288257164252e-05,
      "epoch": 0.7766990291262136,
      "step": 8800
    },
    {
      "loss": 1.4144,
      "grad_norm": 11.594162940979004,
      "learning_rate": 1.025888555727706e-05,
      "epoch": 0.7811120917917035,
      "step": 8850
    },
    {
      "loss": 1.4108,
      "grad_norm": 11.6248140335083,
      "learning_rate": 1.0238482857389871e-05,
      "epoch": 0.7855251544571933,
      "step": 8900
    },
    {
      "loss": 1.3516,
      "grad_norm": 14.093049049377441,
      "learning_rate": 1.0218080157502681e-05,
      "epoch": 0.7899382171226832,
      "step": 8950
    },
    {
      "loss": 1.4027,
      "grad_norm": 13.252737045288086,
      "learning_rate": 1.0197677457615492e-05,
      "epoch": 0.794351279788173,
      "step": 9000
    },
    {
      "loss": 1.4343,
      "grad_norm": 19.542333602905273,
      "learning_rate": 1.01772747577283e-05,
      "epoch": 0.7987643424536628,
      "step": 9050
    },
    {
      "loss": 1.453,
      "grad_norm": 14.921073913574219,
      "learning_rate": 1.015687205784111e-05,
      "epoch": 0.8031774051191527,
      "step": 9100
    },
    {
      "loss": 1.3801,
      "grad_norm": 17.308683395385742,
      "learning_rate": 1.013646935795392e-05,
      "epoch": 0.8075904677846425,
      "step": 9150
    },
    {
      "loss": 1.5014,
      "grad_norm": 15.391987800598145,
      "learning_rate": 1.0116066658066729e-05,
      "epoch": 0.8120035304501324,
      "step": 9200
    },
    {
      "loss": 1.3336,
      "grad_norm": 10.48525333404541,
      "learning_rate": 1.009566395817954e-05,
      "epoch": 0.8164165931156222,
      "step": 9250
    },
    {
      "loss": 1.3459,
      "grad_norm": 13.528636932373047,
      "learning_rate": 1.0075261258292348e-05,
      "epoch": 0.8208296557811121,
      "step": 9300
    },
    {
      "loss": 1.4407,
      "grad_norm": 16.082929611206055,
      "learning_rate": 1.0054858558405157e-05,
      "epoch": 0.8252427184466019,
      "step": 9350
    },
    {
      "loss": 1.4745,
      "grad_norm": 14.920615196228027,
      "learning_rate": 1.0034455858517967e-05,
      "epoch": 0.8296557811120918,
      "step": 9400
    },
    {
      "loss": 1.3862,
      "grad_norm": 12.078356742858887,
      "learning_rate": 1.0014053158630776e-05,
      "epoch": 0.8340688437775816,
      "step": 9450
    },
    {
      "loss": 1.4961,
      "grad_norm": 14.516993522644043,
      "learning_rate": 9.993650458743588e-06,
      "epoch": 0.8384819064430715,
      "step": 9500
    },
    {
      "loss": 1.3789,
      "grad_norm": 11.583812713623047,
      "learning_rate": 9.973247758856397e-06,
      "epoch": 0.8428949691085613,
      "step": 9550
    },
    {
      "loss": 1.3237,
      "grad_norm": 18.394466400146484,
      "learning_rate": 9.952845058969206e-06,
      "epoch": 0.8473080317740512,
      "step": 9600
    },
    {
      "loss": 1.4672,
      "grad_norm": 17.184236526489258,
      "learning_rate": 9.932442359082017e-06,
      "epoch": 0.851721094439541,
      "step": 9650
    },
    {
      "loss": 1.3606,
      "grad_norm": 21.33690071105957,
      "learning_rate": 9.912039659194825e-06,
      "epoch": 0.8561341571050309,
      "step": 9700
    },
    {
      "loss": 1.3091,
      "grad_norm": 15.141535758972168,
      "learning_rate": 9.891636959307636e-06,
      "epoch": 0.8605472197705207,
      "step": 9750
    },
    {
      "loss": 1.4166,
      "grad_norm": 13.640765190124512,
      "learning_rate": 9.871234259420445e-06,
      "epoch": 0.8649602824360106,
      "step": 9800
    },
    {
      "loss": 1.4021,
      "grad_norm": 14.781618118286133,
      "learning_rate": 9.850831559533253e-06,
      "epoch": 0.8693733451015004,
      "step": 9850
    },
    {
      "loss": 1.3934,
      "grad_norm": 13.158429145812988,
      "learning_rate": 9.830428859646064e-06,
      "epoch": 0.8737864077669902,
      "step": 9900
    },
    {
      "loss": 1.3489,
      "grad_norm": 11.79247760772705,
      "learning_rate": 9.810026159758873e-06,
      "epoch": 0.8781994704324801,
      "step": 9950
    },
    {
      "loss": 1.3523,
      "grad_norm": 21.24655532836914,
      "learning_rate": 9.789623459871683e-06,
      "epoch": 0.8826125330979699,
      "step": 10000
    },
    {
      "loss": 1.3584,
      "grad_norm": 16.17195701599121,
      "learning_rate": 9.769220759984494e-06,
      "epoch": 0.8870255957634599,
      "step": 10050
    },
    {
      "loss": 1.2771,
      "grad_norm": 15.845816612243652,
      "learning_rate": 9.748818060097303e-06,
      "epoch": 0.8914386584289496,
      "step": 10100
    },
    {
      "loss": 1.3348,
      "grad_norm": 17.24689292907715,
      "learning_rate": 9.728415360210113e-06,
      "epoch": 0.8958517210944396,
      "step": 10150
    },
    {
      "loss": 1.4093,
      "grad_norm": 12.653352737426758,
      "learning_rate": 9.708012660322922e-06,
      "epoch": 0.9002647837599294,
      "step": 10200
    },
    {
      "loss": 1.3729,
      "grad_norm": 17.495677947998047,
      "learning_rate": 9.68760996043573e-06,
      "epoch": 0.9046778464254193,
      "step": 10250
    },
    {
      "loss": 1.3193,
      "grad_norm": 9.42114543914795,
      "learning_rate": 9.667207260548541e-06,
      "epoch": 0.9090909090909091,
      "step": 10300
    },
    {
      "loss": 1.2924,
      "grad_norm": 10.600845336914062,
      "learning_rate": 9.64680456066135e-06,
      "epoch": 0.913503971756399,
      "step": 10350
    },
    {
      "loss": 1.3799,
      "grad_norm": 10.82281494140625,
      "learning_rate": 9.62640186077416e-06,
      "epoch": 0.9179170344218888,
      "step": 10400
    },
    {
      "loss": 1.3627,
      "grad_norm": 12.370235443115234,
      "learning_rate": 9.60599916088697e-06,
      "epoch": 0.9223300970873787,
      "step": 10450
    },
    {
      "loss": 1.335,
      "grad_norm": 12.00648307800293,
      "learning_rate": 9.585596460999778e-06,
      "epoch": 0.9267431597528685,
      "step": 10500
    },
    {
      "loss": 1.3577,
      "grad_norm": 16.67860984802246,
      "learning_rate": 9.565193761112589e-06,
      "epoch": 0.9311562224183584,
      "step": 10550
    },
    {
      "loss": 1.2934,
      "grad_norm": 12.998245239257812,
      "learning_rate": 9.544791061225399e-06,
      "epoch": 0.9355692850838482,
      "step": 10600
    },
    {
      "loss": 1.281,
      "grad_norm": 14.686728477478027,
      "learning_rate": 9.52438836133821e-06,
      "epoch": 0.9399823477493381,
      "step": 10650
    },
    {
      "loss": 1.3383,
      "grad_norm": 9.396956443786621,
      "learning_rate": 9.503985661451018e-06,
      "epoch": 0.9443954104148279,
      "step": 10700
    },
    {
      "loss": 1.3507,
      "grad_norm": 14.427630424499512,
      "learning_rate": 9.483582961563827e-06,
      "epoch": 0.9488084730803178,
      "step": 10750
    },
    {
      "loss": 1.3012,
      "grad_norm": 11.560017585754395,
      "learning_rate": 9.463180261676638e-06,
      "epoch": 0.9532215357458076,
      "step": 10800
    },
    {
      "loss": 1.3182,
      "grad_norm": 10.455229759216309,
      "learning_rate": 9.442777561789446e-06,
      "epoch": 0.9576345984112974,
      "step": 10850
    },
    {
      "loss": 1.3899,
      "grad_norm": 12.946341514587402,
      "learning_rate": 9.422374861902257e-06,
      "epoch": 0.9620476610767873,
      "step": 10900
    },
    {
      "loss": 1.2794,
      "grad_norm": 14.725224494934082,
      "learning_rate": 9.401972162015066e-06,
      "epoch": 0.9664607237422771,
      "step": 10950
    },
    {
      "loss": 1.3416,
      "grad_norm": 9.697003364562988,
      "learning_rate": 9.381569462127875e-06,
      "epoch": 0.970873786407767,
      "step": 11000
    },
    {
      "loss": 1.3392,
      "grad_norm": 15.429121017456055,
      "learning_rate": 9.361166762240685e-06,
      "epoch": 0.9752868490732568,
      "step": 11050
    },
    {
      "loss": 1.3403,
      "grad_norm": 16.581830978393555,
      "learning_rate": 9.340764062353496e-06,
      "epoch": 0.9796999117387467,
      "step": 11100
    },
    {
      "loss": 1.3376,
      "grad_norm": 15.458304405212402,
      "learning_rate": 9.320361362466306e-06,
      "epoch": 0.9841129744042365,
      "step": 11150
    },
    {
      "loss": 1.3598,
      "grad_norm": 12.343497276306152,
      "learning_rate": 9.299958662579115e-06,
      "epoch": 0.9885260370697264,
      "step": 11200
    },
    {
      "loss": 1.2469,
      "grad_norm": 7.779571056365967,
      "learning_rate": 9.279555962691924e-06,
      "epoch": 0.9929390997352162,
      "step": 11250
    },
    {
      "loss": 1.3174,
      "grad_norm": 13.238293647766113,
      "learning_rate": 9.259153262804734e-06,
      "epoch": 0.9973521624007061,
      "step": 11300
    },
    {
      "eval_loss": 1.1213565390775944,
      "eval_exact_match": 61.410165901870805,
      "eval_f1": 69.48406889337166,
      "eval_samples": 22720,
      "step": 11330
    },
    {
      "eval_loss": 1.1213565390775944,
      "eval_exact_match": 61.410165901870805,
      "eval_f1": 69.48406889337166,
      "eval_samples": 22720,
      "epoch": 1.0,
      "step": 11330
    },
    {
      "loss": 1.2785,
      "grad_norm": 14.858981132507324,
      "learning_rate": 9.238750562917543e-06,
      "epoch": 1.001765225066196,
      "step": 11350
    },
    {
      "loss": 1.3039,
      "grad_norm": 14.624082565307617,
      "learning_rate": 9.218347863030353e-06,
      "epoch": 1.0061782877316858,
      "step": 11400
    },
    {
      "loss": 1.2543,
      "grad_norm": 15.585139274597168,
      "learning_rate": 9.197945163143162e-06,
      "epoch": 1.0105913503971757,
      "step": 11450
    },
    {
      "loss": 1.3626,
      "grad_norm": 13.654000282287598,
      "learning_rate": 9.177542463255971e-06,
      "epoch": 1.0150044130626654,
      "step": 11500
    },
    {
      "loss": 1.2148,
      "grad_norm": 21.439815521240234,
      "learning_rate": 9.157139763368782e-06,
      "epoch": 1.0194174757281553,
      "step": 11550
    },
    {
      "loss": 1.2586,
      "grad_norm": 19.01676368713379,
      "learning_rate": 9.13673706348159e-06,
      "epoch": 1.0238305383936452,
      "step": 11600
    },
    {
      "loss": 1.3346,
      "grad_norm": 13.53304672241211,
      "learning_rate": 9.1163343635944e-06,
      "epoch": 1.0282436010591351,
      "step": 11650
    },
    {
      "loss": 1.2112,
      "grad_norm": 14.023869514465332,
      "learning_rate": 9.095931663707211e-06,
      "epoch": 1.0326566637246248,
      "step": 11700
    },
    {
      "loss": 1.2501,
      "grad_norm": 13.233075141906738,
      "learning_rate": 9.07552896382002e-06,
      "epoch": 1.0370697263901147,
      "step": 11750
    },
    {
      "loss": 1.2721,
      "grad_norm": 14.131040573120117,
      "learning_rate": 9.05512626393283e-06,
      "epoch": 1.0414827890556047,
      "step": 11800
    },
    {
      "loss": 1.1869,
      "grad_norm": 13.756946563720703,
      "learning_rate": 9.03472356404564e-06,
      "epoch": 1.0458958517210943,
      "step": 11850
    },
    {
      "loss": 1.2727,
      "grad_norm": 11.789134979248047,
      "learning_rate": 9.01432086415845e-06,
      "epoch": 1.0503089143865842,
      "step": 11900
    },
    {
      "loss": 1.2155,
      "grad_norm": 16.856218338012695,
      "learning_rate": 8.993918164271259e-06,
      "epoch": 1.0547219770520742,
      "step": 11950
    },
    {
      "loss": 1.195,
      "grad_norm": 14.727522850036621,
      "learning_rate": 8.973515464384068e-06,
      "epoch": 1.059135039717564,
      "step": 12000
    },
    {
      "loss": 1.2016,
      "grad_norm": 12.06583023071289,
      "learning_rate": 8.953112764496878e-06,
      "epoch": 1.0635481023830538,
      "step": 12050
    },
    {
      "loss": 1.2143,
      "grad_norm": 21.1278018951416,
      "learning_rate": 8.932710064609687e-06,
      "epoch": 1.0679611650485437,
      "step": 12100
    },
    {
      "loss": 1.1904,
      "grad_norm": 13.25082778930664,
      "learning_rate": 8.912307364722497e-06,
      "epoch": 1.0723742277140336,
      "step": 12150
    },
    {
      "loss": 1.2948,
      "grad_norm": 13.982437133789062,
      "learning_rate": 8.891904664835308e-06,
      "epoch": 1.0767872903795235,
      "step": 12200
    },
    {
      "loss": 1.2653,
      "grad_norm": 9.692242622375488,
      "learning_rate": 8.871501964948117e-06,
      "epoch": 1.0812003530450132,
      "step": 12250
    },
    {
      "loss": 1.27,
      "grad_norm": 11.807937622070312,
      "learning_rate": 8.851099265060927e-06,
      "epoch": 1.085613415710503,
      "step": 12300
    },
    {
      "loss": 1.316,
      "grad_norm": 17.664081573486328,
      "learning_rate": 8.830696565173736e-06,
      "epoch": 1.090026478375993,
      "step": 12350
    },
    {
      "loss": 1.2174,
      "grad_norm": 12.87047290802002,
      "learning_rate": 8.810293865286546e-06,
      "epoch": 1.0944395410414829,
      "step": 12400
    },
    {
      "loss": 1.3116,
      "grad_norm": 8.507262229919434,
      "learning_rate": 8.789891165399355e-06,
      "epoch": 1.0988526037069726,
      "step": 12450
    },
    {
      "loss": 1.3182,
      "grad_norm": 16.282054901123047,
      "learning_rate": 8.769488465512164e-06,
      "epoch": 1.1032656663724625,
      "step": 12500
    },
    {
      "loss": 1.2006,
      "grad_norm": 11.259284019470215,
      "learning_rate": 8.749085765624975e-06,
      "epoch": 1.1076787290379524,
      "step": 12550
    },
    {
      "loss": 1.2422,
      "grad_norm": 7.7055463790893555,
      "learning_rate": 8.728683065737783e-06,
      "epoch": 1.1120917917034423,
      "step": 12600
    },
    {
      "loss": 1.2631,
      "grad_norm": 18.30033302307129,
      "learning_rate": 8.708280365850592e-06,
      "epoch": 1.116504854368932,
      "step": 12650
    },
    {
      "loss": 1.2417,
      "grad_norm": 12.442190170288086,
      "learning_rate": 8.687877665963403e-06,
      "epoch": 1.120917917034422,
      "step": 12700
    },
    {
      "loss": 1.2791,
      "grad_norm": 15.92206859588623,
      "learning_rate": 8.667474966076213e-06,
      "epoch": 1.1253309796999118,
      "step": 12750
    },
    {
      "loss": 1.2837,
      "grad_norm": 12.858438491821289,
      "learning_rate": 8.647072266189024e-06,
      "epoch": 1.1297440423654015,
      "step": 12800
    },
    {
      "loss": 1.2583,
      "grad_norm": 16.655569076538086,
      "learning_rate": 8.626669566301832e-06,
      "epoch": 1.1341571050308914,
      "step": 12850
    },
    {
      "loss": 1.2162,
      "grad_norm": 13.110662460327148,
      "learning_rate": 8.606266866414641e-06,
      "epoch": 1.1385701676963813,
      "step": 12900
    },
    {
      "loss": 1.2481,
      "grad_norm": 13.926609992980957,
      "learning_rate": 8.585864166527452e-06,
      "epoch": 1.1429832303618712,
      "step": 12950
    },
    {
      "loss": 1.2638,
      "grad_norm": 11.02704906463623,
      "learning_rate": 8.56546146664026e-06,
      "epoch": 1.147396293027361,
      "step": 13000
    },
    {
      "loss": 1.2722,
      "grad_norm": 14.676313400268555,
      "learning_rate": 8.545058766753071e-06,
      "epoch": 1.1518093556928508,
      "step": 13050
    },
    {
      "loss": 1.2535,
      "grad_norm": 9.26861572265625,
      "learning_rate": 8.52465606686588e-06,
      "epoch": 1.1562224183583407,
      "step": 13100
    },
    {
      "loss": 1.2742,
      "grad_norm": 13.695101737976074,
      "learning_rate": 8.504253366978689e-06,
      "epoch": 1.1606354810238306,
      "step": 13150
    },
    {
      "loss": 1.253,
      "grad_norm": 17.604198455810547,
      "learning_rate": 8.483850667091499e-06,
      "epoch": 1.1650485436893203,
      "step": 13200
    },
    {
      "loss": 1.2583,
      "grad_norm": 14.734172821044922,
      "learning_rate": 8.463447967204308e-06,
      "epoch": 1.1694616063548102,
      "step": 13250
    },
    {
      "loss": 1.1997,
      "grad_norm": 15.741259574890137,
      "learning_rate": 8.44304526731712e-06,
      "epoch": 1.1738746690203001,
      "step": 13300
    },
    {
      "loss": 1.2461,
      "grad_norm": 10.605233192443848,
      "learning_rate": 8.422642567429929e-06,
      "epoch": 1.1782877316857898,
      "step": 13350
    },
    {
      "loss": 1.2825,
      "grad_norm": 13.38098430633545,
      "learning_rate": 8.402239867542738e-06,
      "epoch": 1.1827007943512797,
      "step": 13400
    },
    {
      "loss": 1.1686,
      "grad_norm": 12.301793098449707,
      "learning_rate": 8.381837167655548e-06,
      "epoch": 1.1871138570167696,
      "step": 13450
    },
    {
      "loss": 1.2653,
      "grad_norm": 9.115848541259766,
      "learning_rate": 8.361434467768357e-06,
      "epoch": 1.1915269196822595,
      "step": 13500
    },
    {
      "loss": 1.2428,
      "grad_norm": 16.48036003112793,
      "learning_rate": 8.341031767881168e-06,
      "epoch": 1.1959399823477495,
      "step": 13550
    },
    {
      "loss": 1.1209,
      "grad_norm": 16.035730361938477,
      "learning_rate": 8.320629067993976e-06,
      "epoch": 1.2003530450132391,
      "step": 13600
    },
    {
      "loss": 1.2995,
      "grad_norm": 15.94624137878418,
      "learning_rate": 8.300226368106785e-06,
      "epoch": 1.204766107678729,
      "step": 13650
    },
    {
      "loss": 1.1884,
      "grad_norm": 24.795970916748047,
      "learning_rate": 8.279823668219596e-06,
      "epoch": 1.209179170344219,
      "step": 13700
    },
    {
      "loss": 1.3311,
      "grad_norm": 13.671236991882324,
      "learning_rate": 8.259420968332404e-06,
      "epoch": 1.2135922330097086,
      "step": 13750
    },
    {
      "loss": 1.2377,
      "grad_norm": 14.266753196716309,
      "learning_rate": 8.239018268445215e-06,
      "epoch": 1.2180052956751986,
      "step": 13800
    },
    {
      "loss": 1.2333,
      "grad_norm": 21.141414642333984,
      "learning_rate": 8.218615568558025e-06,
      "epoch": 1.2224183583406885,
      "step": 13850
    },
    {
      "loss": 1.2215,
      "grad_norm": 17.50946617126465,
      "learning_rate": 8.198212868670834e-06,
      "epoch": 1.2268314210061784,
      "step": 13900
    },
    {
      "loss": 1.2108,
      "grad_norm": 10.216142654418945,
      "learning_rate": 8.177810168783645e-06,
      "epoch": 1.231244483671668,
      "step": 13950
    },
    {
      "loss": 1.1947,
      "grad_norm": 14.285950660705566,
      "learning_rate": 8.157407468896454e-06,
      "epoch": 1.235657546337158,
      "step": 14000
    },
    {
      "loss": 1.2976,
      "grad_norm": 14.018348693847656,
      "learning_rate": 8.137004769009264e-06,
      "epoch": 1.2400706090026479,
      "step": 14050
    },
    {
      "loss": 1.1108,
      "grad_norm": 14.742088317871094,
      "learning_rate": 8.116602069122073e-06,
      "epoch": 1.2444836716681378,
      "step": 14100
    },
    {
      "loss": 1.2925,
      "grad_norm": 14.169716835021973,
      "learning_rate": 8.096199369234882e-06,
      "epoch": 1.2488967343336275,
      "step": 14150
    },
    {
      "loss": 1.2203,
      "grad_norm": 11.156903266906738,
      "learning_rate": 8.075796669347692e-06,
      "epoch": 1.2533097969991174,
      "step": 14200
    },
    {
      "loss": 1.2728,
      "grad_norm": 14.136842727661133,
      "learning_rate": 8.055393969460501e-06,
      "epoch": 1.2577228596646073,
      "step": 14250
    },
    {
      "loss": 1.1802,
      "grad_norm": 13.895689010620117,
      "learning_rate": 8.034991269573311e-06,
      "epoch": 1.262135922330097,
      "step": 14300
    },
    {
      "loss": 1.1684,
      "grad_norm": 20.87025260925293,
      "learning_rate": 8.01458856968612e-06,
      "epoch": 1.2665489849955869,
      "step": 14350
    },
    {
      "loss": 1.1453,
      "grad_norm": 15.654356002807617,
      "learning_rate": 7.99418586979893e-06,
      "epoch": 1.2709620476610768,
      "step": 14400
    },
    {
      "loss": 1.2198,
      "grad_norm": 13.838726997375488,
      "learning_rate": 7.973783169911741e-06,
      "epoch": 1.2753751103265667,
      "step": 14450
    },
    {
      "loss": 1.207,
      "grad_norm": 16.969066619873047,
      "learning_rate": 7.95338047002455e-06,
      "epoch": 1.2797881729920566,
      "step": 14500
    },
    {
      "loss": 1.2599,
      "grad_norm": 14.7178955078125,
      "learning_rate": 7.93297777013736e-06,
      "epoch": 1.2842012356575463,
      "step": 14550
    },
    {
      "loss": 1.3158,
      "grad_norm": 12.970711708068848,
      "learning_rate": 7.91257507025017e-06,
      "epoch": 1.2886142983230362,
      "step": 14600
    },
    {
      "loss": 1.1656,
      "grad_norm": 12.850105285644531,
      "learning_rate": 7.892172370362978e-06,
      "epoch": 1.293027360988526,
      "step": 14650
    },
    {
      "loss": 1.1725,
      "grad_norm": 12.957489967346191,
      "learning_rate": 7.871769670475789e-06,
      "epoch": 1.2974404236540158,
      "step": 14700
    },
    {
      "loss": 1.2594,
      "grad_norm": 10.903972625732422,
      "learning_rate": 7.851366970588597e-06,
      "epoch": 1.3018534863195057,
      "step": 14750
    },
    {
      "loss": 1.2015,
      "grad_norm": 10.173763275146484,
      "learning_rate": 7.830964270701408e-06,
      "epoch": 1.3062665489849956,
      "step": 14800
    },
    {
      "loss": 1.2044,
      "grad_norm": 13.216156005859375,
      "learning_rate": 7.810561570814217e-06,
      "epoch": 1.3106796116504853,
      "step": 14850
    },
    {
      "loss": 1.1509,
      "grad_norm": 20.46747589111328,
      "learning_rate": 7.790158870927027e-06,
      "epoch": 1.3150926743159752,
      "step": 14900
    },
    {
      "loss": 1.1949,
      "grad_norm": 12.805802345275879,
      "learning_rate": 7.769756171039838e-06,
      "epoch": 1.3195057369814651,
      "step": 14950
    },
    {
      "loss": 1.2645,
      "grad_norm": 11.906641960144043,
      "learning_rate": 7.749353471152647e-06,
      "epoch": 1.323918799646955,
      "step": 15000
    },
    {
      "loss": 1.175,
      "grad_norm": 15.604979515075684,
      "learning_rate": 7.728950771265457e-06,
      "epoch": 1.328331862312445,
      "step": 15050
    },
    {
      "loss": 1.1522,
      "grad_norm": 12.798357963562012,
      "learning_rate": 7.708548071378266e-06,
      "epoch": 1.3327449249779346,
      "step": 15100
    },
    {
      "loss": 1.1797,
      "grad_norm": 15.541008949279785,
      "learning_rate": 7.688145371491075e-06,
      "epoch": 1.3371579876434245,
      "step": 15150
    },
    {
      "loss": 1.1687,
      "grad_norm": 17.660043716430664,
      "learning_rate": 7.667742671603885e-06,
      "epoch": 1.3415710503089144,
      "step": 15200
    },
    {
      "loss": 1.1863,
      "grad_norm": 18.272438049316406,
      "learning_rate": 7.647339971716694e-06,
      "epoch": 1.3459841129744041,
      "step": 15250
    },
    {
      "loss": 1.2205,
      "grad_norm": 21.50924301147461,
      "learning_rate": 7.6269372718295036e-06,
      "epoch": 1.350397175639894,
      "step": 15300
    },
    {
      "loss": 1.1739,
      "grad_norm": 14.174375534057617,
      "learning_rate": 7.606534571942314e-06,
      "epoch": 1.354810238305384,
      "step": 15350
    },
    {
      "loss": 1.1407,
      "grad_norm": 12.353957176208496,
      "learning_rate": 7.586131872055123e-06,
      "epoch": 1.3592233009708738,
      "step": 15400
    },
    {
      "loss": 1.2002,
      "grad_norm": 8.851367950439453,
      "learning_rate": 7.565729172167933e-06,
      "epoch": 1.3636363636363638,
      "step": 15450
    },
    {
      "loss": 1.1175,
      "grad_norm": 18.157482147216797,
      "learning_rate": 7.545326472280742e-06,
      "epoch": 1.3680494263018534,
      "step": 15500
    },
    {
      "loss": 1.1286,
      "grad_norm": 23.676008224487305,
      "learning_rate": 7.524923772393552e-06,
      "epoch": 1.3724624889673434,
      "step": 15550
    },
    {
      "loss": 1.1537,
      "grad_norm": 13.546366691589355,
      "learning_rate": 7.504521072506362e-06,
      "epoch": 1.3768755516328333,
      "step": 15600
    },
    {
      "loss": 1.2298,
      "grad_norm": 19.34038543701172,
      "learning_rate": 7.484118372619171e-06,
      "epoch": 1.381288614298323,
      "step": 15650
    },
    {
      "loss": 1.1931,
      "grad_norm": 13.157590866088867,
      "learning_rate": 7.463715672731982e-06,
      "epoch": 1.3857016769638129,
      "step": 15700
    },
    {
      "loss": 1.212,
      "grad_norm": 14.23835277557373,
      "learning_rate": 7.4433129728447904e-06,
      "epoch": 1.3901147396293028,
      "step": 15750
    },
    {
      "loss": 1.1686,
      "grad_norm": 14.74830436706543,
      "learning_rate": 7.422910272957599e-06,
      "epoch": 1.3945278022947925,
      "step": 15800
    },
    {
      "loss": 1.1883,
      "grad_norm": 14.501373291015625,
      "learning_rate": 7.40250757307041e-06,
      "epoch": 1.3989408649602824,
      "step": 15850
    },
    {
      "loss": 1.2532,
      "grad_norm": 18.695327758789062,
      "learning_rate": 7.382104873183219e-06,
      "epoch": 1.4033539276257723,
      "step": 15900
    },
    {
      "loss": 1.2013,
      "grad_norm": 23.68981170654297,
      "learning_rate": 7.36170217329603e-06,
      "epoch": 1.4077669902912622,
      "step": 15950
    },
    {
      "loss": 1.1927,
      "grad_norm": 14.765815734863281,
      "learning_rate": 7.341299473408839e-06,
      "epoch": 1.412180052956752,
      "step": 16000
    },
    {
      "loss": 1.1699,
      "grad_norm": 14.375064849853516,
      "learning_rate": 7.3208967735216475e-06,
      "epoch": 1.4165931156222418,
      "step": 16050
    },
    {
      "loss": 1.1747,
      "grad_norm": 16.216747283935547,
      "learning_rate": 7.300494073634458e-06,
      "epoch": 1.4210061782877317,
      "step": 16100
    },
    {
      "loss": 1.216,
      "grad_norm": 15.088305473327637,
      "learning_rate": 7.280091373747268e-06,
      "epoch": 1.4254192409532216,
      "step": 16150
    },
    {
      "loss": 1.2241,
      "grad_norm": 15.837590217590332,
      "learning_rate": 7.259688673860078e-06,
      "epoch": 1.4298323036187113,
      "step": 16200
    },
    {
      "loss": 1.2144,
      "grad_norm": 13.54604721069336,
      "learning_rate": 7.239285973972887e-06,
      "epoch": 1.4342453662842012,
      "step": 16250
    },
    {
      "loss": 1.1005,
      "grad_norm": 17.722938537597656,
      "learning_rate": 7.218883274085696e-06,
      "epoch": 1.438658428949691,
      "step": 16300
    },
    {
      "loss": 1.18,
      "grad_norm": 16.90693473815918,
      "learning_rate": 7.198480574198506e-06,
      "epoch": 1.443071491615181,
      "step": 16350
    },
    {
      "loss": 1.165,
      "grad_norm": 14.98210334777832,
      "learning_rate": 7.178077874311316e-06,
      "epoch": 1.447484554280671,
      "step": 16400
    },
    {
      "loss": 1.1162,
      "grad_norm": 13.448516845703125,
      "learning_rate": 7.157675174424126e-06,
      "epoch": 1.4518976169461606,
      "step": 16450
    },
    {
      "loss": 1.295,
      "grad_norm": 18.460445404052734,
      "learning_rate": 7.137272474536935e-06,
      "epoch": 1.4563106796116505,
      "step": 16500
    },
    {
      "loss": 1.1519,
      "grad_norm": 19.046188354492188,
      "learning_rate": 7.116869774649744e-06,
      "epoch": 1.4607237422771404,
      "step": 16550
    },
    {
      "loss": 1.1289,
      "grad_norm": 18.812881469726562,
      "learning_rate": 7.0964670747625545e-06,
      "epoch": 1.46513680494263,
      "step": 16600
    },
    {
      "loss": 1.1217,
      "grad_norm": 15.102571487426758,
      "learning_rate": 7.076064374875364e-06,
      "epoch": 1.46954986760812,
      "step": 16650
    },
    {
      "loss": 1.0968,
      "grad_norm": 22.151058197021484,
      "learning_rate": 7.055661674988175e-06,
      "epoch": 1.47396293027361,
      "step": 16700
    },
    {
      "loss": 1.1427,
      "grad_norm": 18.630422592163086,
      "learning_rate": 7.0352589751009834e-06,
      "epoch": 1.4783759929390996,
      "step": 16750
    },
    {
      "loss": 1.1994,
      "grad_norm": 15.041996955871582,
      "learning_rate": 7.014856275213792e-06,
      "epoch": 1.4827890556045895,
      "step": 16800
    },
    {
      "loss": 1.103,
      "grad_norm": 21.296119689941406,
      "learning_rate": 6.994453575326603e-06,
      "epoch": 1.4872021182700794,
      "step": 16850
    },
    {
      "loss": 1.1035,
      "grad_norm": 17.870235443115234,
      "learning_rate": 6.9740508754394115e-06,
      "epoch": 1.4916151809355693,
      "step": 16900
    },
    {
      "loss": 1.1407,
      "grad_norm": 10.40798568725586,
      "learning_rate": 6.953648175552222e-06,
      "epoch": 1.4960282436010592,
      "step": 16950
    },
    {
      "loss": 1.2354,
      "grad_norm": 16.375699996948242,
      "learning_rate": 6.933245475665032e-06,
      "epoch": 1.500441306266549,
      "step": 17000
    },
    {
      "loss": 1.1009,
      "grad_norm": 24.081951141357422,
      "learning_rate": 6.9128427757778405e-06,
      "epoch": 1.5048543689320388,
      "step": 17050
    },
    {
      "loss": 1.1226,
      "grad_norm": 23.09978485107422,
      "learning_rate": 6.892440075890651e-06,
      "epoch": 1.5092674315975287,
      "step": 17100
    },
    {
      "loss": 1.1779,
      "grad_norm": 13.767187118530273,
      "learning_rate": 6.87203737600346e-06,
      "epoch": 1.5136804942630184,
      "step": 17150
    },
    {
      "loss": 1.1386,
      "grad_norm": 35.16693115234375,
      "learning_rate": 6.85163467611627e-06,
      "epoch": 1.5180935569285083,
      "step": 17200
    },
    {
      "loss": 1.1042,
      "grad_norm": 18.32753562927246,
      "learning_rate": 6.83123197622908e-06,
      "epoch": 1.5225066195939982,
      "step": 17250
    },
    {
      "loss": 1.1752,
      "grad_norm": 15.327139854431152,
      "learning_rate": 6.81082927634189e-06,
      "epoch": 1.526919682259488,
      "step": 17300
    },
    {
      "loss": 1.1483,
      "grad_norm": 21.021793365478516,
      "learning_rate": 6.790426576454698e-06,
      "epoch": 1.531332744924978,
      "step": 17350
    },
    {
      "loss": 1.1742,
      "grad_norm": 16.052799224853516,
      "learning_rate": 6.770023876567508e-06,
      "epoch": 1.5357458075904677,
      "step": 17400
    },
    {
      "loss": 1.2479,
      "grad_norm": 16.330018997192383,
      "learning_rate": 6.749621176680318e-06,
      "epoch": 1.5401588702559577,
      "step": 17450
    },
    {
      "loss": 1.1384,
      "grad_norm": 19.36256217956543,
      "learning_rate": 6.729218476793128e-06,
      "epoch": 1.5445719329214476,
      "step": 17500
    },
    {
      "loss": 1.1976,
      "grad_norm": 18.53885841369629,
      "learning_rate": 6.708815776905938e-06,
      "epoch": 1.5489849955869373,
      "step": 17550
    },
    {
      "loss": 1.1288,
      "grad_norm": 16.122678756713867,
      "learning_rate": 6.688413077018747e-06,
      "epoch": 1.5533980582524272,
      "step": 17600
    },
    {
      "loss": 1.1154,
      "grad_norm": 20.52153205871582,
      "learning_rate": 6.668010377131556e-06,
      "epoch": 1.557811120917917,
      "step": 17650
    },
    {
      "loss": 1.1187,
      "grad_norm": 17.149702072143555,
      "learning_rate": 6.647607677244366e-06,
      "epoch": 1.5622241835834068,
      "step": 17700
    },
    {
      "loss": 1.1185,
      "grad_norm": 39.912635803222656,
      "learning_rate": 6.6272049773571764e-06,
      "epoch": 1.5666372462488969,
      "step": 17750
    },
    {
      "loss": 1.0712,
      "grad_norm": 16.182212829589844,
      "learning_rate": 6.606802277469986e-06,
      "epoch": 1.5710503089143866,
      "step": 17800
    },
    {
      "loss": 1.1634,
      "grad_norm": 13.432002067565918,
      "learning_rate": 6.586399577582795e-06,
      "epoch": 1.5754633715798765,
      "step": 17850
    },
    {
      "loss": 1.0893,
      "grad_norm": 15.901359558105469,
      "learning_rate": 6.5659968776956045e-06,
      "epoch": 1.5798764342453664,
      "step": 17900
    },
    {
      "loss": 1.1843,
      "grad_norm": 18.352083206176758,
      "learning_rate": 6.545594177808414e-06,
      "epoch": 1.584289496910856,
      "step": 17950
    },
    {
      "loss": 1.0899,
      "grad_norm": 17.217832565307617,
      "learning_rate": 6.525191477921224e-06,
      "epoch": 1.588702559576346,
      "step": 18000
    },
    {
      "loss": 1.0749,
      "grad_norm": 15.413064002990723,
      "learning_rate": 6.504788778034034e-06,
      "epoch": 1.593115622241836,
      "step": 18050
    },
    {
      "loss": 0.9997,
      "grad_norm": 14.100568771362305,
      "learning_rate": 6.484386078146843e-06,
      "epoch": 1.5975286849073256,
      "step": 18100
    },
    {
      "loss": 1.0909,
      "grad_norm": 15.527632713317871,
      "learning_rate": 6.463983378259653e-06,
      "epoch": 1.6019417475728155,
      "step": 18150
    },
    {
      "loss": 1.067,
      "grad_norm": 23.339859008789062,
      "learning_rate": 6.4435806783724624e-06,
      "epoch": 1.6063548102383054,
      "step": 18200
    },
    {
      "loss": 1.0812,
      "grad_norm": 13.043073654174805,
      "learning_rate": 6.423177978485272e-06,
      "epoch": 1.610767872903795,
      "step": 18250
    },
    {
      "loss": 1.0802,
      "grad_norm": 11.467777252197266,
      "learning_rate": 6.402775278598083e-06,
      "epoch": 1.6151809355692852,
      "step": 18300
    },
    {
      "loss": 1.1047,
      "grad_norm": 16.393831253051758,
      "learning_rate": 6.382372578710891e-06,
      "epoch": 1.619593998234775,
      "step": 18350
    },
    {
      "loss": 1.1071,
      "grad_norm": 24.471683502197266,
      "learning_rate": 6.361969878823701e-06,
      "epoch": 1.6240070609002648,
      "step": 18400
    },
    {
      "loss": 1.0828,
      "grad_norm": 18.935224533081055,
      "learning_rate": 6.341567178936511e-06,
      "epoch": 1.6284201235657547,
      "step": 18450
    },
    {
      "loss": 1.2169,
      "grad_norm": 16.92889976501465,
      "learning_rate": 6.32116447904932e-06,
      "epoch": 1.6328331862312444,
      "step": 18500
    },
    {
      "loss": 1.0007,
      "grad_norm": 15.21645450592041,
      "learning_rate": 6.30076177916213e-06,
      "epoch": 1.6372462488967343,
      "step": 18550
    },
    {
      "loss": 1.0838,
      "grad_norm": 20.496301651000977,
      "learning_rate": 6.28035907927494e-06,
      "epoch": 1.6416593115622242,
      "step": 18600
    },
    {
      "loss": 1.0683,
      "grad_norm": 16.577329635620117,
      "learning_rate": 6.259956379387749e-06,
      "epoch": 1.646072374227714,
      "step": 18650
    },
    {
      "loss": 1.2306,
      "grad_norm": 13.927969932556152,
      "learning_rate": 6.239553679500559e-06,
      "epoch": 1.650485436893204,
      "step": 18700
    },
    {
      "loss": 1.1637,
      "grad_norm": 14.318134307861328,
      "learning_rate": 6.219150979613369e-06,
      "epoch": 1.6548984995586937,
      "step": 18750
    },
    {
      "loss": 1.0537,
      "grad_norm": 13.622952461242676,
      "learning_rate": 6.198748279726177e-06,
      "epoch": 1.6593115622241836,
      "step": 18800
    },
    {
      "loss": 1.1335,
      "grad_norm": 11.89615249633789,
      "learning_rate": 6.178345579838988e-06,
      "epoch": 1.6637246248896735,
      "step": 18850
    },
    {
      "loss": 1.1724,
      "grad_norm": 11.368369102478027,
      "learning_rate": 6.1579428799517975e-06,
      "epoch": 1.6681376875551632,
      "step": 18900
    },
    {
      "loss": 1.1281,
      "grad_norm": 14.221372604370117,
      "learning_rate": 6.137540180064607e-06,
      "epoch": 1.6725507502206531,
      "step": 18950
    },
    {
      "loss": 1.043,
      "grad_norm": 15.244572639465332,
      "learning_rate": 6.117137480177417e-06,
      "epoch": 1.676963812886143,
      "step": 19000
    },
    {
      "loss": 1.1986,
      "grad_norm": 12.04659652709961,
      "learning_rate": 6.096734780290226e-06,
      "epoch": 1.6813768755516327,
      "step": 19050
    },
    {
      "loss": 1.0462,
      "grad_norm": 11.612807273864746,
      "learning_rate": 6.076332080403036e-06,
      "epoch": 1.6857899382171226,
      "step": 19100
    },
    {
      "loss": 1.1039,
      "grad_norm": 13.687684059143066,
      "learning_rate": 6.055929380515846e-06,
      "epoch": 1.6902030008826125,
      "step": 19150
    },
    {
      "loss": 1.0661,
      "grad_norm": 12.09694766998291,
      "learning_rate": 6.0355266806286554e-06,
      "epoch": 1.6946160635481022,
      "step": 19200
    },
    {
      "loss": 1.11,
      "grad_norm": 16.515913009643555,
      "learning_rate": 6.015123980741465e-06,
      "epoch": 1.6990291262135924,
      "step": 19250
    },
    {
      "loss": 1.1235,
      "grad_norm": 17.08261489868164,
      "learning_rate": 5.994721280854274e-06,
      "epoch": 1.703442188879082,
      "step": 19300
    },
    {
      "loss": 1.0835,
      "grad_norm": 12.00395679473877,
      "learning_rate": 5.9743185809670835e-06,
      "epoch": 1.707855251544572,
      "step": 19350
    },
    {
      "loss": 1.054,
      "grad_norm": 16.26188850402832,
      "learning_rate": 5.953915881079894e-06,
      "epoch": 1.7122683142100619,
      "step": 19400
    },
    {
      "loss": 1.1178,
      "grad_norm": 15.929990768432617,
      "learning_rate": 5.933513181192704e-06,
      "epoch": 1.7166813768755516,
      "step": 19450
    },
    {
      "loss": 1.083,
      "grad_norm": 11.523810386657715,
      "learning_rate": 5.913110481305513e-06,
      "epoch": 1.7210944395410415,
      "step": 19500
    },
    {
      "loss": 1.228,
      "grad_norm": 12.227733612060547,
      "learning_rate": 5.892707781418322e-06,
      "epoch": 1.7255075022065314,
      "step": 19550
    },
    {
      "loss": 1.1458,
      "grad_norm": 13.687134742736816,
      "learning_rate": 5.872305081531132e-06,
      "epoch": 1.729920564872021,
      "step": 19600
    },
    {
      "loss": 1.0911,
      "grad_norm": 12.768349647521973,
      "learning_rate": 5.851902381643942e-06,
      "epoch": 1.7343336275375112,
      "step": 19650
    },
    {
      "loss": 1.1374,
      "grad_norm": 15.408717155456543,
      "learning_rate": 5.831499681756752e-06,
      "epoch": 1.7387466902030009,
      "step": 19700
    },
    {
      "loss": 1.1187,
      "grad_norm": 10.59326171875,
      "learning_rate": 5.811096981869562e-06,
      "epoch": 1.7431597528684908,
      "step": 19750
    },
    {
      "loss": 1.0908,
      "grad_norm": 15.435221672058105,
      "learning_rate": 5.79069428198237e-06,
      "epoch": 1.7475728155339807,
      "step": 19800
    },
    {
      "loss": 1.1053,
      "grad_norm": 11.845566749572754,
      "learning_rate": 5.77029158209518e-06,
      "epoch": 1.7519858781994704,
      "step": 19850
    },
    {
      "loss": 1.0547,
      "grad_norm": 21.680194854736328,
      "learning_rate": 5.74988888220799e-06,
      "epoch": 1.7563989408649603,
      "step": 19900
    },
    {
      "loss": 1.0596,
      "grad_norm": 15.053265571594238,
      "learning_rate": 5.7294861823208e-06,
      "epoch": 1.7608120035304502,
      "step": 19950
    },
    {
      "loss": 1.0722,
      "grad_norm": 13.234689712524414,
      "learning_rate": 5.709083482433609e-06,
      "epoch": 1.7652250661959399,
      "step": 20000
    },
    {
      "loss": 1.0068,
      "grad_norm": 8.743193626403809,
      "learning_rate": 5.688680782546419e-06,
      "epoch": 1.7696381288614298,
      "step": 20050
    },
    {
      "loss": 1.2184,
      "grad_norm": 14.036617279052734,
      "learning_rate": 5.668278082659228e-06,
      "epoch": 1.7740511915269197,
      "step": 20100
    },
    {
      "loss": 1.086,
      "grad_norm": 82.68571472167969,
      "learning_rate": 5.647875382772038e-06,
      "epoch": 1.7784642541924094,
      "step": 20150
    },
    {
      "loss": 0.9472,
      "grad_norm": 20.74526023864746,
      "learning_rate": 5.6274726828848484e-06,
      "epoch": 1.7828773168578995,
      "step": 20200
    },
    {
      "loss": 1.187,
      "grad_norm": 18.68587303161621,
      "learning_rate": 5.607069982997657e-06,
      "epoch": 1.7872903795233892,
      "step": 20250
    },
    {
      "loss": 1.095,
      "grad_norm": 13.755182266235352,
      "learning_rate": 5.586667283110467e-06,
      "epoch": 1.7917034421888791,
      "step": 20300
    },
    {
      "loss": 1.1105,
      "grad_norm": 13.971718788146973,
      "learning_rate": 5.5662645832232765e-06,
      "epoch": 1.796116504854369,
      "step": 20350
    },
    {
      "loss": 1.0642,
      "grad_norm": 14.27880573272705,
      "learning_rate": 5.545861883336086e-06,
      "epoch": 1.8005295675198587,
      "step": 20400
    },
    {
      "loss": 1.132,
      "grad_norm": 14.460464477539062,
      "learning_rate": 5.525459183448896e-06,
      "epoch": 1.8049426301853486,
      "step": 20450
    },
    {
      "loss": 1.0295,
      "grad_norm": 12.887520790100098,
      "learning_rate": 5.5050564835617055e-06,
      "epoch": 1.8093556928508385,
      "step": 20500
    },
    {
      "loss": 1.0872,
      "grad_norm": 21.26783561706543,
      "learning_rate": 5.484653783674515e-06,
      "epoch": 1.8137687555163282,
      "step": 20550
    },
    {
      "loss": 1.1754,
      "grad_norm": 11.38745403289795,
      "learning_rate": 5.464251083787325e-06,
      "epoch": 1.8181818181818183,
      "step": 20600
    },
    {
      "loss": 1.0685,
      "grad_norm": 12.091845512390137,
      "learning_rate": 5.4438483839001344e-06,
      "epoch": 1.822594880847308,
      "step": 20650
    },
    {
      "loss": 1.0625,
      "grad_norm": 15.312439918518066,
      "learning_rate": 5.423445684012944e-06,
      "epoch": 1.8270079435127977,
      "step": 20700
    },
    {
      "loss": 1.0082,
      "grad_norm": 10.579646110534668,
      "learning_rate": 5.403042984125754e-06,
      "epoch": 1.8314210061782878,
      "step": 20750
    },
    {
      "loss": 1.0513,
      "grad_norm": 13.76851749420166,
      "learning_rate": 5.382640284238563e-06,
      "epoch": 1.8358340688437775,
      "step": 20800
    },
    {
      "loss": 1.1477,
      "grad_norm": 10.127151489257812,
      "learning_rate": 5.362237584351373e-06,
      "epoch": 1.8402471315092674,
      "step": 20850
    },
    {
      "loss": 1.1467,
      "grad_norm": 10.853361129760742,
      "learning_rate": 5.341834884464183e-06,
      "epoch": 1.8446601941747574,
      "step": 20900
    },
    {
      "loss": 1.0705,
      "grad_norm": 21.518394470214844,
      "learning_rate": 5.321432184576992e-06,
      "epoch": 1.849073256840247,
      "step": 20950
    },
    {
      "loss": 1.1252,
      "grad_norm": 9.580657005310059,
      "learning_rate": 5.301029484689802e-06,
      "epoch": 1.853486319505737,
      "step": 21000
    },
    {
      "loss": 1.0359,
      "grad_norm": 11.974807739257812,
      "learning_rate": 5.280626784802612e-06,
      "epoch": 1.8578993821712269,
      "step": 21050
    },
    {
      "loss": 1.0555,
      "grad_norm": 14.443572044372559,
      "learning_rate": 5.260224084915421e-06,
      "epoch": 1.8623124448367165,
      "step": 21100
    },
    {
      "loss": 1.0664,
      "grad_norm": 13.121129035949707,
      "learning_rate": 5.239821385028231e-06,
      "epoch": 1.8667255075022067,
      "step": 21150
    },
    {
      "loss": 1.0232,
      "grad_norm": 13.78311538696289,
      "learning_rate": 5.21941868514104e-06,
      "epoch": 1.8711385701676964,
      "step": 21200
    },
    {
      "loss": 1.04,
      "grad_norm": 16.9498291015625,
      "learning_rate": 5.199015985253849e-06,
      "epoch": 1.8755516328331863,
      "step": 21250
    },
    {
      "loss": 1.1045,
      "grad_norm": 11.154120445251465,
      "learning_rate": 5.17861328536666e-06,
      "epoch": 1.8799646954986762,
      "step": 21300
    },
    {
      "loss": 1.0348,
      "grad_norm": 10.86085319519043,
      "learning_rate": 5.1582105854794695e-06,
      "epoch": 1.8843777581641659,
      "step": 21350
    },
    {
      "loss": 1.1354,
      "grad_norm": 18.01984405517578,
      "learning_rate": 5.137807885592279e-06,
      "epoch": 1.8887908208296558,
      "step": 21400
    },
    {
      "loss": 1.0292,
      "grad_norm": 11.925158500671387,
      "learning_rate": 5.117405185705088e-06,
      "epoch": 1.8932038834951457,
      "step": 21450
    },
    {
      "loss": 1.0884,
      "grad_norm": 14.457398414611816,
      "learning_rate": 5.097002485817898e-06,
      "epoch": 1.8976169461606354,
      "step": 21500
    },
    {
      "loss": 1.0808,
      "grad_norm": 10.755921363830566,
      "learning_rate": 5.076599785930708e-06,
      "epoch": 1.9020300088261255,
      "step": 21550
    },
    {
      "loss": 1.1631,
      "grad_norm": 14.708697319030762,
      "learning_rate": 5.056197086043518e-06,
      "epoch": 1.9064430714916152,
      "step": 21600
    },
    {
      "loss": 1.0212,
      "grad_norm": 16.476354598999023,
      "learning_rate": 5.0357943861563274e-06,
      "epoch": 1.9108561341571049,
      "step": 21650
    },
    {
      "loss": 1.1708,
      "grad_norm": 14.623991966247559,
      "learning_rate": 5.015391686269136e-06,
      "epoch": 1.915269196822595,
      "step": 21700
    },
    {
      "loss": 1.1262,
      "grad_norm": 19.396800994873047,
      "learning_rate": 4.994988986381946e-06,
      "epoch": 1.9196822594880847,
      "step": 21750
    },
    {
      "loss": 1.1094,
      "grad_norm": 18.86995506286621,
      "learning_rate": 4.9745862864947555e-06,
      "epoch": 1.9240953221535746,
      "step": 21800
    },
    {
      "loss": 1.1381,
      "grad_norm": 11.5037260055542,
      "learning_rate": 4.954183586607566e-06,
      "epoch": 1.9285083848190645,
      "step": 21850
    },
    {
      "loss": 1.0248,
      "grad_norm": 14.80280876159668,
      "learning_rate": 4.933780886720376e-06,
      "epoch": 1.9329214474845542,
      "step": 21900
    },
    {
      "loss": 1.1791,
      "grad_norm": 12.206268310546875,
      "learning_rate": 4.9133781868331845e-06,
      "epoch": 1.937334510150044,
      "step": 21950
    },
    {
      "loss": 1.0502,
      "grad_norm": 11.72176456451416,
      "learning_rate": 4.892975486945994e-06,
      "epoch": 1.941747572815534,
      "step": 22000
    },
    {
      "loss": 1.0882,
      "grad_norm": 8.121977806091309,
      "learning_rate": 4.872572787058804e-06,
      "epoch": 1.9461606354810237,
      "step": 22050
    },
    {
      "loss": 1.0283,
      "grad_norm": 18.239652633666992,
      "learning_rate": 4.852170087171614e-06,
      "epoch": 1.9505736981465138,
      "step": 22100
    },
    {
      "loss": 1.1187,
      "grad_norm": 14.362407684326172,
      "learning_rate": 4.831767387284424e-06,
      "epoch": 1.9549867608120035,
      "step": 22150
    },
    {
      "loss": 1.1038,
      "grad_norm": 13.369604110717773,
      "learning_rate": 4.811364687397233e-06,
      "epoch": 1.9593998234774934,
      "step": 22200
    },
    {
      "loss": 1.0269,
      "grad_norm": 15.080349922180176,
      "learning_rate": 4.790961987510042e-06,
      "epoch": 1.9638128861429833,
      "step": 22250
    },
    {
      "loss": 1.0944,
      "grad_norm": 13.962642669677734,
      "learning_rate": 4.770559287622852e-06,
      "epoch": 1.968225948808473,
      "step": 22300
    },
    {
      "loss": 1.0601,
      "grad_norm": 11.42572021484375,
      "learning_rate": 4.750156587735662e-06,
      "epoch": 1.972639011473963,
      "step": 22350
    },
    {
      "loss": 1.1249,
      "grad_norm": 13.98323917388916,
      "learning_rate": 4.729753887848472e-06,
      "epoch": 1.9770520741394528,
      "step": 22400
    },
    {
      "loss": 1.1084,
      "grad_norm": 14.701742172241211,
      "learning_rate": 4.709351187961281e-06,
      "epoch": 1.9814651368049425,
      "step": 22450
    },
    {
      "loss": 1.0357,
      "grad_norm": 16.095867156982422,
      "learning_rate": 4.688948488074091e-06,
      "epoch": 1.9858781994704324,
      "step": 22500
    },
    {
      "loss": 1.0949,
      "grad_norm": 17.36328125,
      "learning_rate": 4.6685457881869e-06,
      "epoch": 1.9902912621359223,
      "step": 22550
    },
    {
      "loss": 1.0752,
      "grad_norm": 17.176259994506836,
      "learning_rate": 4.64814308829971e-06,
      "epoch": 1.994704324801412,
      "step": 22600
    },
    {
      "loss": 1.1889,
      "grad_norm": 14.5819730758667,
      "learning_rate": 4.62774038841252e-06,
      "epoch": 1.9991173874669022,
      "step": 22650
    },
    {
      "eval_loss": 0.8981437383837748,
      "eval_exact_match": 76.18249205788916,
      "eval_f1": 82.03021130290776,
      "eval_samples": 22720,
      "step": 22660
    },
    {
      "eval_loss": 0.8981437383837748,
      "eval_exact_match": 76.18249205788916,
      "eval_f1": 82.03021130290776,
      "eval_samples": 22720,
      "epoch": 2.0,
      "step": 22660
    },
    {
      "loss": 1.0839,
      "grad_norm": 15.525327682495117,
      "learning_rate": 4.607337688525329e-06,
      "epoch": 2.003530450132392,
      "step": 22700
    },
    {
      "loss": 0.9946,
      "grad_norm": 12.715763092041016,
      "learning_rate": 4.586934988638139e-06,
      "epoch": 2.0079435127978815,
      "step": 22750
    },
    {
      "loss": 1.0217,
      "grad_norm": 17.09041404724121,
      "learning_rate": 4.5665322887509485e-06,
      "epoch": 2.0123565754633717,
      "step": 22800
    },
    {
      "loss": 1.0232,
      "grad_norm": 14.562848091125488,
      "learning_rate": 4.546129588863758e-06,
      "epoch": 2.0167696381288613,
      "step": 22850
    },
    {
      "loss": 1.0091,
      "grad_norm": 4.612366676330566,
      "learning_rate": 4.525726888976568e-06,
      "epoch": 2.0211827007943515,
      "step": 22900
    },
    {
      "loss": 1.0133,
      "grad_norm": 15.946983337402344,
      "learning_rate": 4.5053241890893775e-06,
      "epoch": 2.025595763459841,
      "step": 22950
    },
    {
      "loss": 1.0201,
      "grad_norm": 10.632513999938965,
      "learning_rate": 4.484921489202187e-06,
      "epoch": 2.030008826125331,
      "step": 23000
    },
    {
      "loss": 0.9942,
      "grad_norm": 29.34673500061035,
      "learning_rate": 4.464518789314997e-06,
      "epoch": 2.034421888790821,
      "step": 23050
    },
    {
      "loss": 0.9383,
      "grad_norm": 19.91978645324707,
      "learning_rate": 4.4441160894278064e-06,
      "epoch": 2.0388349514563107,
      "step": 23100
    },
    {
      "loss": 1.1,
      "grad_norm": 14.480385780334473,
      "learning_rate": 4.423713389540615e-06,
      "epoch": 2.0432480141218003,
      "step": 23150
    },
    {
      "loss": 0.9913,
      "grad_norm": 10.612350463867188,
      "learning_rate": 4.403310689653426e-06,
      "epoch": 2.0476610767872905,
      "step": 23200
    },
    {
      "loss": 0.9719,
      "grad_norm": 7.902286052703857,
      "learning_rate": 4.382907989766235e-06,
      "epoch": 2.05207413945278,
      "step": 23250
    },
    {
      "loss": 0.9563,
      "grad_norm": 14.659430503845215,
      "learning_rate": 4.362505289879045e-06,
      "epoch": 2.0564872021182703,
      "step": 23300
    },
    {
      "loss": 1.0409,
      "grad_norm": 11.156120300292969,
      "learning_rate": 4.342102589991855e-06,
      "epoch": 2.06090026478376,
      "step": 23350
    },
    {
      "loss": 1.0236,
      "grad_norm": 18.506898880004883,
      "learning_rate": 4.3216998901046635e-06,
      "epoch": 2.0653133274492497,
      "step": 23400
    },
    {
      "loss": 1.0337,
      "grad_norm": 11.433013916015625,
      "learning_rate": 4.301297190217474e-06,
      "epoch": 2.06972639011474,
      "step": 23450
    },
    {
      "loss": 0.9641,
      "grad_norm": 8.394614219665527,
      "learning_rate": 4.280894490330284e-06,
      "epoch": 2.0741394527802295,
      "step": 23500
    },
    {
      "loss": 1.0617,
      "grad_norm": 14.919767379760742,
      "learning_rate": 4.260491790443093e-06,
      "epoch": 2.078552515445719,
      "step": 23550
    },
    {
      "loss": 0.9943,
      "grad_norm": 14.074753761291504,
      "learning_rate": 4.240089090555903e-06,
      "epoch": 2.0829655781112093,
      "step": 23600
    },
    {
      "loss": 0.9142,
      "grad_norm": 17.193639755249023,
      "learning_rate": 4.219686390668712e-06,
      "epoch": 2.087378640776699,
      "step": 23650
    },
    {
      "loss": 0.9982,
      "grad_norm": 12.53653621673584,
      "learning_rate": 4.199283690781521e-06,
      "epoch": 2.0917917034421887,
      "step": 23700
    },
    {
      "loss": 1.0354,
      "grad_norm": 12.560670852661133,
      "learning_rate": 4.178880990894332e-06,
      "epoch": 2.096204766107679,
      "step": 23750
    },
    {
      "loss": 0.9944,
      "grad_norm": 19.841468811035156,
      "learning_rate": 4.1584782910071415e-06,
      "epoch": 2.1006178287731685,
      "step": 23800
    },
    {
      "loss": 0.925,
      "grad_norm": 13.018874168395996,
      "learning_rate": 4.13807559111995e-06,
      "epoch": 2.1050308914386586,
      "step": 23850
    },
    {
      "loss": 1.0452,
      "grad_norm": 43.254974365234375,
      "learning_rate": 4.11767289123276e-06,
      "epoch": 2.1094439541041483,
      "step": 23900
    },
    {
      "loss": 1.1141,
      "grad_norm": 22.881383895874023,
      "learning_rate": 4.09727019134557e-06,
      "epoch": 2.113857016769638,
      "step": 23950
    },
    {
      "loss": 1.0748,
      "grad_norm": 20.04684066772461,
      "learning_rate": 4.07686749145838e-06,
      "epoch": 2.118270079435128,
      "step": 24000
    },
    {
      "loss": 1.0345,
      "grad_norm": 16.03610610961914,
      "learning_rate": 4.05646479157119e-06,
      "epoch": 2.122683142100618,
      "step": 24050
    },
    {
      "loss": 1.1093,
      "grad_norm": 18.037548065185547,
      "learning_rate": 4.036062091683999e-06,
      "epoch": 2.1270962047661075,
      "step": 24100
    },
    {
      "loss": 1.019,
      "grad_norm": 16.87113380432129,
      "learning_rate": 4.015659391796808e-06,
      "epoch": 2.1315092674315976,
      "step": 24150
    },
    {
      "loss": 0.9502,
      "grad_norm": 14.539578437805176,
      "learning_rate": 3.995256691909618e-06,
      "epoch": 2.1359223300970873,
      "step": 24200
    },
    {
      "loss": 1.0276,
      "grad_norm": 18.17905616760254,
      "learning_rate": 3.9748539920224275e-06,
      "epoch": 2.1403353927625774,
      "step": 24250
    },
    {
      "loss": 0.9281,
      "grad_norm": 14.685288429260254,
      "learning_rate": 3.954451292135238e-06,
      "epoch": 2.144748455428067,
      "step": 24300
    },
    {
      "loss": 1.0274,
      "grad_norm": 13.586604118347168,
      "learning_rate": 3.934048592248047e-06,
      "epoch": 2.149161518093557,
      "step": 24350
    },
    {
      "loss": 0.9402,
      "grad_norm": 15.940661430358887,
      "learning_rate": 3.9136458923608565e-06,
      "epoch": 2.153574580759047,
      "step": 24400
    },
    {
      "loss": 0.9449,
      "grad_norm": 19.476524353027344,
      "learning_rate": 3.893243192473666e-06,
      "epoch": 2.1579876434245366,
      "step": 24450
    },
    {
      "loss": 0.9473,
      "grad_norm": 11.73668098449707,
      "learning_rate": 3.872840492586476e-06,
      "epoch": 2.1624007060900263,
      "step": 24500
    },
    {
      "loss": 0.9898,
      "grad_norm": 15.602075576782227,
      "learning_rate": 3.852437792699286e-06,
      "epoch": 2.1668137687555165,
      "step": 24550
    },
    {
      "loss": 1.0424,
      "grad_norm": 16.544809341430664,
      "learning_rate": 3.832035092812095e-06,
      "epoch": 2.171226831421006,
      "step": 24600
    },
    {
      "loss": 1.0363,
      "grad_norm": 12.891742706298828,
      "learning_rate": 3.8116323929249047e-06,
      "epoch": 2.175639894086496,
      "step": 24650
    },
    {
      "loss": 1.0415,
      "grad_norm": 21.29412269592285,
      "learning_rate": 3.7912296930377144e-06,
      "epoch": 2.180052956751986,
      "step": 24700
    },
    {
      "loss": 0.993,
      "grad_norm": 8.933428764343262,
      "learning_rate": 3.7708269931505245e-06,
      "epoch": 2.1844660194174756,
      "step": 24750
    },
    {
      "loss": 0.9973,
      "grad_norm": 15.33650016784668,
      "learning_rate": 3.750424293263334e-06,
      "epoch": 2.1888790820829658,
      "step": 24800
    },
    {
      "loss": 0.9819,
      "grad_norm": 14.664259910583496,
      "learning_rate": 3.730021593376143e-06,
      "epoch": 2.1932921447484555,
      "step": 24850
    },
    {
      "loss": 1.0158,
      "grad_norm": 14.191665649414062,
      "learning_rate": 3.709618893488953e-06,
      "epoch": 2.197705207413945,
      "step": 24900
    },
    {
      "loss": 1.0676,
      "grad_norm": 8.288312911987305,
      "learning_rate": 3.6892161936017627e-06,
      "epoch": 2.2021182700794353,
      "step": 24950
    },
    {
      "loss": 1.006,
      "grad_norm": 14.22934627532959,
      "learning_rate": 3.6688134937145723e-06,
      "epoch": 2.206531332744925,
      "step": 25000
    },
    {
      "loss": 1.0593,
      "grad_norm": 20.845218658447266,
      "learning_rate": 3.6484107938273824e-06,
      "epoch": 2.2109443954104147,
      "step": 25050
    },
    {
      "loss": 1.0196,
      "grad_norm": 16.18876838684082,
      "learning_rate": 3.628008093940191e-06,
      "epoch": 2.215357458075905,
      "step": 25100
    },
    {
      "loss": 0.9554,
      "grad_norm": 19.89201545715332,
      "learning_rate": 3.6076053940530013e-06,
      "epoch": 2.2197705207413945,
      "step": 25150
    },
    {
      "loss": 0.9637,
      "grad_norm": 9.702058792114258,
      "learning_rate": 3.587202694165811e-06,
      "epoch": 2.2241835834068846,
      "step": 25200
    },
    {
      "loss": 1.0167,
      "grad_norm": 14.35135269165039,
      "learning_rate": 3.5667999942786206e-06,
      "epoch": 2.2285966460723743,
      "step": 25250
    },
    {
      "loss": 1.0084,
      "grad_norm": 16.870643615722656,
      "learning_rate": 3.5463972943914298e-06,
      "epoch": 2.233009708737864,
      "step": 25300
    },
    {
      "loss": 1.0648,
      "grad_norm": 15.958149909973145,
      "learning_rate": 3.5259945945042394e-06,
      "epoch": 2.237422771403354,
      "step": 25350
    },
    {
      "loss": 0.8692,
      "grad_norm": 16.49650001525879,
      "learning_rate": 3.505591894617049e-06,
      "epoch": 2.241835834068844,
      "step": 25400
    },
    {
      "loss": 1.124,
      "grad_norm": 17.05972671508789,
      "learning_rate": 3.485189194729859e-06,
      "epoch": 2.2462488967343335,
      "step": 25450
    },
    {
      "loss": 1.0241,
      "grad_norm": 12.509108543395996,
      "learning_rate": 3.464786494842669e-06,
      "epoch": 2.2506619593998236,
      "step": 25500
    },
    {
      "loss": 1.0885,
      "grad_norm": 16.52643394470215,
      "learning_rate": 3.444383794955478e-06,
      "epoch": 2.2550750220653133,
      "step": 25550
    },
    {
      "loss": 1.0094,
      "grad_norm": 10.864368438720703,
      "learning_rate": 3.4239810950682877e-06,
      "epoch": 2.259488084730803,
      "step": 25600
    },
    {
      "loss": 0.9845,
      "grad_norm": 14.012365341186523,
      "learning_rate": 3.4035783951810973e-06,
      "epoch": 2.263901147396293,
      "step": 25650
    },
    {
      "loss": 1.002,
      "grad_norm": 13.921289443969727,
      "learning_rate": 3.3831756952939074e-06,
      "epoch": 2.268314210061783,
      "step": 25700
    },
    {
      "loss": 1.0307,
      "grad_norm": 19.768278121948242,
      "learning_rate": 3.3627729954067166e-06,
      "epoch": 2.2727272727272725,
      "step": 25750
    },
    {
      "loss": 0.9708,
      "grad_norm": 11.46767807006836,
      "learning_rate": 3.3423702955195263e-06,
      "epoch": 2.2771403353927626,
      "step": 25800
    },
    {
      "loss": 1.0266,
      "grad_norm": 16.11522674560547,
      "learning_rate": 3.321967595632336e-06,
      "epoch": 2.2815533980582523,
      "step": 25850
    },
    {
      "loss": 0.9539,
      "grad_norm": 14.254081726074219,
      "learning_rate": 3.3015648957451456e-06,
      "epoch": 2.2859664607237424,
      "step": 25900
    },
    {
      "loss": 0.9645,
      "grad_norm": 17.751750946044922,
      "learning_rate": 3.2811621958579552e-06,
      "epoch": 2.290379523389232,
      "step": 25950
    },
    {
      "loss": 0.9877,
      "grad_norm": 15.895837783813477,
      "learning_rate": 3.260759495970765e-06,
      "epoch": 2.294792586054722,
      "step": 26000
    },
    {
      "loss": 1.039,
      "grad_norm": 16.85870933532715,
      "learning_rate": 3.2403567960835745e-06,
      "epoch": 2.299205648720212,
      "step": 26050
    },
    {
      "loss": 1.0757,
      "grad_norm": 19.063217163085938,
      "learning_rate": 3.219954096196384e-06,
      "epoch": 2.3036187113857016,
      "step": 26100
    },
    {
      "loss": 0.9884,
      "grad_norm": 14.055645942687988,
      "learning_rate": 3.199551396309194e-06,
      "epoch": 2.3080317740511918,
      "step": 26150
    },
    {
      "loss": 1.0269,
      "grad_norm": 17.820117950439453,
      "learning_rate": 3.179148696422003e-06,
      "epoch": 2.3124448367166814,
      "step": 26200
    },
    {
      "loss": 1.0135,
      "grad_norm": 11.115182876586914,
      "learning_rate": 3.158745996534813e-06,
      "epoch": 2.316857899382171,
      "step": 26250
    },
    {
      "loss": 1.0181,
      "grad_norm": 12.655003547668457,
      "learning_rate": 3.1383432966476228e-06,
      "epoch": 2.3212709620476613,
      "step": 26300
    },
    {
      "loss": 1.0492,
      "grad_norm": 15.689661979675293,
      "learning_rate": 3.117940596760432e-06,
      "epoch": 2.325684024713151,
      "step": 26350
    },
    {
      "loss": 1.1147,
      "grad_norm": 11.737378120422363,
      "learning_rate": 3.097537896873242e-06,
      "epoch": 2.3300970873786406,
      "step": 26400
    },
    {
      "loss": 1.0533,
      "grad_norm": 14.601167678833008,
      "learning_rate": 3.0771351969860513e-06,
      "epoch": 2.3345101500441308,
      "step": 26450
    },
    {
      "loss": 0.9481,
      "grad_norm": 19.872936248779297,
      "learning_rate": 3.0567324970988614e-06,
      "epoch": 2.3389232127096204,
      "step": 26500
    },
    {
      "loss": 0.9787,
      "grad_norm": 9.098474502563477,
      "learning_rate": 3.036329797211671e-06,
      "epoch": 2.34333627537511,
      "step": 26550
    },
    {
      "loss": 1.0325,
      "grad_norm": 11.969968795776367,
      "learning_rate": 3.0159270973244803e-06,
      "epoch": 2.3477493380406003,
      "step": 26600
    },
    {
      "loss": 1.079,
      "grad_norm": 13.081299781799316,
      "learning_rate": 2.9955243974372903e-06,
      "epoch": 2.35216240070609,
      "step": 26650
    },
    {
      "loss": 1.0696,
      "grad_norm": 14.676441192626953,
      "learning_rate": 2.9751216975500996e-06,
      "epoch": 2.3565754633715796,
      "step": 26700
    },
    {
      "loss": 1.0475,
      "grad_norm": 12.406805992126465,
      "learning_rate": 2.954718997662909e-06,
      "epoch": 2.3609885260370698,
      "step": 26750
    },
    {
      "loss": 0.9141,
      "grad_norm": 14.364137649536133,
      "learning_rate": 2.934316297775719e-06,
      "epoch": 2.3654015887025595,
      "step": 26800
    },
    {
      "loss": 0.9751,
      "grad_norm": 20.79966163635254,
      "learning_rate": 2.9139135978885285e-06,
      "epoch": 2.3698146513680496,
      "step": 26850
    },
    {
      "loss": 1.1989,
      "grad_norm": 14.8768310546875,
      "learning_rate": 2.893510898001338e-06,
      "epoch": 2.3742277140335393,
      "step": 26900
    },
    {
      "loss": 1.0335,
      "grad_norm": 12.388635635375977,
      "learning_rate": 2.873108198114148e-06,
      "epoch": 2.378640776699029,
      "step": 26950
    },
    {
      "loss": 0.9793,
      "grad_norm": 11.189742088317871,
      "learning_rate": 2.8527054982269575e-06,
      "epoch": 2.383053839364519,
      "step": 27000
    },
    {
      "loss": 1.0863,
      "grad_norm": 18.64983367919922,
      "learning_rate": 2.832302798339767e-06,
      "epoch": 2.3874669020300088,
      "step": 27050
    },
    {
      "loss": 1.0827,
      "grad_norm": 18.00901985168457,
      "learning_rate": 2.8119000984525768e-06,
      "epoch": 2.391879964695499,
      "step": 27100
    },
    {
      "loss": 1.1071,
      "grad_norm": 14.236970901489258,
      "learning_rate": 2.7914973985653864e-06,
      "epoch": 2.3962930273609886,
      "step": 27150
    },
    {
      "loss": 1.0339,
      "grad_norm": 21.795034408569336,
      "learning_rate": 2.771094698678196e-06,
      "epoch": 2.4007060900264783,
      "step": 27200
    },
    {
      "loss": 1.0079,
      "grad_norm": 18.7645320892334,
      "learning_rate": 2.7506919987910057e-06,
      "epoch": 2.4051191526919684,
      "step": 27250
    },
    {
      "loss": 0.988,
      "grad_norm": 9.69347858428955,
      "learning_rate": 2.7302892989038154e-06,
      "epoch": 2.409532215357458,
      "step": 27300
    },
    {
      "loss": 1.0123,
      "grad_norm": 6.707220077514648,
      "learning_rate": 2.709886599016625e-06,
      "epoch": 2.413945278022948,
      "step": 27350
    },
    {
      "loss": 1.019,
      "grad_norm": 17.901185989379883,
      "learning_rate": 2.6894838991294342e-06,
      "epoch": 2.418358340688438,
      "step": 27400
    },
    {
      "loss": 1.0627,
      "grad_norm": 17.469741821289062,
      "learning_rate": 2.6690811992422443e-06,
      "epoch": 2.4227714033539276,
      "step": 27450
    },
    {
      "loss": 0.9851,
      "grad_norm": 21.63240623474121,
      "learning_rate": 2.648678499355054e-06,
      "epoch": 2.4271844660194173,
      "step": 27500
    },
    {
      "loss": 1.0398,
      "grad_norm": 17.81309700012207,
      "learning_rate": 2.628275799467863e-06,
      "epoch": 2.4315975286849074,
      "step": 27550
    },
    {
      "loss": 1.0842,
      "grad_norm": 10.665167808532715,
      "learning_rate": 2.6078730995806733e-06,
      "epoch": 2.436010591350397,
      "step": 27600
    },
    {
      "loss": 1.0884,
      "grad_norm": 16.884780883789062,
      "learning_rate": 2.5874703996934825e-06,
      "epoch": 2.440423654015887,
      "step": 27650
    },
    {
      "loss": 1.007,
      "grad_norm": 13.364293098449707,
      "learning_rate": 2.567067699806292e-06,
      "epoch": 2.444836716681377,
      "step": 27700
    },
    {
      "loss": 0.8937,
      "grad_norm": 16.542022705078125,
      "learning_rate": 2.546664999919102e-06,
      "epoch": 2.4492497793468666,
      "step": 27750
    },
    {
      "loss": 1.01,
      "grad_norm": 15.023279190063477,
      "learning_rate": 2.5262623000319114e-06,
      "epoch": 2.4536628420123567,
      "step": 27800
    },
    {
      "loss": 0.9423,
      "grad_norm": 15.80931282043457,
      "learning_rate": 2.505859600144721e-06,
      "epoch": 2.4580759046778464,
      "step": 27850
    },
    {
      "loss": 0.9961,
      "grad_norm": 10.916971206665039,
      "learning_rate": 2.4854569002575307e-06,
      "epoch": 2.462488967343336,
      "step": 27900
    },
    {
      "loss": 1.0204,
      "grad_norm": 18.956890106201172,
      "learning_rate": 2.4650542003703404e-06,
      "epoch": 2.4669020300088262,
      "step": 27950
    },
    {
      "loss": 1.0842,
      "grad_norm": 16.344778060913086,
      "learning_rate": 2.4446515004831505e-06,
      "epoch": 2.471315092674316,
      "step": 28000
    },
    {
      "loss": 0.9497,
      "grad_norm": 19.879417419433594,
      "learning_rate": 2.4242488005959597e-06,
      "epoch": 2.475728155339806,
      "step": 28050
    },
    {
      "loss": 0.9653,
      "grad_norm": 17.9096622467041,
      "learning_rate": 2.4038461007087693e-06,
      "epoch": 2.4801412180052957,
      "step": 28100
    },
    {
      "loss": 1.0131,
      "grad_norm": 14.035149574279785,
      "learning_rate": 2.383443400821579e-06,
      "epoch": 2.4845542806707854,
      "step": 28150
    },
    {
      "loss": 1.0017,
      "grad_norm": 15.449831008911133,
      "learning_rate": 2.3630407009343886e-06,
      "epoch": 2.4889673433362756,
      "step": 28200
    },
    {
      "loss": 1.0565,
      "grad_norm": 14.278995513916016,
      "learning_rate": 2.3426380010471983e-06,
      "epoch": 2.4933804060017652,
      "step": 28250
    },
    {
      "loss": 0.9268,
      "grad_norm": 14.405389785766602,
      "learning_rate": 2.322235301160008e-06,
      "epoch": 2.497793468667255,
      "step": 28300
    },
    {
      "loss": 1.0453,
      "grad_norm": 14.000978469848633,
      "learning_rate": 2.3018326012728176e-06,
      "epoch": 2.502206531332745,
      "step": 28350
    },
    {
      "loss": 0.9886,
      "grad_norm": 13.009491920471191,
      "learning_rate": 2.2814299013856272e-06,
      "epoch": 2.5066195939982348,
      "step": 28400
    },
    {
      "loss": 1.0221,
      "grad_norm": 18.3604679107666,
      "learning_rate": 2.261027201498437e-06,
      "epoch": 2.5110326566637244,
      "step": 28450
    },
    {
      "loss": 1.0297,
      "grad_norm": 18.321992874145508,
      "learning_rate": 2.240624501611246e-06,
      "epoch": 2.5154457193292146,
      "step": 28500
    },
    {
      "loss": 1.0177,
      "grad_norm": 7.289648532867432,
      "learning_rate": 2.220221801724056e-06,
      "epoch": 2.5198587819947043,
      "step": 28550
    },
    {
      "loss": 1.0964,
      "grad_norm": 12.447123527526855,
      "learning_rate": 2.199819101836866e-06,
      "epoch": 2.524271844660194,
      "step": 28600
    },
    {
      "loss": 0.9705,
      "grad_norm": 19.262374877929688,
      "learning_rate": 2.179416401949675e-06,
      "epoch": 2.528684907325684,
      "step": 28650
    },
    {
      "loss": 0.9909,
      "grad_norm": 10.423407554626465,
      "learning_rate": 2.159013702062485e-06,
      "epoch": 2.5330979699911738,
      "step": 28700
    },
    {
      "loss": 1.0737,
      "grad_norm": 16.79375457763672,
      "learning_rate": 2.1386110021752944e-06,
      "epoch": 2.537511032656664,
      "step": 28750
    },
    {
      "loss": 0.9739,
      "grad_norm": 19.32135009765625,
      "learning_rate": 2.1182083022881044e-06,
      "epoch": 2.5419240953221536,
      "step": 28800
    },
    {
      "loss": 1.0148,
      "grad_norm": 10.056742668151855,
      "learning_rate": 2.0978056024009137e-06,
      "epoch": 2.5463371579876433,
      "step": 28850
    },
    {
      "loss": 0.9911,
      "grad_norm": 15.723424911499023,
      "learning_rate": 2.0774029025137233e-06,
      "epoch": 2.5507502206531334,
      "step": 28900
    },
    {
      "loss": 1.0045,
      "grad_norm": 10.750059127807617,
      "learning_rate": 2.0570002026265334e-06,
      "epoch": 2.555163283318623,
      "step": 28950
    },
    {
      "loss": 0.9554,
      "grad_norm": 13.610586166381836,
      "learning_rate": 2.0365975027393426e-06,
      "epoch": 2.559576345984113,
      "step": 29000
    },
    {
      "loss": 0.9996,
      "grad_norm": 17.926761627197266,
      "learning_rate": 2.0161948028521523e-06,
      "epoch": 2.563989408649603,
      "step": 29050
    },
    {
      "loss": 0.9398,
      "grad_norm": 8.70634937286377,
      "learning_rate": 1.995792102964962e-06,
      "epoch": 2.5684024713150926,
      "step": 29100
    },
    {
      "loss": 1.0812,
      "grad_norm": 22.31157684326172,
      "learning_rate": 1.9753894030777716e-06,
      "epoch": 2.5728155339805827,
      "step": 29150
    },
    {
      "loss": 1.012,
      "grad_norm": 12.565547943115234,
      "learning_rate": 1.954986703190581e-06,
      "epoch": 2.5772285966460724,
      "step": 29200
    },
    {
      "loss": 1.1372,
      "grad_norm": 19.90928840637207,
      "learning_rate": 1.934584003303391e-06,
      "epoch": 2.581641659311562,
      "step": 29250
    },
    {
      "loss": 1.0128,
      "grad_norm": 11.20822811126709,
      "learning_rate": 1.9141813034162005e-06,
      "epoch": 2.586054721977052,
      "step": 29300
    },
    {
      "loss": 0.9996,
      "grad_norm": 18.11771583557129,
      "learning_rate": 1.89377860352901e-06,
      "epoch": 2.590467784642542,
      "step": 29350
    },
    {
      "loss": 1.065,
      "grad_norm": 13.318509101867676,
      "learning_rate": 1.8733759036418198e-06,
      "epoch": 2.5948808473080316,
      "step": 29400
    },
    {
      "loss": 1.0398,
      "grad_norm": 20.060850143432617,
      "learning_rate": 1.8529732037546292e-06,
      "epoch": 2.5992939099735217,
      "step": 29450
    },
    {
      "loss": 1.0142,
      "grad_norm": 8.928754806518555,
      "learning_rate": 1.832570503867439e-06,
      "epoch": 2.6037069726390114,
      "step": 29500
    },
    {
      "loss": 1.0095,
      "grad_norm": 13.343457221984863,
      "learning_rate": 1.8121678039802488e-06,
      "epoch": 2.608120035304501,
      "step": 29550
    },
    {
      "loss": 1.0843,
      "grad_norm": 17.29400062561035,
      "learning_rate": 1.7917651040930582e-06,
      "epoch": 2.6125330979699912,
      "step": 29600
    },
    {
      "loss": 0.9833,
      "grad_norm": 20.13625717163086,
      "learning_rate": 1.771362404205868e-06,
      "epoch": 2.616946160635481,
      "step": 29650
    },
    {
      "loss": 0.9127,
      "grad_norm": 4.123074531555176,
      "learning_rate": 1.7509597043186773e-06,
      "epoch": 2.6213592233009706,
      "step": 29700
    },
    {
      "loss": 1.0061,
      "grad_norm": 21.04115867614746,
      "learning_rate": 1.7305570044314872e-06,
      "epoch": 2.6257722859664607,
      "step": 29750
    },
    {
      "loss": 1.0508,
      "grad_norm": 18.243562698364258,
      "learning_rate": 1.710154304544297e-06,
      "epoch": 2.6301853486319504,
      "step": 29800
    },
    {
      "loss": 0.9877,
      "grad_norm": 8.19437026977539,
      "learning_rate": 1.6897516046571065e-06,
      "epoch": 2.6345984112974405,
      "step": 29850
    },
    {
      "loss": 0.966,
      "grad_norm": 11.14891242980957,
      "learning_rate": 1.6693489047699159e-06,
      "epoch": 2.6390114739629302,
      "step": 29900
    },
    {
      "loss": 1.0224,
      "grad_norm": 21.81491470336914,
      "learning_rate": 1.6489462048827258e-06,
      "epoch": 2.6434245366284204,
      "step": 29950
    },
    {
      "loss": 1.0088,
      "grad_norm": 15.0452241897583,
      "learning_rate": 1.6285435049955354e-06,
      "epoch": 2.64783759929391,
      "step": 30000
    },
    {
      "loss": 1.0083,
      "grad_norm": 17.465059280395508,
      "learning_rate": 1.6081408051083448e-06,
      "epoch": 2.6522506619593997,
      "step": 30050
    },
    {
      "loss": 1.0062,
      "grad_norm": 12.335010528564453,
      "learning_rate": 1.5877381052211545e-06,
      "epoch": 2.65666372462489,
      "step": 30100
    },
    {
      "loss": 0.9383,
      "grad_norm": 11.45793342590332,
      "learning_rate": 1.5673354053339641e-06,
      "epoch": 2.6610767872903796,
      "step": 30150
    },
    {
      "loss": 1.0299,
      "grad_norm": 15.886017799377441,
      "learning_rate": 1.5469327054467738e-06,
      "epoch": 2.6654898499558692,
      "step": 30200
    },
    {
      "loss": 0.9482,
      "grad_norm": 16.642112731933594,
      "learning_rate": 1.5265300055595834e-06,
      "epoch": 2.6699029126213594,
      "step": 30250
    },
    {
      "loss": 0.9868,
      "grad_norm": 16.829803466796875,
      "learning_rate": 1.506127305672393e-06,
      "epoch": 2.674315975286849,
      "step": 30300
    },
    {
      "loss": 0.9414,
      "grad_norm": 10.83847427368164,
      "learning_rate": 1.4857246057852027e-06,
      "epoch": 2.6787290379523387,
      "step": 30350
    },
    {
      "loss": 1.058,
      "grad_norm": 19.206571578979492,
      "learning_rate": 1.4653219058980124e-06,
      "epoch": 2.683142100617829,
      "step": 30400
    },
    {
      "loss": 1.0038,
      "grad_norm": 13.54664134979248,
      "learning_rate": 1.4449192060108218e-06,
      "epoch": 2.6875551632833186,
      "step": 30450
    },
    {
      "loss": 1.0004,
      "grad_norm": 23.215120315551758,
      "learning_rate": 1.4245165061236317e-06,
      "epoch": 2.6919682259488082,
      "step": 30500
    },
    {
      "loss": 0.9701,
      "grad_norm": 14.034303665161133,
      "learning_rate": 1.4041138062364413e-06,
      "epoch": 2.6963812886142984,
      "step": 30550
    },
    {
      "loss": 1.0272,
      "grad_norm": 31.749696731567383,
      "learning_rate": 1.383711106349251e-06,
      "epoch": 2.700794351279788,
      "step": 30600
    },
    {
      "loss": 1.0163,
      "grad_norm": 13.445720672607422,
      "learning_rate": 1.3633084064620604e-06,
      "epoch": 2.7052074139452778,
      "step": 30650
    },
    {
      "loss": 0.9513,
      "grad_norm": 12.661784172058105,
      "learning_rate": 1.34290570657487e-06,
      "epoch": 2.709620476610768,
      "step": 30700
    },
    {
      "loss": 0.9952,
      "grad_norm": 14.490520477294922,
      "learning_rate": 1.3225030066876797e-06,
      "epoch": 2.7140335392762576,
      "step": 30750
    },
    {
      "loss": 1.0467,
      "grad_norm": 14.047255516052246,
      "learning_rate": 1.3021003068004894e-06,
      "epoch": 2.7184466019417477,
      "step": 30800
    },
    {
      "loss": 1.0844,
      "grad_norm": 18.308334350585938,
      "learning_rate": 1.281697606913299e-06,
      "epoch": 2.7228596646072374,
      "step": 30850
    },
    {
      "loss": 1.0284,
      "grad_norm": 8.780613899230957,
      "learning_rate": 1.2612949070261087e-06,
      "epoch": 2.7272727272727275,
      "step": 30900
    },
    {
      "loss": 1.0077,
      "grad_norm": 7.858027458190918,
      "learning_rate": 1.2408922071389183e-06,
      "epoch": 2.731685789938217,
      "step": 30950
    },
    {
      "loss": 1.0033,
      "grad_norm": 21.657245635986328,
      "learning_rate": 1.220489507251728e-06,
      "epoch": 2.736098852603707,
      "step": 31000
    },
    {
      "loss": 0.9862,
      "grad_norm": 10.24398422241211,
      "learning_rate": 1.2000868073645374e-06,
      "epoch": 2.740511915269197,
      "step": 31050
    },
    {
      "loss": 1.0438,
      "grad_norm": 14.694067001342773,
      "learning_rate": 1.1796841074773473e-06,
      "epoch": 2.7449249779346867,
      "step": 31100
    },
    {
      "loss": 1.0226,
      "grad_norm": 14.42403793334961,
      "learning_rate": 1.159281407590157e-06,
      "epoch": 2.7493380406001764,
      "step": 31150
    },
    {
      "loss": 0.9326,
      "grad_norm": 7.5288519859313965,
      "learning_rate": 1.1388787077029664e-06,
      "epoch": 2.7537511032656665,
      "step": 31200
    },
    {
      "loss": 1.0424,
      "grad_norm": 13.572766304016113,
      "learning_rate": 1.118476007815776e-06,
      "epoch": 2.758164165931156,
      "step": 31250
    },
    {
      "loss": 1.0387,
      "grad_norm": 13.45823860168457,
      "learning_rate": 1.0980733079285857e-06,
      "epoch": 2.762577228596646,
      "step": 31300
    },
    {
      "loss": 1.0218,
      "grad_norm": 11.499123573303223,
      "learning_rate": 1.0776706080413953e-06,
      "epoch": 2.766990291262136,
      "step": 31350
    },
    {
      "loss": 1.0334,
      "grad_norm": 23.068044662475586,
      "learning_rate": 1.057267908154205e-06,
      "epoch": 2.7714033539276257,
      "step": 31400
    },
    {
      "loss": 1.0205,
      "grad_norm": 17.41263198852539,
      "learning_rate": 1.0368652082670146e-06,
      "epoch": 2.7758164165931154,
      "step": 31450
    },
    {
      "loss": 1.037,
      "grad_norm": 17.616819381713867,
      "learning_rate": 1.0164625083798243e-06,
      "epoch": 2.7802294792586055,
      "step": 31500
    },
    {
      "loss": 1.0026,
      "grad_norm": 23.22841453552246,
      "learning_rate": 9.96059808492634e-07,
      "epoch": 2.784642541924095,
      "step": 31550
    },
    {
      "loss": 1.0552,
      "grad_norm": 9.469770431518555,
      "learning_rate": 9.756571086054434e-07,
      "epoch": 2.789055604589585,
      "step": 31600
    },
    {
      "loss": 1.139,
      "grad_norm": 15.436412811279297,
      "learning_rate": 9.55254408718253e-07,
      "epoch": 2.793468667255075,
      "step": 31650
    },
    {
      "loss": 1.0052,
      "grad_norm": 12.27769660949707,
      "learning_rate": 9.348517088310629e-07,
      "epoch": 2.7978817299205647,
      "step": 31700
    },
    {
      "loss": 0.9182,
      "grad_norm": 10.835833549499512,
      "learning_rate": 9.144490089438724e-07,
      "epoch": 2.802294792586055,
      "step": 31750
    },
    {
      "loss": 0.9168,
      "grad_norm": 11.029850959777832,
      "learning_rate": 8.940463090566821e-07,
      "epoch": 2.8067078552515445,
      "step": 31800
    },
    {
      "loss": 0.9558,
      "grad_norm": 16.79017448425293,
      "learning_rate": 8.736436091694916e-07,
      "epoch": 2.8111209179170347,
      "step": 31850
    },
    {
      "loss": 1.0222,
      "grad_norm": 12.98198413848877,
      "learning_rate": 8.532409092823013e-07,
      "epoch": 2.8155339805825244,
      "step": 31900
    },
    {
      "loss": 0.9572,
      "grad_norm": 13.65769100189209,
      "learning_rate": 8.328382093951109e-07,
      "epoch": 2.819947043248014,
      "step": 31950
    },
    {
      "loss": 1.0561,
      "grad_norm": 24.181671142578125,
      "learning_rate": 8.124355095079205e-07,
      "epoch": 2.824360105913504,
      "step": 32000
    },
    {
      "loss": 0.9398,
      "grad_norm": 12.342857360839844,
      "learning_rate": 7.920328096207302e-07,
      "epoch": 2.828773168578994,
      "step": 32050
    },
    {
      "loss": 0.9687,
      "grad_norm": 15.070364952087402,
      "learning_rate": 7.716301097335398e-07,
      "epoch": 2.8331862312444835,
      "step": 32100
    },
    {
      "loss": 1.026,
      "grad_norm": 15.236604690551758,
      "learning_rate": 7.512274098463494e-07,
      "epoch": 2.8375992939099737,
      "step": 32150
    },
    {
      "loss": 0.9134,
      "grad_norm": 16.92855453491211,
      "learning_rate": 7.30824709959159e-07,
      "epoch": 2.8420123565754634,
      "step": 32200
    },
    {
      "loss": 0.9136,
      "grad_norm": 9.537322044372559,
      "learning_rate": 7.104220100719687e-07,
      "epoch": 2.846425419240953,
      "step": 32250
    },
    {
      "loss": 0.9486,
      "grad_norm": 13.526660919189453,
      "learning_rate": 6.900193101847782e-07,
      "epoch": 2.850838481906443,
      "step": 32300
    },
    {
      "loss": 1.0426,
      "grad_norm": 13.139307975769043,
      "learning_rate": 6.69616610297588e-07,
      "epoch": 2.855251544571933,
      "step": 32350
    },
    {
      "loss": 1.1155,
      "grad_norm": 19.051048278808594,
      "learning_rate": 6.492139104103975e-07,
      "epoch": 2.8596646072374226,
      "step": 32400
    },
    {
      "loss": 0.965,
      "grad_norm": 24.571990966796875,
      "learning_rate": 6.288112105232072e-07,
      "epoch": 2.8640776699029127,
      "step": 32450
    },
    {
      "loss": 0.9629,
      "grad_norm": 12.178293228149414,
      "learning_rate": 6.084085106360168e-07,
      "epoch": 2.8684907325684024,
      "step": 32500
    },
    {
      "loss": 0.9997,
      "grad_norm": 14.931870460510254,
      "learning_rate": 5.880058107488265e-07,
      "epoch": 2.872903795233892,
      "step": 32550
    },
    {
      "loss": 0.9512,
      "grad_norm": 6.7247467041015625,
      "learning_rate": 5.67603110861636e-07,
      "epoch": 2.877316857899382,
      "step": 32600
    },
    {
      "loss": 1.0348,
      "grad_norm": 8.389862060546875,
      "learning_rate": 5.472004109744458e-07,
      "epoch": 2.881729920564872,
      "step": 32650
    },
    {
      "loss": 1.106,
      "grad_norm": 16.17746925354004,
      "learning_rate": 5.267977110872553e-07,
      "epoch": 2.886142983230362,
      "step": 32700
    },
    {
      "loss": 0.9999,
      "grad_norm": 17.557682037353516,
      "learning_rate": 5.06395011200065e-07,
      "epoch": 2.8905560458958517,
      "step": 32750
    },
    {
      "loss": 1.0637,
      "grad_norm": 11.374733924865723,
      "learning_rate": 4.859923113128746e-07,
      "epoch": 2.894969108561342,
      "step": 32800
    },
    {
      "loss": 0.9705,
      "grad_norm": 9.347826957702637,
      "learning_rate": 4.6558961142568424e-07,
      "epoch": 2.8993821712268315,
      "step": 32850
    },
    {
      "loss": 0.9252,
      "grad_norm": 18.792423248291016,
      "learning_rate": 4.4518691153849383e-07,
      "epoch": 2.903795233892321,
      "step": 32900
    },
    {
      "loss": 0.9901,
      "grad_norm": 12.824813842773438,
      "learning_rate": 4.247842116513035e-07,
      "epoch": 2.9082082965578113,
      "step": 32950
    },
    {
      "loss": 1.0225,
      "grad_norm": 13.020695686340332,
      "learning_rate": 4.0438151176411313e-07,
      "epoch": 2.912621359223301,
      "step": 33000
    },
    {
      "loss": 0.9275,
      "grad_norm": 17.00718879699707,
      "learning_rate": 3.839788118769228e-07,
      "epoch": 2.9170344218887907,
      "step": 33050
    },
    {
      "loss": 1.0131,
      "grad_norm": 14.4346284866333,
      "learning_rate": 3.635761119897324e-07,
      "epoch": 2.921447484554281,
      "step": 33100
    },
    {
      "loss": 0.9686,
      "grad_norm": 9.921700477600098,
      "learning_rate": 3.4317341210254203e-07,
      "epoch": 2.9258605472197705,
      "step": 33150
    },
    {
      "loss": 1.026,
      "grad_norm": 12.626928329467773,
      "learning_rate": 3.227707122153517e-07,
      "epoch": 2.93027360988526,
      "step": 33200
    },
    {
      "loss": 1.0026,
      "grad_norm": 17.79872703552246,
      "learning_rate": 3.023680123281613e-07,
      "epoch": 2.9346866725507503,
      "step": 33250
    },
    {
      "loss": 0.9852,
      "grad_norm": 13.137547492980957,
      "learning_rate": 2.8196531244097093e-07,
      "epoch": 2.93909973521624,
      "step": 33300
    },
    {
      "loss": 0.9567,
      "grad_norm": 7.421092987060547,
      "learning_rate": 2.615626125537806e-07,
      "epoch": 2.9435127978817297,
      "step": 33350
    },
    {
      "loss": 0.8558,
      "grad_norm": 15.225329399108887,
      "learning_rate": 2.411599126665902e-07,
      "epoch": 2.94792586054722,
      "step": 33400
    },
    {
      "loss": 1.0144,
      "grad_norm": 16.276350021362305,
      "learning_rate": 2.207572127793998e-07,
      "epoch": 2.9523389232127095,
      "step": 33450
    },
    {
      "loss": 0.9207,
      "grad_norm": 20.347604751586914,
      "learning_rate": 2.0035451289220942e-07,
      "epoch": 2.956751985878199,
      "step": 33500
    },
    {
      "loss": 1.0779,
      "grad_norm": 11.252009391784668,
      "learning_rate": 1.7995181300501907e-07,
      "epoch": 2.9611650485436893,
      "step": 33550
    },
    {
      "loss": 1.0144,
      "grad_norm": 16.181121826171875,
      "learning_rate": 1.595491131178287e-07,
      "epoch": 2.965578111209179,
      "step": 33600
    },
    {
      "loss": 0.9333,
      "grad_norm": 13.017659187316895,
      "learning_rate": 1.3914641323063832e-07,
      "epoch": 2.969991173874669,
      "step": 33650
    },
    {
      "loss": 0.9621,
      "grad_norm": 10.078980445861816,
      "learning_rate": 1.1874371334344796e-07,
      "epoch": 2.974404236540159,
      "step": 33700
    },
    {
      "loss": 0.9687,
      "grad_norm": 14.078813552856445,
      "learning_rate": 9.834101345625758e-08,
      "epoch": 2.978817299205649,
      "step": 33750
    },
    {
      "loss": 0.9804,
      "grad_norm": 15.283591270446777,
      "learning_rate": 7.793831356906722e-08,
      "epoch": 2.9832303618711387,
      "step": 33800
    },
    {
      "loss": 0.975,
      "grad_norm": 16.33843994140625,
      "learning_rate": 5.753561368187685e-08,
      "epoch": 2.9876434245366283,
      "step": 33850
    },
    {
      "loss": 1.1079,
      "grad_norm": 11.502670288085938,
      "learning_rate": 3.713291379468647e-08,
      "epoch": 2.9920564872021185,
      "step": 33900
    },
    {
      "loss": 0.9625,
      "grad_norm": 13.548027992248535,
      "learning_rate": 1.6730213907496105e-08,
      "epoch": 2.996469549867608,
      "step": 33950
    },
    {
      "eval_loss": 0.8779567227713414,
      "eval_exact_match": 77.82827391457819,
      "eval_f1": 83.3270978704618,
      "eval_samples": 22720,
      "step": 33990
    },
    {
      "eval_loss": 0.8779567227713414,
      "eval_exact_match": 77.82827391457819,
      "eval_f1": 83.3270978704618,
      "eval_samples": 22720,
      "epoch": 3.0,
      "step": 33990
    },
    {
      "train_runtime": 21864.4754,
      "train_samples_per_second": 24.873,
      "train_steps_per_second": 1.555,
      "total_flos": 1.5889485017935872e+16,
      "train_loss": 1.31472844154423,
      "epoch": 3.0,
      "step": 33990
    }
  ]
}
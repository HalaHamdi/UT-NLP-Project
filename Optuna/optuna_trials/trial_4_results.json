{
  "trial_number": 4,
  "hyperparameters": {
    "learning_rate": 0.00027832590504596623,
    "per_device_train_batch_size": 32,
    "num_train_epochs": 4,
    "warmup_steps": 271,
    "per_device_eval_batch_size": 32
  },
  "best_f1": 83.87074131560983,
  "all_eval_f1_scores": [
    80.38559810400875,
    80.38559810400875,
    82.56442468213832,
    82.56442468213832,
    83.40447033994434,
    83.40447033994434,
    83.87074131560983,
    83.87074131560983
  ],
  "training_logs": [
    {
      "loss": 5.4383,
      "grad_norm": 6.160701274871826,
      "learning_rate": 5.032461013746253e-05,
      "epoch": 0.0088261253309797,
      "step": 50
    },
    {
      "loss": 3.4253,
      "grad_norm": 5.458010673522949,
      "learning_rate": 0.00010167625313487327,
      "epoch": 0.0176522506619594,
      "step": 100
    },
    {
      "loss": 2.642,
      "grad_norm": 11.2682466506958,
      "learning_rate": 0.00015302789613228402,
      "epoch": 0.0264783759929391,
      "step": 150
    },
    {
      "loss": 2.3821,
      "grad_norm": 8.309600830078125,
      "learning_rate": 0.00020437953912969477,
      "epoch": 0.0353045013239188,
      "step": 200
    },
    {
      "loss": 2.2468,
      "grad_norm": 8.333353042602539,
      "learning_rate": 0.0002557311821271055,
      "epoch": 0.0441306266548985,
      "step": 250
    },
    {
      "loss": 2.2018,
      "grad_norm": 9.781432151794434,
      "learning_rate": 0.00027797782673334454,
      "epoch": 0.0529567519858782,
      "step": 300
    },
    {
      "loss": 2.0236,
      "grad_norm": 7.645312309265137,
      "learning_rate": 0.00027735625831794866,
      "epoch": 0.0617828773168579,
      "step": 350
    },
    {
      "loss": 1.982,
      "grad_norm": 10.984950065612793,
      "learning_rate": 0.0002767346899025528,
      "epoch": 0.0706090026478376,
      "step": 400
    },
    {
      "loss": 1.9165,
      "grad_norm": 9.322941780090332,
      "learning_rate": 0.0002761131214871569,
      "epoch": 0.0794351279788173,
      "step": 450
    },
    {
      "loss": 1.8498,
      "grad_norm": 10.230514526367188,
      "learning_rate": 0.000275491553071761,
      "epoch": 0.088261253309797,
      "step": 500
    },
    {
      "loss": 1.8069,
      "grad_norm": 11.259480476379395,
      "learning_rate": 0.00027486998465636514,
      "epoch": 0.0970873786407767,
      "step": 550
    },
    {
      "loss": 1.7933,
      "grad_norm": 8.466050148010254,
      "learning_rate": 0.00027424841624096926,
      "epoch": 0.1059135039717564,
      "step": 600
    },
    {
      "loss": 1.7807,
      "grad_norm": 7.346068859100342,
      "learning_rate": 0.00027362684782557343,
      "epoch": 0.1147396293027361,
      "step": 650
    },
    {
      "loss": 1.7358,
      "grad_norm": 11.13249683380127,
      "learning_rate": 0.0002730052794101775,
      "epoch": 0.1235657546337158,
      "step": 700
    },
    {
      "loss": 1.6708,
      "grad_norm": 7.596665382385254,
      "learning_rate": 0.00027238371099478167,
      "epoch": 0.1323918799646955,
      "step": 750
    },
    {
      "loss": 1.6941,
      "grad_norm": 8.665538787841797,
      "learning_rate": 0.00027176214257938573,
      "epoch": 0.1412180052956752,
      "step": 800
    },
    {
      "loss": 1.664,
      "grad_norm": 7.40175199508667,
      "learning_rate": 0.00027114057416398985,
      "epoch": 0.1500441306266549,
      "step": 850
    },
    {
      "loss": 1.6625,
      "grad_norm": 9.568511009216309,
      "learning_rate": 0.00027051900574859403,
      "epoch": 0.1588702559576346,
      "step": 900
    },
    {
      "loss": 1.6754,
      "grad_norm": 9.127029418945312,
      "learning_rate": 0.0002698974373331981,
      "epoch": 0.1676963812886143,
      "step": 950
    },
    {
      "loss": 1.6459,
      "grad_norm": 11.571934700012207,
      "learning_rate": 0.00026927586891780227,
      "epoch": 0.176522506619594,
      "step": 1000
    },
    {
      "loss": 1.6218,
      "grad_norm": 6.196564674377441,
      "learning_rate": 0.0002686543005024064,
      "epoch": 0.1853486319505737,
      "step": 1050
    },
    {
      "loss": 1.6606,
      "grad_norm": 10.51903247833252,
      "learning_rate": 0.0002680327320870105,
      "epoch": 0.1941747572815534,
      "step": 1100
    },
    {
      "loss": 1.5729,
      "grad_norm": 9.363781929016113,
      "learning_rate": 0.0002674111636716146,
      "epoch": 0.2030008826125331,
      "step": 1150
    },
    {
      "loss": 1.601,
      "grad_norm": 9.751728057861328,
      "learning_rate": 0.00026678959525621874,
      "epoch": 0.2118270079435128,
      "step": 1200
    },
    {
      "loss": 1.5731,
      "grad_norm": 9.357500076293945,
      "learning_rate": 0.00026616802684082286,
      "epoch": 0.22065313327449249,
      "step": 1250
    },
    {
      "loss": 1.5817,
      "grad_norm": 10.787847518920898,
      "learning_rate": 0.000265546458425427,
      "epoch": 0.2294792586054722,
      "step": 1300
    },
    {
      "loss": 1.6147,
      "grad_norm": 12.74243450164795,
      "learning_rate": 0.0002649248900100311,
      "epoch": 0.2383053839364519,
      "step": 1350
    },
    {
      "loss": 1.5916,
      "grad_norm": 9.1340913772583,
      "learning_rate": 0.0002643033215946352,
      "epoch": 0.2471315092674316,
      "step": 1400
    },
    {
      "loss": 1.6624,
      "grad_norm": 9.58297061920166,
      "learning_rate": 0.00026368175317923934,
      "epoch": 0.2559576345984113,
      "step": 1450
    },
    {
      "loss": 1.5949,
      "grad_norm": 9.02406120300293,
      "learning_rate": 0.00026306018476384346,
      "epoch": 0.264783759929391,
      "step": 1500
    },
    {
      "loss": 1.564,
      "grad_norm": 6.36644983291626,
      "learning_rate": 0.0002624386163484476,
      "epoch": 0.2736098852603707,
      "step": 1550
    },
    {
      "loss": 1.5847,
      "grad_norm": 10.286211967468262,
      "learning_rate": 0.0002618170479330517,
      "epoch": 0.2824360105913504,
      "step": 1600
    },
    {
      "loss": 1.5172,
      "grad_norm": 10.826457023620605,
      "learning_rate": 0.0002611954795176558,
      "epoch": 0.2912621359223301,
      "step": 1650
    },
    {
      "loss": 1.5411,
      "grad_norm": 11.095166206359863,
      "learning_rate": 0.00026057391110225994,
      "epoch": 0.3000882612533098,
      "step": 1700
    },
    {
      "loss": 1.4688,
      "grad_norm": 7.444531440734863,
      "learning_rate": 0.00025995234268686405,
      "epoch": 0.3089143865842895,
      "step": 1750
    },
    {
      "loss": 1.4724,
      "grad_norm": 6.9251017570495605,
      "learning_rate": 0.00025933077427146823,
      "epoch": 0.3177405119152692,
      "step": 1800
    },
    {
      "loss": 1.5069,
      "grad_norm": 8.960512161254883,
      "learning_rate": 0.0002587092058560723,
      "epoch": 0.3265666372462489,
      "step": 1850
    },
    {
      "loss": 1.4705,
      "grad_norm": 10.051587104797363,
      "learning_rate": 0.00025808763744067647,
      "epoch": 0.3353927625772286,
      "step": 1900
    },
    {
      "loss": 1.4828,
      "grad_norm": 8.538637161254883,
      "learning_rate": 0.00025746606902528053,
      "epoch": 0.3442188879082083,
      "step": 1950
    },
    {
      "loss": 1.3705,
      "grad_norm": 9.258869171142578,
      "learning_rate": 0.0002568445006098847,
      "epoch": 0.353045013239188,
      "step": 2000
    },
    {
      "loss": 1.466,
      "grad_norm": 12.761923789978027,
      "learning_rate": 0.0002562229321944888,
      "epoch": 0.36187113857016767,
      "step": 2050
    },
    {
      "loss": 1.4205,
      "grad_norm": 11.941726684570312,
      "learning_rate": 0.00025560136377909294,
      "epoch": 0.3706972639011474,
      "step": 2100
    },
    {
      "loss": 1.4519,
      "grad_norm": 5.874866008758545,
      "learning_rate": 0.00025497979536369706,
      "epoch": 0.3795233892321271,
      "step": 2150
    },
    {
      "loss": 1.4508,
      "grad_norm": 9.952140808105469,
      "learning_rate": 0.0002543582269483012,
      "epoch": 0.3883495145631068,
      "step": 2200
    },
    {
      "loss": 1.4275,
      "grad_norm": 6.690066814422607,
      "learning_rate": 0.0002537366585329053,
      "epoch": 0.3971756398940865,
      "step": 2250
    },
    {
      "loss": 1.4255,
      "grad_norm": 7.816132545471191,
      "learning_rate": 0.0002531150901175094,
      "epoch": 0.4060017652250662,
      "step": 2300
    },
    {
      "loss": 1.4226,
      "grad_norm": 7.770109176635742,
      "learning_rate": 0.00025249352170211354,
      "epoch": 0.4148278905560459,
      "step": 2350
    },
    {
      "loss": 1.4956,
      "grad_norm": 9.407224655151367,
      "learning_rate": 0.00025187195328671766,
      "epoch": 0.4236540158870256,
      "step": 2400
    },
    {
      "loss": 1.4231,
      "grad_norm": 11.01612377166748,
      "learning_rate": 0.0002512503848713218,
      "epoch": 0.4324801412180053,
      "step": 2450
    },
    {
      "loss": 1.3805,
      "grad_norm": 8.246696472167969,
      "learning_rate": 0.0002506288164559259,
      "epoch": 0.44130626654898497,
      "step": 2500
    },
    {
      "loss": 1.3986,
      "grad_norm": 6.477057456970215,
      "learning_rate": 0.00025000724804053,
      "epoch": 0.4501323918799647,
      "step": 2550
    },
    {
      "loss": 1.4104,
      "grad_norm": 7.886297702789307,
      "learning_rate": 0.00024938567962513414,
      "epoch": 0.4589585172109444,
      "step": 2600
    },
    {
      "loss": 1.3751,
      "grad_norm": 8.657071113586426,
      "learning_rate": 0.00024876411120973826,
      "epoch": 0.4677846425419241,
      "step": 2650
    },
    {
      "loss": 1.3493,
      "grad_norm": 9.634462356567383,
      "learning_rate": 0.00024814254279434243,
      "epoch": 0.4766107678729038,
      "step": 2700
    },
    {
      "loss": 1.3771,
      "grad_norm": 6.2241997718811035,
      "learning_rate": 0.0002475209743789465,
      "epoch": 0.4854368932038835,
      "step": 2750
    },
    {
      "loss": 1.3808,
      "grad_norm": 9.718838691711426,
      "learning_rate": 0.00024689940596355067,
      "epoch": 0.4942630185348632,
      "step": 2800
    },
    {
      "loss": 1.3708,
      "grad_norm": 11.756584167480469,
      "learning_rate": 0.00024627783754815473,
      "epoch": 0.5030891438658429,
      "step": 2850
    },
    {
      "loss": 1.3634,
      "grad_norm": 6.298731327056885,
      "learning_rate": 0.0002456562691327589,
      "epoch": 0.5119152691968226,
      "step": 2900
    },
    {
      "loss": 1.3225,
      "grad_norm": 5.096014499664307,
      "learning_rate": 0.000245034700717363,
      "epoch": 0.5207413945278023,
      "step": 2950
    },
    {
      "loss": 1.4745,
      "grad_norm": 16.5655460357666,
      "learning_rate": 0.00024441313230196714,
      "epoch": 0.529567519858782,
      "step": 3000
    },
    {
      "loss": 1.4251,
      "grad_norm": 7.630894660949707,
      "learning_rate": 0.00024379156388657126,
      "epoch": 0.5383936451897617,
      "step": 3050
    },
    {
      "loss": 1.3271,
      "grad_norm": 7.612614631652832,
      "learning_rate": 0.00024316999547117536,
      "epoch": 0.5472197705207414,
      "step": 3100
    },
    {
      "loss": 1.3687,
      "grad_norm": 13.850142478942871,
      "learning_rate": 0.0002425484270557795,
      "epoch": 0.556045895851721,
      "step": 3150
    },
    {
      "loss": 1.33,
      "grad_norm": 8.584513664245605,
      "learning_rate": 0.00024192685864038362,
      "epoch": 0.5648720211827007,
      "step": 3200
    },
    {
      "loss": 1.3267,
      "grad_norm": 8.633399963378906,
      "learning_rate": 0.00024130529022498774,
      "epoch": 0.5736981465136805,
      "step": 3250
    },
    {
      "loss": 1.3373,
      "grad_norm": 7.01778507232666,
      "learning_rate": 0.00024068372180959186,
      "epoch": 0.5825242718446602,
      "step": 3300
    },
    {
      "loss": 1.3261,
      "grad_norm": 8.866384506225586,
      "learning_rate": 0.00024006215339419598,
      "epoch": 0.5913503971756399,
      "step": 3350
    },
    {
      "loss": 1.2786,
      "grad_norm": 9.681187629699707,
      "learning_rate": 0.0002394405849788001,
      "epoch": 0.6001765225066196,
      "step": 3400
    },
    {
      "loss": 1.3064,
      "grad_norm": 6.040998935699463,
      "learning_rate": 0.00023881901656340424,
      "epoch": 0.6090026478375993,
      "step": 3450
    },
    {
      "loss": 1.3436,
      "grad_norm": 8.152751922607422,
      "learning_rate": 0.00023819744814800834,
      "epoch": 0.617828773168579,
      "step": 3500
    },
    {
      "loss": 1.2645,
      "grad_norm": 7.163968563079834,
      "learning_rate": 0.00023757587973261248,
      "epoch": 0.6266548984995587,
      "step": 3550
    },
    {
      "loss": 1.3752,
      "grad_norm": 6.4479570388793945,
      "learning_rate": 0.0002369543113172166,
      "epoch": 0.6354810238305384,
      "step": 3600
    },
    {
      "loss": 1.2723,
      "grad_norm": 6.220064640045166,
      "learning_rate": 0.00023633274290182072,
      "epoch": 0.6443071491615181,
      "step": 3650
    },
    {
      "loss": 1.3513,
      "grad_norm": 9.359908103942871,
      "learning_rate": 0.00023571117448642484,
      "epoch": 0.6531332744924978,
      "step": 3700
    },
    {
      "loss": 1.2544,
      "grad_norm": 5.443975925445557,
      "learning_rate": 0.00023508960607102896,
      "epoch": 0.6619593998234775,
      "step": 3750
    },
    {
      "loss": 1.3028,
      "grad_norm": 8.242233276367188,
      "learning_rate": 0.00023446803765563308,
      "epoch": 0.6707855251544572,
      "step": 3800
    },
    {
      "loss": 1.2377,
      "grad_norm": 5.3130621910095215,
      "learning_rate": 0.00023384646924023723,
      "epoch": 0.6796116504854369,
      "step": 3850
    },
    {
      "loss": 1.345,
      "grad_norm": 6.252277374267578,
      "learning_rate": 0.00023322490082484132,
      "epoch": 0.6884377758164166,
      "step": 3900
    },
    {
      "loss": 1.313,
      "grad_norm": 7.806342124938965,
      "learning_rate": 0.00023260333240944546,
      "epoch": 0.6972639011473963,
      "step": 3950
    },
    {
      "loss": 1.3759,
      "grad_norm": 7.126820087432861,
      "learning_rate": 0.00023198176399404956,
      "epoch": 0.706090026478376,
      "step": 4000
    },
    {
      "loss": 1.2675,
      "grad_norm": 6.984587669372559,
      "learning_rate": 0.0002313601955786537,
      "epoch": 0.7149161518093556,
      "step": 4050
    },
    {
      "loss": 1.3691,
      "grad_norm": 7.370738506317139,
      "learning_rate": 0.00023073862716325782,
      "epoch": 0.7237422771403353,
      "step": 4100
    },
    {
      "loss": 1.2678,
      "grad_norm": 7.307541370391846,
      "learning_rate": 0.00023011705874786194,
      "epoch": 0.732568402471315,
      "step": 4150
    },
    {
      "loss": 1.2159,
      "grad_norm": 7.954808235168457,
      "learning_rate": 0.00022949549033246606,
      "epoch": 0.7413945278022948,
      "step": 4200
    },
    {
      "loss": 1.2481,
      "grad_norm": 6.136627197265625,
      "learning_rate": 0.00022887392191707018,
      "epoch": 0.7502206531332745,
      "step": 4250
    },
    {
      "loss": 1.2857,
      "grad_norm": 8.315775871276855,
      "learning_rate": 0.0002282523535016743,
      "epoch": 0.7590467784642542,
      "step": 4300
    },
    {
      "loss": 1.291,
      "grad_norm": 37.195777893066406,
      "learning_rate": 0.00022763078508627845,
      "epoch": 0.7678729037952339,
      "step": 4350
    },
    {
      "loss": 1.2806,
      "grad_norm": 6.761205673217773,
      "learning_rate": 0.00022700921667088254,
      "epoch": 0.7766990291262136,
      "step": 4400
    },
    {
      "loss": 1.2726,
      "grad_norm": 7.718475341796875,
      "learning_rate": 0.00022638764825548668,
      "epoch": 0.7855251544571933,
      "step": 4450
    },
    {
      "loss": 1.2258,
      "grad_norm": 6.670193672180176,
      "learning_rate": 0.00022576607984009078,
      "epoch": 0.794351279788173,
      "step": 4500
    },
    {
      "loss": 1.3036,
      "grad_norm": 7.690534591674805,
      "learning_rate": 0.00022514451142469492,
      "epoch": 0.8031774051191527,
      "step": 4550
    },
    {
      "loss": 1.3029,
      "grad_norm": 10.343646049499512,
      "learning_rate": 0.00022452294300929904,
      "epoch": 0.8120035304501324,
      "step": 4600
    },
    {
      "loss": 1.2075,
      "grad_norm": 7.5680341720581055,
      "learning_rate": 0.00022390137459390316,
      "epoch": 0.8208296557811121,
      "step": 4650
    },
    {
      "loss": 1.2749,
      "grad_norm": 6.032724380493164,
      "learning_rate": 0.00022327980617850728,
      "epoch": 0.8296557811120918,
      "step": 4700
    },
    {
      "loss": 1.3273,
      "grad_norm": 8.25380802154541,
      "learning_rate": 0.0002226582377631114,
      "epoch": 0.8384819064430715,
      "step": 4750
    },
    {
      "loss": 1.2052,
      "grad_norm": 7.543370723724365,
      "learning_rate": 0.00022203666934771552,
      "epoch": 0.8473080317740512,
      "step": 4800
    },
    {
      "loss": 1.33,
      "grad_norm": 5.370461463928223,
      "learning_rate": 0.00022141510093231967,
      "epoch": 0.8561341571050309,
      "step": 4850
    },
    {
      "loss": 1.2503,
      "grad_norm": 7.515510082244873,
      "learning_rate": 0.00022079353251692376,
      "epoch": 0.8649602824360106,
      "step": 4900
    },
    {
      "loss": 1.2696,
      "grad_norm": 5.736773490905762,
      "learning_rate": 0.0002201719641015279,
      "epoch": 0.8737864077669902,
      "step": 4950
    },
    {
      "loss": 1.2849,
      "grad_norm": 7.267833709716797,
      "learning_rate": 0.00021955039568613202,
      "epoch": 0.8826125330979699,
      "step": 5000
    },
    {
      "loss": 1.2224,
      "grad_norm": 7.778234958648682,
      "learning_rate": 0.00021892882727073614,
      "epoch": 0.8914386584289496,
      "step": 5050
    },
    {
      "loss": 1.2817,
      "grad_norm": 7.820588111877441,
      "learning_rate": 0.00021830725885534026,
      "epoch": 0.9002647837599294,
      "step": 5100
    },
    {
      "loss": 1.2421,
      "grad_norm": 6.7456488609313965,
      "learning_rate": 0.00021768569043994438,
      "epoch": 0.9090909090909091,
      "step": 5150
    },
    {
      "loss": 1.1818,
      "grad_norm": 8.553448677062988,
      "learning_rate": 0.0002170641220245485,
      "epoch": 0.9179170344218888,
      "step": 5200
    },
    {
      "loss": 1.2442,
      "grad_norm": 5.647120952606201,
      "learning_rate": 0.00021644255360915265,
      "epoch": 0.9267431597528685,
      "step": 5250
    },
    {
      "loss": 1.2203,
      "grad_norm": 6.790367126464844,
      "learning_rate": 0.00021582098519375674,
      "epoch": 0.9355692850838482,
      "step": 5300
    },
    {
      "loss": 1.1993,
      "grad_norm": 5.8426618576049805,
      "learning_rate": 0.00021519941677836088,
      "epoch": 0.9443954104148279,
      "step": 5350
    },
    {
      "loss": 1.194,
      "grad_norm": 8.370033264160156,
      "learning_rate": 0.00021457784836296498,
      "epoch": 0.9532215357458076,
      "step": 5400
    },
    {
      "loss": 1.286,
      "grad_norm": 6.793262958526611,
      "learning_rate": 0.00021395627994756912,
      "epoch": 0.9620476610767873,
      "step": 5450
    },
    {
      "loss": 1.205,
      "grad_norm": 12.545263290405273,
      "learning_rate": 0.00021333471153217324,
      "epoch": 0.970873786407767,
      "step": 5500
    },
    {
      "loss": 1.2464,
      "grad_norm": 6.542319297790527,
      "learning_rate": 0.00021271314311677736,
      "epoch": 0.9796999117387467,
      "step": 5550
    },
    {
      "loss": 1.1993,
      "grad_norm": 7.150249481201172,
      "learning_rate": 0.00021209157470138148,
      "epoch": 0.9885260370697264,
      "step": 5600
    },
    {
      "loss": 1.1509,
      "grad_norm": 8.922234535217285,
      "learning_rate": 0.0002114700062859856,
      "epoch": 0.9973521624007061,
      "step": 5650
    },
    {
      "eval_loss": 1.0110157240574398,
      "eval_exact_match": 74.23667490292975,
      "eval_f1": 80.38559810400875,
      "eval_samples": 22720,
      "step": 5665
    },
    {
      "eval_loss": 1.0110157240574398,
      "eval_exact_match": 74.23667490292975,
      "eval_f1": 80.38559810400875,
      "eval_samples": 22720,
      "epoch": 1.0,
      "step": 5665
    },
    {
      "loss": 1.1354,
      "grad_norm": 8.116678237915039,
      "learning_rate": 0.00021084843787058972,
      "epoch": 1.0061782877316858,
      "step": 5700
    },
    {
      "loss": 1.1257,
      "grad_norm": 8.240909576416016,
      "learning_rate": 0.00021022686945519387,
      "epoch": 1.0150044130626654,
      "step": 5750
    },
    {
      "loss": 1.0476,
      "grad_norm": 14.783562660217285,
      "learning_rate": 0.00020960530103979796,
      "epoch": 1.0238305383936452,
      "step": 5800
    },
    {
      "loss": 1.069,
      "grad_norm": 7.524343967437744,
      "learning_rate": 0.0002089837326244021,
      "epoch": 1.0326566637246248,
      "step": 5850
    },
    {
      "loss": 1.0721,
      "grad_norm": 7.825323581695557,
      "learning_rate": 0.0002083621642090062,
      "epoch": 1.0414827890556047,
      "step": 5900
    },
    {
      "loss": 1.0608,
      "grad_norm": 11.611668586730957,
      "learning_rate": 0.00020774059579361034,
      "epoch": 1.0503089143865842,
      "step": 5950
    },
    {
      "loss": 1.0298,
      "grad_norm": 9.75796127319336,
      "learning_rate": 0.00020711902737821446,
      "epoch": 1.059135039717564,
      "step": 6000
    },
    {
      "loss": 1.0726,
      "grad_norm": 7.205778121948242,
      "learning_rate": 0.00020649745896281855,
      "epoch": 1.0679611650485437,
      "step": 6050
    },
    {
      "loss": 1.0459,
      "grad_norm": 11.214508056640625,
      "learning_rate": 0.0002058758905474227,
      "epoch": 1.0767872903795235,
      "step": 6100
    },
    {
      "loss": 1.0865,
      "grad_norm": 6.473666191101074,
      "learning_rate": 0.0002052543221320268,
      "epoch": 1.085613415710503,
      "step": 6150
    },
    {
      "loss": 1.0969,
      "grad_norm": 9.368637084960938,
      "learning_rate": 0.00020463275371663094,
      "epoch": 1.0944395410414829,
      "step": 6200
    },
    {
      "loss": 1.1202,
      "grad_norm": 9.439746856689453,
      "learning_rate": 0.00020401118530123509,
      "epoch": 1.1032656663724625,
      "step": 6250
    },
    {
      "loss": 1.0489,
      "grad_norm": 8.406535148620605,
      "learning_rate": 0.00020338961688583918,
      "epoch": 1.1120917917034423,
      "step": 6300
    },
    {
      "loss": 1.0955,
      "grad_norm": 6.785347938537598,
      "learning_rate": 0.00020276804847044332,
      "epoch": 1.120917917034422,
      "step": 6350
    },
    {
      "loss": 1.1383,
      "grad_norm": 9.0236234664917,
      "learning_rate": 0.00020214648005504744,
      "epoch": 1.1297440423654015,
      "step": 6400
    },
    {
      "loss": 1.0784,
      "grad_norm": 6.582566261291504,
      "learning_rate": 0.00020152491163965154,
      "epoch": 1.1385701676963813,
      "step": 6450
    },
    {
      "loss": 1.088,
      "grad_norm": 9.320045471191406,
      "learning_rate": 0.00020090334322425568,
      "epoch": 1.147396293027361,
      "step": 6500
    },
    {
      "loss": 1.09,
      "grad_norm": 7.689285755157471,
      "learning_rate": 0.00020028177480885977,
      "epoch": 1.1562224183583407,
      "step": 6550
    },
    {
      "loss": 1.0958,
      "grad_norm": 5.509209632873535,
      "learning_rate": 0.00019966020639346392,
      "epoch": 1.1650485436893203,
      "step": 6600
    },
    {
      "loss": 1.0909,
      "grad_norm": 5.700100898742676,
      "learning_rate": 0.00019903863797806807,
      "epoch": 1.1738746690203001,
      "step": 6650
    },
    {
      "loss": 1.0855,
      "grad_norm": 7.24970006942749,
      "learning_rate": 0.00019841706956267216,
      "epoch": 1.1827007943512797,
      "step": 6700
    },
    {
      "loss": 1.0836,
      "grad_norm": 6.5752387046813965,
      "learning_rate": 0.0001977955011472763,
      "epoch": 1.1915269196822595,
      "step": 6750
    },
    {
      "loss": 1.0262,
      "grad_norm": 9.487581253051758,
      "learning_rate": 0.0001971739327318804,
      "epoch": 1.2003530450132391,
      "step": 6800
    },
    {
      "loss": 1.1199,
      "grad_norm": 11.281576156616211,
      "learning_rate": 0.00019655236431648452,
      "epoch": 1.209179170344219,
      "step": 6850
    },
    {
      "loss": 1.1188,
      "grad_norm": 6.982426166534424,
      "learning_rate": 0.00019593079590108866,
      "epoch": 1.2180052956751986,
      "step": 6900
    },
    {
      "loss": 1.0787,
      "grad_norm": 11.924744606018066,
      "learning_rate": 0.00019530922748569276,
      "epoch": 1.2268314210061784,
      "step": 6950
    },
    {
      "loss": 1.0495,
      "grad_norm": 9.497509002685547,
      "learning_rate": 0.0001946876590702969,
      "epoch": 1.235657546337158,
      "step": 7000
    },
    {
      "loss": 1.0705,
      "grad_norm": 6.308356285095215,
      "learning_rate": 0.000194066090654901,
      "epoch": 1.2444836716681378,
      "step": 7050
    },
    {
      "loss": 1.1188,
      "grad_norm": 7.598369598388672,
      "learning_rate": 0.00019344452223950514,
      "epoch": 1.2533097969991174,
      "step": 7100
    },
    {
      "loss": 1.0931,
      "grad_norm": 8.177531242370605,
      "learning_rate": 0.00019282295382410926,
      "epoch": 1.262135922330097,
      "step": 7150
    },
    {
      "loss": 1.0208,
      "grad_norm": 8.443592071533203,
      "learning_rate": 0.00019220138540871338,
      "epoch": 1.2709620476610768,
      "step": 7200
    },
    {
      "loss": 1.0846,
      "grad_norm": 7.283238887786865,
      "learning_rate": 0.0001915798169933175,
      "epoch": 1.2797881729920566,
      "step": 7250
    },
    {
      "loss": 1.1787,
      "grad_norm": 4.225623607635498,
      "learning_rate": 0.00019095824857792162,
      "epoch": 1.2886142983230362,
      "step": 7300
    },
    {
      "loss": 1.0305,
      "grad_norm": 8.156217575073242,
      "learning_rate": 0.00019033668016252574,
      "epoch": 1.2974404236540158,
      "step": 7350
    },
    {
      "loss": 1.1099,
      "grad_norm": 6.278928279876709,
      "learning_rate": 0.00018971511174712988,
      "epoch": 1.3062665489849956,
      "step": 7400
    },
    {
      "loss": 1.0754,
      "grad_norm": 8.06221866607666,
      "learning_rate": 0.00018909354333173397,
      "epoch": 1.3150926743159752,
      "step": 7450
    },
    {
      "loss": 1.0864,
      "grad_norm": 9.284916877746582,
      "learning_rate": 0.00018847197491633812,
      "epoch": 1.323918799646955,
      "step": 7500
    },
    {
      "loss": 1.0514,
      "grad_norm": 9.429871559143066,
      "learning_rate": 0.0001878504065009422,
      "epoch": 1.3327449249779346,
      "step": 7550
    },
    {
      "loss": 1.061,
      "grad_norm": 11.374197006225586,
      "learning_rate": 0.00018722883808554636,
      "epoch": 1.3415710503089144,
      "step": 7600
    },
    {
      "loss": 1.0911,
      "grad_norm": 7.7019219398498535,
      "learning_rate": 0.00018660726967015048,
      "epoch": 1.350397175639894,
      "step": 7650
    },
    {
      "loss": 1.0753,
      "grad_norm": 7.989026069641113,
      "learning_rate": 0.0001859857012547546,
      "epoch": 1.3592233009708738,
      "step": 7700
    },
    {
      "loss": 1.0639,
      "grad_norm": 5.880735874176025,
      "learning_rate": 0.00018536413283935872,
      "epoch": 1.3680494263018534,
      "step": 7750
    },
    {
      "loss": 1.0204,
      "grad_norm": 12.076141357421875,
      "learning_rate": 0.00018474256442396286,
      "epoch": 1.3768755516328333,
      "step": 7800
    },
    {
      "loss": 1.0599,
      "grad_norm": 7.5556488037109375,
      "learning_rate": 0.00018412099600856696,
      "epoch": 1.3857016769638129,
      "step": 7850
    },
    {
      "loss": 1.067,
      "grad_norm": 8.519927978515625,
      "learning_rate": 0.0001834994275931711,
      "epoch": 1.3945278022947925,
      "step": 7900
    },
    {
      "loss": 1.1116,
      "grad_norm": 8.46830940246582,
      "learning_rate": 0.0001828778591777752,
      "epoch": 1.4033539276257723,
      "step": 7950
    },
    {
      "loss": 1.1013,
      "grad_norm": 6.621870994567871,
      "learning_rate": 0.00018225629076237934,
      "epoch": 1.412180052956752,
      "step": 8000
    },
    {
      "loss": 1.0788,
      "grad_norm": 5.318288326263428,
      "learning_rate": 0.00018163472234698346,
      "epoch": 1.4210061782877317,
      "step": 8050
    },
    {
      "loss": 1.0965,
      "grad_norm": 5.082319259643555,
      "learning_rate": 0.00018101315393158758,
      "epoch": 1.4298323036187113,
      "step": 8100
    },
    {
      "loss": 1.0589,
      "grad_norm": 7.286401271820068,
      "learning_rate": 0.0001803915855161917,
      "epoch": 1.438658428949691,
      "step": 8150
    },
    {
      "loss": 1.0884,
      "grad_norm": 9.998330116271973,
      "learning_rate": 0.00017977001710079582,
      "epoch": 1.447484554280671,
      "step": 8200
    },
    {
      "loss": 1.1124,
      "grad_norm": 8.5348482131958,
      "learning_rate": 0.00017914844868539994,
      "epoch": 1.4563106796116505,
      "step": 8250
    },
    {
      "loss": 1.0696,
      "grad_norm": 7.353103160858154,
      "learning_rate": 0.00017852688027000408,
      "epoch": 1.46513680494263,
      "step": 8300
    },
    {
      "loss": 1.0473,
      "grad_norm": 9.847696304321289,
      "learning_rate": 0.00017790531185460818,
      "epoch": 1.47396293027361,
      "step": 8350
    },
    {
      "loss": 1.1013,
      "grad_norm": 7.591369152069092,
      "learning_rate": 0.00017728374343921232,
      "epoch": 1.4827890556045895,
      "step": 8400
    },
    {
      "loss": 1.059,
      "grad_norm": 8.035244941711426,
      "learning_rate": 0.00017666217502381641,
      "epoch": 1.4916151809355693,
      "step": 8450
    },
    {
      "loss": 1.1186,
      "grad_norm": 8.917489051818848,
      "learning_rate": 0.00017604060660842056,
      "epoch": 1.500441306266549,
      "step": 8500
    },
    {
      "loss": 1.0622,
      "grad_norm": 8.596293449401855,
      "learning_rate": 0.00017541903819302468,
      "epoch": 1.5092674315975287,
      "step": 8550
    },
    {
      "loss": 1.0625,
      "grad_norm": 5.728512763977051,
      "learning_rate": 0.0001747974697776288,
      "epoch": 1.5180935569285083,
      "step": 8600
    },
    {
      "loss": 1.1038,
      "grad_norm": 10.463641166687012,
      "learning_rate": 0.00017417590136223292,
      "epoch": 1.526919682259488,
      "step": 8650
    },
    {
      "loss": 1.0914,
      "grad_norm": 6.250115871429443,
      "learning_rate": 0.00017355433294683704,
      "epoch": 1.5357458075904677,
      "step": 8700
    },
    {
      "loss": 1.1526,
      "grad_norm": 6.193512916564941,
      "learning_rate": 0.00017293276453144116,
      "epoch": 1.5445719329214476,
      "step": 8750
    },
    {
      "loss": 1.1108,
      "grad_norm": 9.04201889038086,
      "learning_rate": 0.0001723111961160453,
      "epoch": 1.5533980582524272,
      "step": 8800
    },
    {
      "loss": 1.0424,
      "grad_norm": 8.020503997802734,
      "learning_rate": 0.0001716896277006494,
      "epoch": 1.5622241835834068,
      "step": 8850
    },
    {
      "loss": 1.0634,
      "grad_norm": 8.140830993652344,
      "learning_rate": 0.00017106805928525354,
      "epoch": 1.5710503089143866,
      "step": 8900
    },
    {
      "loss": 1.0809,
      "grad_norm": 9.524280548095703,
      "learning_rate": 0.00017044649086985763,
      "epoch": 1.5798764342453664,
      "step": 8950
    },
    {
      "loss": 1.0255,
      "grad_norm": 7.635785102844238,
      "learning_rate": 0.00016982492245446178,
      "epoch": 1.588702559576346,
      "step": 9000
    },
    {
      "loss": 0.9538,
      "grad_norm": 11.82308578491211,
      "learning_rate": 0.0001692033540390659,
      "epoch": 1.5975286849073256,
      "step": 9050
    },
    {
      "loss": 1.0589,
      "grad_norm": 7.074512481689453,
      "learning_rate": 0.00016858178562367002,
      "epoch": 1.6063548102383054,
      "step": 9100
    },
    {
      "loss": 1.0273,
      "grad_norm": 6.164821147918701,
      "learning_rate": 0.00016796021720827414,
      "epoch": 1.6151809355692852,
      "step": 9150
    },
    {
      "loss": 1.0869,
      "grad_norm": 7.657373428344727,
      "learning_rate": 0.00016733864879287828,
      "epoch": 1.6240070609002648,
      "step": 9200
    },
    {
      "loss": 1.0968,
      "grad_norm": 8.272111892700195,
      "learning_rate": 0.00016671708037748238,
      "epoch": 1.6328331862312444,
      "step": 9250
    },
    {
      "loss": 1.0036,
      "grad_norm": 9.425148010253906,
      "learning_rate": 0.00016609551196208652,
      "epoch": 1.6416593115622242,
      "step": 9300
    },
    {
      "loss": 1.1081,
      "grad_norm": 8.302048683166504,
      "learning_rate": 0.00016547394354669061,
      "epoch": 1.650485436893204,
      "step": 9350
    },
    {
      "loss": 1.0626,
      "grad_norm": 7.224957466125488,
      "learning_rate": 0.00016485237513129476,
      "epoch": 1.6593115622241836,
      "step": 9400
    },
    {
      "loss": 1.1077,
      "grad_norm": 6.282571792602539,
      "learning_rate": 0.00016423080671589888,
      "epoch": 1.6681376875551632,
      "step": 9450
    },
    {
      "loss": 1.0271,
      "grad_norm": 6.106993198394775,
      "learning_rate": 0.000163609238300503,
      "epoch": 1.676963812886143,
      "step": 9500
    },
    {
      "loss": 1.0942,
      "grad_norm": 7.346442699432373,
      "learning_rate": 0.00016298766988510712,
      "epoch": 1.6857899382171226,
      "step": 9550
    },
    {
      "loss": 1.051,
      "grad_norm": 7.3367509841918945,
      "learning_rate": 0.00016236610146971124,
      "epoch": 1.6946160635481022,
      "step": 9600
    },
    {
      "loss": 1.1005,
      "grad_norm": 9.73558521270752,
      "learning_rate": 0.00016174453305431536,
      "epoch": 1.703442188879082,
      "step": 9650
    },
    {
      "loss": 1.0285,
      "grad_norm": 5.912950038909912,
      "learning_rate": 0.0001611229646389195,
      "epoch": 1.7122683142100619,
      "step": 9700
    },
    {
      "loss": 1.1019,
      "grad_norm": 5.84098482131958,
      "learning_rate": 0.0001605013962235236,
      "epoch": 1.7210944395410415,
      "step": 9750
    },
    {
      "loss": 1.161,
      "grad_norm": 9.157594680786133,
      "learning_rate": 0.00015987982780812774,
      "epoch": 1.729920564872021,
      "step": 9800
    },
    {
      "loss": 1.0714,
      "grad_norm": 9.280315399169922,
      "learning_rate": 0.00015925825939273183,
      "epoch": 1.7387466902030009,
      "step": 9850
    },
    {
      "loss": 1.0414,
      "grad_norm": 6.367634296417236,
      "learning_rate": 0.00015863669097733598,
      "epoch": 1.7475728155339807,
      "step": 9900
    },
    {
      "loss": 0.9794,
      "grad_norm": 10.019068717956543,
      "learning_rate": 0.0001580151225619401,
      "epoch": 1.7563989408649603,
      "step": 9950
    },
    {
      "loss": 1.0231,
      "grad_norm": 6.429697513580322,
      "learning_rate": 0.00015739355414654422,
      "epoch": 1.7652250661959399,
      "step": 10000
    },
    {
      "loss": 1.0586,
      "grad_norm": 4.801761150360107,
      "learning_rate": 0.00015677198573114834,
      "epoch": 1.7740511915269197,
      "step": 10050
    },
    {
      "loss": 0.9799,
      "grad_norm": 6.417276382446289,
      "learning_rate": 0.00015615041731575246,
      "epoch": 1.7828773168578995,
      "step": 10100
    },
    {
      "loss": 1.101,
      "grad_norm": 5.551143169403076,
      "learning_rate": 0.00015552884890035658,
      "epoch": 1.7917034421888791,
      "step": 10150
    },
    {
      "loss": 1.0277,
      "grad_norm": 8.415411949157715,
      "learning_rate": 0.00015490728048496072,
      "epoch": 1.8005295675198587,
      "step": 10200
    },
    {
      "loss": 1.0409,
      "grad_norm": 6.2346391677856445,
      "learning_rate": 0.00015428571206956482,
      "epoch": 1.8093556928508385,
      "step": 10250
    },
    {
      "loss": 1.0806,
      "grad_norm": 5.013322353363037,
      "learning_rate": 0.00015366414365416896,
      "epoch": 1.8181818181818183,
      "step": 10300
    },
    {
      "loss": 1.0153,
      "grad_norm": 5.776547431945801,
      "learning_rate": 0.00015304257523877305,
      "epoch": 1.8270079435127977,
      "step": 10350
    },
    {
      "loss": 1.0199,
      "grad_norm": 11.349815368652344,
      "learning_rate": 0.0001524210068233772,
      "epoch": 1.8358340688437775,
      "step": 10400
    },
    {
      "loss": 1.1242,
      "grad_norm": 5.468106269836426,
      "learning_rate": 0.00015179943840798132,
      "epoch": 1.8446601941747574,
      "step": 10450
    },
    {
      "loss": 1.0422,
      "grad_norm": 5.048928260803223,
      "learning_rate": 0.00015117786999258544,
      "epoch": 1.853486319505737,
      "step": 10500
    },
    {
      "loss": 1.0291,
      "grad_norm": 6.012978553771973,
      "learning_rate": 0.00015055630157718956,
      "epoch": 1.8623124448367165,
      "step": 10550
    },
    {
      "loss": 0.9816,
      "grad_norm": 9.033581733703613,
      "learning_rate": 0.0001499347331617937,
      "epoch": 1.8711385701676964,
      "step": 10600
    },
    {
      "loss": 1.003,
      "grad_norm": 5.670246601104736,
      "learning_rate": 0.0001493131647463978,
      "epoch": 1.8799646954986762,
      "step": 10650
    },
    {
      "loss": 1.0118,
      "grad_norm": 7.768233776092529,
      "learning_rate": 0.00014869159633100194,
      "epoch": 1.8887908208296558,
      "step": 10700
    },
    {
      "loss": 1.0085,
      "grad_norm": 7.750670433044434,
      "learning_rate": 0.00014807002791560604,
      "epoch": 1.8976169461606354,
      "step": 10750
    },
    {
      "loss": 1.0739,
      "grad_norm": 5.9006733894348145,
      "learning_rate": 0.00014744845950021018,
      "epoch": 1.9064430714916152,
      "step": 10800
    },
    {
      "loss": 1.0707,
      "grad_norm": 5.8012237548828125,
      "learning_rate": 0.0001468268910848143,
      "epoch": 1.915269196822595,
      "step": 10850
    },
    {
      "loss": 1.0704,
      "grad_norm": 10.240633964538574,
      "learning_rate": 0.00014620532266941842,
      "epoch": 1.9240953221535746,
      "step": 10900
    },
    {
      "loss": 1.024,
      "grad_norm": 6.424793243408203,
      "learning_rate": 0.00014558375425402254,
      "epoch": 1.9329214474845542,
      "step": 10950
    },
    {
      "loss": 1.0374,
      "grad_norm": 6.862234592437744,
      "learning_rate": 0.00014496218583862666,
      "epoch": 1.941747572815534,
      "step": 11000
    },
    {
      "loss": 1.0046,
      "grad_norm": 9.196907997131348,
      "learning_rate": 0.00014434061742323078,
      "epoch": 1.9505736981465138,
      "step": 11050
    },
    {
      "loss": 1.0449,
      "grad_norm": 5.659909725189209,
      "learning_rate": 0.00014371904900783492,
      "epoch": 1.9593998234774934,
      "step": 11100
    },
    {
      "loss": 1.0502,
      "grad_norm": 6.5159196853637695,
      "learning_rate": 0.00014309748059243902,
      "epoch": 1.968225948808473,
      "step": 11150
    },
    {
      "loss": 1.0351,
      "grad_norm": 7.217179775238037,
      "learning_rate": 0.00014247591217704316,
      "epoch": 1.9770520741394528,
      "step": 11200
    },
    {
      "loss": 1.0167,
      "grad_norm": 6.272320747375488,
      "learning_rate": 0.00014185434376164725,
      "epoch": 1.9858781994704324,
      "step": 11250
    },
    {
      "loss": 1.0546,
      "grad_norm": 6.9545440673828125,
      "learning_rate": 0.0001412327753462514,
      "epoch": 1.994704324801412,
      "step": 11300
    },
    {
      "eval_loss": 0.9230817973088794,
      "eval_exact_match": 76.7340275326509,
      "eval_f1": 82.56442468213832,
      "eval_samples": 22720,
      "step": 11330
    },
    {
      "eval_loss": 0.9230817973088794,
      "eval_exact_match": 76.7340275326509,
      "eval_f1": 82.56442468213832,
      "eval_samples": 22720,
      "epoch": 2.0,
      "step": 11330
    },
    {
      "loss": 1.0242,
      "grad_norm": 10.775839805603027,
      "learning_rate": 0.00014061120693085552,
      "epoch": 2.003530450132392,
      "step": 11350
    },
    {
      "loss": 0.7984,
      "grad_norm": 5.477610111236572,
      "learning_rate": 0.00013998963851545964,
      "epoch": 2.0123565754633717,
      "step": 11400
    },
    {
      "loss": 0.8327,
      "grad_norm": 5.194202423095703,
      "learning_rate": 0.00013936807010006376,
      "epoch": 2.0211827007943515,
      "step": 11450
    },
    {
      "loss": 0.8733,
      "grad_norm": 5.557086944580078,
      "learning_rate": 0.00013874650168466788,
      "epoch": 2.030008826125331,
      "step": 11500
    },
    {
      "loss": 0.7983,
      "grad_norm": 8.898210525512695,
      "learning_rate": 0.000138124933269272,
      "epoch": 2.0388349514563107,
      "step": 11550
    },
    {
      "loss": 0.8509,
      "grad_norm": 5.459594249725342,
      "learning_rate": 0.00013750336485387612,
      "epoch": 2.0476610767872905,
      "step": 11600
    },
    {
      "loss": 0.7803,
      "grad_norm": 7.772529602050781,
      "learning_rate": 0.00013688179643848026,
      "epoch": 2.0564872021182703,
      "step": 11650
    },
    {
      "loss": 0.8419,
      "grad_norm": 8.923324584960938,
      "learning_rate": 0.00013626022802308438,
      "epoch": 2.0653133274492497,
      "step": 11700
    },
    {
      "loss": 0.8583,
      "grad_norm": 10.0366792678833,
      "learning_rate": 0.0001356386596076885,
      "epoch": 2.0741394527802295,
      "step": 11750
    },
    {
      "loss": 0.8798,
      "grad_norm": 7.106313705444336,
      "learning_rate": 0.0001350170911922926,
      "epoch": 2.0829655781112093,
      "step": 11800
    },
    {
      "loss": 0.7782,
      "grad_norm": 4.4538350105285645,
      "learning_rate": 0.0001343955227768967,
      "epoch": 2.0917917034421887,
      "step": 11850
    },
    {
      "loss": 0.835,
      "grad_norm": 9.814018249511719,
      "learning_rate": 0.00013377395436150086,
      "epoch": 2.1006178287731685,
      "step": 11900
    },
    {
      "loss": 0.7918,
      "grad_norm": 7.608264446258545,
      "learning_rate": 0.00013315238594610498,
      "epoch": 2.1094439541041483,
      "step": 11950
    },
    {
      "loss": 0.9485,
      "grad_norm": 6.371960163116455,
      "learning_rate": 0.0001325308175307091,
      "epoch": 2.118270079435128,
      "step": 12000
    },
    {
      "loss": 0.9163,
      "grad_norm": 8.390690803527832,
      "learning_rate": 0.00013190924911531322,
      "epoch": 2.1270962047661075,
      "step": 12050
    },
    {
      "loss": 0.8428,
      "grad_norm": 9.193058013916016,
      "learning_rate": 0.00013128768069991736,
      "epoch": 2.1359223300970873,
      "step": 12100
    },
    {
      "loss": 0.8153,
      "grad_norm": 9.314689636230469,
      "learning_rate": 0.00013066611228452148,
      "epoch": 2.144748455428067,
      "step": 12150
    },
    {
      "loss": 0.8284,
      "grad_norm": 9.048276901245117,
      "learning_rate": 0.00013004454386912557,
      "epoch": 2.153574580759047,
      "step": 12200
    },
    {
      "loss": 0.7732,
      "grad_norm": 7.425994396209717,
      "learning_rate": 0.0001294229754537297,
      "epoch": 2.1624007060900263,
      "step": 12250
    },
    {
      "loss": 0.8731,
      "grad_norm": 6.536899566650391,
      "learning_rate": 0.0001288014070383338,
      "epoch": 2.171226831421006,
      "step": 12300
    },
    {
      "loss": 0.9075,
      "grad_norm": 8.173980712890625,
      "learning_rate": 0.00012817983862293796,
      "epoch": 2.180052956751986,
      "step": 12350
    },
    {
      "loss": 0.8347,
      "grad_norm": 9.112236022949219,
      "learning_rate": 0.00012755827020754208,
      "epoch": 2.1888790820829658,
      "step": 12400
    },
    {
      "loss": 0.8424,
      "grad_norm": 6.014855861663818,
      "learning_rate": 0.0001269367017921462,
      "epoch": 2.197705207413945,
      "step": 12450
    },
    {
      "loss": 0.8621,
      "grad_norm": 8.120233535766602,
      "learning_rate": 0.00012631513337675032,
      "epoch": 2.206531332744925,
      "step": 12500
    },
    {
      "loss": 0.8881,
      "grad_norm": 9.425558090209961,
      "learning_rate": 0.00012569356496135444,
      "epoch": 2.215357458075905,
      "step": 12550
    },
    {
      "loss": 0.833,
      "grad_norm": 8.170931816101074,
      "learning_rate": 0.00012507199654595856,
      "epoch": 2.2241835834068846,
      "step": 12600
    },
    {
      "loss": 0.8452,
      "grad_norm": 7.774138927459717,
      "learning_rate": 0.00012445042813056268,
      "epoch": 2.233009708737864,
      "step": 12650
    },
    {
      "loss": 0.8016,
      "grad_norm": 8.587437629699707,
      "learning_rate": 0.0001238288597151668,
      "epoch": 2.241835834068844,
      "step": 12700
    },
    {
      "loss": 0.9094,
      "grad_norm": 7.415671348571777,
      "learning_rate": 0.00012320729129977091,
      "epoch": 2.2506619593998236,
      "step": 12750
    },
    {
      "loss": 0.9073,
      "grad_norm": 6.003215312957764,
      "learning_rate": 0.00012258572288437506,
      "epoch": 2.259488084730803,
      "step": 12800
    },
    {
      "loss": 0.8092,
      "grad_norm": 7.253715515136719,
      "learning_rate": 0.00012196415446897918,
      "epoch": 2.268314210061783,
      "step": 12850
    },
    {
      "loss": 0.8377,
      "grad_norm": 7.3666205406188965,
      "learning_rate": 0.0001213425860535833,
      "epoch": 2.2771403353927626,
      "step": 12900
    },
    {
      "loss": 0.8452,
      "grad_norm": 5.540134906768799,
      "learning_rate": 0.00012072101763818742,
      "epoch": 2.2859664607237424,
      "step": 12950
    },
    {
      "loss": 0.8236,
      "grad_norm": 6.275925636291504,
      "learning_rate": 0.00012009944922279154,
      "epoch": 2.294792586054722,
      "step": 13000
    },
    {
      "loss": 0.8751,
      "grad_norm": 11.947138786315918,
      "learning_rate": 0.00011947788080739567,
      "epoch": 2.3036187113857016,
      "step": 13050
    },
    {
      "loss": 0.8536,
      "grad_norm": 8.587794303894043,
      "learning_rate": 0.00011885631239199979,
      "epoch": 2.3124448367166814,
      "step": 13100
    },
    {
      "loss": 0.8818,
      "grad_norm": 6.945739269256592,
      "learning_rate": 0.00011823474397660391,
      "epoch": 2.3212709620476613,
      "step": 13150
    },
    {
      "loss": 0.9429,
      "grad_norm": 6.475551605224609,
      "learning_rate": 0.00011761317556120803,
      "epoch": 2.3300970873786406,
      "step": 13200
    },
    {
      "loss": 0.8472,
      "grad_norm": 7.430232524871826,
      "learning_rate": 0.00011699160714581215,
      "epoch": 2.3389232127096204,
      "step": 13250
    },
    {
      "loss": 0.8408,
      "grad_norm": 7.366629600524902,
      "learning_rate": 0.00011637003873041628,
      "epoch": 2.3477493380406003,
      "step": 13300
    },
    {
      "loss": 0.8898,
      "grad_norm": 6.414175033569336,
      "learning_rate": 0.0001157484703150204,
      "epoch": 2.3565754633715796,
      "step": 13350
    },
    {
      "loss": 0.8627,
      "grad_norm": 8.718127250671387,
      "learning_rate": 0.00011512690189962452,
      "epoch": 2.3654015887025595,
      "step": 13400
    },
    {
      "loss": 0.9259,
      "grad_norm": 7.007136821746826,
      "learning_rate": 0.00011450533348422864,
      "epoch": 2.3742277140335393,
      "step": 13450
    },
    {
      "loss": 0.8341,
      "grad_norm": 6.233308792114258,
      "learning_rate": 0.00011388376506883277,
      "epoch": 2.383053839364519,
      "step": 13500
    },
    {
      "loss": 0.8838,
      "grad_norm": 16.536865234375,
      "learning_rate": 0.00011326219665343689,
      "epoch": 2.391879964695499,
      "step": 13550
    },
    {
      "loss": 0.9308,
      "grad_norm": 9.698689460754395,
      "learning_rate": 0.00011264062823804101,
      "epoch": 2.4007060900264783,
      "step": 13600
    },
    {
      "loss": 0.8225,
      "grad_norm": 4.315132141113281,
      "learning_rate": 0.00011201905982264513,
      "epoch": 2.409532215357458,
      "step": 13650
    },
    {
      "loss": 0.8429,
      "grad_norm": 7.045336723327637,
      "learning_rate": 0.00011139749140724925,
      "epoch": 2.418358340688438,
      "step": 13700
    },
    {
      "loss": 0.8822,
      "grad_norm": 8.808379173278809,
      "learning_rate": 0.00011077592299185338,
      "epoch": 2.4271844660194173,
      "step": 13750
    },
    {
      "loss": 0.8698,
      "grad_norm": 6.54335355758667,
      "learning_rate": 0.0001101543545764575,
      "epoch": 2.436010591350397,
      "step": 13800
    },
    {
      "loss": 0.8764,
      "grad_norm": 8.166483879089355,
      "learning_rate": 0.00010953278616106162,
      "epoch": 2.444836716681377,
      "step": 13850
    },
    {
      "loss": 0.8151,
      "grad_norm": 8.961556434631348,
      "learning_rate": 0.00010891121774566574,
      "epoch": 2.4536628420123567,
      "step": 13900
    },
    {
      "loss": 0.8456,
      "grad_norm": 6.540038585662842,
      "learning_rate": 0.00010828964933026986,
      "epoch": 2.462488967343336,
      "step": 13950
    },
    {
      "loss": 0.8758,
      "grad_norm": 7.455525875091553,
      "learning_rate": 0.00010766808091487399,
      "epoch": 2.471315092674316,
      "step": 14000
    },
    {
      "loss": 0.8321,
      "grad_norm": 7.690399169921875,
      "learning_rate": 0.00010704651249947811,
      "epoch": 2.4801412180052957,
      "step": 14050
    },
    {
      "loss": 0.883,
      "grad_norm": 7.639386177062988,
      "learning_rate": 0.00010642494408408223,
      "epoch": 2.4889673433362756,
      "step": 14100
    },
    {
      "loss": 0.8372,
      "grad_norm": 8.239116668701172,
      "learning_rate": 0.00010580337566868635,
      "epoch": 2.497793468667255,
      "step": 14150
    },
    {
      "loss": 0.8559,
      "grad_norm": 7.790866851806641,
      "learning_rate": 0.00010518180725329048,
      "epoch": 2.5066195939982348,
      "step": 14200
    },
    {
      "loss": 0.846,
      "grad_norm": 6.720611095428467,
      "learning_rate": 0.0001045602388378946,
      "epoch": 2.5154457193292146,
      "step": 14250
    },
    {
      "loss": 0.8801,
      "grad_norm": 7.3517985343933105,
      "learning_rate": 0.00010393867042249872,
      "epoch": 2.524271844660194,
      "step": 14300
    },
    {
      "loss": 0.8396,
      "grad_norm": 8.258038520812988,
      "learning_rate": 0.00010331710200710284,
      "epoch": 2.5330979699911738,
      "step": 14350
    },
    {
      "loss": 0.8456,
      "grad_norm": 9.758561134338379,
      "learning_rate": 0.00010269553359170696,
      "epoch": 2.5419240953221536,
      "step": 14400
    },
    {
      "loss": 0.8739,
      "grad_norm": 8.569517135620117,
      "learning_rate": 0.00010207396517631109,
      "epoch": 2.5507502206531334,
      "step": 14450
    },
    {
      "loss": 0.814,
      "grad_norm": 7.469639301300049,
      "learning_rate": 0.00010145239676091521,
      "epoch": 2.559576345984113,
      "step": 14500
    },
    {
      "loss": 0.8352,
      "grad_norm": 4.692676544189453,
      "learning_rate": 0.00010083082834551933,
      "epoch": 2.5684024713150926,
      "step": 14550
    },
    {
      "loss": 0.8857,
      "grad_norm": 5.985733985900879,
      "learning_rate": 0.00010020925993012343,
      "epoch": 2.5772285966460724,
      "step": 14600
    },
    {
      "loss": 0.9011,
      "grad_norm": 7.739294528961182,
      "learning_rate": 9.958769151472755e-05,
      "epoch": 2.586054721977052,
      "step": 14650
    },
    {
      "loss": 0.8753,
      "grad_norm": 7.367109775543213,
      "learning_rate": 9.89661230993317e-05,
      "epoch": 2.5948808473080316,
      "step": 14700
    },
    {
      "loss": 0.836,
      "grad_norm": 4.299952030181885,
      "learning_rate": 9.834455468393582e-05,
      "epoch": 2.6037069726390114,
      "step": 14750
    },
    {
      "loss": 0.8915,
      "grad_norm": 6.610008716583252,
      "learning_rate": 9.772298626853992e-05,
      "epoch": 2.6125330979699912,
      "step": 14800
    },
    {
      "loss": 0.8422,
      "grad_norm": 6.56003475189209,
      "learning_rate": 9.710141785314404e-05,
      "epoch": 2.6213592233009706,
      "step": 14850
    },
    {
      "loss": 0.8647,
      "grad_norm": 7.3995747566223145,
      "learning_rate": 9.647984943774819e-05,
      "epoch": 2.6301853486319504,
      "step": 14900
    },
    {
      "loss": 0.8411,
      "grad_norm": 7.126554489135742,
      "learning_rate": 9.58582810223523e-05,
      "epoch": 2.6390114739629302,
      "step": 14950
    },
    {
      "loss": 0.8143,
      "grad_norm": 7.942038059234619,
      "learning_rate": 9.523671260695642e-05,
      "epoch": 2.64783759929391,
      "step": 15000
    },
    {
      "loss": 0.8376,
      "grad_norm": 6.108339786529541,
      "learning_rate": 9.461514419156053e-05,
      "epoch": 2.65666372462489,
      "step": 15050
    },
    {
      "loss": 0.8536,
      "grad_norm": 9.077841758728027,
      "learning_rate": 9.399357577616465e-05,
      "epoch": 2.6654898499558692,
      "step": 15100
    },
    {
      "loss": 0.799,
      "grad_norm": 7.632053852081299,
      "learning_rate": 9.337200736076879e-05,
      "epoch": 2.674315975286849,
      "step": 15150
    },
    {
      "loss": 0.8621,
      "grad_norm": 5.940423488616943,
      "learning_rate": 9.27504389453729e-05,
      "epoch": 2.683142100617829,
      "step": 15200
    },
    {
      "loss": 0.8159,
      "grad_norm": 6.501969814300537,
      "learning_rate": 9.212887052997703e-05,
      "epoch": 2.6919682259488082,
      "step": 15250
    },
    {
      "loss": 0.8514,
      "grad_norm": 9.429015159606934,
      "learning_rate": 9.150730211458114e-05,
      "epoch": 2.700794351279788,
      "step": 15300
    },
    {
      "loss": 0.8251,
      "grad_norm": 6.975646018981934,
      "learning_rate": 9.088573369918526e-05,
      "epoch": 2.709620476610768,
      "step": 15350
    },
    {
      "loss": 0.878,
      "grad_norm": 9.224119186401367,
      "learning_rate": 9.02641652837894e-05,
      "epoch": 2.7184466019417477,
      "step": 15400
    },
    {
      "loss": 0.883,
      "grad_norm": 6.250499725341797,
      "learning_rate": 8.964259686839352e-05,
      "epoch": 2.7272727272727275,
      "step": 15450
    },
    {
      "loss": 0.8217,
      "grad_norm": 10.685720443725586,
      "learning_rate": 8.902102845299764e-05,
      "epoch": 2.736098852603707,
      "step": 15500
    },
    {
      "loss": 0.8227,
      "grad_norm": 7.798045635223389,
      "learning_rate": 8.839946003760175e-05,
      "epoch": 2.7449249779346867,
      "step": 15550
    },
    {
      "loss": 0.832,
      "grad_norm": 5.94196081161499,
      "learning_rate": 8.777789162220589e-05,
      "epoch": 2.7537511032656665,
      "step": 15600
    },
    {
      "loss": 0.8713,
      "grad_norm": 7.640738487243652,
      "learning_rate": 8.715632320681e-05,
      "epoch": 2.762577228596646,
      "step": 15650
    },
    {
      "loss": 0.846,
      "grad_norm": 7.987496852874756,
      "learning_rate": 8.653475479141413e-05,
      "epoch": 2.7714033539276257,
      "step": 15700
    },
    {
      "loss": 0.8328,
      "grad_norm": 6.519802570343018,
      "learning_rate": 8.591318637601824e-05,
      "epoch": 2.7802294792586055,
      "step": 15750
    },
    {
      "loss": 0.8584,
      "grad_norm": 4.536189556121826,
      "learning_rate": 8.529161796062236e-05,
      "epoch": 2.789055604589585,
      "step": 15800
    },
    {
      "loss": 0.9168,
      "grad_norm": 6.811583995819092,
      "learning_rate": 8.46700495452265e-05,
      "epoch": 2.7978817299205647,
      "step": 15850
    },
    {
      "loss": 0.7324,
      "grad_norm": 7.387560844421387,
      "learning_rate": 8.404848112983062e-05,
      "epoch": 2.8067078552515445,
      "step": 15900
    },
    {
      "loss": 0.7962,
      "grad_norm": 5.825690746307373,
      "learning_rate": 8.342691271443474e-05,
      "epoch": 2.8155339805825244,
      "step": 15950
    },
    {
      "loss": 0.865,
      "grad_norm": 9.869906425476074,
      "learning_rate": 8.280534429903885e-05,
      "epoch": 2.824360105913504,
      "step": 16000
    },
    {
      "loss": 0.8279,
      "grad_norm": 6.259353160858154,
      "learning_rate": 8.218377588364297e-05,
      "epoch": 2.8331862312444835,
      "step": 16050
    },
    {
      "loss": 0.8376,
      "grad_norm": 5.927052974700928,
      "learning_rate": 8.156220746824711e-05,
      "epoch": 2.8420123565754634,
      "step": 16100
    },
    {
      "loss": 0.7924,
      "grad_norm": 7.120930194854736,
      "learning_rate": 8.094063905285123e-05,
      "epoch": 2.850838481906443,
      "step": 16150
    },
    {
      "loss": 0.8655,
      "grad_norm": 7.854066371917725,
      "learning_rate": 8.031907063745535e-05,
      "epoch": 2.8596646072374226,
      "step": 16200
    },
    {
      "loss": 0.8217,
      "grad_norm": 7.521939754486084,
      "learning_rate": 7.969750222205946e-05,
      "epoch": 2.8684907325684024,
      "step": 16250
    },
    {
      "loss": 0.8028,
      "grad_norm": 6.195815563201904,
      "learning_rate": 7.90759338066636e-05,
      "epoch": 2.877316857899382,
      "step": 16300
    },
    {
      "loss": 0.9353,
      "grad_norm": 7.017354965209961,
      "learning_rate": 7.845436539126772e-05,
      "epoch": 2.886142983230362,
      "step": 16350
    },
    {
      "loss": 0.8288,
      "grad_norm": 7.226588249206543,
      "learning_rate": 7.783279697587184e-05,
      "epoch": 2.894969108561342,
      "step": 16400
    },
    {
      "loss": 0.8103,
      "grad_norm": 8.590141296386719,
      "learning_rate": 7.721122856047596e-05,
      "epoch": 2.903795233892321,
      "step": 16450
    },
    {
      "loss": 0.8505,
      "grad_norm": 8.923724174499512,
      "learning_rate": 7.658966014508007e-05,
      "epoch": 2.912621359223301,
      "step": 16500
    },
    {
      "loss": 0.7941,
      "grad_norm": 6.910223007202148,
      "learning_rate": 7.596809172968421e-05,
      "epoch": 2.921447484554281,
      "step": 16550
    },
    {
      "loss": 0.8049,
      "grad_norm": 6.641226291656494,
      "learning_rate": 7.534652331428833e-05,
      "epoch": 2.93027360988526,
      "step": 16600
    },
    {
      "loss": 0.7995,
      "grad_norm": 7.7646870613098145,
      "learning_rate": 7.472495489889245e-05,
      "epoch": 2.93909973521624,
      "step": 16650
    },
    {
      "loss": 0.7625,
      "grad_norm": 9.082245826721191,
      "learning_rate": 7.410338648349656e-05,
      "epoch": 2.94792586054722,
      "step": 16700
    },
    {
      "loss": 0.8335,
      "grad_norm": 7.49630880355835,
      "learning_rate": 7.348181806810068e-05,
      "epoch": 2.956751985878199,
      "step": 16750
    },
    {
      "loss": 0.8815,
      "grad_norm": 7.747447967529297,
      "learning_rate": 7.286024965270482e-05,
      "epoch": 2.965578111209179,
      "step": 16800
    },
    {
      "loss": 0.7962,
      "grad_norm": 5.073005199432373,
      "learning_rate": 7.223868123730894e-05,
      "epoch": 2.974404236540159,
      "step": 16850
    },
    {
      "loss": 0.7789,
      "grad_norm": 8.903424263000488,
      "learning_rate": 7.161711282191306e-05,
      "epoch": 2.9832303618711387,
      "step": 16900
    },
    {
      "loss": 0.8586,
      "grad_norm": 5.4643025398254395,
      "learning_rate": 7.099554440651717e-05,
      "epoch": 2.9920564872021185,
      "step": 16950
    },
    {
      "eval_loss": 0.9061394903567688,
      "eval_exact_match": 77.75326509001059,
      "eval_f1": 83.40447033994434,
      "eval_samples": 22720,
      "step": 16995
    },
    {
      "eval_loss": 0.9061394903567688,
      "eval_exact_match": 77.75326509001059,
      "eval_f1": 83.40447033994434,
      "eval_samples": 22720,
      "epoch": 3.0,
      "step": 16995
    },
    {
      "loss": 0.7977,
      "grad_norm": 5.519711494445801,
      "learning_rate": 7.037397599112131e-05,
      "epoch": 3.000882612533098,
      "step": 17000
    },
    {
      "loss": 0.6676,
      "grad_norm": 7.827389717102051,
      "learning_rate": 6.975240757572543e-05,
      "epoch": 3.0097087378640777,
      "step": 17050
    },
    {
      "loss": 0.603,
      "grad_norm": 8.900306701660156,
      "learning_rate": 6.913083916032955e-05,
      "epoch": 3.0185348631950575,
      "step": 17100
    },
    {
      "loss": 0.6679,
      "grad_norm": 9.240979194641113,
      "learning_rate": 6.850927074493367e-05,
      "epoch": 3.027360988526037,
      "step": 17150
    },
    {
      "loss": 0.6293,
      "grad_norm": 5.101949214935303,
      "learning_rate": 6.78877023295378e-05,
      "epoch": 3.0361871138570167,
      "step": 17200
    },
    {
      "loss": 0.6659,
      "grad_norm": 9.562044143676758,
      "learning_rate": 6.726613391414192e-05,
      "epoch": 3.0450132391879965,
      "step": 17250
    },
    {
      "loss": 0.602,
      "grad_norm": 6.813666820526123,
      "learning_rate": 6.664456549874604e-05,
      "epoch": 3.0538393645189763,
      "step": 17300
    },
    {
      "loss": 0.6518,
      "grad_norm": 19.276609420776367,
      "learning_rate": 6.602299708335016e-05,
      "epoch": 3.0626654898499557,
      "step": 17350
    },
    {
      "loss": 0.6675,
      "grad_norm": 8.18226432800293,
      "learning_rate": 6.540142866795429e-05,
      "epoch": 3.0714916151809355,
      "step": 17400
    },
    {
      "loss": 0.6397,
      "grad_norm": 8.327679634094238,
      "learning_rate": 6.477986025255841e-05,
      "epoch": 3.0803177405119153,
      "step": 17450
    },
    {
      "loss": 0.6644,
      "grad_norm": 9.447574615478516,
      "learning_rate": 6.415829183716251e-05,
      "epoch": 3.089143865842895,
      "step": 17500
    },
    {
      "loss": 0.6518,
      "grad_norm": 5.4025187492370605,
      "learning_rate": 6.353672342176665e-05,
      "epoch": 3.0979699911738745,
      "step": 17550
    },
    {
      "loss": 0.6279,
      "grad_norm": 12.159156799316406,
      "learning_rate": 6.291515500637077e-05,
      "epoch": 3.1067961165048543,
      "step": 17600
    },
    {
      "loss": 0.6764,
      "grad_norm": 8.924456596374512,
      "learning_rate": 6.229358659097488e-05,
      "epoch": 3.115622241835834,
      "step": 17650
    },
    {
      "loss": 0.6564,
      "grad_norm": 7.721076488494873,
      "learning_rate": 6.1672018175579e-05,
      "epoch": 3.124448367166814,
      "step": 17700
    },
    {
      "loss": 0.6092,
      "grad_norm": 3.4185590744018555,
      "learning_rate": 6.105044976018314e-05,
      "epoch": 3.1332744924977933,
      "step": 17750
    },
    {
      "loss": 0.6374,
      "grad_norm": 7.279105186462402,
      "learning_rate": 6.0428881344787256e-05,
      "epoch": 3.142100617828773,
      "step": 17800
    },
    {
      "loss": 0.6353,
      "grad_norm": 9.105291366577148,
      "learning_rate": 5.9807312929391376e-05,
      "epoch": 3.150926743159753,
      "step": 17850
    },
    {
      "loss": 0.619,
      "grad_norm": 5.898952484130859,
      "learning_rate": 5.91857445139955e-05,
      "epoch": 3.159752868490733,
      "step": 17900
    },
    {
      "loss": 0.6129,
      "grad_norm": 7.903196334838867,
      "learning_rate": 5.856417609859962e-05,
      "epoch": 3.168578993821712,
      "step": 17950
    },
    {
      "loss": 0.6384,
      "grad_norm": 11.054888725280762,
      "learning_rate": 5.794260768320375e-05,
      "epoch": 3.177405119152692,
      "step": 18000
    },
    {
      "loss": 0.6381,
      "grad_norm": 6.275055408477783,
      "learning_rate": 5.7321039267807866e-05,
      "epoch": 3.186231244483672,
      "step": 18050
    },
    {
      "loss": 0.6681,
      "grad_norm": 6.382673740386963,
      "learning_rate": 5.669947085241199e-05,
      "epoch": 3.195057369814651,
      "step": 18100
    },
    {
      "loss": 0.6499,
      "grad_norm": 7.5814595222473145,
      "learning_rate": 5.607790243701611e-05,
      "epoch": 3.203883495145631,
      "step": 18150
    },
    {
      "loss": 0.667,
      "grad_norm": 6.238790512084961,
      "learning_rate": 5.545633402162023e-05,
      "epoch": 3.212709620476611,
      "step": 18200
    },
    {
      "loss": 0.6313,
      "grad_norm": 8.998161315917969,
      "learning_rate": 5.483476560622436e-05,
      "epoch": 3.2215357458075906,
      "step": 18250
    },
    {
      "loss": 0.6509,
      "grad_norm": 10.132698059082031,
      "learning_rate": 5.4213197190828476e-05,
      "epoch": 3.23036187113857,
      "step": 18300
    },
    {
      "loss": 0.6234,
      "grad_norm": 7.303945064544678,
      "learning_rate": 5.35916287754326e-05,
      "epoch": 3.23918799646955,
      "step": 18350
    },
    {
      "loss": 0.6497,
      "grad_norm": 6.305966377258301,
      "learning_rate": 5.297006036003672e-05,
      "epoch": 3.2480141218005296,
      "step": 18400
    },
    {
      "loss": 0.6347,
      "grad_norm": 6.282613277435303,
      "learning_rate": 5.234849194464085e-05,
      "epoch": 3.2568402471315094,
      "step": 18450
    },
    {
      "loss": 0.649,
      "grad_norm": 8.239541053771973,
      "learning_rate": 5.1726923529244966e-05,
      "epoch": 3.265666372462489,
      "step": 18500
    },
    {
      "loss": 0.6606,
      "grad_norm": 4.11978006362915,
      "learning_rate": 5.1105355113849086e-05,
      "epoch": 3.2744924977934686,
      "step": 18550
    },
    {
      "loss": 0.613,
      "grad_norm": 7.924506187438965,
      "learning_rate": 5.048378669845321e-05,
      "epoch": 3.2833186231244484,
      "step": 18600
    },
    {
      "loss": 0.677,
      "grad_norm": 5.247287750244141,
      "learning_rate": 4.986221828305733e-05,
      "epoch": 3.2921447484554283,
      "step": 18650
    },
    {
      "loss": 0.6669,
      "grad_norm": 8.74836540222168,
      "learning_rate": 4.924064986766146e-05,
      "epoch": 3.3009708737864076,
      "step": 18700
    },
    {
      "loss": 0.687,
      "grad_norm": 5.1114888191223145,
      "learning_rate": 4.8619081452265576e-05,
      "epoch": 3.3097969991173875,
      "step": 18750
    },
    {
      "loss": 0.6067,
      "grad_norm": 6.282088756561279,
      "learning_rate": 4.79975130368697e-05,
      "epoch": 3.3186231244483673,
      "step": 18800
    },
    {
      "loss": 0.6544,
      "grad_norm": 9.002800941467285,
      "learning_rate": 4.737594462147382e-05,
      "epoch": 3.327449249779347,
      "step": 18850
    },
    {
      "loss": 0.6481,
      "grad_norm": 5.5416178703308105,
      "learning_rate": 4.6754376206077934e-05,
      "epoch": 3.3362753751103265,
      "step": 18900
    },
    {
      "loss": 0.6065,
      "grad_norm": 7.41606330871582,
      "learning_rate": 4.613280779068206e-05,
      "epoch": 3.3451015004413063,
      "step": 18950
    },
    {
      "loss": 0.6181,
      "grad_norm": 9.071112632751465,
      "learning_rate": 4.551123937528618e-05,
      "epoch": 3.353927625772286,
      "step": 19000
    },
    {
      "loss": 0.7077,
      "grad_norm": 7.154027462005615,
      "learning_rate": 4.4889670959890305e-05,
      "epoch": 3.3627537511032655,
      "step": 19050
    },
    {
      "loss": 0.6019,
      "grad_norm": 7.006039142608643,
      "learning_rate": 4.4268102544494425e-05,
      "epoch": 3.3715798764342453,
      "step": 19100
    },
    {
      "loss": 0.6458,
      "grad_norm": 10.513084411621094,
      "learning_rate": 4.364653412909855e-05,
      "epoch": 3.380406001765225,
      "step": 19150
    },
    {
      "loss": 0.6347,
      "grad_norm": 9.554496765136719,
      "learning_rate": 4.302496571370267e-05,
      "epoch": 3.389232127096205,
      "step": 19200
    },
    {
      "loss": 0.627,
      "grad_norm": 5.989056587219238,
      "learning_rate": 4.240339729830679e-05,
      "epoch": 3.3980582524271843,
      "step": 19250
    },
    {
      "loss": 0.6708,
      "grad_norm": 7.970277309417725,
      "learning_rate": 4.1781828882910915e-05,
      "epoch": 3.406884377758164,
      "step": 19300
    },
    {
      "loss": 0.6738,
      "grad_norm": 8.798075675964355,
      "learning_rate": 4.1160260467515034e-05,
      "epoch": 3.415710503089144,
      "step": 19350
    },
    {
      "loss": 0.6473,
      "grad_norm": 7.814610481262207,
      "learning_rate": 4.053869205211916e-05,
      "epoch": 3.4245366284201237,
      "step": 19400
    },
    {
      "loss": 0.6895,
      "grad_norm": 8.108319282531738,
      "learning_rate": 3.991712363672328e-05,
      "epoch": 3.433362753751103,
      "step": 19450
    },
    {
      "loss": 0.6482,
      "grad_norm": 8.527336120605469,
      "learning_rate": 3.9295555221327406e-05,
      "epoch": 3.442188879082083,
      "step": 19500
    },
    {
      "loss": 0.6579,
      "grad_norm": 6.987371444702148,
      "learning_rate": 3.8673986805931525e-05,
      "epoch": 3.4510150044130627,
      "step": 19550
    },
    {
      "loss": 0.6346,
      "grad_norm": 4.691695213317871,
      "learning_rate": 3.8052418390535644e-05,
      "epoch": 3.459841129744042,
      "step": 19600
    },
    {
      "loss": 0.649,
      "grad_norm": 6.081472873687744,
      "learning_rate": 3.743084997513977e-05,
      "epoch": 3.468667255075022,
      "step": 19650
    },
    {
      "loss": 0.6008,
      "grad_norm": 6.046916484832764,
      "learning_rate": 3.680928155974389e-05,
      "epoch": 3.4774933804060018,
      "step": 19700
    },
    {
      "loss": 0.6525,
      "grad_norm": 8.460518836975098,
      "learning_rate": 3.6187713144348016e-05,
      "epoch": 3.4863195057369816,
      "step": 19750
    },
    {
      "loss": 0.607,
      "grad_norm": 6.354000568389893,
      "learning_rate": 3.5566144728952135e-05,
      "epoch": 3.4951456310679614,
      "step": 19800
    },
    {
      "loss": 0.6105,
      "grad_norm": 5.602382183074951,
      "learning_rate": 3.494457631355626e-05,
      "epoch": 3.5039717563989408,
      "step": 19850
    },
    {
      "loss": 0.6496,
      "grad_norm": 10.0712890625,
      "learning_rate": 3.432300789816038e-05,
      "epoch": 3.5127978817299206,
      "step": 19900
    },
    {
      "loss": 0.5781,
      "grad_norm": 7.811047554016113,
      "learning_rate": 3.3701439482764506e-05,
      "epoch": 3.5216240070609004,
      "step": 19950
    },
    {
      "loss": 0.6696,
      "grad_norm": 7.502331256866455,
      "learning_rate": 3.3079871067368625e-05,
      "epoch": 3.5304501323918798,
      "step": 20000
    },
    {
      "loss": 0.653,
      "grad_norm": 7.827236175537109,
      "learning_rate": 3.245830265197275e-05,
      "epoch": 3.5392762577228596,
      "step": 20050
    },
    {
      "loss": 0.6348,
      "grad_norm": 9.248882293701172,
      "learning_rate": 3.183673423657687e-05,
      "epoch": 3.5481023830538394,
      "step": 20100
    },
    {
      "loss": 0.6436,
      "grad_norm": 6.613554000854492,
      "learning_rate": 3.121516582118099e-05,
      "epoch": 3.556928508384819,
      "step": 20150
    },
    {
      "loss": 0.6351,
      "grad_norm": 9.514015197753906,
      "learning_rate": 3.0593597405785116e-05,
      "epoch": 3.565754633715799,
      "step": 20200
    },
    {
      "loss": 0.6491,
      "grad_norm": 6.294433116912842,
      "learning_rate": 2.9972028990389235e-05,
      "epoch": 3.5745807590467784,
      "step": 20250
    },
    {
      "loss": 0.6309,
      "grad_norm": 7.79498291015625,
      "learning_rate": 2.9350460574993358e-05,
      "epoch": 3.5834068843777582,
      "step": 20300
    },
    {
      "loss": 0.5967,
      "grad_norm": 5.887730121612549,
      "learning_rate": 2.872889215959748e-05,
      "epoch": 3.592233009708738,
      "step": 20350
    },
    {
      "loss": 0.5564,
      "grad_norm": 7.313828468322754,
      "learning_rate": 2.8107323744201603e-05,
      "epoch": 3.6010591350397174,
      "step": 20400
    },
    {
      "loss": 0.6507,
      "grad_norm": 7.179670333862305,
      "learning_rate": 2.7485755328805722e-05,
      "epoch": 3.6098852603706972,
      "step": 20450
    },
    {
      "loss": 0.6666,
      "grad_norm": 5.726776599884033,
      "learning_rate": 2.6864186913409845e-05,
      "epoch": 3.618711385701677,
      "step": 20500
    },
    {
      "loss": 0.642,
      "grad_norm": 10.478453636169434,
      "learning_rate": 2.6242618498013968e-05,
      "epoch": 3.6275375110326564,
      "step": 20550
    },
    {
      "loss": 0.6748,
      "grad_norm": 6.270308971405029,
      "learning_rate": 2.562105008261809e-05,
      "epoch": 3.6363636363636362,
      "step": 20600
    },
    {
      "loss": 0.5954,
      "grad_norm": 6.894772052764893,
      "learning_rate": 2.4999481667222213e-05,
      "epoch": 3.645189761694616,
      "step": 20650
    },
    {
      "loss": 0.6564,
      "grad_norm": 7.767794132232666,
      "learning_rate": 2.4377913251826336e-05,
      "epoch": 3.654015887025596,
      "step": 20700
    },
    {
      "loss": 0.6234,
      "grad_norm": 9.87767505645752,
      "learning_rate": 2.3756344836430458e-05,
      "epoch": 3.6628420123565757,
      "step": 20750
    },
    {
      "loss": 0.6386,
      "grad_norm": 7.129696846008301,
      "learning_rate": 2.3134776421034577e-05,
      "epoch": 3.671668137687555,
      "step": 20800
    },
    {
      "loss": 0.6182,
      "grad_norm": 5.6042609214782715,
      "learning_rate": 2.25132080056387e-05,
      "epoch": 3.680494263018535,
      "step": 20850
    },
    {
      "loss": 0.6068,
      "grad_norm": 7.238020896911621,
      "learning_rate": 2.189163959024282e-05,
      "epoch": 3.6893203883495147,
      "step": 20900
    },
    {
      "loss": 0.639,
      "grad_norm": 7.867794513702393,
      "learning_rate": 2.1270071174846942e-05,
      "epoch": 3.698146513680494,
      "step": 20950
    },
    {
      "loss": 0.6196,
      "grad_norm": 8.507255554199219,
      "learning_rate": 2.0648502759451065e-05,
      "epoch": 3.706972639011474,
      "step": 21000
    },
    {
      "loss": 0.6428,
      "grad_norm": 7.261495113372803,
      "learning_rate": 2.0026934344055187e-05,
      "epoch": 3.7157987643424537,
      "step": 21050
    },
    {
      "loss": 0.6288,
      "grad_norm": 9.805139541625977,
      "learning_rate": 1.940536592865931e-05,
      "epoch": 3.7246248896734335,
      "step": 21100
    },
    {
      "loss": 0.6952,
      "grad_norm": 5.955319404602051,
      "learning_rate": 1.878379751326343e-05,
      "epoch": 3.733451015004413,
      "step": 21150
    },
    {
      "loss": 0.6539,
      "grad_norm": 6.216365814208984,
      "learning_rate": 1.8162229097867552e-05,
      "epoch": 3.7422771403353927,
      "step": 21200
    },
    {
      "loss": 0.5989,
      "grad_norm": 8.099669456481934,
      "learning_rate": 1.7540660682471674e-05,
      "epoch": 3.7511032656663725,
      "step": 21250
    },
    {
      "loss": 0.6009,
      "grad_norm": 6.327956199645996,
      "learning_rate": 1.6919092267075797e-05,
      "epoch": 3.7599293909973523,
      "step": 21300
    },
    {
      "loss": 0.6142,
      "grad_norm": 9.87912368774414,
      "learning_rate": 1.629752385167992e-05,
      "epoch": 3.7687555163283317,
      "step": 21350
    },
    {
      "loss": 0.6111,
      "grad_norm": 8.37782096862793,
      "learning_rate": 1.5675955436284042e-05,
      "epoch": 3.7775816416593115,
      "step": 21400
    },
    {
      "loss": 0.6441,
      "grad_norm": 8.346784591674805,
      "learning_rate": 1.5054387020888163e-05,
      "epoch": 3.7864077669902914,
      "step": 21450
    },
    {
      "loss": 0.664,
      "grad_norm": 11.991272926330566,
      "learning_rate": 1.4432818605492286e-05,
      "epoch": 3.7952338923212707,
      "step": 21500
    },
    {
      "loss": 0.5872,
      "grad_norm": 7.541512489318848,
      "learning_rate": 1.3811250190096409e-05,
      "epoch": 3.8040600176522505,
      "step": 21550
    },
    {
      "loss": 0.6272,
      "grad_norm": 11.226617813110352,
      "learning_rate": 1.318968177470053e-05,
      "epoch": 3.8128861429832304,
      "step": 21600
    },
    {
      "loss": 0.6225,
      "grad_norm": 8.68942642211914,
      "learning_rate": 1.2568113359304652e-05,
      "epoch": 3.82171226831421,
      "step": 21650
    },
    {
      "loss": 0.5947,
      "grad_norm": 7.008941650390625,
      "learning_rate": 1.1946544943908775e-05,
      "epoch": 3.83053839364519,
      "step": 21700
    },
    {
      "loss": 0.6402,
      "grad_norm": 8.077462196350098,
      "learning_rate": 1.1324976528512897e-05,
      "epoch": 3.8393645189761694,
      "step": 21750
    },
    {
      "loss": 0.6067,
      "grad_norm": 5.831202030181885,
      "learning_rate": 1.0703408113117018e-05,
      "epoch": 3.848190644307149,
      "step": 21800
    },
    {
      "loss": 0.628,
      "grad_norm": 8.718656539916992,
      "learning_rate": 1.0081839697721141e-05,
      "epoch": 3.857016769638129,
      "step": 21850
    },
    {
      "loss": 0.642,
      "grad_norm": 7.3919291496276855,
      "learning_rate": 9.460271282325264e-06,
      "epoch": 3.8658428949691084,
      "step": 21900
    },
    {
      "loss": 0.6424,
      "grad_norm": 6.937540054321289,
      "learning_rate": 8.838702866929383e-06,
      "epoch": 3.874669020300088,
      "step": 21950
    },
    {
      "loss": 0.6159,
      "grad_norm": 5.609546661376953,
      "learning_rate": 8.217134451533506e-06,
      "epoch": 3.883495145631068,
      "step": 22000
    },
    {
      "loss": 0.5952,
      "grad_norm": 5.7982869148254395,
      "learning_rate": 7.595566036137629e-06,
      "epoch": 3.8923212709620474,
      "step": 22050
    },
    {
      "loss": 0.6119,
      "grad_norm": 8.884469985961914,
      "learning_rate": 6.973997620741751e-06,
      "epoch": 3.901147396293027,
      "step": 22100
    },
    {
      "loss": 0.6507,
      "grad_norm": 6.26836633682251,
      "learning_rate": 6.352429205345873e-06,
      "epoch": 3.909973521624007,
      "step": 22150
    },
    {
      "loss": 0.644,
      "grad_norm": 8.09826946258545,
      "learning_rate": 5.7308607899499945e-06,
      "epoch": 3.918799646954987,
      "step": 22200
    },
    {
      "loss": 0.641,
      "grad_norm": 4.9142351150512695,
      "learning_rate": 5.109292374554117e-06,
      "epoch": 3.9276257722859667,
      "step": 22250
    },
    {
      "loss": 0.6029,
      "grad_norm": 7.409400939941406,
      "learning_rate": 4.487723959158239e-06,
      "epoch": 3.936451897616946,
      "step": 22300
    },
    {
      "loss": 0.584,
      "grad_norm": 7.409244060516357,
      "learning_rate": 3.866155543762361e-06,
      "epoch": 3.945278022947926,
      "step": 22350
    },
    {
      "loss": 0.6639,
      "grad_norm": 5.519606590270996,
      "learning_rate": 3.244587128366483e-06,
      "epoch": 3.9541041482789057,
      "step": 22400
    },
    {
      "loss": 0.6345,
      "grad_norm": 6.950862407684326,
      "learning_rate": 2.623018712970605e-06,
      "epoch": 3.962930273609885,
      "step": 22450
    },
    {
      "loss": 0.6255,
      "grad_norm": 9.729214668273926,
      "learning_rate": 2.001450297574727e-06,
      "epoch": 3.971756398940865,
      "step": 22500
    },
    {
      "loss": 0.6267,
      "grad_norm": 4.42899751663208,
      "learning_rate": 1.3798818821788491e-06,
      "epoch": 3.9805825242718447,
      "step": 22550
    },
    {
      "loss": 0.5913,
      "grad_norm": 7.4639973640441895,
      "learning_rate": 7.583134667829711e-07,
      "epoch": 3.9894086496028245,
      "step": 22600
    },
    {
      "loss": 0.6266,
      "grad_norm": 12.757220268249512,
      "learning_rate": 1.3674505138709315e-07,
      "epoch": 3.9982347749338043,
      "step": 22650
    },
    {
      "eval_loss": 0.9539067444114745,
      "eval_exact_match": 78.42834451111895,
      "eval_f1": 83.87074131560983,
      "eval_samples": 22720,
      "step": 22660
    },
    {
      "eval_loss": 0.9539067444114745,
      "eval_exact_match": 78.42834451111895,
      "eval_f1": 83.87074131560983,
      "eval_samples": 22720,
      "epoch": 4.0,
      "step": 22660
    },
    {
      "train_runtime": 28026.5284,
      "train_samples_per_second": 25.872,
      "train_steps_per_second": 0.809,
      "total_flos": 2.1185980023914496e+16,
      "train_loss": 1.0141101594320567,
      "epoch": 4.0,
      "step": 22660
    }
  ]
}
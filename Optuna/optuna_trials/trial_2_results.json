{
  "trial_number": 2,
  "hyperparameters": {
    "learning_rate": 4.352618669836682e-05,
    "per_device_train_batch_size": 32,
    "num_train_epochs": 6,
    "warmup_steps": 40,
    "per_device_eval_batch_size": 64
  },
  "best_f1": 85.3528191581396,
  "all_eval_f1_scores": [
    83.31368012272497,
    83.31368012272497,
    84.50250645148638,
    84.50250645148638,
    85.10937248632536,
    85.10937248632536,
    85.320759576353,
    85.320759576353,
    85.33223656630197,
    85.33223656630197,
    85.3528191581396,
    85.3528191581396
  ],
  "training_logs": [
    {
      "loss": 5.2909,
      "grad_norm": 6.362296104431152,
      "learning_rate": 4.351464809217285e-05,
      "epoch": 0.0088261253309797,
      "step": 50
    },
    {
      "loss": 3.4857,
      "grad_norm": 5.987567901611328,
      "learning_rate": 4.345054472442857e-05,
      "epoch": 0.0176522506619594,
      "step": 100
    },
    {
      "loss": 2.91,
      "grad_norm": 6.413936614990234,
      "learning_rate": 4.338644135668429e-05,
      "epoch": 0.0264783759929391,
      "step": 150
    },
    {
      "loss": 2.6117,
      "grad_norm": 10.972007751464844,
      "learning_rate": 4.332233798894001e-05,
      "epoch": 0.0353045013239188,
      "step": 200
    },
    {
      "loss": 2.4042,
      "grad_norm": 8.439506530761719,
      "learning_rate": 4.325823462119573e-05,
      "epoch": 0.0441306266548985,
      "step": 250
    },
    {
      "loss": 2.2838,
      "grad_norm": 12.99245834350586,
      "learning_rate": 4.319413125345145e-05,
      "epoch": 0.0529567519858782,
      "step": 300
    },
    {
      "loss": 2.1318,
      "grad_norm": 9.193328857421875,
      "learning_rate": 4.3130027885707166e-05,
      "epoch": 0.0617828773168579,
      "step": 350
    },
    {
      "loss": 2.0087,
      "grad_norm": 9.163748741149902,
      "learning_rate": 4.306592451796288e-05,
      "epoch": 0.0706090026478376,
      "step": 400
    },
    {
      "loss": 2.0187,
      "grad_norm": 9.302196502685547,
      "learning_rate": 4.30018211502186e-05,
      "epoch": 0.0794351279788173,
      "step": 450
    },
    {
      "loss": 1.8947,
      "grad_norm": 10.932498931884766,
      "learning_rate": 4.293771778247432e-05,
      "epoch": 0.088261253309797,
      "step": 500
    },
    {
      "loss": 1.8568,
      "grad_norm": 9.551907539367676,
      "learning_rate": 4.287361441473004e-05,
      "epoch": 0.0970873786407767,
      "step": 550
    },
    {
      "loss": 1.7624,
      "grad_norm": 11.869648933410645,
      "learning_rate": 4.280951104698576e-05,
      "epoch": 0.1059135039717564,
      "step": 600
    },
    {
      "loss": 1.7514,
      "grad_norm": 10.435521125793457,
      "learning_rate": 4.274540767924147e-05,
      "epoch": 0.1147396293027361,
      "step": 650
    },
    {
      "loss": 1.6836,
      "grad_norm": 11.60377025604248,
      "learning_rate": 4.268130431149719e-05,
      "epoch": 0.1235657546337158,
      "step": 700
    },
    {
      "loss": 1.6637,
      "grad_norm": 7.835193157196045,
      "learning_rate": 4.261720094375291e-05,
      "epoch": 0.1323918799646955,
      "step": 750
    },
    {
      "loss": 1.6216,
      "grad_norm": 9.61462688446045,
      "learning_rate": 4.255309757600863e-05,
      "epoch": 0.1412180052956752,
      "step": 800
    },
    {
      "loss": 1.6196,
      "grad_norm": 12.044607162475586,
      "learning_rate": 4.248899420826435e-05,
      "epoch": 0.1500441306266549,
      "step": 850
    },
    {
      "loss": 1.5826,
      "grad_norm": 10.660100936889648,
      "learning_rate": 4.242489084052007e-05,
      "epoch": 0.1588702559576346,
      "step": 900
    },
    {
      "loss": 1.5644,
      "grad_norm": 8.371803283691406,
      "learning_rate": 4.236078747277579e-05,
      "epoch": 0.1676963812886143,
      "step": 950
    },
    {
      "loss": 1.57,
      "grad_norm": 10.38375186920166,
      "learning_rate": 4.229668410503151e-05,
      "epoch": 0.176522506619594,
      "step": 1000
    },
    {
      "loss": 1.5498,
      "grad_norm": 7.673215866088867,
      "learning_rate": 4.223258073728723e-05,
      "epoch": 0.1853486319505737,
      "step": 1050
    },
    {
      "loss": 1.5496,
      "grad_norm": 9.71845817565918,
      "learning_rate": 4.216847736954295e-05,
      "epoch": 0.1941747572815534,
      "step": 1100
    },
    {
      "loss": 1.4837,
      "grad_norm": 9.164594650268555,
      "learning_rate": 4.210437400179867e-05,
      "epoch": 0.2030008826125331,
      "step": 1150
    },
    {
      "loss": 1.5244,
      "grad_norm": 7.726940631866455,
      "learning_rate": 4.204027063405438e-05,
      "epoch": 0.2118270079435128,
      "step": 1200
    },
    {
      "loss": 1.4812,
      "grad_norm": 8.974446296691895,
      "learning_rate": 4.19761672663101e-05,
      "epoch": 0.22065313327449249,
      "step": 1250
    },
    {
      "loss": 1.507,
      "grad_norm": 8.861644744873047,
      "learning_rate": 4.191206389856582e-05,
      "epoch": 0.2294792586054722,
      "step": 1300
    },
    {
      "loss": 1.5315,
      "grad_norm": 12.924120903015137,
      "learning_rate": 4.184796053082154e-05,
      "epoch": 0.2383053839364519,
      "step": 1350
    },
    {
      "loss": 1.5302,
      "grad_norm": 7.688392639160156,
      "learning_rate": 4.178385716307726e-05,
      "epoch": 0.2471315092674316,
      "step": 1400
    },
    {
      "loss": 1.5164,
      "grad_norm": 8.574348449707031,
      "learning_rate": 4.1719753795332975e-05,
      "epoch": 0.2559576345984113,
      "step": 1450
    },
    {
      "loss": 1.4997,
      "grad_norm": 9.462411880493164,
      "learning_rate": 4.1655650427588694e-05,
      "epoch": 0.264783759929391,
      "step": 1500
    },
    {
      "loss": 1.4938,
      "grad_norm": 6.400106906890869,
      "learning_rate": 4.1591547059844414e-05,
      "epoch": 0.2736098852603707,
      "step": 1550
    },
    {
      "loss": 1.4778,
      "grad_norm": 11.672879219055176,
      "learning_rate": 4.1527443692100134e-05,
      "epoch": 0.2824360105913504,
      "step": 1600
    },
    {
      "loss": 1.4117,
      "grad_norm": 9.207748413085938,
      "learning_rate": 4.1463340324355854e-05,
      "epoch": 0.2912621359223301,
      "step": 1650
    },
    {
      "loss": 1.4531,
      "grad_norm": 12.298111915588379,
      "learning_rate": 4.1399236956611574e-05,
      "epoch": 0.3000882612533098,
      "step": 1700
    },
    {
      "loss": 1.3561,
      "grad_norm": 10.728325843811035,
      "learning_rate": 4.1335133588867293e-05,
      "epoch": 0.3089143865842895,
      "step": 1750
    },
    {
      "loss": 1.4266,
      "grad_norm": 9.796634674072266,
      "learning_rate": 4.127103022112301e-05,
      "epoch": 0.3177405119152692,
      "step": 1800
    },
    {
      "loss": 1.4128,
      "grad_norm": 9.103387832641602,
      "learning_rate": 4.120692685337873e-05,
      "epoch": 0.3265666372462489,
      "step": 1850
    },
    {
      "loss": 1.3985,
      "grad_norm": 10.55270767211914,
      "learning_rate": 4.114282348563445e-05,
      "epoch": 0.3353927625772286,
      "step": 1900
    },
    {
      "loss": 1.423,
      "grad_norm": 9.737071990966797,
      "learning_rate": 4.1078720117890166e-05,
      "epoch": 0.3442188879082083,
      "step": 1950
    },
    {
      "loss": 1.3209,
      "grad_norm": 10.221602439880371,
      "learning_rate": 4.1014616750145886e-05,
      "epoch": 0.353045013239188,
      "step": 2000
    },
    {
      "loss": 1.431,
      "grad_norm": 12.108111381530762,
      "learning_rate": 4.0950513382401605e-05,
      "epoch": 0.36187113857016767,
      "step": 2050
    },
    {
      "loss": 1.3594,
      "grad_norm": 8.826041221618652,
      "learning_rate": 4.0886410014657325e-05,
      "epoch": 0.3706972639011474,
      "step": 2100
    },
    {
      "loss": 1.365,
      "grad_norm": 8.595191955566406,
      "learning_rate": 4.0822306646913045e-05,
      "epoch": 0.3795233892321271,
      "step": 2150
    },
    {
      "loss": 1.3567,
      "grad_norm": 7.733283519744873,
      "learning_rate": 4.0758203279168765e-05,
      "epoch": 0.3883495145631068,
      "step": 2200
    },
    {
      "loss": 1.3238,
      "grad_norm": 8.746124267578125,
      "learning_rate": 4.0694099911424485e-05,
      "epoch": 0.3971756398940865,
      "step": 2250
    },
    {
      "loss": 1.3485,
      "grad_norm": 8.545846939086914,
      "learning_rate": 4.0629996543680204e-05,
      "epoch": 0.4060017652250662,
      "step": 2300
    },
    {
      "loss": 1.3724,
      "grad_norm": 7.858334064483643,
      "learning_rate": 4.0565893175935924e-05,
      "epoch": 0.4148278905560459,
      "step": 2350
    },
    {
      "loss": 1.3692,
      "grad_norm": 9.902745246887207,
      "learning_rate": 4.0501789808191644e-05,
      "epoch": 0.4236540158870256,
      "step": 2400
    },
    {
      "loss": 1.2978,
      "grad_norm": 9.430157661437988,
      "learning_rate": 4.0437686440447364e-05,
      "epoch": 0.4324801412180053,
      "step": 2450
    },
    {
      "loss": 1.3216,
      "grad_norm": 8.130873680114746,
      "learning_rate": 4.037358307270308e-05,
      "epoch": 0.44130626654898497,
      "step": 2500
    },
    {
      "loss": 1.3013,
      "grad_norm": 9.425052642822266,
      "learning_rate": 4.0309479704958797e-05,
      "epoch": 0.4501323918799647,
      "step": 2550
    },
    {
      "loss": 1.3175,
      "grad_norm": 7.774972915649414,
      "learning_rate": 4.0245376337214516e-05,
      "epoch": 0.4589585172109444,
      "step": 2600
    },
    {
      "loss": 1.2899,
      "grad_norm": 8.9555082321167,
      "learning_rate": 4.0181272969470236e-05,
      "epoch": 0.4677846425419241,
      "step": 2650
    },
    {
      "loss": 1.2483,
      "grad_norm": 11.462456703186035,
      "learning_rate": 4.011716960172595e-05,
      "epoch": 0.4766107678729038,
      "step": 2700
    },
    {
      "loss": 1.3047,
      "grad_norm": 7.947118759155273,
      "learning_rate": 4.005306623398167e-05,
      "epoch": 0.4854368932038835,
      "step": 2750
    },
    {
      "loss": 1.3035,
      "grad_norm": 8.011129379272461,
      "learning_rate": 3.998896286623739e-05,
      "epoch": 0.4942630185348632,
      "step": 2800
    },
    {
      "loss": 1.3161,
      "grad_norm": 12.843958854675293,
      "learning_rate": 3.992485949849311e-05,
      "epoch": 0.5030891438658429,
      "step": 2850
    },
    {
      "loss": 1.2923,
      "grad_norm": 9.050745010375977,
      "learning_rate": 3.986075613074883e-05,
      "epoch": 0.5119152691968226,
      "step": 2900
    },
    {
      "loss": 1.2293,
      "grad_norm": 7.436609268188477,
      "learning_rate": 3.979665276300455e-05,
      "epoch": 0.5207413945278023,
      "step": 2950
    },
    {
      "loss": 1.3595,
      "grad_norm": 7.012319087982178,
      "learning_rate": 3.973254939526027e-05,
      "epoch": 0.529567519858782,
      "step": 3000
    },
    {
      "loss": 1.3228,
      "grad_norm": 8.315056800842285,
      "learning_rate": 3.966844602751599e-05,
      "epoch": 0.5383936451897617,
      "step": 3050
    },
    {
      "loss": 1.1924,
      "grad_norm": 9.063392639160156,
      "learning_rate": 3.960434265977171e-05,
      "epoch": 0.5472197705207414,
      "step": 3100
    },
    {
      "loss": 1.2819,
      "grad_norm": 9.644421577453613,
      "learning_rate": 3.954023929202743e-05,
      "epoch": 0.556045895851721,
      "step": 3150
    },
    {
      "loss": 1.2788,
      "grad_norm": 9.04163646697998,
      "learning_rate": 3.947613592428315e-05,
      "epoch": 0.5648720211827007,
      "step": 3200
    },
    {
      "loss": 1.2355,
      "grad_norm": 7.978917598724365,
      "learning_rate": 3.941203255653886e-05,
      "epoch": 0.5736981465136805,
      "step": 3250
    },
    {
      "loss": 1.286,
      "grad_norm": 8.276432037353516,
      "learning_rate": 3.934792918879458e-05,
      "epoch": 0.5825242718446602,
      "step": 3300
    },
    {
      "loss": 1.2744,
      "grad_norm": 8.17701244354248,
      "learning_rate": 3.92838258210503e-05,
      "epoch": 0.5913503971756399,
      "step": 3350
    },
    {
      "loss": 1.2079,
      "grad_norm": 9.061064720153809,
      "learning_rate": 3.921972245330602e-05,
      "epoch": 0.6001765225066196,
      "step": 3400
    },
    {
      "loss": 1.2746,
      "grad_norm": 7.041611671447754,
      "learning_rate": 3.915561908556174e-05,
      "epoch": 0.6090026478375993,
      "step": 3450
    },
    {
      "loss": 1.2897,
      "grad_norm": 9.800015449523926,
      "learning_rate": 3.909151571781746e-05,
      "epoch": 0.617828773168579,
      "step": 3500
    },
    {
      "loss": 1.1889,
      "grad_norm": 7.5719895362854,
      "learning_rate": 3.902741235007317e-05,
      "epoch": 0.6266548984995587,
      "step": 3550
    },
    {
      "loss": 1.2819,
      "grad_norm": 8.122187614440918,
      "learning_rate": 3.896330898232889e-05,
      "epoch": 0.6354810238305384,
      "step": 3600
    },
    {
      "loss": 1.1783,
      "grad_norm": 8.519959449768066,
      "learning_rate": 3.889920561458461e-05,
      "epoch": 0.6443071491615181,
      "step": 3650
    },
    {
      "loss": 1.2594,
      "grad_norm": 6.747169017791748,
      "learning_rate": 3.883510224684033e-05,
      "epoch": 0.6531332744924978,
      "step": 3700
    },
    {
      "loss": 1.1838,
      "grad_norm": 7.327986240386963,
      "learning_rate": 3.877099887909605e-05,
      "epoch": 0.6619593998234775,
      "step": 3750
    },
    {
      "loss": 1.2101,
      "grad_norm": 22.26561737060547,
      "learning_rate": 3.870689551135177e-05,
      "epoch": 0.6707855251544572,
      "step": 3800
    },
    {
      "loss": 1.1617,
      "grad_norm": 6.409900188446045,
      "learning_rate": 3.864279214360749e-05,
      "epoch": 0.6796116504854369,
      "step": 3850
    },
    {
      "loss": 1.2464,
      "grad_norm": 8.988412857055664,
      "learning_rate": 3.857868877586321e-05,
      "epoch": 0.6884377758164166,
      "step": 3900
    },
    {
      "loss": 1.2397,
      "grad_norm": 8.083924293518066,
      "learning_rate": 3.851458540811893e-05,
      "epoch": 0.6972639011473963,
      "step": 3950
    },
    {
      "loss": 1.2738,
      "grad_norm": 8.376997947692871,
      "learning_rate": 3.845048204037464e-05,
      "epoch": 0.706090026478376,
      "step": 4000
    },
    {
      "loss": 1.1401,
      "grad_norm": 8.826237678527832,
      "learning_rate": 3.838637867263036e-05,
      "epoch": 0.7149161518093556,
      "step": 4050
    },
    {
      "loss": 1.2762,
      "grad_norm": 9.997306823730469,
      "learning_rate": 3.832227530488608e-05,
      "epoch": 0.7237422771403353,
      "step": 4100
    },
    {
      "loss": 1.1911,
      "grad_norm": 7.457097053527832,
      "learning_rate": 3.82581719371418e-05,
      "epoch": 0.732568402471315,
      "step": 4150
    },
    {
      "loss": 1.1521,
      "grad_norm": 8.229065895080566,
      "learning_rate": 3.819406856939752e-05,
      "epoch": 0.7413945278022948,
      "step": 4200
    },
    {
      "loss": 1.1688,
      "grad_norm": 10.279549598693848,
      "learning_rate": 3.812996520165324e-05,
      "epoch": 0.7502206531332745,
      "step": 4250
    },
    {
      "loss": 1.2202,
      "grad_norm": 8.570114135742188,
      "learning_rate": 3.806586183390896e-05,
      "epoch": 0.7590467784642542,
      "step": 4300
    },
    {
      "loss": 1.2181,
      "grad_norm": 8.210062026977539,
      "learning_rate": 3.800175846616468e-05,
      "epoch": 0.7678729037952339,
      "step": 4350
    },
    {
      "loss": 1.2053,
      "grad_norm": 9.978492736816406,
      "learning_rate": 3.79376550984204e-05,
      "epoch": 0.7766990291262136,
      "step": 4400
    },
    {
      "loss": 1.2238,
      "grad_norm": 7.347683906555176,
      "learning_rate": 3.787355173067612e-05,
      "epoch": 0.7855251544571933,
      "step": 4450
    },
    {
      "loss": 1.1298,
      "grad_norm": 8.586689949035645,
      "learning_rate": 3.780944836293184e-05,
      "epoch": 0.794351279788173,
      "step": 4500
    },
    {
      "loss": 1.2195,
      "grad_norm": 9.170548439025879,
      "learning_rate": 3.7745344995187554e-05,
      "epoch": 0.8031774051191527,
      "step": 4550
    },
    {
      "loss": 1.2388,
      "grad_norm": 9.635210037231445,
      "learning_rate": 3.7681241627443274e-05,
      "epoch": 0.8120035304501324,
      "step": 4600
    },
    {
      "loss": 1.1261,
      "grad_norm": 9.162776947021484,
      "learning_rate": 3.7617138259698994e-05,
      "epoch": 0.8208296557811121,
      "step": 4650
    },
    {
      "loss": 1.2153,
      "grad_norm": 7.194104194641113,
      "learning_rate": 3.7553034891954714e-05,
      "epoch": 0.8296557811120918,
      "step": 4700
    },
    {
      "loss": 1.2213,
      "grad_norm": 8.07409381866455,
      "learning_rate": 3.7488931524210427e-05,
      "epoch": 0.8384819064430715,
      "step": 4750
    },
    {
      "loss": 1.1319,
      "grad_norm": 9.250334739685059,
      "learning_rate": 3.7424828156466146e-05,
      "epoch": 0.8473080317740512,
      "step": 4800
    },
    {
      "loss": 1.1913,
      "grad_norm": 9.240548133850098,
      "learning_rate": 3.7360724788721866e-05,
      "epoch": 0.8561341571050309,
      "step": 4850
    },
    {
      "loss": 1.1532,
      "grad_norm": 7.565762519836426,
      "learning_rate": 3.7296621420977586e-05,
      "epoch": 0.8649602824360106,
      "step": 4900
    },
    {
      "loss": 1.1556,
      "grad_norm": 10.215211868286133,
      "learning_rate": 3.7232518053233306e-05,
      "epoch": 0.8737864077669902,
      "step": 4950
    },
    {
      "loss": 1.1243,
      "grad_norm": 11.449259757995605,
      "learning_rate": 3.7168414685489026e-05,
      "epoch": 0.8826125330979699,
      "step": 5000
    },
    {
      "loss": 1.0778,
      "grad_norm": 13.261942863464355,
      "learning_rate": 3.7104311317744745e-05,
      "epoch": 0.8914386584289496,
      "step": 5050
    },
    {
      "loss": 1.1729,
      "grad_norm": 9.478865623474121,
      "learning_rate": 3.7040207950000465e-05,
      "epoch": 0.9002647837599294,
      "step": 5100
    },
    {
      "loss": 1.1433,
      "grad_norm": 7.977890491485596,
      "learning_rate": 3.6976104582256185e-05,
      "epoch": 0.9090909090909091,
      "step": 5150
    },
    {
      "loss": 1.0628,
      "grad_norm": 8.690689086914062,
      "learning_rate": 3.6912001214511905e-05,
      "epoch": 0.9179170344218888,
      "step": 5200
    },
    {
      "loss": 1.1153,
      "grad_norm": 8.208168029785156,
      "learning_rate": 3.6847897846767625e-05,
      "epoch": 0.9267431597528685,
      "step": 5250
    },
    {
      "loss": 1.0602,
      "grad_norm": 8.107687950134277,
      "learning_rate": 3.678379447902334e-05,
      "epoch": 0.9355692850838482,
      "step": 5300
    },
    {
      "loss": 1.0404,
      "grad_norm": 6.972935199737549,
      "learning_rate": 3.671969111127906e-05,
      "epoch": 0.9443954104148279,
      "step": 5350
    },
    {
      "loss": 1.0575,
      "grad_norm": 8.86992073059082,
      "learning_rate": 3.665558774353478e-05,
      "epoch": 0.9532215357458076,
      "step": 5400
    },
    {
      "loss": 1.0707,
      "grad_norm": 7.726958751678467,
      "learning_rate": 3.65914843757905e-05,
      "epoch": 0.9620476610767873,
      "step": 5450
    },
    {
      "loss": 1.0785,
      "grad_norm": 8.34543228149414,
      "learning_rate": 3.652738100804622e-05,
      "epoch": 0.970873786407767,
      "step": 5500
    },
    {
      "loss": 1.0902,
      "grad_norm": 9.234066009521484,
      "learning_rate": 3.6463277640301936e-05,
      "epoch": 0.9796999117387467,
      "step": 5550
    },
    {
      "loss": 1.079,
      "grad_norm": 8.345229148864746,
      "learning_rate": 3.6399174272557656e-05,
      "epoch": 0.9885260370697264,
      "step": 5600
    },
    {
      "loss": 0.9939,
      "grad_norm": 8.468073844909668,
      "learning_rate": 3.6335070904813376e-05,
      "epoch": 0.9973521624007061,
      "step": 5650
    },
    {
      "eval_loss": 0.8681686625172365,
      "eval_exact_match": 78.08418637486763,
      "eval_f1": 83.31368012272497,
      "eval_samples": 22720,
      "step": 5665
    },
    {
      "eval_loss": 0.8681686625172365,
      "eval_exact_match": 78.08418637486763,
      "eval_f1": 83.31368012272497,
      "eval_samples": 22720,
      "epoch": 1.0,
      "step": 5665
    },
    {
      "loss": 0.9801,
      "grad_norm": 12.7169189453125,
      "learning_rate": 3.627096753706909e-05,
      "epoch": 1.0061782877316858,
      "step": 5700
    },
    {
      "loss": 1.0151,
      "grad_norm": 11.42490005493164,
      "learning_rate": 3.620686416932481e-05,
      "epoch": 1.0150044130626654,
      "step": 5750
    },
    {
      "loss": 0.9144,
      "grad_norm": 11.93662166595459,
      "learning_rate": 3.614276080158053e-05,
      "epoch": 1.0238305383936452,
      "step": 5800
    },
    {
      "loss": 0.9689,
      "grad_norm": 10.7666654586792,
      "learning_rate": 3.607865743383625e-05,
      "epoch": 1.0326566637246248,
      "step": 5850
    },
    {
      "loss": 0.9732,
      "grad_norm": 8.36527156829834,
      "learning_rate": 3.601455406609197e-05,
      "epoch": 1.0414827890556047,
      "step": 5900
    },
    {
      "loss": 0.9414,
      "grad_norm": 9.927774429321289,
      "learning_rate": 3.595045069834769e-05,
      "epoch": 1.0503089143865842,
      "step": 5950
    },
    {
      "loss": 0.9119,
      "grad_norm": 10.624006271362305,
      "learning_rate": 3.588634733060341e-05,
      "epoch": 1.059135039717564,
      "step": 6000
    },
    {
      "loss": 0.9251,
      "grad_norm": 12.259233474731445,
      "learning_rate": 3.582224396285912e-05,
      "epoch": 1.0679611650485437,
      "step": 6050
    },
    {
      "loss": 0.9382,
      "grad_norm": 10.616215705871582,
      "learning_rate": 3.575814059511484e-05,
      "epoch": 1.0767872903795235,
      "step": 6100
    },
    {
      "loss": 0.9585,
      "grad_norm": 8.153969764709473,
      "learning_rate": 3.569403722737056e-05,
      "epoch": 1.085613415710503,
      "step": 6150
    },
    {
      "loss": 0.9892,
      "grad_norm": 9.690794944763184,
      "learning_rate": 3.562993385962628e-05,
      "epoch": 1.0944395410414829,
      "step": 6200
    },
    {
      "loss": 1.0121,
      "grad_norm": 11.277714729309082,
      "learning_rate": 3.5565830491882e-05,
      "epoch": 1.1032656663724625,
      "step": 6250
    },
    {
      "loss": 0.9402,
      "grad_norm": 8.597515106201172,
      "learning_rate": 3.550172712413772e-05,
      "epoch": 1.1120917917034423,
      "step": 6300
    },
    {
      "loss": 0.9995,
      "grad_norm": 7.258155822753906,
      "learning_rate": 3.543762375639344e-05,
      "epoch": 1.120917917034422,
      "step": 6350
    },
    {
      "loss": 0.9937,
      "grad_norm": 9.128819465637207,
      "learning_rate": 3.537352038864916e-05,
      "epoch": 1.1297440423654015,
      "step": 6400
    },
    {
      "loss": 0.9456,
      "grad_norm": 13.251728057861328,
      "learning_rate": 3.530941702090488e-05,
      "epoch": 1.1385701676963813,
      "step": 6450
    },
    {
      "loss": 0.9492,
      "grad_norm": 11.19885540008545,
      "learning_rate": 3.52453136531606e-05,
      "epoch": 1.147396293027361,
      "step": 6500
    },
    {
      "loss": 0.9584,
      "grad_norm": 8.109066009521484,
      "learning_rate": 3.518121028541632e-05,
      "epoch": 1.1562224183583407,
      "step": 6550
    },
    {
      "loss": 0.9848,
      "grad_norm": 9.540047645568848,
      "learning_rate": 3.511710691767203e-05,
      "epoch": 1.1650485436893203,
      "step": 6600
    },
    {
      "loss": 0.9836,
      "grad_norm": 9.975323677062988,
      "learning_rate": 3.505300354992775e-05,
      "epoch": 1.1738746690203001,
      "step": 6650
    },
    {
      "loss": 0.9682,
      "grad_norm": 9.082137107849121,
      "learning_rate": 3.498890018218347e-05,
      "epoch": 1.1827007943512797,
      "step": 6700
    },
    {
      "loss": 0.9715,
      "grad_norm": 6.998427391052246,
      "learning_rate": 3.492479681443919e-05,
      "epoch": 1.1915269196822595,
      "step": 6750
    },
    {
      "loss": 0.8824,
      "grad_norm": 7.002401351928711,
      "learning_rate": 3.4860693446694904e-05,
      "epoch": 1.2003530450132391,
      "step": 6800
    },
    {
      "loss": 0.9727,
      "grad_norm": 14.878588676452637,
      "learning_rate": 3.4796590078950624e-05,
      "epoch": 1.209179170344219,
      "step": 6850
    },
    {
      "loss": 0.999,
      "grad_norm": 11.318312644958496,
      "learning_rate": 3.4732486711206344e-05,
      "epoch": 1.2180052956751986,
      "step": 6900
    },
    {
      "loss": 0.9292,
      "grad_norm": 10.770858764648438,
      "learning_rate": 3.4668383343462063e-05,
      "epoch": 1.2268314210061784,
      "step": 6950
    },
    {
      "loss": 0.925,
      "grad_norm": 9.143333435058594,
      "learning_rate": 3.460427997571778e-05,
      "epoch": 1.235657546337158,
      "step": 7000
    },
    {
      "loss": 0.9242,
      "grad_norm": 8.92878532409668,
      "learning_rate": 3.45401766079735e-05,
      "epoch": 1.2444836716681378,
      "step": 7050
    },
    {
      "loss": 1.0046,
      "grad_norm": 7.329770088195801,
      "learning_rate": 3.447607324022922e-05,
      "epoch": 1.2533097969991174,
      "step": 7100
    },
    {
      "loss": 0.9712,
      "grad_norm": 9.463786125183105,
      "learning_rate": 3.441196987248494e-05,
      "epoch": 1.262135922330097,
      "step": 7150
    },
    {
      "loss": 0.8843,
      "grad_norm": 10.481189727783203,
      "learning_rate": 3.434786650474066e-05,
      "epoch": 1.2709620476610768,
      "step": 7200
    },
    {
      "loss": 0.9462,
      "grad_norm": 8.135371208190918,
      "learning_rate": 3.428376313699638e-05,
      "epoch": 1.2797881729920566,
      "step": 7250
    },
    {
      "loss": 1.0233,
      "grad_norm": 5.751575946807861,
      "learning_rate": 3.42196597692521e-05,
      "epoch": 1.2886142983230362,
      "step": 7300
    },
    {
      "loss": 0.915,
      "grad_norm": 9.445685386657715,
      "learning_rate": 3.4155556401507815e-05,
      "epoch": 1.2974404236540158,
      "step": 7350
    },
    {
      "loss": 0.9781,
      "grad_norm": 6.737827301025391,
      "learning_rate": 3.4091453033763535e-05,
      "epoch": 1.3062665489849956,
      "step": 7400
    },
    {
      "loss": 0.9337,
      "grad_norm": 6.680018901824951,
      "learning_rate": 3.4027349666019255e-05,
      "epoch": 1.3150926743159752,
      "step": 7450
    },
    {
      "loss": 0.9638,
      "grad_norm": 8.34383487701416,
      "learning_rate": 3.3963246298274974e-05,
      "epoch": 1.323918799646955,
      "step": 7500
    },
    {
      "loss": 0.9163,
      "grad_norm": 10.58243465423584,
      "learning_rate": 3.3899142930530694e-05,
      "epoch": 1.3327449249779346,
      "step": 7550
    },
    {
      "loss": 0.9011,
      "grad_norm": 8.300098419189453,
      "learning_rate": 3.3835039562786414e-05,
      "epoch": 1.3415710503089144,
      "step": 7600
    },
    {
      "loss": 0.9554,
      "grad_norm": 12.388028144836426,
      "learning_rate": 3.3770936195042134e-05,
      "epoch": 1.350397175639894,
      "step": 7650
    },
    {
      "loss": 0.9318,
      "grad_norm": 10.9182767868042,
      "learning_rate": 3.3706832827297854e-05,
      "epoch": 1.3592233009708738,
      "step": 7700
    },
    {
      "loss": 0.9408,
      "grad_norm": 8.748025894165039,
      "learning_rate": 3.364272945955357e-05,
      "epoch": 1.3680494263018534,
      "step": 7750
    },
    {
      "loss": 0.8917,
      "grad_norm": 8.56874942779541,
      "learning_rate": 3.3578626091809286e-05,
      "epoch": 1.3768755516328333,
      "step": 7800
    },
    {
      "loss": 0.9687,
      "grad_norm": 10.41118049621582,
      "learning_rate": 3.3514522724065006e-05,
      "epoch": 1.3857016769638129,
      "step": 7850
    },
    {
      "loss": 0.9364,
      "grad_norm": 7.949821472167969,
      "learning_rate": 3.3450419356320726e-05,
      "epoch": 1.3945278022947925,
      "step": 7900
    },
    {
      "loss": 0.9891,
      "grad_norm": 8.233199119567871,
      "learning_rate": 3.3386315988576446e-05,
      "epoch": 1.4033539276257723,
      "step": 7950
    },
    {
      "loss": 0.9667,
      "grad_norm": 8.565099716186523,
      "learning_rate": 3.3322212620832165e-05,
      "epoch": 1.412180052956752,
      "step": 8000
    },
    {
      "loss": 0.9443,
      "grad_norm": 7.929345607757568,
      "learning_rate": 3.3258109253087885e-05,
      "epoch": 1.4210061782877317,
      "step": 8050
    },
    {
      "loss": 0.9706,
      "grad_norm": 11.504149436950684,
      "learning_rate": 3.31940058853436e-05,
      "epoch": 1.4298323036187113,
      "step": 8100
    },
    {
      "loss": 0.9481,
      "grad_norm": 9.165224075317383,
      "learning_rate": 3.312990251759932e-05,
      "epoch": 1.438658428949691,
      "step": 8150
    },
    {
      "loss": 0.9391,
      "grad_norm": 11.745450973510742,
      "learning_rate": 3.306579914985504e-05,
      "epoch": 1.447484554280671,
      "step": 8200
    },
    {
      "loss": 0.9967,
      "grad_norm": 12.617849349975586,
      "learning_rate": 3.300169578211076e-05,
      "epoch": 1.4563106796116505,
      "step": 8250
    },
    {
      "loss": 0.9587,
      "grad_norm": 9.215476036071777,
      "learning_rate": 3.293759241436648e-05,
      "epoch": 1.46513680494263,
      "step": 8300
    },
    {
      "loss": 0.9205,
      "grad_norm": 14.102267265319824,
      "learning_rate": 3.28734890466222e-05,
      "epoch": 1.47396293027361,
      "step": 8350
    },
    {
      "loss": 0.9786,
      "grad_norm": 13.410865783691406,
      "learning_rate": 3.280938567887792e-05,
      "epoch": 1.4827890556045895,
      "step": 8400
    },
    {
      "loss": 0.9421,
      "grad_norm": 12.183485984802246,
      "learning_rate": 3.274528231113364e-05,
      "epoch": 1.4916151809355693,
      "step": 8450
    },
    {
      "loss": 0.9918,
      "grad_norm": 11.063284873962402,
      "learning_rate": 3.268117894338936e-05,
      "epoch": 1.500441306266549,
      "step": 8500
    },
    {
      "loss": 0.9286,
      "grad_norm": 8.674165725708008,
      "learning_rate": 3.2617075575645076e-05,
      "epoch": 1.5092674315975287,
      "step": 8550
    },
    {
      "loss": 0.9766,
      "grad_norm": 6.81576681137085,
      "learning_rate": 3.2552972207900796e-05,
      "epoch": 1.5180935569285083,
      "step": 8600
    },
    {
      "loss": 0.9808,
      "grad_norm": 9.125890731811523,
      "learning_rate": 3.248886884015651e-05,
      "epoch": 1.526919682259488,
      "step": 8650
    },
    {
      "loss": 0.9758,
      "grad_norm": 8.321240425109863,
      "learning_rate": 3.242476547241223e-05,
      "epoch": 1.5357458075904677,
      "step": 8700
    },
    {
      "loss": 0.9758,
      "grad_norm": 7.475276947021484,
      "learning_rate": 3.236066210466795e-05,
      "epoch": 1.5445719329214476,
      "step": 8750
    },
    {
      "loss": 0.9711,
      "grad_norm": 10.089385986328125,
      "learning_rate": 3.229655873692367e-05,
      "epoch": 1.5533980582524272,
      "step": 8800
    },
    {
      "loss": 0.9339,
      "grad_norm": 10.578923225402832,
      "learning_rate": 3.223245536917938e-05,
      "epoch": 1.5622241835834068,
      "step": 8850
    },
    {
      "loss": 0.9354,
      "grad_norm": 7.910135746002197,
      "learning_rate": 3.21683520014351e-05,
      "epoch": 1.5710503089143866,
      "step": 8900
    },
    {
      "loss": 0.9575,
      "grad_norm": 10.648882865905762,
      "learning_rate": 3.210424863369082e-05,
      "epoch": 1.5798764342453664,
      "step": 8950
    },
    {
      "loss": 0.922,
      "grad_norm": 8.759440422058105,
      "learning_rate": 3.204014526594654e-05,
      "epoch": 1.588702559576346,
      "step": 9000
    },
    {
      "loss": 0.873,
      "grad_norm": 8.455114364624023,
      "learning_rate": 3.197604189820226e-05,
      "epoch": 1.5975286849073256,
      "step": 9050
    },
    {
      "loss": 0.912,
      "grad_norm": 9.544926643371582,
      "learning_rate": 3.191193853045798e-05,
      "epoch": 1.6063548102383054,
      "step": 9100
    },
    {
      "loss": 0.9011,
      "grad_norm": 7.277437686920166,
      "learning_rate": 3.18478351627137e-05,
      "epoch": 1.6151809355692852,
      "step": 9150
    },
    {
      "loss": 0.9379,
      "grad_norm": 9.072114944458008,
      "learning_rate": 3.178373179496942e-05,
      "epoch": 1.6240070609002648,
      "step": 9200
    },
    {
      "loss": 0.9684,
      "grad_norm": 7.499343395233154,
      "learning_rate": 3.171962842722514e-05,
      "epoch": 1.6328331862312444,
      "step": 9250
    },
    {
      "loss": 0.8809,
      "grad_norm": 10.587018966674805,
      "learning_rate": 3.165552505948086e-05,
      "epoch": 1.6416593115622242,
      "step": 9300
    },
    {
      "loss": 0.9759,
      "grad_norm": 10.031527519226074,
      "learning_rate": 3.159142169173658e-05,
      "epoch": 1.650485436893204,
      "step": 9350
    },
    {
      "loss": 0.9303,
      "grad_norm": 13.450616836547852,
      "learning_rate": 3.152731832399229e-05,
      "epoch": 1.6593115622241836,
      "step": 9400
    },
    {
      "loss": 1.0022,
      "grad_norm": 7.512403964996338,
      "learning_rate": 3.146321495624801e-05,
      "epoch": 1.6681376875551632,
      "step": 9450
    },
    {
      "loss": 0.8903,
      "grad_norm": 7.0693888664245605,
      "learning_rate": 3.139911158850373e-05,
      "epoch": 1.676963812886143,
      "step": 9500
    },
    {
      "loss": 0.967,
      "grad_norm": 6.245750427246094,
      "learning_rate": 3.133500822075945e-05,
      "epoch": 1.6857899382171226,
      "step": 9550
    },
    {
      "loss": 0.914,
      "grad_norm": 6.988870620727539,
      "learning_rate": 3.127090485301517e-05,
      "epoch": 1.6946160635481022,
      "step": 9600
    },
    {
      "loss": 0.9585,
      "grad_norm": 9.56134033203125,
      "learning_rate": 3.120680148527089e-05,
      "epoch": 1.703442188879082,
      "step": 9650
    },
    {
      "loss": 0.9199,
      "grad_norm": 8.892352104187012,
      "learning_rate": 3.114269811752661e-05,
      "epoch": 1.7122683142100619,
      "step": 9700
    },
    {
      "loss": 0.98,
      "grad_norm": 6.833015441894531,
      "learning_rate": 3.107859474978233e-05,
      "epoch": 1.7210944395410415,
      "step": 9750
    },
    {
      "loss": 1.0379,
      "grad_norm": 8.402481079101562,
      "learning_rate": 3.101449138203805e-05,
      "epoch": 1.729920564872021,
      "step": 9800
    },
    {
      "loss": 0.9626,
      "grad_norm": 8.510778427124023,
      "learning_rate": 3.095038801429377e-05,
      "epoch": 1.7387466902030009,
      "step": 9850
    },
    {
      "loss": 0.9578,
      "grad_norm": 10.387343406677246,
      "learning_rate": 3.088628464654949e-05,
      "epoch": 1.7475728155339807,
      "step": 9900
    },
    {
      "loss": 0.8931,
      "grad_norm": 11.677456855773926,
      "learning_rate": 3.0822181278805203e-05,
      "epoch": 1.7563989408649603,
      "step": 9950
    },
    {
      "loss": 0.9111,
      "grad_norm": 7.014607906341553,
      "learning_rate": 3.075807791106092e-05,
      "epoch": 1.7652250661959399,
      "step": 10000
    },
    {
      "loss": 0.9506,
      "grad_norm": 7.677653789520264,
      "learning_rate": 3.069397454331664e-05,
      "epoch": 1.7740511915269197,
      "step": 10050
    },
    {
      "loss": 0.8601,
      "grad_norm": 8.74587345123291,
      "learning_rate": 3.062987117557236e-05,
      "epoch": 1.7828773168578995,
      "step": 10100
    },
    {
      "loss": 0.9645,
      "grad_norm": 6.479196071624756,
      "learning_rate": 3.0565767807828076e-05,
      "epoch": 1.7917034421888791,
      "step": 10150
    },
    {
      "loss": 0.927,
      "grad_norm": 11.9170503616333,
      "learning_rate": 3.05016644400838e-05,
      "epoch": 1.8005295675198587,
      "step": 10200
    },
    {
      "loss": 0.9242,
      "grad_norm": 7.611870765686035,
      "learning_rate": 3.043756107233952e-05,
      "epoch": 1.8093556928508385,
      "step": 10250
    },
    {
      "loss": 0.9673,
      "grad_norm": 5.660294055938721,
      "learning_rate": 3.0373457704595235e-05,
      "epoch": 1.8181818181818183,
      "step": 10300
    },
    {
      "loss": 0.9181,
      "grad_norm": 7.266419410705566,
      "learning_rate": 3.0309354336850955e-05,
      "epoch": 1.8270079435127977,
      "step": 10350
    },
    {
      "loss": 0.9142,
      "grad_norm": 9.954853057861328,
      "learning_rate": 3.0245250969106675e-05,
      "epoch": 1.8358340688437775,
      "step": 10400
    },
    {
      "loss": 0.9983,
      "grad_norm": 7.367123126983643,
      "learning_rate": 3.0181147601362395e-05,
      "epoch": 1.8446601941747574,
      "step": 10450
    },
    {
      "loss": 0.9405,
      "grad_norm": 16.8397216796875,
      "learning_rate": 3.0117044233618114e-05,
      "epoch": 1.853486319505737,
      "step": 10500
    },
    {
      "loss": 0.9056,
      "grad_norm": 15.009339332580566,
      "learning_rate": 3.0052940865873834e-05,
      "epoch": 1.8623124448367165,
      "step": 10550
    },
    {
      "loss": 0.8779,
      "grad_norm": 6.640561580657959,
      "learning_rate": 2.998883749812955e-05,
      "epoch": 1.8711385701676964,
      "step": 10600
    },
    {
      "loss": 0.9086,
      "grad_norm": 6.998659610748291,
      "learning_rate": 2.992473413038527e-05,
      "epoch": 1.8799646954986762,
      "step": 10650
    },
    {
      "loss": 0.9196,
      "grad_norm": 7.981821537017822,
      "learning_rate": 2.986063076264099e-05,
      "epoch": 1.8887908208296558,
      "step": 10700
    },
    {
      "loss": 0.8911,
      "grad_norm": 7.786427021026611,
      "learning_rate": 2.979652739489671e-05,
      "epoch": 1.8976169461606354,
      "step": 10750
    },
    {
      "loss": 0.9857,
      "grad_norm": 20.790775299072266,
      "learning_rate": 2.973242402715243e-05,
      "epoch": 1.9064430714916152,
      "step": 10800
    },
    {
      "loss": 0.9412,
      "grad_norm": 10.27903938293457,
      "learning_rate": 2.9668320659408146e-05,
      "epoch": 1.915269196822595,
      "step": 10850
    },
    {
      "loss": 0.9566,
      "grad_norm": 10.35544490814209,
      "learning_rate": 2.9604217291663866e-05,
      "epoch": 1.9240953221535746,
      "step": 10900
    },
    {
      "loss": 0.9132,
      "grad_norm": 10.68510913848877,
      "learning_rate": 2.9540113923919586e-05,
      "epoch": 1.9329214474845542,
      "step": 10950
    },
    {
      "loss": 0.982,
      "grad_norm": 8.9281005859375,
      "learning_rate": 2.9476010556175302e-05,
      "epoch": 1.941747572815534,
      "step": 11000
    },
    {
      "loss": 0.9285,
      "grad_norm": 10.671899795532227,
      "learning_rate": 2.941190718843102e-05,
      "epoch": 1.9505736981465138,
      "step": 11050
    },
    {
      "loss": 0.9487,
      "grad_norm": 9.93637752532959,
      "learning_rate": 2.9347803820686738e-05,
      "epoch": 1.9593998234774934,
      "step": 11100
    },
    {
      "loss": 0.9204,
      "grad_norm": 7.882655620574951,
      "learning_rate": 2.9283700452942458e-05,
      "epoch": 1.968225948808473,
      "step": 11150
    },
    {
      "loss": 0.9258,
      "grad_norm": 8.64917278289795,
      "learning_rate": 2.9219597085198178e-05,
      "epoch": 1.9770520741394528,
      "step": 11200
    },
    {
      "loss": 0.9424,
      "grad_norm": 10.104042053222656,
      "learning_rate": 2.9155493717453898e-05,
      "epoch": 1.9858781994704324,
      "step": 11250
    },
    {
      "loss": 0.9555,
      "grad_norm": 8.776640892028809,
      "learning_rate": 2.9091390349709614e-05,
      "epoch": 1.994704324801412,
      "step": 11300
    },
    {
      "eval_loss": 0.8146497811881847,
      "eval_exact_match": 79.35933639251677,
      "eval_f1": 84.50250645148638,
      "eval_samples": 22720,
      "step": 11330
    },
    {
      "eval_loss": 0.8146497811881847,
      "eval_exact_match": 79.35933639251677,
      "eval_f1": 84.50250645148638,
      "eval_samples": 22720,
      "epoch": 2.0,
      "step": 11330
    },
    {
      "loss": 0.9514,
      "grad_norm": 8.614767074584961,
      "learning_rate": 2.9027286981965334e-05,
      "epoch": 2.003530450132392,
      "step": 11350
    },
    {
      "loss": 0.7889,
      "grad_norm": 6.420618057250977,
      "learning_rate": 2.8963183614221054e-05,
      "epoch": 2.0123565754633717,
      "step": 11400
    },
    {
      "loss": 0.8251,
      "grad_norm": 6.7083234786987305,
      "learning_rate": 2.8899080246476773e-05,
      "epoch": 2.0211827007943515,
      "step": 11450
    },
    {
      "loss": 0.8457,
      "grad_norm": 7.185153484344482,
      "learning_rate": 2.8834976878732493e-05,
      "epoch": 2.030008826125331,
      "step": 11500
    },
    {
      "loss": 0.766,
      "grad_norm": 8.545641899108887,
      "learning_rate": 2.8770873510988213e-05,
      "epoch": 2.0388349514563107,
      "step": 11550
    },
    {
      "loss": 0.8124,
      "grad_norm": 7.493302345275879,
      "learning_rate": 2.870677014324393e-05,
      "epoch": 2.0476610767872905,
      "step": 11600
    },
    {
      "loss": 0.7412,
      "grad_norm": 10.670631408691406,
      "learning_rate": 2.864266677549965e-05,
      "epoch": 2.0564872021182703,
      "step": 11650
    },
    {
      "loss": 0.8064,
      "grad_norm": 11.402158737182617,
      "learning_rate": 2.857856340775537e-05,
      "epoch": 2.0653133274492497,
      "step": 11700
    },
    {
      "loss": 0.8127,
      "grad_norm": 9.413491249084473,
      "learning_rate": 2.851446004001109e-05,
      "epoch": 2.0741394527802295,
      "step": 11750
    },
    {
      "loss": 0.8555,
      "grad_norm": 9.72669792175293,
      "learning_rate": 2.845035667226681e-05,
      "epoch": 2.0829655781112093,
      "step": 11800
    },
    {
      "loss": 0.77,
      "grad_norm": 10.501432418823242,
      "learning_rate": 2.8386253304522528e-05,
      "epoch": 2.0917917034421887,
      "step": 11850
    },
    {
      "loss": 0.7996,
      "grad_norm": 10.37234115600586,
      "learning_rate": 2.8322149936778245e-05,
      "epoch": 2.1006178287731685,
      "step": 11900
    },
    {
      "loss": 0.7798,
      "grad_norm": 12.136983871459961,
      "learning_rate": 2.8258046569033964e-05,
      "epoch": 2.1094439541041483,
      "step": 11950
    },
    {
      "loss": 0.8704,
      "grad_norm": 8.687420845031738,
      "learning_rate": 2.8193943201289684e-05,
      "epoch": 2.118270079435128,
      "step": 12000
    },
    {
      "loss": 0.8685,
      "grad_norm": 8.016881942749023,
      "learning_rate": 2.8129839833545397e-05,
      "epoch": 2.1270962047661075,
      "step": 12050
    },
    {
      "loss": 0.789,
      "grad_norm": 9.228126525878906,
      "learning_rate": 2.8065736465801117e-05,
      "epoch": 2.1359223300970873,
      "step": 12100
    },
    {
      "loss": 0.7936,
      "grad_norm": 9.216368675231934,
      "learning_rate": 2.8001633098056837e-05,
      "epoch": 2.144748455428067,
      "step": 12150
    },
    {
      "loss": 0.8063,
      "grad_norm": 9.965180397033691,
      "learning_rate": 2.7937529730312557e-05,
      "epoch": 2.153574580759047,
      "step": 12200
    },
    {
      "loss": 0.7442,
      "grad_norm": 11.915022850036621,
      "learning_rate": 2.7873426362568276e-05,
      "epoch": 2.1624007060900263,
      "step": 12250
    },
    {
      "loss": 0.8025,
      "grad_norm": 9.909904479980469,
      "learning_rate": 2.7809322994823996e-05,
      "epoch": 2.171226831421006,
      "step": 12300
    },
    {
      "loss": 0.8686,
      "grad_norm": 11.417901039123535,
      "learning_rate": 2.7745219627079713e-05,
      "epoch": 2.180052956751986,
      "step": 12350
    },
    {
      "loss": 0.8211,
      "grad_norm": 12.773555755615234,
      "learning_rate": 2.7681116259335432e-05,
      "epoch": 2.1888790820829658,
      "step": 12400
    },
    {
      "loss": 0.8208,
      "grad_norm": 9.08776569366455,
      "learning_rate": 2.7617012891591152e-05,
      "epoch": 2.197705207413945,
      "step": 12450
    },
    {
      "loss": 0.8072,
      "grad_norm": 9.195549011230469,
      "learning_rate": 2.7552909523846872e-05,
      "epoch": 2.206531332744925,
      "step": 12500
    },
    {
      "loss": 0.8138,
      "grad_norm": 10.85183334350586,
      "learning_rate": 2.7488806156102592e-05,
      "epoch": 2.215357458075905,
      "step": 12550
    },
    {
      "loss": 0.7717,
      "grad_norm": 9.831299781799316,
      "learning_rate": 2.742470278835831e-05,
      "epoch": 2.2241835834068846,
      "step": 12600
    },
    {
      "loss": 0.8271,
      "grad_norm": 10.034131050109863,
      "learning_rate": 2.7360599420614028e-05,
      "epoch": 2.233009708737864,
      "step": 12650
    },
    {
      "loss": 0.7811,
      "grad_norm": 10.871519088745117,
      "learning_rate": 2.7296496052869748e-05,
      "epoch": 2.241835834068844,
      "step": 12700
    },
    {
      "loss": 0.8782,
      "grad_norm": 8.040666580200195,
      "learning_rate": 2.7232392685125468e-05,
      "epoch": 2.2506619593998236,
      "step": 12750
    },
    {
      "loss": 0.8812,
      "grad_norm": 7.552033424377441,
      "learning_rate": 2.7168289317381187e-05,
      "epoch": 2.259488084730803,
      "step": 12800
    },
    {
      "loss": 0.7993,
      "grad_norm": 9.248165130615234,
      "learning_rate": 2.7104185949636907e-05,
      "epoch": 2.268314210061783,
      "step": 12850
    },
    {
      "loss": 0.7898,
      "grad_norm": 10.8870210647583,
      "learning_rate": 2.7040082581892624e-05,
      "epoch": 2.2771403353927626,
      "step": 12900
    },
    {
      "loss": 0.8109,
      "grad_norm": 8.164989471435547,
      "learning_rate": 2.6975979214148343e-05,
      "epoch": 2.2859664607237424,
      "step": 12950
    },
    {
      "loss": 0.7784,
      "grad_norm": 9.09850788116455,
      "learning_rate": 2.6911875846404063e-05,
      "epoch": 2.294792586054722,
      "step": 13000
    },
    {
      "loss": 0.8387,
      "grad_norm": 14.98360538482666,
      "learning_rate": 2.6847772478659783e-05,
      "epoch": 2.3036187113857016,
      "step": 13050
    },
    {
      "loss": 0.8142,
      "grad_norm": 16.13229751586914,
      "learning_rate": 2.6783669110915496e-05,
      "epoch": 2.3124448367166814,
      "step": 13100
    },
    {
      "loss": 0.8283,
      "grad_norm": 10.804264068603516,
      "learning_rate": 2.6719565743171216e-05,
      "epoch": 2.3212709620476613,
      "step": 13150
    },
    {
      "loss": 0.8889,
      "grad_norm": 9.076895713806152,
      "learning_rate": 2.6655462375426936e-05,
      "epoch": 2.3300970873786406,
      "step": 13200
    },
    {
      "loss": 0.8159,
      "grad_norm": 10.993535041809082,
      "learning_rate": 2.6591359007682655e-05,
      "epoch": 2.3389232127096204,
      "step": 13250
    },
    {
      "loss": 0.8182,
      "grad_norm": 8.566084861755371,
      "learning_rate": 2.6527255639938375e-05,
      "epoch": 2.3477493380406003,
      "step": 13300
    },
    {
      "loss": 0.8625,
      "grad_norm": 9.228364944458008,
      "learning_rate": 2.646315227219409e-05,
      "epoch": 2.3565754633715796,
      "step": 13350
    },
    {
      "loss": 0.8182,
      "grad_norm": 11.572361946105957,
      "learning_rate": 2.639904890444981e-05,
      "epoch": 2.3654015887025595,
      "step": 13400
    },
    {
      "loss": 0.8603,
      "grad_norm": 9.651941299438477,
      "learning_rate": 2.633494553670553e-05,
      "epoch": 2.3742277140335393,
      "step": 13450
    },
    {
      "loss": 0.8252,
      "grad_norm": 10.250252723693848,
      "learning_rate": 2.627084216896125e-05,
      "epoch": 2.383053839364519,
      "step": 13500
    },
    {
      "loss": 0.8892,
      "grad_norm": 9.49056339263916,
      "learning_rate": 2.620673880121697e-05,
      "epoch": 2.391879964695499,
      "step": 13550
    },
    {
      "loss": 0.851,
      "grad_norm": 10.175487518310547,
      "learning_rate": 2.614263543347269e-05,
      "epoch": 2.4007060900264783,
      "step": 13600
    },
    {
      "loss": 0.7894,
      "grad_norm": 6.69562292098999,
      "learning_rate": 2.6078532065728407e-05,
      "epoch": 2.409532215357458,
      "step": 13650
    },
    {
      "loss": 0.8178,
      "grad_norm": 9.000487327575684,
      "learning_rate": 2.6014428697984127e-05,
      "epoch": 2.418358340688438,
      "step": 13700
    },
    {
      "loss": 0.8259,
      "grad_norm": 11.389532089233398,
      "learning_rate": 2.5950325330239846e-05,
      "epoch": 2.4271844660194173,
      "step": 13750
    },
    {
      "loss": 0.8209,
      "grad_norm": 5.897740840911865,
      "learning_rate": 2.5886221962495566e-05,
      "epoch": 2.436010591350397,
      "step": 13800
    },
    {
      "loss": 0.8534,
      "grad_norm": 9.485291481018066,
      "learning_rate": 2.5822118594751286e-05,
      "epoch": 2.444836716681377,
      "step": 13850
    },
    {
      "loss": 0.7756,
      "grad_norm": 12.91889476776123,
      "learning_rate": 2.5758015227007006e-05,
      "epoch": 2.4536628420123567,
      "step": 13900
    },
    {
      "loss": 0.794,
      "grad_norm": 7.795487403869629,
      "learning_rate": 2.5693911859262722e-05,
      "epoch": 2.462488967343336,
      "step": 13950
    },
    {
      "loss": 0.8336,
      "grad_norm": 8.20224380493164,
      "learning_rate": 2.5629808491518442e-05,
      "epoch": 2.471315092674316,
      "step": 14000
    },
    {
      "loss": 0.7953,
      "grad_norm": 9.709888458251953,
      "learning_rate": 2.5565705123774162e-05,
      "epoch": 2.4801412180052957,
      "step": 14050
    },
    {
      "loss": 0.8366,
      "grad_norm": 10.916078567504883,
      "learning_rate": 2.550160175602988e-05,
      "epoch": 2.4889673433362756,
      "step": 14100
    },
    {
      "loss": 0.8174,
      "grad_norm": 11.191149711608887,
      "learning_rate": 2.54374983882856e-05,
      "epoch": 2.497793468667255,
      "step": 14150
    },
    {
      "loss": 0.8223,
      "grad_norm": 10.08021068572998,
      "learning_rate": 2.5373395020541314e-05,
      "epoch": 2.5066195939982348,
      "step": 14200
    },
    {
      "loss": 0.8279,
      "grad_norm": 11.37723159790039,
      "learning_rate": 2.5309291652797034e-05,
      "epoch": 2.5154457193292146,
      "step": 14250
    },
    {
      "loss": 0.8552,
      "grad_norm": 9.322110176086426,
      "learning_rate": 2.5245188285052754e-05,
      "epoch": 2.524271844660194,
      "step": 14300
    },
    {
      "loss": 0.7837,
      "grad_norm": 8.273896217346191,
      "learning_rate": 2.5181084917308474e-05,
      "epoch": 2.5330979699911738,
      "step": 14350
    },
    {
      "loss": 0.8118,
      "grad_norm": 13.766669273376465,
      "learning_rate": 2.511698154956419e-05,
      "epoch": 2.5419240953221536,
      "step": 14400
    },
    {
      "loss": 0.8333,
      "grad_norm": 10.522360801696777,
      "learning_rate": 2.505287818181991e-05,
      "epoch": 2.5507502206531334,
      "step": 14450
    },
    {
      "loss": 0.7951,
      "grad_norm": 8.375765800476074,
      "learning_rate": 2.498877481407563e-05,
      "epoch": 2.559576345984113,
      "step": 14500
    },
    {
      "loss": 0.7883,
      "grad_norm": 5.760937213897705,
      "learning_rate": 2.492467144633135e-05,
      "epoch": 2.5684024713150926,
      "step": 14550
    },
    {
      "loss": 0.8666,
      "grad_norm": 9.848971366882324,
      "learning_rate": 2.486056807858707e-05,
      "epoch": 2.5772285966460724,
      "step": 14600
    },
    {
      "loss": 0.8632,
      "grad_norm": 8.282008171081543,
      "learning_rate": 2.479646471084279e-05,
      "epoch": 2.586054721977052,
      "step": 14650
    },
    {
      "loss": 0.8593,
      "grad_norm": 13.822320938110352,
      "learning_rate": 2.4732361343098505e-05,
      "epoch": 2.5948808473080316,
      "step": 14700
    },
    {
      "loss": 0.8104,
      "grad_norm": 9.854291915893555,
      "learning_rate": 2.4668257975354225e-05,
      "epoch": 2.6037069726390114,
      "step": 14750
    },
    {
      "loss": 0.8456,
      "grad_norm": 9.053326606750488,
      "learning_rate": 2.4604154607609945e-05,
      "epoch": 2.6125330979699912,
      "step": 14800
    },
    {
      "loss": 0.7854,
      "grad_norm": 4.498661041259766,
      "learning_rate": 2.4540051239865665e-05,
      "epoch": 2.6213592233009706,
      "step": 14850
    },
    {
      "loss": 0.8508,
      "grad_norm": 11.594408988952637,
      "learning_rate": 2.4475947872121385e-05,
      "epoch": 2.6301853486319504,
      "step": 14900
    },
    {
      "loss": 0.801,
      "grad_norm": 9.271868705749512,
      "learning_rate": 2.44118445043771e-05,
      "epoch": 2.6390114739629302,
      "step": 14950
    },
    {
      "loss": 0.8075,
      "grad_norm": 7.691229820251465,
      "learning_rate": 2.434774113663282e-05,
      "epoch": 2.64783759929391,
      "step": 15000
    },
    {
      "loss": 0.8164,
      "grad_norm": 7.90020751953125,
      "learning_rate": 2.428363776888854e-05,
      "epoch": 2.65666372462489,
      "step": 15050
    },
    {
      "loss": 0.8066,
      "grad_norm": 11.090386390686035,
      "learning_rate": 2.421953440114426e-05,
      "epoch": 2.6654898499558692,
      "step": 15100
    },
    {
      "loss": 0.7748,
      "grad_norm": 11.0160551071167,
      "learning_rate": 2.415543103339998e-05,
      "epoch": 2.674315975286849,
      "step": 15150
    },
    {
      "loss": 0.8173,
      "grad_norm": 10.875399589538574,
      "learning_rate": 2.40913276656557e-05,
      "epoch": 2.683142100617829,
      "step": 15200
    },
    {
      "loss": 0.8303,
      "grad_norm": 10.289151191711426,
      "learning_rate": 2.4027224297911413e-05,
      "epoch": 2.6919682259488082,
      "step": 15250
    },
    {
      "loss": 0.8075,
      "grad_norm": 15.067001342773438,
      "learning_rate": 2.3963120930167133e-05,
      "epoch": 2.700794351279788,
      "step": 15300
    },
    {
      "loss": 0.8173,
      "grad_norm": 9.002785682678223,
      "learning_rate": 2.3899017562422853e-05,
      "epoch": 2.709620476610768,
      "step": 15350
    },
    {
      "loss": 0.8458,
      "grad_norm": 9.296377182006836,
      "learning_rate": 2.383491419467857e-05,
      "epoch": 2.7184466019417477,
      "step": 15400
    },
    {
      "loss": 0.879,
      "grad_norm": 7.581871032714844,
      "learning_rate": 2.377081082693429e-05,
      "epoch": 2.7272727272727275,
      "step": 15450
    },
    {
      "loss": 0.8121,
      "grad_norm": 10.132076263427734,
      "learning_rate": 2.370670745919001e-05,
      "epoch": 2.736098852603707,
      "step": 15500
    },
    {
      "loss": 0.8376,
      "grad_norm": 10.040284156799316,
      "learning_rate": 2.364260409144573e-05,
      "epoch": 2.7449249779346867,
      "step": 15550
    },
    {
      "loss": 0.7764,
      "grad_norm": 7.604587078094482,
      "learning_rate": 2.3578500723701448e-05,
      "epoch": 2.7537511032656665,
      "step": 15600
    },
    {
      "loss": 0.8463,
      "grad_norm": 11.703646659851074,
      "learning_rate": 2.3514397355957168e-05,
      "epoch": 2.762577228596646,
      "step": 15650
    },
    {
      "loss": 0.8271,
      "grad_norm": 9.887145042419434,
      "learning_rate": 2.3450293988212884e-05,
      "epoch": 2.7714033539276257,
      "step": 15700
    },
    {
      "loss": 0.8255,
      "grad_norm": 9.89859390258789,
      "learning_rate": 2.3386190620468604e-05,
      "epoch": 2.7802294792586055,
      "step": 15750
    },
    {
      "loss": 0.8305,
      "grad_norm": 8.196589469909668,
      "learning_rate": 2.3322087252724324e-05,
      "epoch": 2.789055604589585,
      "step": 15800
    },
    {
      "loss": 0.8917,
      "grad_norm": 8.193035125732422,
      "learning_rate": 2.3257983884980044e-05,
      "epoch": 2.7978817299205647,
      "step": 15850
    },
    {
      "loss": 0.7356,
      "grad_norm": 9.053667068481445,
      "learning_rate": 2.3193880517235763e-05,
      "epoch": 2.8067078552515445,
      "step": 15900
    },
    {
      "loss": 0.7781,
      "grad_norm": 10.916492462158203,
      "learning_rate": 2.3129777149491483e-05,
      "epoch": 2.8155339805825244,
      "step": 15950
    },
    {
      "loss": 0.8417,
      "grad_norm": 11.802359580993652,
      "learning_rate": 2.30656737817472e-05,
      "epoch": 2.824360105913504,
      "step": 16000
    },
    {
      "loss": 0.7687,
      "grad_norm": 9.217109680175781,
      "learning_rate": 2.300157041400292e-05,
      "epoch": 2.8331862312444835,
      "step": 16050
    },
    {
      "loss": 0.7793,
      "grad_norm": 10.522432327270508,
      "learning_rate": 2.293746704625864e-05,
      "epoch": 2.8420123565754634,
      "step": 16100
    },
    {
      "loss": 0.7703,
      "grad_norm": 7.8290581703186035,
      "learning_rate": 2.287336367851436e-05,
      "epoch": 2.850838481906443,
      "step": 16150
    },
    {
      "loss": 0.8669,
      "grad_norm": 13.558819770812988,
      "learning_rate": 2.280926031077008e-05,
      "epoch": 2.8596646072374226,
      "step": 16200
    },
    {
      "loss": 0.778,
      "grad_norm": 11.826288223266602,
      "learning_rate": 2.27451569430258e-05,
      "epoch": 2.8684907325684024,
      "step": 16250
    },
    {
      "loss": 0.798,
      "grad_norm": 4.976966857910156,
      "learning_rate": 2.268105357528151e-05,
      "epoch": 2.877316857899382,
      "step": 16300
    },
    {
      "loss": 0.8962,
      "grad_norm": 8.438821792602539,
      "learning_rate": 2.261695020753723e-05,
      "epoch": 2.886142983230362,
      "step": 16350
    },
    {
      "loss": 0.819,
      "grad_norm": 9.85647201538086,
      "learning_rate": 2.255284683979295e-05,
      "epoch": 2.894969108561342,
      "step": 16400
    },
    {
      "loss": 0.7639,
      "grad_norm": 13.257092475891113,
      "learning_rate": 2.2488743472048668e-05,
      "epoch": 2.903795233892321,
      "step": 16450
    },
    {
      "loss": 0.8009,
      "grad_norm": 8.94777774810791,
      "learning_rate": 2.2424640104304387e-05,
      "epoch": 2.912621359223301,
      "step": 16500
    },
    {
      "loss": 0.7977,
      "grad_norm": 9.014217376708984,
      "learning_rate": 2.2360536736560107e-05,
      "epoch": 2.921447484554281,
      "step": 16550
    },
    {
      "loss": 0.8148,
      "grad_norm": 7.843110084533691,
      "learning_rate": 2.2296433368815827e-05,
      "epoch": 2.93027360988526,
      "step": 16600
    },
    {
      "loss": 0.8025,
      "grad_norm": 7.8966803550720215,
      "learning_rate": 2.2232330001071547e-05,
      "epoch": 2.93909973521624,
      "step": 16650
    },
    {
      "loss": 0.7447,
      "grad_norm": 12.103073120117188,
      "learning_rate": 2.2168226633327267e-05,
      "epoch": 2.94792586054722,
      "step": 16700
    },
    {
      "loss": 0.801,
      "grad_norm": 9.873054504394531,
      "learning_rate": 2.2104123265582983e-05,
      "epoch": 2.956751985878199,
      "step": 16750
    },
    {
      "loss": 0.8668,
      "grad_norm": 10.8434476852417,
      "learning_rate": 2.2040019897838703e-05,
      "epoch": 2.965578111209179,
      "step": 16800
    },
    {
      "loss": 0.7711,
      "grad_norm": 7.40233850479126,
      "learning_rate": 2.1975916530094423e-05,
      "epoch": 2.974404236540159,
      "step": 16850
    },
    {
      "loss": 0.7712,
      "grad_norm": 12.763787269592285,
      "learning_rate": 2.1911813162350142e-05,
      "epoch": 2.9832303618711387,
      "step": 16900
    },
    {
      "loss": 0.8621,
      "grad_norm": 9.000141143798828,
      "learning_rate": 2.1847709794605862e-05,
      "epoch": 2.9920564872021185,
      "step": 16950
    },
    {
      "eval_loss": 0.8105672053113613,
      "eval_exact_match": 79.94617013766326,
      "eval_f1": 85.10937248632536,
      "eval_samples": 22720,
      "step": 16995
    },
    {
      "eval_loss": 0.8105672053113613,
      "eval_exact_match": 79.94617013766326,
      "eval_f1": 85.10937248632536,
      "eval_samples": 22720,
      "epoch": 3.0,
      "step": 16995
    },
    {
      "loss": 0.7898,
      "grad_norm": 9.205302238464355,
      "learning_rate": 2.178360642686158e-05,
      "epoch": 3.000882612533098,
      "step": 17000
    },
    {
      "loss": 0.7528,
      "grad_norm": 8.52016544342041,
      "learning_rate": 2.17195030591173e-05,
      "epoch": 3.0097087378640777,
      "step": 17050
    },
    {
      "loss": 0.6697,
      "grad_norm": 11.558841705322266,
      "learning_rate": 2.1655399691373015e-05,
      "epoch": 3.0185348631950575,
      "step": 17100
    },
    {
      "loss": 0.7215,
      "grad_norm": 12.988028526306152,
      "learning_rate": 2.1591296323628735e-05,
      "epoch": 3.027360988526037,
      "step": 17150
    },
    {
      "loss": 0.6958,
      "grad_norm": 6.618630886077881,
      "learning_rate": 2.1527192955884454e-05,
      "epoch": 3.0361871138570167,
      "step": 17200
    },
    {
      "loss": 0.7396,
      "grad_norm": 21.767677307128906,
      "learning_rate": 2.1463089588140174e-05,
      "epoch": 3.0450132391879965,
      "step": 17250
    },
    {
      "loss": 0.6679,
      "grad_norm": 9.377787590026855,
      "learning_rate": 2.1398986220395894e-05,
      "epoch": 3.0538393645189763,
      "step": 17300
    },
    {
      "loss": 0.7278,
      "grad_norm": 10.276799201965332,
      "learning_rate": 2.1334882852651614e-05,
      "epoch": 3.0626654898499557,
      "step": 17350
    },
    {
      "loss": 0.779,
      "grad_norm": 9.195140838623047,
      "learning_rate": 2.127077948490733e-05,
      "epoch": 3.0714916151809355,
      "step": 17400
    },
    {
      "loss": 0.6937,
      "grad_norm": 9.607242584228516,
      "learning_rate": 2.120667611716305e-05,
      "epoch": 3.0803177405119153,
      "step": 17450
    },
    {
      "loss": 0.7014,
      "grad_norm": 30.773597717285156,
      "learning_rate": 2.114257274941877e-05,
      "epoch": 3.089143865842895,
      "step": 17500
    },
    {
      "loss": 0.7188,
      "grad_norm": 8.456437110900879,
      "learning_rate": 2.107846938167449e-05,
      "epoch": 3.0979699911738745,
      "step": 17550
    },
    {
      "loss": 0.6892,
      "grad_norm": 13.5591459274292,
      "learning_rate": 2.1014366013930206e-05,
      "epoch": 3.1067961165048543,
      "step": 17600
    },
    {
      "loss": 0.7276,
      "grad_norm": 7.500815391540527,
      "learning_rate": 2.0950262646185926e-05,
      "epoch": 3.115622241835834,
      "step": 17650
    },
    {
      "loss": 0.6966,
      "grad_norm": 10.916701316833496,
      "learning_rate": 2.0886159278441645e-05,
      "epoch": 3.124448367166814,
      "step": 17700
    },
    {
      "loss": 0.6885,
      "grad_norm": 5.669236660003662,
      "learning_rate": 2.0822055910697362e-05,
      "epoch": 3.1332744924977933,
      "step": 17750
    },
    {
      "loss": 0.7289,
      "grad_norm": 7.820493698120117,
      "learning_rate": 2.075795254295308e-05,
      "epoch": 3.142100617828773,
      "step": 17800
    },
    {
      "loss": 0.7162,
      "grad_norm": 7.42659330368042,
      "learning_rate": 2.06938491752088e-05,
      "epoch": 3.150926743159753,
      "step": 17850
    },
    {
      "loss": 0.6985,
      "grad_norm": 6.069251537322998,
      "learning_rate": 2.062974580746452e-05,
      "epoch": 3.159752868490733,
      "step": 17900
    },
    {
      "loss": 0.6709,
      "grad_norm": 9.631830215454102,
      "learning_rate": 2.056564243972024e-05,
      "epoch": 3.168578993821712,
      "step": 17950
    },
    {
      "loss": 0.7232,
      "grad_norm": 11.607009887695312,
      "learning_rate": 2.050153907197596e-05,
      "epoch": 3.177405119152692,
      "step": 18000
    },
    {
      "loss": 0.6841,
      "grad_norm": 7.422651767730713,
      "learning_rate": 2.0437435704231677e-05,
      "epoch": 3.186231244483672,
      "step": 18050
    },
    {
      "loss": 0.7192,
      "grad_norm": 9.52755355834961,
      "learning_rate": 2.0373332336487397e-05,
      "epoch": 3.195057369814651,
      "step": 18100
    },
    {
      "loss": 0.7262,
      "grad_norm": 9.314577102661133,
      "learning_rate": 2.0309228968743113e-05,
      "epoch": 3.203883495145631,
      "step": 18150
    },
    {
      "loss": 0.7337,
      "grad_norm": 7.818636417388916,
      "learning_rate": 2.0245125600998833e-05,
      "epoch": 3.212709620476611,
      "step": 18200
    },
    {
      "loss": 0.6938,
      "grad_norm": 15.528626441955566,
      "learning_rate": 2.0181022233254553e-05,
      "epoch": 3.2215357458075906,
      "step": 18250
    },
    {
      "loss": 0.7518,
      "grad_norm": 8.60793685913086,
      "learning_rate": 2.0116918865510273e-05,
      "epoch": 3.23036187113857,
      "step": 18300
    },
    {
      "loss": 0.7289,
      "grad_norm": 10.925946235656738,
      "learning_rate": 2.0052815497765993e-05,
      "epoch": 3.23918799646955,
      "step": 18350
    },
    {
      "loss": 0.6975,
      "grad_norm": 6.7763214111328125,
      "learning_rate": 1.998871213002171e-05,
      "epoch": 3.2480141218005296,
      "step": 18400
    },
    {
      "loss": 0.7272,
      "grad_norm": 8.210394859313965,
      "learning_rate": 1.992460876227743e-05,
      "epoch": 3.2568402471315094,
      "step": 18450
    },
    {
      "loss": 0.7215,
      "grad_norm": 8.36162281036377,
      "learning_rate": 1.986050539453315e-05,
      "epoch": 3.265666372462489,
      "step": 18500
    },
    {
      "loss": 0.7513,
      "grad_norm": 8.8025484085083,
      "learning_rate": 1.9796402026788868e-05,
      "epoch": 3.2744924977934686,
      "step": 18550
    },
    {
      "loss": 0.7022,
      "grad_norm": 9.025144577026367,
      "learning_rate": 1.9732298659044588e-05,
      "epoch": 3.2833186231244484,
      "step": 18600
    },
    {
      "loss": 0.7356,
      "grad_norm": 8.599987030029297,
      "learning_rate": 1.9668195291300308e-05,
      "epoch": 3.2921447484554283,
      "step": 18650
    },
    {
      "loss": 0.7424,
      "grad_norm": 13.530416488647461,
      "learning_rate": 1.9604091923556024e-05,
      "epoch": 3.3009708737864076,
      "step": 18700
    },
    {
      "loss": 0.7678,
      "grad_norm": 7.503584861755371,
      "learning_rate": 1.9539988555811744e-05,
      "epoch": 3.3097969991173875,
      "step": 18750
    },
    {
      "loss": 0.7046,
      "grad_norm": 7.374327659606934,
      "learning_rate": 1.947588518806746e-05,
      "epoch": 3.3186231244483673,
      "step": 18800
    },
    {
      "loss": 0.726,
      "grad_norm": 9.038247108459473,
      "learning_rate": 1.941178182032318e-05,
      "epoch": 3.327449249779347,
      "step": 18850
    },
    {
      "loss": 0.7256,
      "grad_norm": 6.722421169281006,
      "learning_rate": 1.93476784525789e-05,
      "epoch": 3.3362753751103265,
      "step": 18900
    },
    {
      "loss": 0.677,
      "grad_norm": 12.992952346801758,
      "learning_rate": 1.928357508483462e-05,
      "epoch": 3.3451015004413063,
      "step": 18950
    },
    {
      "loss": 0.7004,
      "grad_norm": 10.336409568786621,
      "learning_rate": 1.921947171709034e-05,
      "epoch": 3.353927625772286,
      "step": 19000
    },
    {
      "loss": 0.7807,
      "grad_norm": 7.563750267028809,
      "learning_rate": 1.9155368349346056e-05,
      "epoch": 3.3627537511032655,
      "step": 19050
    },
    {
      "loss": 0.6903,
      "grad_norm": 11.249589920043945,
      "learning_rate": 1.9091264981601776e-05,
      "epoch": 3.3715798764342453,
      "step": 19100
    },
    {
      "loss": 0.7424,
      "grad_norm": 7.947124481201172,
      "learning_rate": 1.9027161613857496e-05,
      "epoch": 3.380406001765225,
      "step": 19150
    },
    {
      "loss": 0.6837,
      "grad_norm": 11.26718521118164,
      "learning_rate": 1.8963058246113212e-05,
      "epoch": 3.389232127096205,
      "step": 19200
    },
    {
      "loss": 0.6953,
      "grad_norm": 8.423931121826172,
      "learning_rate": 1.8898954878368932e-05,
      "epoch": 3.3980582524271843,
      "step": 19250
    },
    {
      "loss": 0.7467,
      "grad_norm": 11.14010238647461,
      "learning_rate": 1.883485151062465e-05,
      "epoch": 3.406884377758164,
      "step": 19300
    },
    {
      "loss": 0.7353,
      "grad_norm": 14.37755012512207,
      "learning_rate": 1.877074814288037e-05,
      "epoch": 3.415710503089144,
      "step": 19350
    },
    {
      "loss": 0.7465,
      "grad_norm": 10.475126266479492,
      "learning_rate": 1.870664477513609e-05,
      "epoch": 3.4245366284201237,
      "step": 19400
    },
    {
      "loss": 0.7757,
      "grad_norm": 11.246670722961426,
      "learning_rate": 1.8642541407391808e-05,
      "epoch": 3.433362753751103,
      "step": 19450
    },
    {
      "loss": 0.7445,
      "grad_norm": 11.895380020141602,
      "learning_rate": 1.8578438039647527e-05,
      "epoch": 3.442188879082083,
      "step": 19500
    },
    {
      "loss": 0.787,
      "grad_norm": 10.110032081604004,
      "learning_rate": 1.8514334671903247e-05,
      "epoch": 3.4510150044130627,
      "step": 19550
    },
    {
      "loss": 0.739,
      "grad_norm": 9.695874214172363,
      "learning_rate": 1.8450231304158967e-05,
      "epoch": 3.459841129744042,
      "step": 19600
    },
    {
      "loss": 0.714,
      "grad_norm": 7.057192325592041,
      "learning_rate": 1.8386127936414687e-05,
      "epoch": 3.468667255075022,
      "step": 19650
    },
    {
      "loss": 0.6717,
      "grad_norm": 10.704667091369629,
      "learning_rate": 1.8322024568670403e-05,
      "epoch": 3.4774933804060018,
      "step": 19700
    },
    {
      "loss": 0.7378,
      "grad_norm": 9.792905807495117,
      "learning_rate": 1.8257921200926123e-05,
      "epoch": 3.4863195057369816,
      "step": 19750
    },
    {
      "loss": 0.7076,
      "grad_norm": 12.700325965881348,
      "learning_rate": 1.819381783318184e-05,
      "epoch": 3.4951456310679614,
      "step": 19800
    },
    {
      "loss": 0.7041,
      "grad_norm": 6.482036590576172,
      "learning_rate": 1.812971446543756e-05,
      "epoch": 3.5039717563989408,
      "step": 19850
    },
    {
      "loss": 0.7293,
      "grad_norm": 11.765169143676758,
      "learning_rate": 1.806561109769328e-05,
      "epoch": 3.5127978817299206,
      "step": 19900
    },
    {
      "loss": 0.6684,
      "grad_norm": 13.32990837097168,
      "learning_rate": 1.8001507729949e-05,
      "epoch": 3.5216240070609004,
      "step": 19950
    },
    {
      "loss": 0.7457,
      "grad_norm": 8.287629127502441,
      "learning_rate": 1.793740436220472e-05,
      "epoch": 3.5304501323918798,
      "step": 20000
    },
    {
      "loss": 0.7099,
      "grad_norm": 8.90684700012207,
      "learning_rate": 1.7873300994460438e-05,
      "epoch": 3.5392762577228596,
      "step": 20050
    },
    {
      "loss": 0.7485,
      "grad_norm": 8.645637512207031,
      "learning_rate": 1.7809197626716155e-05,
      "epoch": 3.5481023830538394,
      "step": 20100
    },
    {
      "loss": 0.7212,
      "grad_norm": 10.041352272033691,
      "learning_rate": 1.7745094258971874e-05,
      "epoch": 3.556928508384819,
      "step": 20150
    },
    {
      "loss": 0.741,
      "grad_norm": 8.615543365478516,
      "learning_rate": 1.7680990891227594e-05,
      "epoch": 3.565754633715799,
      "step": 20200
    },
    {
      "loss": 0.7285,
      "grad_norm": 7.305023670196533,
      "learning_rate": 1.7616887523483314e-05,
      "epoch": 3.5745807590467784,
      "step": 20250
    },
    {
      "loss": 0.7081,
      "grad_norm": 8.564136505126953,
      "learning_rate": 1.755278415573903e-05,
      "epoch": 3.5834068843777582,
      "step": 20300
    },
    {
      "loss": 0.7102,
      "grad_norm": 6.759955883026123,
      "learning_rate": 1.748868078799475e-05,
      "epoch": 3.592233009708738,
      "step": 20350
    },
    {
      "loss": 0.6583,
      "grad_norm": 11.577958106994629,
      "learning_rate": 1.742457742025047e-05,
      "epoch": 3.6010591350397174,
      "step": 20400
    },
    {
      "loss": 0.7501,
      "grad_norm": 12.716229438781738,
      "learning_rate": 1.7360474052506186e-05,
      "epoch": 3.6098852603706972,
      "step": 20450
    },
    {
      "loss": 0.7442,
      "grad_norm": 8.390119552612305,
      "learning_rate": 1.7296370684761906e-05,
      "epoch": 3.618711385701677,
      "step": 20500
    },
    {
      "loss": 0.7156,
      "grad_norm": 12.630844116210938,
      "learning_rate": 1.7232267317017626e-05,
      "epoch": 3.6275375110326564,
      "step": 20550
    },
    {
      "loss": 0.7486,
      "grad_norm": 12.490992546081543,
      "learning_rate": 1.7168163949273346e-05,
      "epoch": 3.6363636363636362,
      "step": 20600
    },
    {
      "loss": 0.6964,
      "grad_norm": 10.50502872467041,
      "learning_rate": 1.7104060581529066e-05,
      "epoch": 3.645189761694616,
      "step": 20650
    },
    {
      "loss": 0.7739,
      "grad_norm": 9.997674942016602,
      "learning_rate": 1.7039957213784785e-05,
      "epoch": 3.654015887025596,
      "step": 20700
    },
    {
      "loss": 0.6909,
      "grad_norm": 14.074088096618652,
      "learning_rate": 1.6975853846040502e-05,
      "epoch": 3.6628420123565757,
      "step": 20750
    },
    {
      "loss": 0.7384,
      "grad_norm": 12.475248336791992,
      "learning_rate": 1.691175047829622e-05,
      "epoch": 3.671668137687555,
      "step": 20800
    },
    {
      "loss": 0.7182,
      "grad_norm": 7.949179172515869,
      "learning_rate": 1.6847647110551938e-05,
      "epoch": 3.680494263018535,
      "step": 20850
    },
    {
      "loss": 0.6842,
      "grad_norm": 11.223998069763184,
      "learning_rate": 1.6783543742807658e-05,
      "epoch": 3.6893203883495147,
      "step": 20900
    },
    {
      "loss": 0.7366,
      "grad_norm": 12.359197616577148,
      "learning_rate": 1.6719440375063378e-05,
      "epoch": 3.698146513680494,
      "step": 20950
    },
    {
      "loss": 0.7218,
      "grad_norm": 10.990015029907227,
      "learning_rate": 1.6655337007319097e-05,
      "epoch": 3.706972639011474,
      "step": 21000
    },
    {
      "loss": 0.7441,
      "grad_norm": 10.573659896850586,
      "learning_rate": 1.6591233639574817e-05,
      "epoch": 3.7157987643424537,
      "step": 21050
    },
    {
      "loss": 0.7271,
      "grad_norm": 9.216804504394531,
      "learning_rate": 1.6527130271830534e-05,
      "epoch": 3.7246248896734335,
      "step": 21100
    },
    {
      "loss": 0.7596,
      "grad_norm": 11.160425186157227,
      "learning_rate": 1.6463026904086253e-05,
      "epoch": 3.733451015004413,
      "step": 21150
    },
    {
      "loss": 0.783,
      "grad_norm": 7.390434741973877,
      "learning_rate": 1.6398923536341973e-05,
      "epoch": 3.7422771403353927,
      "step": 21200
    },
    {
      "loss": 0.6672,
      "grad_norm": 10.573756217956543,
      "learning_rate": 1.6334820168597693e-05,
      "epoch": 3.7511032656663725,
      "step": 21250
    },
    {
      "loss": 0.7099,
      "grad_norm": 10.376164436340332,
      "learning_rate": 1.6270716800853413e-05,
      "epoch": 3.7599293909973523,
      "step": 21300
    },
    {
      "loss": 0.6756,
      "grad_norm": 19.44808006286621,
      "learning_rate": 1.620661343310913e-05,
      "epoch": 3.7687555163283317,
      "step": 21350
    },
    {
      "loss": 0.6897,
      "grad_norm": 6.216602802276611,
      "learning_rate": 1.614251006536485e-05,
      "epoch": 3.7775816416593115,
      "step": 21400
    },
    {
      "loss": 0.7449,
      "grad_norm": 12.751132011413574,
      "learning_rate": 1.607840669762057e-05,
      "epoch": 3.7864077669902914,
      "step": 21450
    },
    {
      "loss": 0.7606,
      "grad_norm": 10.055968284606934,
      "learning_rate": 1.6014303329876285e-05,
      "epoch": 3.7952338923212707,
      "step": 21500
    },
    {
      "loss": 0.6576,
      "grad_norm": 11.718358993530273,
      "learning_rate": 1.5950199962132005e-05,
      "epoch": 3.8040600176522505,
      "step": 21550
    },
    {
      "loss": 0.7405,
      "grad_norm": 12.390162467956543,
      "learning_rate": 1.5886096594387725e-05,
      "epoch": 3.8128861429832304,
      "step": 21600
    },
    {
      "loss": 0.6917,
      "grad_norm": 10.330427169799805,
      "learning_rate": 1.5821993226643444e-05,
      "epoch": 3.82171226831421,
      "step": 21650
    },
    {
      "loss": 0.6714,
      "grad_norm": 6.3465895652771,
      "learning_rate": 1.5757889858899164e-05,
      "epoch": 3.83053839364519,
      "step": 21700
    },
    {
      "loss": 0.7573,
      "grad_norm": 12.126763343811035,
      "learning_rate": 1.569378649115488e-05,
      "epoch": 3.8393645189761694,
      "step": 21750
    },
    {
      "loss": 0.715,
      "grad_norm": 7.791685104370117,
      "learning_rate": 1.56296831234106e-05,
      "epoch": 3.848190644307149,
      "step": 21800
    },
    {
      "loss": 0.7301,
      "grad_norm": 11.941661834716797,
      "learning_rate": 1.5565579755666317e-05,
      "epoch": 3.857016769638129,
      "step": 21850
    },
    {
      "loss": 0.7342,
      "grad_norm": 8.258964538574219,
      "learning_rate": 1.5501476387922037e-05,
      "epoch": 3.8658428949691084,
      "step": 21900
    },
    {
      "loss": 0.7336,
      "grad_norm": 12.810972213745117,
      "learning_rate": 1.5437373020177756e-05,
      "epoch": 3.874669020300088,
      "step": 21950
    },
    {
      "loss": 0.7257,
      "grad_norm": 7.073654651641846,
      "learning_rate": 1.5373269652433476e-05,
      "epoch": 3.883495145631068,
      "step": 22000
    },
    {
      "loss": 0.6798,
      "grad_norm": 5.7993364334106445,
      "learning_rate": 1.5309166284689196e-05,
      "epoch": 3.8923212709620474,
      "step": 22050
    },
    {
      "loss": 0.7078,
      "grad_norm": 8.587984085083008,
      "learning_rate": 1.5245062916944914e-05,
      "epoch": 3.901147396293027,
      "step": 22100
    },
    {
      "loss": 0.7385,
      "grad_norm": 8.785640716552734,
      "learning_rate": 1.5180959549200634e-05,
      "epoch": 3.909973521624007,
      "step": 22150
    },
    {
      "loss": 0.7239,
      "grad_norm": 9.991622924804688,
      "learning_rate": 1.5116856181456352e-05,
      "epoch": 3.918799646954987,
      "step": 22200
    },
    {
      "loss": 0.7156,
      "grad_norm": 8.945380210876465,
      "learning_rate": 1.5052752813712072e-05,
      "epoch": 3.9276257722859667,
      "step": 22250
    },
    {
      "loss": 0.7138,
      "grad_norm": 10.6295166015625,
      "learning_rate": 1.4988649445967792e-05,
      "epoch": 3.936451897616946,
      "step": 22300
    },
    {
      "loss": 0.7146,
      "grad_norm": 9.183344841003418,
      "learning_rate": 1.492454607822351e-05,
      "epoch": 3.945278022947926,
      "step": 22350
    },
    {
      "loss": 0.7464,
      "grad_norm": 5.784789562225342,
      "learning_rate": 1.4860442710479228e-05,
      "epoch": 3.9541041482789057,
      "step": 22400
    },
    {
      "loss": 0.7226,
      "grad_norm": 9.57544231414795,
      "learning_rate": 1.4796339342734946e-05,
      "epoch": 3.962930273609885,
      "step": 22450
    },
    {
      "loss": 0.7428,
      "grad_norm": 11.411245346069336,
      "learning_rate": 1.4732235974990666e-05,
      "epoch": 3.971756398940865,
      "step": 22500
    },
    {
      "loss": 0.7168,
      "grad_norm": 10.653379440307617,
      "learning_rate": 1.4668132607246385e-05,
      "epoch": 3.9805825242718447,
      "step": 22550
    },
    {
      "loss": 0.669,
      "grad_norm": 6.453338623046875,
      "learning_rate": 1.4604029239502103e-05,
      "epoch": 3.9894086496028245,
      "step": 22600
    },
    {
      "loss": 0.7357,
      "grad_norm": 14.075057983398438,
      "learning_rate": 1.4539925871757823e-05,
      "epoch": 3.9982347749338043,
      "step": 22650
    },
    {
      "eval_loss": 0.8259770894456522,
      "eval_exact_match": 80.36533709848217,
      "eval_f1": 85.320759576353,
      "eval_samples": 22720,
      "step": 22660
    },
    {
      "eval_loss": 0.8259770894456522,
      "eval_exact_match": 80.36533709848217,
      "eval_f1": 85.320759576353,
      "eval_samples": 22720,
      "epoch": 4.0,
      "step": 22660
    },
    {
      "loss": 0.6977,
      "grad_norm": 4.943683624267578,
      "learning_rate": 1.4475822504013541e-05,
      "epoch": 4.007060900264784,
      "step": 22700
    },
    {
      "loss": 0.6634,
      "grad_norm": 8.378392219543457,
      "learning_rate": 1.4411719136269261e-05,
      "epoch": 4.015887025595763,
      "step": 22750
    },
    {
      "loss": 0.6548,
      "grad_norm": 5.589222431182861,
      "learning_rate": 1.4347615768524981e-05,
      "epoch": 4.024713150926743,
      "step": 22800
    },
    {
      "loss": 0.6629,
      "grad_norm": 10.806556701660156,
      "learning_rate": 1.4283512400780699e-05,
      "epoch": 4.033539276257723,
      "step": 22850
    },
    {
      "loss": 0.6222,
      "grad_norm": 11.851094245910645,
      "learning_rate": 1.4219409033036419e-05,
      "epoch": 4.042365401588703,
      "step": 22900
    },
    {
      "loss": 0.6866,
      "grad_norm": 8.844337463378906,
      "learning_rate": 1.4155305665292135e-05,
      "epoch": 4.051191526919682,
      "step": 22950
    },
    {
      "loss": 0.6547,
      "grad_norm": 9.188187599182129,
      "learning_rate": 1.4091202297547855e-05,
      "epoch": 4.060017652250662,
      "step": 23000
    },
    {
      "loss": 0.6015,
      "grad_norm": 11.851268768310547,
      "learning_rate": 1.4027098929803575e-05,
      "epoch": 4.068843777581642,
      "step": 23050
    },
    {
      "loss": 0.6369,
      "grad_norm": 10.431928634643555,
      "learning_rate": 1.3962995562059293e-05,
      "epoch": 4.077669902912621,
      "step": 23100
    },
    {
      "loss": 0.6414,
      "grad_norm": 8.346092224121094,
      "learning_rate": 1.3898892194315013e-05,
      "epoch": 4.086496028243601,
      "step": 23150
    },
    {
      "loss": 0.6664,
      "grad_norm": 9.324417114257812,
      "learning_rate": 1.3834788826570732e-05,
      "epoch": 4.095322153574581,
      "step": 23200
    },
    {
      "loss": 0.6207,
      "grad_norm": 10.165616035461426,
      "learning_rate": 1.377068545882645e-05,
      "epoch": 4.10414827890556,
      "step": 23250
    },
    {
      "loss": 0.6137,
      "grad_norm": 8.17167854309082,
      "learning_rate": 1.370658209108217e-05,
      "epoch": 4.112974404236541,
      "step": 23300
    },
    {
      "loss": 0.6968,
      "grad_norm": 13.246964454650879,
      "learning_rate": 1.364247872333789e-05,
      "epoch": 4.12180052956752,
      "step": 23350
    },
    {
      "loss": 0.645,
      "grad_norm": 48.47251892089844,
      "learning_rate": 1.3578375355593608e-05,
      "epoch": 4.130626654898499,
      "step": 23400
    },
    {
      "loss": 0.6113,
      "grad_norm": 10.326251029968262,
      "learning_rate": 1.3514271987849325e-05,
      "epoch": 4.13945278022948,
      "step": 23450
    },
    {
      "loss": 0.673,
      "grad_norm": 12.471549034118652,
      "learning_rate": 1.3450168620105044e-05,
      "epoch": 4.148278905560459,
      "step": 23500
    },
    {
      "loss": 0.6322,
      "grad_norm": 10.436114311218262,
      "learning_rate": 1.3386065252360764e-05,
      "epoch": 4.157105030891438,
      "step": 23550
    },
    {
      "loss": 0.6428,
      "grad_norm": 10.667623519897461,
      "learning_rate": 1.3321961884616482e-05,
      "epoch": 4.165931156222419,
      "step": 23600
    },
    {
      "loss": 0.6297,
      "grad_norm": 14.628188133239746,
      "learning_rate": 1.3257858516872202e-05,
      "epoch": 4.174757281553398,
      "step": 23650
    },
    {
      "loss": 0.6247,
      "grad_norm": 8.834684371948242,
      "learning_rate": 1.3193755149127922e-05,
      "epoch": 4.183583406884377,
      "step": 23700
    },
    {
      "loss": 0.6364,
      "grad_norm": 12.378057479858398,
      "learning_rate": 1.312965178138364e-05,
      "epoch": 4.192409532215358,
      "step": 23750
    },
    {
      "loss": 0.6572,
      "grad_norm": 8.639141082763672,
      "learning_rate": 1.306554841363936e-05,
      "epoch": 4.201235657546337,
      "step": 23800
    },
    {
      "loss": 0.6548,
      "grad_norm": 9.840982437133789,
      "learning_rate": 1.300144504589508e-05,
      "epoch": 4.210061782877317,
      "step": 23850
    },
    {
      "loss": 0.6484,
      "grad_norm": 9.140303611755371,
      "learning_rate": 1.2937341678150798e-05,
      "epoch": 4.218887908208297,
      "step": 23900
    },
    {
      "loss": 0.6467,
      "grad_norm": 12.329554557800293,
      "learning_rate": 1.2873238310406517e-05,
      "epoch": 4.227714033539276,
      "step": 23950
    },
    {
      "loss": 0.679,
      "grad_norm": 11.17806625366211,
      "learning_rate": 1.2809134942662234e-05,
      "epoch": 4.236540158870256,
      "step": 24000
    },
    {
      "loss": 0.6398,
      "grad_norm": 5.3148016929626465,
      "learning_rate": 1.2745031574917954e-05,
      "epoch": 4.245366284201236,
      "step": 24050
    },
    {
      "loss": 0.667,
      "grad_norm": 6.25297737121582,
      "learning_rate": 1.2680928207173672e-05,
      "epoch": 4.254192409532215,
      "step": 24100
    },
    {
      "loss": 0.6864,
      "grad_norm": 11.573769569396973,
      "learning_rate": 1.2616824839429392e-05,
      "epoch": 4.263018534863195,
      "step": 24150
    },
    {
      "loss": 0.6421,
      "grad_norm": 6.9548258781433105,
      "learning_rate": 1.2552721471685111e-05,
      "epoch": 4.271844660194175,
      "step": 24200
    },
    {
      "loss": 0.655,
      "grad_norm": 9.299763679504395,
      "learning_rate": 1.248861810394083e-05,
      "epoch": 4.280670785525155,
      "step": 24250
    },
    {
      "loss": 0.6506,
      "grad_norm": 4.690859794616699,
      "learning_rate": 1.242451473619655e-05,
      "epoch": 4.289496910856134,
      "step": 24300
    },
    {
      "loss": 0.6336,
      "grad_norm": 12.773460388183594,
      "learning_rate": 1.2360411368452269e-05,
      "epoch": 4.298323036187114,
      "step": 24350
    },
    {
      "loss": 0.6686,
      "grad_norm": 8.77985668182373,
      "learning_rate": 1.2296308000707987e-05,
      "epoch": 4.307149161518094,
      "step": 24400
    },
    {
      "loss": 0.655,
      "grad_norm": 8.992852210998535,
      "learning_rate": 1.2232204632963707e-05,
      "epoch": 4.315975286849073,
      "step": 24450
    },
    {
      "loss": 0.6922,
      "grad_norm": 12.367140769958496,
      "learning_rate": 1.2168101265219423e-05,
      "epoch": 4.324801412180053,
      "step": 24500
    },
    {
      "loss": 0.6241,
      "grad_norm": 10.449273109436035,
      "learning_rate": 1.2103997897475143e-05,
      "epoch": 4.333627537511033,
      "step": 24550
    },
    {
      "loss": 0.6393,
      "grad_norm": 5.120397567749023,
      "learning_rate": 1.2039894529730863e-05,
      "epoch": 4.342453662842012,
      "step": 24600
    },
    {
      "loss": 0.6202,
      "grad_norm": 11.920722007751465,
      "learning_rate": 1.1975791161986581e-05,
      "epoch": 4.351279788172992,
      "step": 24650
    },
    {
      "loss": 0.6101,
      "grad_norm": 11.696610450744629,
      "learning_rate": 1.19116877942423e-05,
      "epoch": 4.360105913503972,
      "step": 24700
    },
    {
      "loss": 0.6622,
      "grad_norm": 8.64603328704834,
      "learning_rate": 1.1847584426498019e-05,
      "epoch": 4.368932038834951,
      "step": 24750
    },
    {
      "loss": 0.6085,
      "grad_norm": 16.57855796813965,
      "learning_rate": 1.1783481058753739e-05,
      "epoch": 4.3777581641659316,
      "step": 24800
    },
    {
      "loss": 0.6341,
      "grad_norm": 8.9037504196167,
      "learning_rate": 1.1719377691009458e-05,
      "epoch": 4.386584289496911,
      "step": 24850
    },
    {
      "loss": 0.6575,
      "grad_norm": 6.826592445373535,
      "learning_rate": 1.1655274323265177e-05,
      "epoch": 4.39541041482789,
      "step": 24900
    },
    {
      "loss": 0.6441,
      "grad_norm": 8.328352928161621,
      "learning_rate": 1.1591170955520896e-05,
      "epoch": 4.404236540158871,
      "step": 24950
    },
    {
      "loss": 0.6321,
      "grad_norm": 11.278501510620117,
      "learning_rate": 1.1527067587776616e-05,
      "epoch": 4.41306266548985,
      "step": 25000
    },
    {
      "loss": 0.6348,
      "grad_norm": 10.737892150878906,
      "learning_rate": 1.1462964220032333e-05,
      "epoch": 4.421888790820829,
      "step": 25050
    },
    {
      "loss": 0.6525,
      "grad_norm": 11.884450912475586,
      "learning_rate": 1.1398860852288052e-05,
      "epoch": 4.43071491615181,
      "step": 25100
    },
    {
      "loss": 0.6187,
      "grad_norm": 8.583343505859375,
      "learning_rate": 1.133475748454377e-05,
      "epoch": 4.439541041482789,
      "step": 25150
    },
    {
      "loss": 0.5836,
      "grad_norm": 12.090494155883789,
      "learning_rate": 1.127065411679949e-05,
      "epoch": 4.448367166813769,
      "step": 25200
    },
    {
      "loss": 0.7129,
      "grad_norm": 14.060958862304688,
      "learning_rate": 1.120655074905521e-05,
      "epoch": 4.457193292144749,
      "step": 25250
    },
    {
      "loss": 0.6449,
      "grad_norm": 8.25212574005127,
      "learning_rate": 1.1142447381310928e-05,
      "epoch": 4.466019417475728,
      "step": 25300
    },
    {
      "loss": 0.6724,
      "grad_norm": 12.732463836669922,
      "learning_rate": 1.1078344013566648e-05,
      "epoch": 4.474845542806708,
      "step": 25350
    },
    {
      "loss": 0.6683,
      "grad_norm": 8.171820640563965,
      "learning_rate": 1.1014240645822368e-05,
      "epoch": 4.483671668137688,
      "step": 25400
    },
    {
      "loss": 0.6376,
      "grad_norm": 11.823792457580566,
      "learning_rate": 1.0950137278078086e-05,
      "epoch": 4.492497793468667,
      "step": 25450
    },
    {
      "loss": 0.6328,
      "grad_norm": 6.722728252410889,
      "learning_rate": 1.0886033910333806e-05,
      "epoch": 4.501323918799647,
      "step": 25500
    },
    {
      "loss": 0.6789,
      "grad_norm": 11.05587387084961,
      "learning_rate": 1.0821930542589524e-05,
      "epoch": 4.510150044130627,
      "step": 25550
    },
    {
      "loss": 0.6891,
      "grad_norm": 10.442450523376465,
      "learning_rate": 1.0757827174845242e-05,
      "epoch": 4.518976169461606,
      "step": 25600
    },
    {
      "loss": 0.6648,
      "grad_norm": 10.239688873291016,
      "learning_rate": 1.0693723807100962e-05,
      "epoch": 4.527802294792586,
      "step": 25650
    },
    {
      "loss": 0.7119,
      "grad_norm": 7.154690742492676,
      "learning_rate": 1.062962043935668e-05,
      "epoch": 4.536628420123566,
      "step": 25700
    },
    {
      "loss": 0.64,
      "grad_norm": 11.407023429870605,
      "learning_rate": 1.05655170716124e-05,
      "epoch": 4.545454545454545,
      "step": 25750
    },
    {
      "loss": 0.6375,
      "grad_norm": 7.828510284423828,
      "learning_rate": 1.0501413703868118e-05,
      "epoch": 4.554280670785525,
      "step": 25800
    },
    {
      "loss": 0.6306,
      "grad_norm": 8.344382286071777,
      "learning_rate": 1.0437310336123837e-05,
      "epoch": 4.563106796116505,
      "step": 25850
    },
    {
      "loss": 0.6637,
      "grad_norm": 14.79720687866211,
      "learning_rate": 1.0373206968379557e-05,
      "epoch": 4.571932921447485,
      "step": 25900
    },
    {
      "loss": 0.6605,
      "grad_norm": 8.779214859008789,
      "learning_rate": 1.0309103600635275e-05,
      "epoch": 4.580759046778464,
      "step": 25950
    },
    {
      "loss": 0.6538,
      "grad_norm": 9.567919731140137,
      "learning_rate": 1.0245000232890993e-05,
      "epoch": 4.589585172109444,
      "step": 26000
    },
    {
      "loss": 0.6632,
      "grad_norm": 9.837514877319336,
      "learning_rate": 1.0180896865146713e-05,
      "epoch": 4.598411297440424,
      "step": 26050
    },
    {
      "loss": 0.6728,
      "grad_norm": 7.769359588623047,
      "learning_rate": 1.0116793497402433e-05,
      "epoch": 4.607237422771403,
      "step": 26100
    },
    {
      "loss": 0.6686,
      "grad_norm": 9.360169410705566,
      "learning_rate": 1.0052690129658151e-05,
      "epoch": 4.6160635481023835,
      "step": 26150
    },
    {
      "loss": 0.6476,
      "grad_norm": 10.040655136108398,
      "learning_rate": 9.98858676191387e-06,
      "epoch": 4.624889673433363,
      "step": 26200
    },
    {
      "loss": 0.6652,
      "grad_norm": 10.991339683532715,
      "learning_rate": 9.924483394169589e-06,
      "epoch": 4.633715798764342,
      "step": 26250
    },
    {
      "loss": 0.6121,
      "grad_norm": 8.923680305480957,
      "learning_rate": 9.860380026425307e-06,
      "epoch": 4.6425419240953225,
      "step": 26300
    },
    {
      "loss": 0.6853,
      "grad_norm": 8.74590015411377,
      "learning_rate": 9.796276658681027e-06,
      "epoch": 4.651368049426302,
      "step": 26350
    },
    {
      "loss": 0.6493,
      "grad_norm": 10.24193000793457,
      "learning_rate": 9.732173290936747e-06,
      "epoch": 4.660194174757281,
      "step": 26400
    },
    {
      "loss": 0.6391,
      "grad_norm": 9.0751314163208,
      "learning_rate": 9.668069923192465e-06,
      "epoch": 4.6690203000882615,
      "step": 26450
    },
    {
      "loss": 0.6009,
      "grad_norm": 10.846900939941406,
      "learning_rate": 9.603966555448183e-06,
      "epoch": 4.677846425419241,
      "step": 26500
    },
    {
      "loss": 0.6737,
      "grad_norm": 8.101409912109375,
      "learning_rate": 9.539863187703902e-06,
      "epoch": 4.68667255075022,
      "step": 26550
    },
    {
      "loss": 0.6373,
      "grad_norm": 5.906172752380371,
      "learning_rate": 9.475759819959622e-06,
      "epoch": 4.6954986760812005,
      "step": 26600
    },
    {
      "loss": 0.6499,
      "grad_norm": 13.762541770935059,
      "learning_rate": 9.41165645221534e-06,
      "epoch": 4.70432480141218,
      "step": 26650
    },
    {
      "loss": 0.6301,
      "grad_norm": 8.95790958404541,
      "learning_rate": 9.34755308447106e-06,
      "epoch": 4.713150926743159,
      "step": 26700
    },
    {
      "loss": 0.677,
      "grad_norm": 12.40058708190918,
      "learning_rate": 9.28344971672678e-06,
      "epoch": 4.7219770520741395,
      "step": 26750
    },
    {
      "loss": 0.6694,
      "grad_norm": 9.758111953735352,
      "learning_rate": 9.219346348982496e-06,
      "epoch": 4.730803177405119,
      "step": 26800
    },
    {
      "loss": 0.6332,
      "grad_norm": 6.911203384399414,
      "learning_rate": 9.155242981238216e-06,
      "epoch": 4.739629302736099,
      "step": 26850
    },
    {
      "loss": 0.6476,
      "grad_norm": 11.494077682495117,
      "learning_rate": 9.091139613493936e-06,
      "epoch": 4.7484554280670785,
      "step": 26900
    },
    {
      "loss": 0.6344,
      "grad_norm": 13.778582572937012,
      "learning_rate": 9.027036245749654e-06,
      "epoch": 4.757281553398058,
      "step": 26950
    },
    {
      "loss": 0.6667,
      "grad_norm": 8.237838745117188,
      "learning_rate": 8.962932878005374e-06,
      "epoch": 4.766107678729038,
      "step": 27000
    },
    {
      "loss": 0.6264,
      "grad_norm": 7.823890209197998,
      "learning_rate": 8.898829510261092e-06,
      "epoch": 4.7749338040600176,
      "step": 27050
    },
    {
      "loss": 0.5858,
      "grad_norm": 9.039804458618164,
      "learning_rate": 8.834726142516812e-06,
      "epoch": 4.783759929390998,
      "step": 27100
    },
    {
      "loss": 0.6795,
      "grad_norm": 8.732526779174805,
      "learning_rate": 8.77062277477253e-06,
      "epoch": 4.792586054721977,
      "step": 27150
    },
    {
      "loss": 0.6635,
      "grad_norm": 7.579305648803711,
      "learning_rate": 8.70651940702825e-06,
      "epoch": 4.801412180052957,
      "step": 27200
    },
    {
      "loss": 0.6662,
      "grad_norm": 13.68974781036377,
      "learning_rate": 8.64241603928397e-06,
      "epoch": 4.810238305383937,
      "step": 27250
    },
    {
      "loss": 0.6328,
      "grad_norm": 9.758129119873047,
      "learning_rate": 8.578312671539687e-06,
      "epoch": 4.819064430714916,
      "step": 27300
    },
    {
      "loss": 0.6674,
      "grad_norm": 10.319592475891113,
      "learning_rate": 8.514209303795406e-06,
      "epoch": 4.827890556045896,
      "step": 27350
    },
    {
      "loss": 0.6076,
      "grad_norm": 9.916899681091309,
      "learning_rate": 8.450105936051125e-06,
      "epoch": 4.836716681376876,
      "step": 27400
    },
    {
      "loss": 0.6546,
      "grad_norm": 8.89077091217041,
      "learning_rate": 8.386002568306845e-06,
      "epoch": 4.845542806707855,
      "step": 27450
    },
    {
      "loss": 0.6131,
      "grad_norm": 5.982450485229492,
      "learning_rate": 8.321899200562563e-06,
      "epoch": 4.854368932038835,
      "step": 27500
    },
    {
      "loss": 0.6745,
      "grad_norm": 7.2635498046875,
      "learning_rate": 8.257795832818281e-06,
      "epoch": 4.863195057369815,
      "step": 27550
    },
    {
      "loss": 0.6241,
      "grad_norm": 13.618016242980957,
      "learning_rate": 8.193692465074001e-06,
      "epoch": 4.872021182700794,
      "step": 27600
    },
    {
      "loss": 0.6329,
      "grad_norm": 12.419414520263672,
      "learning_rate": 8.12958909732972e-06,
      "epoch": 4.880847308031774,
      "step": 27650
    },
    {
      "loss": 0.6176,
      "grad_norm": 10.818105697631836,
      "learning_rate": 8.065485729585439e-06,
      "epoch": 4.889673433362754,
      "step": 27700
    },
    {
      "loss": 0.6731,
      "grad_norm": 10.947783470153809,
      "learning_rate": 8.001382361841159e-06,
      "epoch": 4.898499558693733,
      "step": 27750
    },
    {
      "loss": 0.6413,
      "grad_norm": 15.759203910827637,
      "learning_rate": 7.937278994096877e-06,
      "epoch": 4.9073256840247135,
      "step": 27800
    },
    {
      "loss": 0.6661,
      "grad_norm": 12.081360816955566,
      "learning_rate": 7.873175626352595e-06,
      "epoch": 4.916151809355693,
      "step": 27850
    },
    {
      "loss": 0.6768,
      "grad_norm": 12.072226524353027,
      "learning_rate": 7.809072258608315e-06,
      "epoch": 4.924977934686672,
      "step": 27900
    },
    {
      "loss": 0.6533,
      "grad_norm": 11.961487770080566,
      "learning_rate": 7.744968890864035e-06,
      "epoch": 4.9338040600176525,
      "step": 27950
    },
    {
      "loss": 0.6639,
      "grad_norm": 12.848736763000488,
      "learning_rate": 7.680865523119753e-06,
      "epoch": 4.942630185348632,
      "step": 28000
    },
    {
      "loss": 0.6345,
      "grad_norm": 12.917084693908691,
      "learning_rate": 7.6167621553754725e-06,
      "epoch": 4.951456310679612,
      "step": 28050
    },
    {
      "loss": 0.6531,
      "grad_norm": 12.933789253234863,
      "learning_rate": 7.5526587876311906e-06,
      "epoch": 4.9602824360105915,
      "step": 28100
    },
    {
      "loss": 0.6609,
      "grad_norm": 8.700865745544434,
      "learning_rate": 7.4885554198869095e-06,
      "epoch": 4.969108561341571,
      "step": 28150
    },
    {
      "loss": 0.6081,
      "grad_norm": 10.911104202270508,
      "learning_rate": 7.4244520521426284e-06,
      "epoch": 4.977934686672551,
      "step": 28200
    },
    {
      "loss": 0.6129,
      "grad_norm": 7.946423053741455,
      "learning_rate": 7.360348684398348e-06,
      "epoch": 4.9867608120035305,
      "step": 28250
    },
    {
      "loss": 0.6609,
      "grad_norm": 13.297666549682617,
      "learning_rate": 7.296245316654067e-06,
      "epoch": 4.99558693733451,
      "step": 28300
    },
    {
      "eval_loss": 0.8425956253078613,
      "eval_exact_match": 80.36092481468408,
      "eval_f1": 85.33223656630197,
      "eval_samples": 22720,
      "step": 28325
    },
    {
      "eval_loss": 0.8425956253078613,
      "eval_exact_match": 80.36092481468408,
      "eval_f1": 85.33223656630197,
      "eval_samples": 22720,
      "epoch": 5.0,
      "step": 28325
    },
    {
      "loss": 0.6614,
      "grad_norm": 7.3954081535339355,
      "learning_rate": 7.232141948909785e-06,
      "epoch": 5.00441306266549,
      "step": 28350
    },
    {
      "loss": 0.5979,
      "grad_norm": 7.274240016937256,
      "learning_rate": 7.168038581165504e-06,
      "epoch": 5.0132391879964695,
      "step": 28400
    },
    {
      "loss": 0.6061,
      "grad_norm": 12.547003746032715,
      "learning_rate": 7.103935213421223e-06,
      "epoch": 5.022065313327449,
      "step": 28450
    },
    {
      "loss": 0.5995,
      "grad_norm": 9.276871681213379,
      "learning_rate": 7.039831845676943e-06,
      "epoch": 5.030891438658429,
      "step": 28500
    },
    {
      "loss": 0.5939,
      "grad_norm": 8.10113525390625,
      "learning_rate": 6.975728477932662e-06,
      "epoch": 5.0397175639894085,
      "step": 28550
    },
    {
      "loss": 0.6018,
      "grad_norm": 8.161291122436523,
      "learning_rate": 6.911625110188381e-06,
      "epoch": 5.048543689320389,
      "step": 28600
    },
    {
      "loss": 0.5507,
      "grad_norm": 10.446709632873535,
      "learning_rate": 6.847521742444099e-06,
      "epoch": 5.057369814651368,
      "step": 28650
    },
    {
      "loss": 0.5843,
      "grad_norm": 8.677431106567383,
      "learning_rate": 6.783418374699819e-06,
      "epoch": 5.0661959399823475,
      "step": 28700
    },
    {
      "loss": 0.4884,
      "grad_norm": 6.839537143707275,
      "learning_rate": 6.719315006955538e-06,
      "epoch": 5.075022065313328,
      "step": 28750
    },
    {
      "loss": 0.5706,
      "grad_norm": 10.535660743713379,
      "learning_rate": 6.655211639211257e-06,
      "epoch": 5.083848190644307,
      "step": 28800
    },
    {
      "loss": 0.5934,
      "grad_norm": 17.066486358642578,
      "learning_rate": 6.5911082714669755e-06,
      "epoch": 5.0926743159752865,
      "step": 28850
    },
    {
      "loss": 0.6105,
      "grad_norm": 6.318231582641602,
      "learning_rate": 6.527004903722694e-06,
      "epoch": 5.101500441306267,
      "step": 28900
    },
    {
      "loss": 0.588,
      "grad_norm": 11.365327835083008,
      "learning_rate": 6.462901535978413e-06,
      "epoch": 5.110326566637246,
      "step": 28950
    },
    {
      "loss": 0.6097,
      "grad_norm": 12.607831001281738,
      "learning_rate": 6.398798168234132e-06,
      "epoch": 5.1191526919682255,
      "step": 29000
    },
    {
      "loss": 0.6305,
      "grad_norm": 11.729033470153809,
      "learning_rate": 6.334694800489851e-06,
      "epoch": 5.127978817299206,
      "step": 29050
    },
    {
      "loss": 0.5784,
      "grad_norm": 11.48563003540039,
      "learning_rate": 6.27059143274557e-06,
      "epoch": 5.136804942630185,
      "step": 29100
    },
    {
      "loss": 0.5517,
      "grad_norm": 13.312698364257812,
      "learning_rate": 6.206488065001288e-06,
      "epoch": 5.145631067961165,
      "step": 29150
    },
    {
      "loss": 0.6538,
      "grad_norm": 14.19382381439209,
      "learning_rate": 6.142384697257008e-06,
      "epoch": 5.154457193292145,
      "step": 29200
    },
    {
      "loss": 0.5839,
      "grad_norm": 9.875740051269531,
      "learning_rate": 6.078281329512727e-06,
      "epoch": 5.163283318623124,
      "step": 29250
    },
    {
      "loss": 0.6196,
      "grad_norm": 12.819831848144531,
      "learning_rate": 6.014177961768446e-06,
      "epoch": 5.172109443954104,
      "step": 29300
    },
    {
      "loss": 0.5584,
      "grad_norm": 11.080440521240234,
      "learning_rate": 5.950074594024166e-06,
      "epoch": 5.180935569285084,
      "step": 29350
    },
    {
      "loss": 0.6074,
      "grad_norm": 10.957423210144043,
      "learning_rate": 5.885971226279885e-06,
      "epoch": 5.189761694616063,
      "step": 29400
    },
    {
      "loss": 0.6227,
      "grad_norm": 15.84340763092041,
      "learning_rate": 5.821867858535603e-06,
      "epoch": 5.198587819947043,
      "step": 29450
    },
    {
      "loss": 0.5915,
      "grad_norm": 9.02678394317627,
      "learning_rate": 5.757764490791322e-06,
      "epoch": 5.207413945278023,
      "step": 29500
    },
    {
      "loss": 0.6114,
      "grad_norm": 7.109209060668945,
      "learning_rate": 5.693661123047041e-06,
      "epoch": 5.216240070609003,
      "step": 29550
    },
    {
      "loss": 0.5916,
      "grad_norm": 9.705595016479492,
      "learning_rate": 5.6295577553027605e-06,
      "epoch": 5.2250661959399824,
      "step": 29600
    },
    {
      "loss": 0.6876,
      "grad_norm": 11.1472806930542,
      "learning_rate": 5.5654543875584795e-06,
      "epoch": 5.233892321270962,
      "step": 29650
    },
    {
      "loss": 0.5707,
      "grad_norm": 10.933928489685059,
      "learning_rate": 5.5013510198141976e-06,
      "epoch": 5.242718446601942,
      "step": 29700
    },
    {
      "loss": 0.6097,
      "grad_norm": 16.80666160583496,
      "learning_rate": 5.4372476520699165e-06,
      "epoch": 5.2515445719329215,
      "step": 29750
    },
    {
      "loss": 0.5604,
      "grad_norm": 8.261306762695312,
      "learning_rate": 5.3731442843256354e-06,
      "epoch": 5.260370697263901,
      "step": 29800
    },
    {
      "loss": 0.5845,
      "grad_norm": 8.673043251037598,
      "learning_rate": 5.309040916581355e-06,
      "epoch": 5.269196822594881,
      "step": 29850
    },
    {
      "loss": 0.58,
      "grad_norm": 11.476496696472168,
      "learning_rate": 5.244937548837073e-06,
      "epoch": 5.2780229479258605,
      "step": 29900
    },
    {
      "loss": 0.5665,
      "grad_norm": 12.383391380310059,
      "learning_rate": 5.180834181092793e-06,
      "epoch": 5.28684907325684,
      "step": 29950
    },
    {
      "loss": 0.6722,
      "grad_norm": 14.094810485839844,
      "learning_rate": 5.116730813348511e-06,
      "epoch": 5.29567519858782,
      "step": 30000
    },
    {
      "loss": 0.5508,
      "grad_norm": 12.623584747314453,
      "learning_rate": 5.052627445604231e-06,
      "epoch": 5.3045013239187995,
      "step": 30050
    },
    {
      "loss": 0.5894,
      "grad_norm": 10.478256225585938,
      "learning_rate": 4.98852407785995e-06,
      "epoch": 5.31332744924978,
      "step": 30100
    },
    {
      "loss": 0.5934,
      "grad_norm": 10.137423515319824,
      "learning_rate": 4.924420710115668e-06,
      "epoch": 5.322153574580759,
      "step": 30150
    },
    {
      "loss": 0.542,
      "grad_norm": 8.008980751037598,
      "learning_rate": 4.860317342371388e-06,
      "epoch": 5.3309796999117385,
      "step": 30200
    },
    {
      "loss": 0.646,
      "grad_norm": 10.496953964233398,
      "learning_rate": 4.796213974627107e-06,
      "epoch": 5.339805825242719,
      "step": 30250
    },
    {
      "loss": 0.6382,
      "grad_norm": 11.094091415405273,
      "learning_rate": 4.732110606882826e-06,
      "epoch": 5.348631950573698,
      "step": 30300
    },
    {
      "loss": 0.6132,
      "grad_norm": 10.970301628112793,
      "learning_rate": 4.668007239138545e-06,
      "epoch": 5.3574580759046775,
      "step": 30350
    },
    {
      "loss": 0.5931,
      "grad_norm": 10.62838363647461,
      "learning_rate": 4.603903871394264e-06,
      "epoch": 5.366284201235658,
      "step": 30400
    },
    {
      "loss": 0.5761,
      "grad_norm": 9.015778541564941,
      "learning_rate": 4.5398005036499825e-06,
      "epoch": 5.375110326566637,
      "step": 30450
    },
    {
      "loss": 0.6185,
      "grad_norm": 5.653952598571777,
      "learning_rate": 4.4756971359057015e-06,
      "epoch": 5.3839364518976165,
      "step": 30500
    },
    {
      "loss": 0.5855,
      "grad_norm": 8.015743255615234,
      "learning_rate": 4.4115937681614204e-06,
      "epoch": 5.392762577228597,
      "step": 30550
    },
    {
      "loss": 0.6234,
      "grad_norm": 13.51584529876709,
      "learning_rate": 4.347490400417139e-06,
      "epoch": 5.401588702559576,
      "step": 30600
    },
    {
      "loss": 0.6521,
      "grad_norm": 10.100883483886719,
      "learning_rate": 4.283387032672858e-06,
      "epoch": 5.410414827890556,
      "step": 30650
    },
    {
      "loss": 0.5964,
      "grad_norm": 12.621158599853516,
      "learning_rate": 4.219283664928577e-06,
      "epoch": 5.419240953221536,
      "step": 30700
    },
    {
      "loss": 0.6006,
      "grad_norm": 11.342507362365723,
      "learning_rate": 4.155180297184296e-06,
      "epoch": 5.428067078552515,
      "step": 30750
    },
    {
      "loss": 0.624,
      "grad_norm": 8.497654914855957,
      "learning_rate": 4.091076929440015e-06,
      "epoch": 5.436893203883495,
      "step": 30800
    },
    {
      "loss": 0.5759,
      "grad_norm": 11.405197143554688,
      "learning_rate": 4.026973561695734e-06,
      "epoch": 5.445719329214475,
      "step": 30850
    },
    {
      "loss": 0.6213,
      "grad_norm": 10.692686080932617,
      "learning_rate": 3.962870193951453e-06,
      "epoch": 5.454545454545454,
      "step": 30900
    },
    {
      "loss": 0.5814,
      "grad_norm": 10.382841110229492,
      "learning_rate": 3.898766826207172e-06,
      "epoch": 5.463371579876434,
      "step": 30950
    },
    {
      "loss": 0.6033,
      "grad_norm": 7.411540985107422,
      "learning_rate": 3.834663458462891e-06,
      "epoch": 5.472197705207414,
      "step": 31000
    },
    {
      "loss": 0.5974,
      "grad_norm": 9.695995330810547,
      "learning_rate": 3.7705600907186103e-06,
      "epoch": 5.481023830538394,
      "step": 31050
    },
    {
      "loss": 0.5767,
      "grad_norm": 17.59457778930664,
      "learning_rate": 3.706456722974329e-06,
      "epoch": 5.489849955869373,
      "step": 31100
    },
    {
      "loss": 0.5964,
      "grad_norm": 11.501946449279785,
      "learning_rate": 3.642353355230048e-06,
      "epoch": 5.498676081200353,
      "step": 31150
    },
    {
      "loss": 0.6214,
      "grad_norm": 13.508743286132812,
      "learning_rate": 3.5782499874857667e-06,
      "epoch": 5.507502206531333,
      "step": 31200
    },
    {
      "loss": 0.6238,
      "grad_norm": 7.77008581161499,
      "learning_rate": 3.514146619741486e-06,
      "epoch": 5.516328331862312,
      "step": 31250
    },
    {
      "loss": 0.6252,
      "grad_norm": 7.818075656890869,
      "learning_rate": 3.450043251997205e-06,
      "epoch": 5.525154457193292,
      "step": 31300
    },
    {
      "loss": 0.602,
      "grad_norm": 11.697222709655762,
      "learning_rate": 3.385939884252924e-06,
      "epoch": 5.533980582524272,
      "step": 31350
    },
    {
      "loss": 0.5901,
      "grad_norm": 10.300638198852539,
      "learning_rate": 3.321836516508643e-06,
      "epoch": 5.542806707855251,
      "step": 31400
    },
    {
      "loss": 0.6147,
      "grad_norm": 10.570033073425293,
      "learning_rate": 3.2577331487643622e-06,
      "epoch": 5.551632833186231,
      "step": 31450
    },
    {
      "loss": 0.633,
      "grad_norm": 12.212743759155273,
      "learning_rate": 3.1936297810200808e-06,
      "epoch": 5.560458958517211,
      "step": 31500
    },
    {
      "loss": 0.6155,
      "grad_norm": 10.886144638061523,
      "learning_rate": 3.1295264132758e-06,
      "epoch": 5.56928508384819,
      "step": 31550
    },
    {
      "loss": 0.5547,
      "grad_norm": 7.161771297454834,
      "learning_rate": 3.0654230455315186e-06,
      "epoch": 5.578111209179171,
      "step": 31600
    },
    {
      "loss": 0.6285,
      "grad_norm": 12.425077438354492,
      "learning_rate": 3.0013196777872376e-06,
      "epoch": 5.58693733451015,
      "step": 31650
    },
    {
      "loss": 0.582,
      "grad_norm": 9.116974830627441,
      "learning_rate": 2.937216310042957e-06,
      "epoch": 5.595763459841129,
      "step": 31700
    },
    {
      "loss": 0.5859,
      "grad_norm": 9.29853630065918,
      "learning_rate": 2.8731129422986755e-06,
      "epoch": 5.60458958517211,
      "step": 31750
    },
    {
      "loss": 0.6274,
      "grad_norm": 9.187543869018555,
      "learning_rate": 2.809009574554395e-06,
      "epoch": 5.613415710503089,
      "step": 31800
    },
    {
      "loss": 0.5839,
      "grad_norm": 9.806077003479004,
      "learning_rate": 2.7449062068101138e-06,
      "epoch": 5.622241835834069,
      "step": 31850
    },
    {
      "loss": 0.6055,
      "grad_norm": 13.737460136413574,
      "learning_rate": 2.6808028390658327e-06,
      "epoch": 5.631067961165049,
      "step": 31900
    },
    {
      "loss": 0.6157,
      "grad_norm": 9.968599319458008,
      "learning_rate": 2.6166994713215517e-06,
      "epoch": 5.639894086496028,
      "step": 31950
    },
    {
      "loss": 0.583,
      "grad_norm": 8.446131706237793,
      "learning_rate": 2.5525961035772706e-06,
      "epoch": 5.648720211827008,
      "step": 32000
    },
    {
      "loss": 0.5526,
      "grad_norm": 16.337615966796875,
      "learning_rate": 2.4884927358329896e-06,
      "epoch": 5.657546337157988,
      "step": 32050
    },
    {
      "loss": 0.5682,
      "grad_norm": 8.899507522583008,
      "learning_rate": 2.4243893680887085e-06,
      "epoch": 5.666372462488967,
      "step": 32100
    },
    {
      "loss": 0.6126,
      "grad_norm": 9.624113082885742,
      "learning_rate": 2.3602860003444274e-06,
      "epoch": 5.675198587819947,
      "step": 32150
    },
    {
      "loss": 0.5662,
      "grad_norm": 15.677495956420898,
      "learning_rate": 2.2961826326001464e-06,
      "epoch": 5.684024713150927,
      "step": 32200
    },
    {
      "loss": 0.5689,
      "grad_norm": 23.497344970703125,
      "learning_rate": 2.2320792648558653e-06,
      "epoch": 5.692850838481906,
      "step": 32250
    },
    {
      "loss": 0.6718,
      "grad_norm": 9.625481605529785,
      "learning_rate": 2.1679758971115843e-06,
      "epoch": 5.701676963812886,
      "step": 32300
    },
    {
      "loss": 0.5947,
      "grad_norm": 7.963656425476074,
      "learning_rate": 2.1038725293673036e-06,
      "epoch": 5.710503089143866,
      "step": 32350
    },
    {
      "loss": 0.6379,
      "grad_norm": 8.677214622497559,
      "learning_rate": 2.0397691616230226e-06,
      "epoch": 5.719329214474845,
      "step": 32400
    },
    {
      "loss": 0.6063,
      "grad_norm": 13.34499454498291,
      "learning_rate": 1.975665793878741e-06,
      "epoch": 5.728155339805825,
      "step": 32450
    },
    {
      "loss": 0.6086,
      "grad_norm": 10.077481269836426,
      "learning_rate": 1.91156242613446e-06,
      "epoch": 5.736981465136805,
      "step": 32500
    },
    {
      "loss": 0.6037,
      "grad_norm": 14.835489273071289,
      "learning_rate": 1.8474590583901794e-06,
      "epoch": 5.745807590467785,
      "step": 32550
    },
    {
      "loss": 0.6214,
      "grad_norm": 12.866863250732422,
      "learning_rate": 1.7833556906458983e-06,
      "epoch": 5.754633715798764,
      "step": 32600
    },
    {
      "loss": 0.5889,
      "grad_norm": 10.646842002868652,
      "learning_rate": 1.7192523229016173e-06,
      "epoch": 5.763459841129744,
      "step": 32650
    },
    {
      "loss": 0.5473,
      "grad_norm": 9.20966911315918,
      "learning_rate": 1.655148955157336e-06,
      "epoch": 5.772285966460724,
      "step": 32700
    },
    {
      "loss": 0.5843,
      "grad_norm": 10.706168174743652,
      "learning_rate": 1.5910455874130554e-06,
      "epoch": 5.781112091791703,
      "step": 32750
    },
    {
      "loss": 0.5984,
      "grad_norm": 14.733247756958008,
      "learning_rate": 1.5269422196687741e-06,
      "epoch": 5.789938217122684,
      "step": 32800
    },
    {
      "loss": 0.6249,
      "grad_norm": 6.795326232910156,
      "learning_rate": 1.462838851924493e-06,
      "epoch": 5.798764342453663,
      "step": 32850
    },
    {
      "loss": 0.6004,
      "grad_norm": 11.488643646240234,
      "learning_rate": 1.398735484180212e-06,
      "epoch": 5.807590467784642,
      "step": 32900
    },
    {
      "loss": 0.5939,
      "grad_norm": 12.494946479797363,
      "learning_rate": 1.334632116435931e-06,
      "epoch": 5.816416593115623,
      "step": 32950
    },
    {
      "loss": 0.5882,
      "grad_norm": 6.8465776443481445,
      "learning_rate": 1.2705287486916499e-06,
      "epoch": 5.825242718446602,
      "step": 33000
    },
    {
      "loss": 0.5949,
      "grad_norm": 5.833385944366455,
      "learning_rate": 1.206425380947369e-06,
      "epoch": 5.834068843777581,
      "step": 33050
    },
    {
      "loss": 0.5997,
      "grad_norm": 9.595091819763184,
      "learning_rate": 1.1423220132030878e-06,
      "epoch": 5.842894969108562,
      "step": 33100
    },
    {
      "loss": 0.649,
      "grad_norm": 13.354251861572266,
      "learning_rate": 1.078218645458807e-06,
      "epoch": 5.851721094439541,
      "step": 33150
    },
    {
      "loss": 0.6004,
      "grad_norm": 12.666457176208496,
      "learning_rate": 1.0141152777145259e-06,
      "epoch": 5.86054721977052,
      "step": 33200
    },
    {
      "loss": 0.6039,
      "grad_norm": 9.4973726272583,
      "learning_rate": 9.500119099702448e-07,
      "epoch": 5.869373345101501,
      "step": 33250
    },
    {
      "loss": 0.5906,
      "grad_norm": 6.095244407653809,
      "learning_rate": 8.859085422259637e-07,
      "epoch": 5.87819947043248,
      "step": 33300
    },
    {
      "loss": 0.6647,
      "grad_norm": 11.277740478515625,
      "learning_rate": 8.218051744816828e-07,
      "epoch": 5.887025595763459,
      "step": 33350
    },
    {
      "loss": 0.5934,
      "grad_norm": 8.904623031616211,
      "learning_rate": 7.577018067374017e-07,
      "epoch": 5.89585172109444,
      "step": 33400
    },
    {
      "loss": 0.5866,
      "grad_norm": 6.120640277862549,
      "learning_rate": 6.935984389931208e-07,
      "epoch": 5.904677846425419,
      "step": 33450
    },
    {
      "loss": 0.6196,
      "grad_norm": 11.637290000915527,
      "learning_rate": 6.294950712488397e-07,
      "epoch": 5.913503971756399,
      "step": 33500
    },
    {
      "loss": 0.5832,
      "grad_norm": 9.728588104248047,
      "learning_rate": 5.653917035045587e-07,
      "epoch": 5.922330097087379,
      "step": 33550
    },
    {
      "loss": 0.5546,
      "grad_norm": 5.281918525695801,
      "learning_rate": 5.012883357602776e-07,
      "epoch": 5.931156222418358,
      "step": 33600
    },
    {
      "loss": 0.6642,
      "grad_norm": 11.433001518249512,
      "learning_rate": 4.371849680159966e-07,
      "epoch": 5.939982347749338,
      "step": 33650
    },
    {
      "loss": 0.5867,
      "grad_norm": 8.761950492858887,
      "learning_rate": 3.730816002717156e-07,
      "epoch": 5.948808473080318,
      "step": 33700
    },
    {
      "loss": 0.5883,
      "grad_norm": 14.671381950378418,
      "learning_rate": 3.0897823252743455e-07,
      "epoch": 5.957634598411297,
      "step": 33750
    },
    {
      "loss": 0.5936,
      "grad_norm": 9.239190101623535,
      "learning_rate": 2.448748647831535e-07,
      "epoch": 5.966460723742277,
      "step": 33800
    },
    {
      "loss": 0.5582,
      "grad_norm": 9.301194190979004,
      "learning_rate": 1.807714970388725e-07,
      "epoch": 5.975286849073257,
      "step": 33850
    },
    {
      "loss": 0.5744,
      "grad_norm": 7.664218425750732,
      "learning_rate": 1.1666812929459148e-07,
      "epoch": 5.984112974404237,
      "step": 33900
    },
    {
      "loss": 0.6169,
      "grad_norm": 10.807767868041992,
      "learning_rate": 5.256476155031044e-08,
      "epoch": 5.992939099735216,
      "step": 33950
    },
    {
      "eval_loss": 0.8720761335210394,
      "eval_exact_match": 80.29032827391458,
      "eval_f1": 85.3528191581396,
      "eval_samples": 22720,
      "step": 33990
    },
    {
      "eval_loss": 0.8720761335210394,
      "eval_exact_match": 80.29032827391458,
      "eval_f1": 85.3528191581396,
      "eval_samples": 22720,
      "epoch": 6.0,
      "step": 33990
    },
    {
      "train_runtime": 42675.2083,
      "train_samples_per_second": 25.487,
      "train_steps_per_second": 0.796,
      "total_flos": 3.1778970035871744e+16,
      "train_loss": 0.8610604637754282,
      "epoch": 6.0,
      "step": 33990
    }
  ]
}